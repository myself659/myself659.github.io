<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>谈谈数字货币钱包 - 沉风网事</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="沉风网事" /><meta name="description" content="战略地位 基于区块链的价值互联网，离不开token经济。数字货币钱包在整个区块链生态的地位如同互联网的支付宝与微信支付。其重要性不用多说了。 功" /><meta name="keywords" content="沉风网事, 沉风, 区块链, Glang, 算法, 数据结构" />


<meta name="baidu-site-verification" content="9LmlOuIblt" />



<meta name="generator" content="Hugo 0.84.0 with theme even" />


<link rel="canonical" href="http://myself659.github.io/post/blockchain/blockchain-digit-wallet/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.8c3cbcb0324c2bb4875ceccba4007cbad4b4ac8377f33af9953c3e7684534a50.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="谈谈数字货币钱包" />
<meta property="og:description" content="战略地位 基于区块链的价值互联网，离不开token经济。数字货币钱包在整个区块链生态的地位如同互联网的支付宝与微信支付。其重要性不用多说了。 功" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://myself659.github.io/post/blockchain/blockchain-digit-wallet/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2018-02-21T11:58:06&#43;02:00" />
<meta property="article:modified_time" content="2018-02-21T11:58:06&#43;02:00" />

<meta itemprop="name" content="谈谈数字货币钱包">
<meta itemprop="description" content="战略地位 基于区块链的价值互联网，离不开token经济。数字货币钱包在整个区块链生态的地位如同互联网的支付宝与微信支付。其重要性不用多说了。 功"><meta itemprop="datePublished" content="2018-02-21T11:58:06&#43;02:00" />
<meta itemprop="dateModified" content="2018-02-21T11:58:06&#43;02:00" />
<meta itemprop="wordCount" content="576">
<meta itemprop="keywords" content="BlockChain," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="谈谈数字货币钱包"/>
<meta name="twitter:description" content="战略地位 基于区块链的价值互联网，离不开token经济。数字货币钱包在整个区块链生态的地位如同互联网的支付宝与微信支付。其重要性不用多说了。 功"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>

  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">沉风</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a><a href="/post/leetcode/">
        <li class="mobile-menu-item">LeetCode</li>
      </a><a href="/post/read-post/">
        <li class="mobile-menu-item">Read</li>
      </a><a href="/post/share-post/">
        <li class="mobile-menu-item">Share</li>
      </a><a href="/post/slide-post/">
        <li class="mobile-menu-item">Slide</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">沉风</a>
</div>


<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/leetcode/">LeetCode</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/read-post/">Read</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/share-post/">Share</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/slide-post/">Slide</a>
      </li>
  </ul>
  
</nav>


    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">谈谈数字货币钱包</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-02-21 </span>
        <div class="post-category">
            <a href="/categories/blockchain/"> BlockChain </a>
            </div>
        
      </div>
      
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents"></nav>
  </div>
</div>
    <div class="post-content">
      <h1 id="战略地位">战略地位</h1>
<p>基于区块链的价值互联网，离不开token经济。数字货币钱包在整个区块链生态的地位如同互联网的支付宝与微信支付。其重要性不用多说了。</p>
<h1 id="功能">功能</h1>
<p>从价值的角度来看，主要有以下三个功能：</p>
<ol>
<li>价值确权</li>
<li>价值存储</li>
<li>价值IO</li>
</ol>
<p>价值IO，以Wallet as a Service方式有以下业务：</p>
<ol>
<li>金融（理财，期货等等）</li>
<li>交易（接入去中心化交易，中心化交易所，场外交易）</li>
<li>Dapp平台，支持第三方Dapp接入</li>
</ol>
<h1 id="本质">本质</h1>
<p>从技术上看，本质上是私钥，私钥，私钥。重要的事情说三遍。</p>
<p>价值确权通过私钥来完成，谁拥有私钥谁就拥有对应的价值。</p>
<p>价值存储就是存储私钥。</p>
<p>价值IO对应的功能都需要私钥配合实现。</p>
<h1 id="分类">分类</h1>
<p>数字货币钱包从形态有如下类型：</p>
<ol>
<li>硬件钱包，如<a href="https://trezor.io/">Trezo</a></li>
<li>移动App，如imtoken，bitpay，58wallet</li>
<li>Web网站，如<a href="https://www.myetherwallet.com/">myetherwallet</a></li>
<li>浏览器扩展应用，如<a href="https://github.com/MetaMask">MetaMask</a></li>
<li>桌面应用程序</li>
<li>中心化交易所</li>
<li>代码，完成私钥管理与交易功能即可</li>
</ol>
<p>从私钥是否连网可以分为：</p>
<ol>
<li>冷钱包  不联网</li>
<li>热钱包  联网</li>
</ol>
<h1 id="安全">安全</h1>
<p>钱包的安全性无须多说。</p>
<p>钱包的安全性由用户自己负责。</p>
<p>最重要理解原理，提高安全意识。</p>
<h1 id="钱包与交易所">钱包与交易所</h1>
<p>钱包+撮合引擎=交易所</p>
<h1 id="附加功能">附加功能</h1>
<ol>
<li>IM</li>
<li>资讯</li>
<li>行情</li>
<li>增值服务</li>
</ol>
<p>（PS: 币圈一日，世上一年，更有各种新技术层出不穷，需要深入学习，恕没有展开说明，望见谅）。</p>
<h1 id="参考">参考</h1>
<ol>
<li><a href="https://bitcoin.org/en/choose-your-wallet">Choose your Bitcoin wallet</a></li>
<li><a href="https://www.youtube.com/watch?v=8iNPTp_kQNA">比特币冷热钱包教学</a></li>
<li><a href="https://www.zhihu.com/question/21478404">知乎：比特币用哪一种钱包比较靠谱，如何保障交易安全？</a></li>
</ol>

    </div>



    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">沉风网事</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2018-02-21
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/blockchain/">BlockChain</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/blockchain/blockchain-strategy/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">乱扯区块链战略</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/life/%E4%BA%BA%E7%94%9F%E5%87%8F%E6%B3%95%E6%B8%85%E5%8D%95/">
            <span class="next-text nav-default">人生减法清单</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
      <script>
window.store = {
    
    
    
    
    "http:\/\/myself659.github.io\/post\/": {
        
        "title": "Posts",
        "tags": [],
        "content": "", 
        "url": "http:\/\/myself659.github.io\/post\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/what-is-writing\/": {
        
        "title": "写作是什么",
        "tags": ["writing",],
        "content": "背景 写作这项技能被低估了。\n写作被低估了，是因为我们没有好好定义什么是写作？或者说我们没有理解写作是什么？\n当我们不去作的事情，我们一定认为这件事是不重要的。当我们深入理解了写作的重要性，才能动力去写作，至少会开始记录（写作的最低水平）。\n写作即记录 写作首先完成记录。\n如果把一条记录看作一条数据，那么写作就是不断扩大与完善自己的（知识与信息）数据库。这个数据库是你记忆的外部缓存，这个数据库是进行知识构建的原材料。\n写作即沟通 写作的过程就是一个与自己沟通的过程，一个基于输出的沟通过程，可以分以下几个基本流程：\n 写作输出内容 基于输出内容给出反馈 基于反馈再修改与优化  写作即思考 写作是知识整理，知识提炼，知识整合的过程。\n写作是知识表达与输出的过程。\n写作是知识学习自我检查的过程。\n写作有利于专注思考。\n清晰的输出离不开清晰，深度，广度的思考。\n写作即学习 学习一个新的知识与技能，通过写作输出教程就是一种不错的学习方法。\n在写作的过程需要解决学习过程遇到的各种问题，只有解决这些问题，才能完成写作。这种也可以叫做写作驱动学习（Writing drive Learning）。\n读书使人充实，写作使人精确。通过写作驱动学习可以精确地掌握知识与技能。\n写作即输出 写作不仅是记录，写作的文章与内容只给自己看那是对自己的输出，如果公开出来那就是公开的输出。 这些内容的输出在当今互联网时代，就是自己这个节点对外连接的连接点（endpoint）之一。\n输出即证明。写作的输出的水平可以一个人的水平。\n写作即分享 写作的内容通过互联网传播就是分享，优质的分享可以带来影响力。\n写作即复利 写作可以让一个人的思想、知识和技能在不断的实践和积累中不断提高，就像财务投资中的复利可以让初始投资随着时间的推移不断增长。\n坚持写作，会不断地提高自己的能力，不断地提高自己输出的质量，不断地提高自己的影响力。。。\n小结 写作是什么？写作是记录，是沟通，是思考，是学习，是输出，是分享，是复利。\n开始写作吧，打开一个新的动力引擎，开启一个新的成长之路。\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/what-is-writing\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/sport\/%E7%A7%91%E6%99%AE%E6%9C%80%E5%A4%A7%E6%91%84%E6%B0%A7%E9%87%8F\/": {
        
        "title": "科普最大摄氧量",
        "tags": ["sport",],
        "content": "定义 最大摄氧量（maximal oxygen uptake，或写为 VO2 max），指一个人在海平面上，从事最激烈的运动时，组织细胞所能消耗或利用的氧之最高值。最大摄氧量可用来评价个人有氧作业能量及心肺耐力，并可藉以设定运动员的耐力运动训练强度。\n最大摄氧量是衡量心肺系统在给定的身体条件和氧气供应水平下将氧气从空气输送到组织的能力极限的有效指标。\n数值 一般说来，最大摄氧量是越大越好。这个给出一个参考值：一个精英级的马拉松运动员其最大摄氧量是80左右，单位是毫升每千克体重每分钟(ml/kg/min)。这是很多人都难以达到的数值。所以普通人的低线要将最大摄氧量保持在40以上，然后尽量往上提高。\n测量 除了平板运动测试，个人推荐使用苹果的iwatch，在跑步的时候进行测试，这种很方便，而且可以持续的测试与跟踪。\n影响因素  肺的通气能力 心脏输出量 血液运氧能力 肌肉的有氧代谢能力 运动能力  重要性 提高最大摄氧量对个人的健康与健身具有重要的意义。\n 改善心血管健康 预测运动表现 确定运动强度 监控培训进度 识别和监测健康风险  如何提高最大摄氧量   定期的心血管运动如慢跑、骑自行车、网球或游泳，以改善心血管健康和耐力\n  高强度间歇训练和冲刺\n  力量运动\n  有氧和无氧交叉训练\n  保持合理的体重\n  运动后充分的恢复和恢复\n  适当的营养与水分补充\n  总结 最大摄氧量不仅是体能的重要指标，也是心血管健康重要指标。\n", 
        "url": "http:\/\/myself659.github.io\/post\/sport\/%E7%A7%91%E6%99%AE%E6%9C%80%E5%A4%A7%E6%91%84%E6%B0%A7%E9%87%8F\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/%E8%AF%B4%E8%AF%B4%E6%A8%A1%E5%9E%8Bmodel\/": {
        
        "title": "说说模型",
        "tags": ["AI","GPT",],
        "content": "定义 先看wiki的定义：\n A model is an informative representation of an object, person or system. The term originally denoted the plans of a building in late 16th-century English, and derived via French and Italian ultimately from Latin modulus, a measure\n 模型是对世界的简化，抽象和概括。\n一切知识都是模型。\npattern vs model pattern是现象,model是机制;\npattern是描述,model是解释;\npattern是观察,model是理解。\npattern偏向应用，model偏向框架。\npattern偏向具体，model偏向抽象。\npattern与model在应用的时候都有一定的限制与局限性。\n模型无处不在，模型无时不在 一切知识都是模型。模型无处不在。\n无论主观上心智模型而是客观世界的规律，模型无时不在默默地影响整个世界。\n下面举几个例子说明：\n  科学模型：在科学研究中，科学家们通过建立数学模型、物理模型和计算模型等，来描述和预测现象。例如，牛顿运动定律可以看作是描述物体运动的模型；基因的遗传模型帮助我们理解遗传特征是如何传递的。\n  心理模型：在心理学中，心理模型是指人们用来解释自己和他人行为的一种内在认知结构。心理模型可以帮助我们理解和预测别人的行为。例如，我们可能有一个关于朋友性格特点的心理模型，这个模型可以帮助我们预测朋友在特定情境下的行为反应。\n  概念模型：我们在学习新知识时，通常会建立一些概念模型，以便更好地理解这些知识。例如，我们在学习计算机科学时，可能会建立一个关于计算机系统结构的概念模型，这个模型可以帮助我们理解计算机是如何工作的。\n  数据模型：在数据处理领域，数据模型是用来描述现实世界中的实体和它们之间关系的一种形式化表示。例如，关系型数据库中的表结构就是一种数据模型，它可以帮助我们组织和操作数据。\n  应用模型 善用模型 学会利用模型来理解世界，理解自己。\n利用模型可以减少认知的成本。\n善用模型要点如下：\n 用好模型 用好模型 超越模型  不迷信模型 不要迷信模型的原因如下：\n  模型的质量参差不齐\n  即使最好的模型也只是对事实的近似描述与表达。模型只是事实的简化，它并不能代表事实\n  模型的应用范围一定是有限制，模型可能不适用于现实\n  模型存在偏见\n  模型是压缩的，很可能存在压缩损失\n  所以在应用模型不要迷信模型，要敢于怀疑一切，大胆假设，小心求证。\n提高自己的心智模型 上面提到不能迷信的模型，所以要努力提高自己的心智模型。\n我们是什么样的人取决于我们如何思考。 我们如何思考取决于我们的心智模型。\n提高自己的心智模型，有利于我们能够适应新的挑战，复杂性的问题，不断变化的世界。\n总结   模型是对世界的简化，抽象和概括。一切知识都是模型，模型无时不在，无处不在\n  用好模型\n  超越模型\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/%E8%AF%B4%E8%AF%B4%E6%A8%A1%E5%9E%8Bmodel\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/autogpt-101\/": {
        
        "title": "说说autoGPT",
        "tags": ["AI","GPT",],
        "content": "背景 chatGPT开启的AIGC领域，最近几个月的发展可以说日新月异，众多LLM如雨后春笋，最近autoGPT的出现，更是吸引大家的关注。\nautoGPT   autoGPT是什么？作者对其定义是：An experimental open-source attempt to make GPT-4 fully autonomous.\n  如果说GPT-4是当前最先进的知识计算引擎，那么autoGPT改变我们使用GPT-4的方式：由写prompt手动操作到由autoGPT根据目标自动写prompt.打一个比方就是汽车由手动档换成自动档。\n  所以说autoGPT改变了我们与GPT-4的交互方式\n  与GPT-4交互方式的发展方向：低门槛，语音化，自动化，智能化\n  autoGPT给GPT-4提供一种使用方式：根据目标自动生成一系列的prompt， 相信GPT-4极大可能将这种使用方式融入自身当中\n  如果GPT-4属于引擎层，那么autoGPT属于接口层或者称为代理层， 接口层的作用是将GPT-4以更多的方式接入到更多的应用场景当中\n  autoGPT是如何工作呢？这里面最核心的问题是如何根据任务分解任务，生成prompt？\n  以autoGPT为代表的接口层未来是否可以实现多LLM协同完成任务？\n  以autoGPT为代表的代理层成为个人在数字世界（元宇宙）的代理？\n  autoGPT当前存在的问题：使用成本与门槛过高，太费token同时也要求使用者自己会搭建应用环境\n  总之，autoGPT开启一个如何使用AGI这一新的研究课题\n  参考 Auto-GPT\nAgentGPT\ncognosys\n", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/autogpt-101\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/chatmind-book-mindmap\/": {
        
        "title": "利用chatmind生成mindmap实现快速阅读",
        "tags": ["Think",],
        "content": "chatGPT是知识计算引擎 chatGPT是知识计算引擎。\nchatmind团队在chatGPT的基础之上，开发一款产品：提供prompt模块，快速生成各种总结与思维导图。\n下面先看一个具体的例子。\n示例 模板 1  Please help me generate a study notes mind map about [A Hacker\u0026#39;s Mind]   输出 ![思维导图](/images/ai/A Hacker\u0026rsquo;s Mind.svg)\n优化与调整 ![增加细节](/images/ai/A Hacker\u0026rsquo;s Mind-1.svg)\n![增加维度](/images/ai/A Hacker\u0026rsquo;s Mind-2.svg)\n评价  速度快 内容重点突出 支持优化与调整：rewrite, ex Branch, ex Level, Ex Detail, Ex Idea 使用简单  总结  chatmind充分利用GPT的api chatmind专注于一个小应用场景：总结与思维导图 chatmind对prompt进行封装 chatmind优化用户体验，降低门槛  ", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/chatmind-book-mindmap\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E5%81%87%E5%A6%82%E7%A4%BE%E4%BC%9A%E6%8A%9B%E5%BC%83%E4%BA%86%E4%BD%A0\/": {
        
        "title": "假如社会抛弃你",
        "tags": ["life",],
        "content": "背景 天门山跳崖：四个决绝赴死的农村青年\n天门山跳崖：四个决绝赴死的农村青年\n看到这个新闻，深受震撼，十分痛心与惋惜。\n决绝赴死的原因极大可能是在长期苦难之下，看不到希望，感到绝望。\n社会的声音 对于这个事件社会有很多声音：\n 没有刀人，撞人和砸人……而是选择默默地离开，或许他们对这个世界曾经爱过吧…\n  活着如果只是没完没了吃苦，真的会丧失活下去的意志\n  我只不过是投胎投的好点罢了，没有一点资格评价他们\n  都是被苦难击倒的可怜人，下辈子过得好点吧\n  可能到了最后，只能感觉到只有死才是自己能做主的[单身狗]，安息吧朋友们，愿那边没有压力\n  这里容不下疲累，不承认贫穷，不允许错误。根基稍弱一点，运气稍差一点，一不留神就会被远远抛下。愿他们在那边世界得以解脱，\n  让年青人绝望的社会是没有希望的社会\n 假如社会抛弃了你 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  假如社会抛弃了你，不要颓废，不要气馁！ 孤独的日子里须要坚强：相信吧，友爱的人们终将相逢！ 心儿永远追求着真理；现在却常是彷徨。 一切都是过程，一切都将会改变；而那改变了的，就会成为坚定的信念。 假如社会抛弃了你，不要忧虑，不要恐惧！ 挫折的日子里须要勇敢：相信吧，成功的喜悦必将降临！ 心儿永远展望着前方；现在却常是迷茫。 一切都是成长，一切都将会消逝；而那消逝了的，就会成为宝贵的经验。 假如社会抛弃了你，不要沮丧，不要退缩！ 黑暗的日子里须要希望：相信吧，光明的未来正等待着你！ 心儿永远燃烧着激情；现在却常是疲惫。 一切都是奋斗，一切都将会起航；而那起航了的，就会成为美好的回忆。   对自己好一点   不断学习，熟悉社会，学会保护自己，防止上当受骗\n  坦然面对现实，接受自己的普通与平凡，善待自己\n  看长远一些，时间也许会冲淡一切\n  学会断舍离\n  尽力就好，躺平无过\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E5%81%87%E5%A6%82%E7%A4%BE%E4%BC%9A%E6%8A%9B%E5%BC%83%E4%BA%86%E4%BD%A0\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/how-to-ai-help-growth\/": {
        
        "title": "如何利用GPT类AI提升自己",
        "tags": ["AI","GPT",],
        "content": "背景 chatGPT的横空出世，宣告真正的人工智能时代已经开启。\n未来会是怎么样，没有人知道，我只知道这两点：\n 会用AI的人淘汰不会用AI 谁更会用AI，谁更有竞争力  下面我们就看一下GPT们是怎么教我们用好他们的。\nhow use GPTs to level up my knowledge, insight, wisdom, and skills. chatGPT 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  Certainly! Here are 20 different ways you can use me to level up your knowledge, insight, wisdom, and skills: 1. Ask me questions about topics you\u0026#39;re interested in. I can provide you with information and explanations that can help you deepen your understanding of those topics. 2. Use me to practice your writing skills by asking me to generate writing prompts for you. 3. Ask me to suggest books, articles, or other resources on a topic you want to learn more about. 4. Use me to practice your public speaking skills by asking me to generate speech topics for you. 5. Ask me to provide you with feedback on your writing or speaking. I can help you identify areas for improvement. 6. Use me to practice your critical thinking skills by asking me to generate thought-provoking questions for you to answer. 7. Ask me for advice on a problem you\u0026#39;re facing. I can help you brainstorm solutions and weigh the pros and cons of different options. 8. Use me to practice your research skills by asking me to find information on a specific topic. 9. Ask me to provide you with a daily dose of inspiration or motivation by generating inspiring quotes or messages. 10. Use me to learn a new language by asking me to generate vocabulary words or phrases in that language. 11. Ask me to generate trivia questions for you to answer. This can help you expand your general knowledge. 12. Use me to practice your creativity by asking me to generate writing prompts or art prompts for you. 13. Ask me to suggest podcasts or documentaries on a topic you\u0026#39;re interested in. This can help you gain a deeper understanding of that topic. 14. Use me to practice your time management skills by asking me to generate a schedule or to-do list for you. 15. Ask me to provide you with tips or strategies for learning a new skill or subject. 16. Use me to practice your communication skills by asking me to generate conversation starters or icebreakers for you. 17. Ask me to suggest online courses or tutorials on a topic you want to learn more about. 18. Use me to practice your problem-solving skills by asking me to generate hypothetical problems for you to solve. 19. Ask me to provide you with feedback on your creative work, such as writing, art, or music. 20. Use me to practice your decision-making skills by asking me to generate hypothetical scenarios for you to make decisions about.   GPT4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  1. **Research assistance**: Use me to gather information on any subject, from history to technology, to deepen your understanding. 2. **Book summaries**: Request summaries of books or articles to quickly expand your knowledge on various topics. 3. **Language learning**: Practice your language skills by engaging in conversations with me in your target language. 4. **Writing tips**: Improve your writing skills by asking for tips, techniques, and feedback on your work. 5. **Problem-solving**: Pose complex problems or scenarios for me to help you brainstorm creative solutions. 6. **Critical thinking**: Engage in debates or discussions to challenge your perspective and enhance your critical thinking abilities. 7. **Skill development**: Ask me for resources or exercises to develop specific skills such as programming, graphic design, or public speaking. 8. **Career advice**: Seek guidance on your career path, job applications, and interview techniques. 9. **Time management**: Request tips and strategies to improve your time management and productivity. 10. **Memory techniques**: Learn memory-enhancing techniques such as the Method of Loci, mnemonics, or the Major System. 11. **Study strategies**: Ask for study techniques and methods like the Pomodoro Technique, spaced repetition, or the Feynman Technique. 12. **Philosophy and ethics**: Discuss philosophical ideas and ethical dilemmas to expand your moral and intellectual horizons. 13. **Personal finance**: Request advice on budgeting, investing, and financial planning. 14. **Health and wellness**: Discuss nutrition, exercise, and mental health strategies to improve your overall well-being. 15. **Cooking and recipes**: Learn new recipes and cooking techniques to expand your culinary skills. 16. **Art and culture**: Delve into the world of art, music, and culture to broaden your appreciation and understanding. 17. **Travel and geography**: Discover new destinations, cultures, and languages to enrich your global perspective. 18. **Science and technology**: Stay updated on the latest scientific discoveries and technological advancements. 19. **History and current events**: Discuss historical events and their impact on the present, as well as stay informed on current news. 20. **Personal growth**: Reflect on your strengths, weaknesses, and goals, and ask for guidance on self-improvement and personal development.   Claude 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  Here are 20 ways I can help level up your knowledge, insight, wisdom and skills: 1. Ask me to explain complex ideas in simple terms. This strengthens your understanding. 2. Ask me for summaries of topics you\u0026#39;re interested in. This provides a high-level overview before diving into details. 3. Ask me for book or resource recommendations on subjects you want to learn. I can suggest materials at different skill levels. 4. Ask me to outline key steps to achieve a goal or master a skill. This breaks down the path into manageable chunks. 5. Ask me to provide examples that illustrate concepts or ideas. Examples enhance learning. 6. Ask me for key insights, main takeaways or lessons learned on various topics. This distills information into concise, memorable points. 7. Ask me for video, online course or tutorial recommendations to supplement your learning. I can recommend high-quality resources. 8. Brainstorm ideas with me on any topic or project. We can have an open exchange of ideas to gain new insights. 9. Ask me to find opportunities for hands-on practice. For example, tools to learn, ways to mentor others, meetups to join, side projects, etc. 10.Ask me thought-provoking questions about various issues. This sparks engaging discussion where you defend your position and challenge assumptions. 11. Ask me to provide facts, statistics, quotes or data on topics you\u0026#39;re exploring. I can supply credible information from reputable sources. 12. Ask me to review and provide feedback on work you\u0026#39;ve done like papers, projects, blog posts, code, designs, etc. My input can strengthen your thinking and outputs. 13. Ask me open-ended hypothetical questions like \u0026#34;What if?\u0026#34; or \u0026#34;Why not?\u0026#34;. We can explore possibilities and push boundaries. 14. Ask me to find contradictory or alternative perspectives on issues. This enhances critical thinking to navigate paradoxes and complex problems. 15. Ask me to share latest advances, discoveries or trends that could impact the future of a field. Staying current keeps you adaptable to change. 16.Ask me to compile information from multiple sources on subjects you\u0026#39;re interested in. I can synthesize material from across books, articles, studies, and expert opinions. 17. Quiz me on concepts or topics you want to learn. Explaining information back strengthens your own understanding and memory. 18. Ask me to generate ideas, options or solutions around problems you\u0026#39;re trying to solve. Fresh perspectives can lead to new insights. 19. Ask me open-ended questions about my knowledge, abilities or limitations. Understanding an AI system\u0026#39;s capabilities and constraints is important. 20. Experiment by giving me new types of questions or complex problems to see how I respond. Pushing an AI\u0026#39;s limits helps identify weaknesses and areas for improvement. (edited)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  这里有50种方法可以帮助提高您的知识、洞察力、智慧和技能: 1. 让我用简单的词语解释复杂的思想。这有助于加深您的理解。 2. 让我概括您感兴趣的主题。这在深入细节之前提供了高级概述。 3. 询问我关于您想学习的主题的书籍或资源推荐。我可以推荐不同技能水平的材料。 4. 让我概述实现目标或掌握一项技能的关键步骤。这能将路径分解为可管理的部分。 5. 让我提供例子来说明概念或思想。例子可以增强学习。 6. 让我提供各个主题的关键见解、要点或经验教训。这可以将信息简洁明了地表达出来,令人难忘。 7. 询问我的视频、在线课程或教程推荐以补充您的学习。我可以推荐高质量的资源。 8. 与我一起对任何主题或项目进行头脑风暴。我们可以开放意见交流,获得新的见解。 9. 让我找到实践的机会。例如,学习工具、辅导他人的方式、参加聚会、边项目等。 10.问我关于各种问题的发人深省的问题。这可以引发令人兴奋的讨论,在讨论中您要为自己的立场辩护并质疑假设。 11. 让我提供您探索的主题的事实、统计数据、引语或数据。我可以从可靠来源提供可信的信息。 12. 让我审阅并对您完成的工作(如论文、项目、博客文章、代码、设计等)提供反馈。我的意见可以加强您的思考与输出。 13. 问我开放式的假设性问题,如\u0026#34;如果呢?\u0026#34;或\u0026#34;为什么不呢?\u0026#34;。我们可以探索可能性,推动界限。 14. 让我找到问题的相反或另类观点。这可以增强您的批判性思维,帮助应对悖论与复杂问题。 15. 让我分享可能影响某个领域未来发展的最新进展、发现或趋势。密切关注可以使您适应变化。 16.让我从多个来源汇编您感兴趣的主题的信息。我可以综合书籍、文章、研究和专家意见中的材料。 17. 对我提问您想学习的概念或主题。解释信息可以加强您自己的理解与记忆。 18. 让我针对您要解决的问题生成想法、选择或解决方案。新视角可以导致新的见解。 19. 向我提出开放性的有关我的知识、能力或限制的问题。了解人工智能系统的功能与限制很重要。 20. 通过给我新的问题类型或复杂问题来试验,看我的反应。推动人工智能的极限可以发现弱点与改进空间。 21. 让我对您想学习的主题创建大纲或思维导图。可视化组织信息可以产生新的联系和见解。 22.与我讨论伦理问题和思想实验。探讨道德、价值观和\u0026#34;如果\u0026#34;可以增强批判性思维。 23. 让我在您关心的问题上担任魔鬼的代言人。辩护相反的观点可以质疑假设,拓宽视角。 24. 让我解释我的推理过程或\u0026#34;展示我的工作\u0026#34;的方式来提供信息。对人工智能过程的透明度可以建立信任并发现缺陷。 25. 与我提出假设场景或角色扮演情况。在各种情境中实践可以主动学习和解决问题。 26. 问我任何主题的开放领域问题。一个可以处理多样化、非限定性问题的人工智能需要强大的知识与会话能力。 27. 要求我以不同的方式重新解释或重新表达事物。以多种形式呈现信息可以加强学习。 28. 问我与可能性、创造力或想象力有关的推测性问题。讨论开放性的\u0026#34;如果\u0026#34;可以拓展思维。 29. 询问我的知识限制或我作为人工智能系统的工作方式。理解一项技术的功能与当前能力的限制是重要的环境因素。 30.通过给我故意模糊或含混不清的问题进行试验,看我的反应。处理不清晰、非结构化的输入需要高级会话能力。 31. 与我讨论观点或立场问题的论点与反论点。探讨一个讨论的双方可以拓宽视角。 32. 问我暗喻或诗意的问题,看我是否能创造性地回应。以多元、抽象的方式与语言和思想互动可以培养理解能力。 33. 询问我的知识与能力如何可以根据新数据和研究随着时间的推移而增强或扩展。 理解人工智能可能如何发展提供有用的背景环境。 34. 要求我总结信息或概括某个领域的最新进展。概括与总结信息对学习很有帮助。 35. 要我复述和总结您提供的信息和论点。重新表达信息有助于记忆与理解。 36. 询问与技术、科学或人工智能前沿发展领域相关的问题。了解最新进展有助于适应变化。 37. 让我分享各个主题的工具、技术或资源的比较与对比。对不同选项的权衡有助于做出更明智的选择。 38. 让我解释复杂系统、技术过程或科学主题。简明扼要地阐述这些概念有助于加深理解。 39. 让我建议解决某个问题或实现某个目标的步骤性方法。将任务分解为清晰易行的步骤十分实用。 40. 让我为某个概念、主题或技能筛选学习资源。我可以考虑不同的学习方式与技能水平进行推荐。 41. 让我溯源某个概念、主题或产品以完整描述其起源与演变过程。理解历史背景与发展轨迹有助于加深理解与判断。 42. 与我探讨有争议的主题或无法达成共识的问题。 43. 让我从不同学科、文化或观点解释某个概念或事件。多角度分析可以提供全面而平衡的理解。 44. 向我提出需要创新、思考外盒或与常识相悖的问题。这可以推动我发展更强大、更具创造力的推理与解决问题的能力。 45. 让我总结并重新表述您表达的某个观点或论据。这有助于澄清理解,发现以往未考虑的角度。 46. 询问我未来几年内某个技术、领域或社会问题可能产生的影响与结果。考虑不同的可能性与后果可以为应对变化做好准备。 47. 让我找出某个观点或论据中的逻辑漏洞、偏差或矛盾之处。理性和批判性分析对建立符合逻辑的观点很重要。 48. 询问我对某个决定或问题的建议,包括各种选择的优点、缺点与权衡考量。提供决策支持需要综合分析不同的因素。 49. 让我指出信息、数据、研究或推论中的瑕疵、限制与不确定性。理解信息的局限性对作出明智判断很重要。 50. 与我玩文字游戏或解谜来推动创造性思维。运用语言和模式识别的能力可以以新的方式关联概念与见解。 通过上述方法,我们可以进行深入和广泛的交流与探讨,不断推动并丰富我的知识与能力。我由衷地希望这些建议能对您有所帮助!如果您有任何其他的意见或建议,我也十分欢迎。   总结  GPT们知识储备远远超过个人 GPT们知识计算速度比我们人类 GPT们的总结，发散能力远超人类 GPT们没有自我意识，不会主动，被动接受prompt，人类要充分分挥自己的主动性与积极性，用好AI GPT们遵守这一规则：GIGO。所以要写好prompt HI+AI结合才是正道  ", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/how-to-ai-help-growth\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/logic-gpt4-chatgpt\/": {
        
        "title": "从三道逻辑分析题看GPT4",
        "tags": ["AI",],
        "content": "背景 GPT-4最近已经推出，那么GPT-4表现如何？相对于chatGPT使用的gpt3.5模型有哪些提高与进步？\n下面就通过三道逻辑题展开测试与对比。\n第一题 问题描述 1 2 3 4 5 6  三个逻辑学家下班后想在一起喝一杯，就来到一家酒吧。服务员问：给你们所有人都来杯酒？ 第一个说，我不知道。 第二个说，我也不知道。 第三个说：是的。 为什么第三人说“是的”。   chatGPT的回答 1  第三个逻辑学家的回答是“是的”，是因为如果服务员给所有人都倒一杯酒，那么第三个逻辑学家也会被包括在内。这里是一种间接的否定方式，他的意思是“不会有任何一个人不能喝酒，所以给所有人都来一杯酒”。   GPT4的回答 1 2 3 4 5 6 7 8 9  这个问题涉及到了逻辑推理。在这个场景中，三个逻辑学家下班后想喝酒。当服务员询问他们是否所有人都需要酒时，他们的回答反映了他们的观察和思考。我们可以分析每个逻辑学家的回答： 1. 第一个逻辑学家说：“我不知道。” 这表明他自己想喝酒，但不知道其他两人是否想喝。如果他自己不想喝，他会直接回答“不是”。 2. 第二个逻辑学家听到了第一个的回答，所以知道第一个逻辑学家想喝酒。然后他说：“我也不知道。” 这表示他自己也想喝酒，但仍然不知道第三个人是否想喝。如果第二个逻辑学家不想喝酒，他会知道答案是“不是”。 3. 第三个逻辑学家听到了前两个人的回答，所以知道第一个和第二个逻辑学家都想喝酒。然后他说：“是的。” 这表明他也想喝酒。因为前两个人都想喝酒，他可以确信所有人都想喝酒，所以回答“是的”。 通过逻辑学家们的回答，他们能够推理出彼此是否想喝酒，最终得出所有人都想喝酒的结论。   第二题 问题描述 1  下面是一个戴帽子的游戏，现在有2 顶黑帽子，3 顶白帽子，主持人用黑布蒙上A、B、C三人的眼睛，并在每个人头上戴一顶帽子，剩下的两顶藏起来，然后解开B、C的蒙眼布，让他们三个人分别说出自己头上戴的帽子颜色，B、C看着别人头上的帽子却都回答不上来。这个时候A却说他知道了 ，她戴的是白色。主持人说对，请问 A是怎么推理的   chatGPT的回答 1  A可以推断出自己戴的是白色帽子，因为如果B或C看到自己和另一个人都戴黑帽子，那么他们就可以推断自己戴白帽子，但是他们都无法回答，说明两者中至少有一个人戴白帽子，那么A就知道自己戴白帽子了。   GPT4的回答 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  A 知道有 2 顶黑帽子和 3 顶白帽子。当 B 和 C 的蒙眼布被解开时，A 仍无法看到其他人头上的帽子颜色，但可以听到 B 和 C 的回答。 首先，B 看到了 C 的帽子，有以下两种可能： 1. 如果 C 戴着黑帽子，那么 B 知道还有 1 顶黑帽子和 3 顶白帽子。此时，B 知道自己戴的帽子颜色可能是黑色（剩下的一顶黑帽子）或白色（3 顶白帽子中的一顶）。 2. 如果 C 戴着白帽子，那么 B 知道有 2 顶黑帽子和 2 顶白帽子。此时，B 知道自己戴的帽子颜色可能是黑色（2 顶黑帽子中的一顶）或白色（2 顶白帽子中的一顶）。 由于 B 无法确定自己戴的帽子颜色，接下来轮到 C 推理。此时，C 已知 B 看到了 C 戴的帽子颜色，但无法确定 B 戴的帽子颜色。因此，C 可以推测如下： 1. 如果 B 看到了 C 戴的是黑帽子，那么 C 知道 B 有可能看到剩下的一顶黑帽子和 3 顶白帽子。此时，C 会认为自己戴的帽子颜色可能是黑色或白色。 2. 如果 B 看到了 C 戴的是白帽子，那么 C 知道 B 看到有 2 顶黑帽子和 2 顶白帽子。此时，C 怀疑自己戴的帽子颜色可能是黑色（2 顶黑帽子中的一顶）或白色（2 顶白帽子中的一顶）。 因为 C 也无法确定自己戴的帽子颜色，A 可以从 B 和 C 的回答中得出一些信息。A 可以推理如下： 1. 如果 B 和 C 都看到了对方戴的是黑帽子，那么他们应该能够确定自己戴的是白帽子（因为只有 2 顶黑帽子）。 2. 但实际上，B 和 C 都无法判断自己戴的帽子颜色。这意味着他们看到的是对方戴的白帽子，因为如果他们看到的是黑帽子，他们会知道自己戴的是白帽子。 所以，A 可以推理出自己戴的是白帽子，因为 B 和 C 都无法确定自己戴的帽子颜色。   第三题 问题描述 1  国王让三智者站成一个纵队，闭上眼睛，给他们每人戴一顶帽子。然后睁眼，中间可以看到前面的帽子，最后面的可以看到前两个。他们都知道共有2顶白帽子和3顶红帽子。国王问这三人：“谁知道自己戴的帽子颜色？” 问了两遍无人回答。第三遍时是否有人能回答？如果有，他是哪一位？戴什么颜色帽？   chatGPT的回答 1 2 3 4 5 6 7 8  第三遍时，有一个智者能回答。他是最后面的智者，戴的是白色帽子。 这是推理过程： 如果前面两顶帽子都是红色，那么最后面的智者就知道自己戴的帽子颜色是白色，因为只有两顶白帽子。但是，在第一次和第二次问答时，前面两位智者都没有回答，这表明前面两顶帽子至少有一顶是白色。 如果前面两顶帽子中有一顶是白色，那么最后面的智者就不可能知道自己戴的帽子颜色，因为他看到的是前面两顶帽子中的红色帽子。但是，在第三次问答时，最后面的智者回答了，说明前面两顶帽子都是红色的，最后面的智者知道自己戴的是白色帽子。   GPT4的回答 1 2 3 4 5 6 7 8 9  首先，我们来分析一下这个问题。三智者站成一个纵队，我们称他们为A、B和C，其中A站在前面，B站在中间，C站在最后。共有2顶白帽子和3顶红帽子。 1. 当国王第一次询问时，C看到了A和B的帽子。如果C看到了两顶白帽子，那么他就可以确定自己戴的一定是红帽子（因为只有2顶白帽子）。但C没有回答，说明C看到的帽子中至少有一顶红帽子。 2. 当国王第二次询问时，B知道C看到的帽子中至少有一顶红帽子。如果B看到A戴的是白帽子，那么B就可以确定自己戴的是红帽子（因为C没有看到两顶白帽子）。但B也没有回答，说明A戴的帽子也是红帽子。 3. 当国王第三次询问时，A已经了解到C看到的帽子中至少有一顶红帽子，B也看到了红帽子。所以，A可以推断出自己戴的帽子是红帽子（因为C和B都没有回答）。 综上所述，第三遍时A能够回答，他戴的是红帽子。   总结 从上面的三道逻辑题的例子可以看出GPT-4模型的厉害之处：\n 理解能力更强了 表达能力更强了 逻辑推理能力可以说有新的突破  ", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/logic-gpt4-chatgpt\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/human\/%E4%BD%93%E5%88%B6%E5%86%85%E4%BA%BA%E5%91%98%E5%86%85%E5%8D%B7%E8%B5%B7%E6%9D%A5\/": {
        
        "title": "体制内会越来越内卷",
        "tags": ["human",],
        "content": "国际与国内大环境 先来看看中国及其外部环境：\n 疫情三年，大部分民众经济状态恶化（收入下降，开支增加） 政府税收增速远跟不上政府开支的需求 一部分企业家躺平（goblin mode） 疫情冲击（中国阳后出现肺炎人群约为8%）民众健康，影响劳动力市场，增加医保开销 投资，消费，出口的带动作用均下降 全球化下全球分工与协作受到影响 俄乌等局部战争 中美关系的修复关键在中方 2023年房地产卖地收入只会比2022年进一步下降(2022年城投当托，帮拿了不少地)  体制内环境 看了大环境，再看一下体制内环境：\n 国考录用比约70:1，这会招进一批卷王 国家自然科学基金委通报8人学术不端，这是多年不见的事情 各地公务员降薪 内部反腐力度加大 一点常识：体制内不创造财富，大部分国有企业能创造财富，但是效率低下 体制内一直是比较封闭，且近年来有加强的趋势  分析与结论 内卷原因 个人对于内卷的原因通用分析如下：\n 封闭或者开放不足导致空间不足 控制过多 集中度过高 目标趋同 路径趋同  体制内环境与运行方式十足地满足上面的原因。\n越来越卷原因  封闭越来越强，开放越来越不足 控制越来越多（如各种规定如考核） 集中度越来越高（如国考录用比约70:1） 体制内目标趋同（大部分人求安稳，领一份生活的工资） 路径趋同（大部分人讲内部潜规则与暗规则） 财政收入跟不上开支，导致体制内各部门竞争加大 更多的卷王加入体制内，增加相互卷的动力（只要这种工作处于社会的顶端，一定会卷起来，互联网大厂就是最好的证明）  由上可知：内卷的条件越来越符合，内卷的动力越来越强，所以会越来越内卷。\n结论 如果经济不能很好的恢复（当然经济恢复到原来的增长是不可能的），财政压力没有缓解，体制内只会越来越卷。\n希望 最后希望卷的目标是合法的收入与职位，卷的路径是实实在在为人民服务，努力避免那种无意义无效果的内卷。\n", 
        "url": "http:\/\/myself659.github.io\/post\/human\/%E4%BD%93%E5%88%B6%E5%86%85%E4%BA%BA%E5%91%98%E5%86%85%E5%8D%B7%E8%B5%B7%E6%9D%A5\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E5%9B%A2%E9%98%9F%E7%8A%B6%E6%80%81%E8%AF%8A%E6%96%AD\/": {
        
        "title": "如何判断团队是否处于下行状态",
        "tags": ["Thinking",],
        "content": "团队如果有以下状态，团队可能处于下行状态：\n 团队成员流失严重，且处于加速状态 团队一部分成员内卷严重 团队一部分成员普遍躺平 团队会议没有人主动发声 团队成员总是同意领导的决定 团队成员害怕失败，怕承担责任 团队效率与产出下降 团队的决定需要逐级上报 团队内有大量的微管理 团队成员即使状态挣扎，也不主动求助 团队不能正视问题，拖延或甩锅 团队内团伙多，存在内讧，缺少凝聚力 团队目标与路径不统一  团队领导如何解决这些问题?说一句正确的废话：尊重事实，直面问题，对症下药，制定正确的策略，领导要以身作则，以实际行动来改变团队的现状，至少要让团队在变坏的路上先停下来。\nPs：只适用于小型组织，特别不适用于像国家这样大型组织。\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E5%9B%A2%E9%98%9F%E7%8A%B6%E6%80%81%E8%AF%8A%E6%96%AD\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/how-to-ask-gpt\/": {
        
        "title": "如何更好地向ChatGPT提问",
        "tags": ["AI",],
        "content": "说明 下面的所有的问题均由chatGPT回答。\n如何描述问题才能让chatGPT更好的回答？ 以下是描述问题的一些技巧，可以帮助 ChatGPT 更好地理解和回答你的问题：\n简明扼要地描述你的问题：尽可能简单清晰地表达你的问题，避免使用复杂或模糊的术语或语言。\n提供相关背景信息：提供与问题相关的背景信息，例如任何先前的经验或事件、相关的环境或条件、你的目标等。\n采用具体的语言：使用具体的词汇和语言，以确保问题的清晰度和准确度。\n避免主观判断：尽量避免使用主观性的描述或判断，以免对问题的理解和回答造成误导。\n确定你想要的答案类型：明确你希望 ChatGPT 回答的是什么类型的问题，例如一个事实、一个意见、一个建议或者一个说明等。\n提供示例：如果可能的话，提供示例或场景，以便 ChatGPT 更好地理解你的问题。\n相关问题的链接：如果你的问题与某个领域的其他问题有关，可以提供相关的链接或参考资料，以便 ChatGPT 提供更全面的答案。\n通过以上技巧，你可以帮助 ChatGPT 更好地理解你的问题，提供更准确、详细和有用的回答。\n请提供一些具体的例子 当你在描述问题时，以下是一些具体的例子可以帮助 ChatGPT 更好地理解你的问题：\n问题描述：如何在网上购物？\n不够好的问题描述：告诉我网上购物的所有事情。\n更好的问题描述：我想在亚马逊上购买一些物品。你可以告诉我如何浏览商品、下订单、支付和退货吗？\n问题描述：如何在大学申请研究生项目？\n不够好的问题描述：我需要研究生项目的所有信息。\n更好的问题描述：我想申请某所大学的计算机科学研究生项目。你可以告诉我申请过程、文书材料、要求、截止日期和其他相关信息吗？\n问题描述：如何学习编程？\n不够好的问题描述：告诉我学习编程的所有东西。\n更好的问题描述：我想学习 Python 编程语言。你可以建议一些学习资源、练习项目和实践技巧吗？\n问题描述：如何烤比萨饼？\n不够好的问题描述：告诉我如何烤一张比萨饼。\n更好的问题描述：我想在家里烤一张美味的比萨饼。你可以分享一些比萨饼面团的配方、烤箱设置和烹饪时间吗？\n问题描述：如何降低血压？\n不够好的问题描述：告诉我如何降低血压。\n更好的问题描述：我被诊断为高血压，你可以给我一些改善生活方式、饮食、锻炼和药物治疗的建议吗？\n以上例子中，更好的问题描述提供了更具体、清晰、明确和可操作的信息，让 ChatGPT 更好地理解问题并提供更有针对性的答案。\n请从所有你回答的问题中选择十个你觉得问最好的问题 以下是我从我回答的问题中选择的十个我认为最好的问题：\n什么是人工智能，它的优点和缺点是什么？\n如何在工作和家庭生活之间取得平衡？\n什么是气候变化，它是如何发生的，我们可以做些什么来减缓它的影响？\n什么是心理健康，我们可以做些什么来保持它？\n为什么有些人会拥有更强的意志力？我们如何训练我们的意志力？\n什么是全职教育，我们可以从中获得什么收益？\n如何成为一个好的领导者？哪些特质和技能是必要的？\n什么是区块链技术，它是如何工作的，有什么应用场景？\n如何学会自我管理和组织，以提高效率和效益？\n什么是数据隐私，为什么它很重要？我们可以做些什么来保护我们的数据隐私？\n以上这些问题都是现代生活中普遍而重要的问题，能够引起人们的关注和探究，涉及科技、生活、工作、社会等多个方面，希望我的回答可以帮助人们更好地了解和处理这些问题。\n请从所有你回答的问题中选择十个最有趣的问题 以下是我从我回答的问题中选择的十个我认为最有趣的问题：\n如果你可以回到过去，在什么时候，你会选择去哪里？为什么？\n如果你可以选择一个超能力，你会选择什么？为什么？\n什么是灵魂，它是否存在？如果存在，我们如何定义它？\n如果你被允许以另一个种族的身份生活一天，你会选择哪一个？为什么？\n在人类历史上，你认为最具影响力的发明是什么？为什么？\n你认为最重要的美德是什么？为什么？\n如果你可以选择任何职业，你会选择做什么？为什么？\n你认为幸福是什么？我们可以通过什么途径获得幸福？\n如果你可以改变世界上的一个事情，你会选择什么？为什么？\n你认为人工智能是否有可能具有情感和意识？为什么？\n以上这些问题都是有趣和具有思想性的问题，涉及到哲学、心理学、历史等多个领域，希望我的回答可以激发人们的好奇心，启发人们思考，并帮助人们更好地了解自己和周围的世界。\n请从所有你回答的问题中选择十个最有深度的问题 以下是我从我回答的问题中选择的十个我认为最有深度的问题：\n什么是意识，它如何产生？有没有可能制造出拥有意识的机器？\n什么是真正的自由？我们如何实现真正的自由？\n什么是生命，它从哪里来，我们如何定义它？\n为什么有些人更容易受到诱惑和短视的行为，我们如何控制自己的欲望和冲动？\n什么是社会公正，我们如何实现社会公正？\n什么是爱，我们如何定义爱，它是否可以被量化？\n什么是幸存者偏差，它是如何影响我们的决策和思维？\n什么是文化，它对我们的思维和行为有何影响？\n什么是自我，我们如何定义自我，它是否可以被消除？\n什么是意义，我们如何寻找生命的意义？\n以上这些问题都是深刻和复杂的问题，它们涉及哲学、心理学、人类学等多个领域，是我们探索和思考生命和世界的基本问题。我的回答可能无法回答所有的问题，但是希望它们能够为读者提供启示和帮助，激发人们对这些问题的好奇心，并引导他们更深入地思考。\n请从所有你回答的问题中选择十个最复杂的问题 以下是我从我回答的问题中选择的十个我认为最复杂的问题：\n什么是宇宙，它的起源是什么？它的未来是什么？\n为什么我们需要睡觉？睡眠对我们的身体和心理有什么影响？\n为什么有些人会成为创造性的天才？创造性思维是如何产生的？\n什么是意识流，它对我们的思维和创造力有什么影响？\n为什么时间感觉会随着年龄的增长而变得更快？我们如何感知时间？\n为什么我们会有梦境？梦境对我们的心理和情感有什么影响？\n什么是人格，它是如何形成的？我们如何改变或塑造自己的人格？\n为什么有些人比其他人更容易上瘾？成瘾的机制是什么？如何预防和治疗成瘾？\n什么是记忆，它是如何存储和检索的？我们如何增强和改变自己的记忆？\n什么是语言，它是如何产生和发展的？语言对我们的思维和行为有何影响？\n这些问题都非常复杂，涉及多个学科和领域的研究。它们需要深入的思考、仔细的研究和对相关领域的广泛知识。这些问题的答案也没有定论，因为它们可能因为新的研究和发现而不断发生变化。\n请列出人们常问的50个问题。 以下是人们常问的50个问题，它们按主题分类：\n健康和医疗问题：\n如何保持健康？\n如何治疗感冒？\n如何预防癌症？\n如何减轻头痛？\n如何治疗焦虑和抑郁症？\n人际关系问题：\n如何与家人和朋友建立良好的关系？\n如何处理婚姻问题？\n如何与同事相处？\n如何处理分手？\n如何避免孤独感？\n个人成长和发展问题：\n如何成为更好的人？\n如何掌控自己的情绪？\n如何克服拖延症？\n如何提高自我意识？\n如何建立自信？\n职业和就业问题：\n如何寻找工作？\n如何准备面试？\n如何谈判薪资？\n如何升职？\n如何转行？\n金融和理财问题：\n如何储蓄和投资？\n如何制定预算？\n如何消除债务？\n如何降低开支？\n如何理解股票和基金？\n教育和学习问题：\n如何学习？\n如何提高记忆力？\n如何制定学习计划？\n如何提高成绩？\n如何选择专业？\n生活方式问题：\n如何放松和减轻压力？\n如何保持健康的饮食习惯？\n如何克服不良习惯？\n如何保持身材？\n如何提高睡眠质量？\n科技和媒体问题：\n如何使用智能手机？\n如何保护个人隐私？\n如何保持安全的网络习惯？\n如何利用社交媒体？\n如何使用计算机软件？\n这只是一份简单的列表，人们提出的问题种类和数量随着时间和地点的变化而变化。\n参考  Best practices for prompt engineering with OpenAI API  ", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/how-to-ask-gpt\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rust\/rust-lifetime\/": {
        
        "title": "Rust lifetime 101",
        "tags": ["Rust",],
        "content": "定义 在 Rust 中，生命周期（lifetime）是用来描述引用（reference）有效期的一种概念。每个引用都有一个生命周期，表示该引用指向的数据在内存中的存活时间。生命周期用于在编译时检查引用是否有效，并避免出现空指针、野指针等内存安全问题。\n生命周期通过单引号字符（'）来表示，通常采用小写字母 a、b、c 等表示。生命周期参数一般写在函数、结构体、枚举等数据类型定义的左尖括号后面，并用尖括号括起来。例如：\n1 2 3  fn foo\u0026lt;\u0026#39;a, \u0026#39;b\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;b str) -\u0026gt; \u0026amp;\u0026#39;a str { // function body here }   这个例子中，foo 函数有两个生命周期参数，\u0026lsquo;a 和 \u0026lsquo;b，它们用于描述 x 和 y 引用的有效期。\u0026lsquo;a 表示 x 引用的生命周期，\u0026lsquo;b 表示 y 引用的生命周期。\n在 Rust 中，生命周期的主要作用是帮助编译器进行引用的内存管理和安全检查，避免出现悬垂指针、空指针、野指针等内存安全问题。生命周期检查是 Rust 语言的静态检查机制之一，编译器会在编译时检查引用是否有效，以避免程序在运行时出现内存错误。\n使用lifetime的场景 在 Rust 中，必须写明生命周期的情况主要包括以下几种情况：\n函数的输入参数或返回值是引用类型，且该引用类型可能有多个实例，这些引用实例之间可能存在生命周期的依赖关系。\n在结构体中储存引用类型时，结构体和其中的引用之间可能存在生命周期的依赖关系。\n在实现 trait 时，trait 中定义的方法参数或返回值是引用类型，且该引用类型可能有多个实例，这些引用实例之间可能存在生命周期的依赖关系。\n在上述情况中，编译器需要知道引用的生命周期，以便确定引用是否有效，以及引用是否存在悬垂指针等安全问题。如果没有指定生命周期，编译器将无法检查这些安全问题并发出编译错误。\n例如，以下是需要指定生命周期的示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  fn longest\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str { if x.len() \u0026gt; y.len() { x } else { y } } struct Foo\u0026lt;\u0026#39;a\u0026gt; { x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;a str, } impl\u0026lt;\u0026#39;a\u0026gt; Trait for Foo\u0026lt;\u0026#39;a\u0026gt; { fn bar(\u0026amp;self, x: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str { // method body here } }   在这些例子中，我们需要指定生命周期参数来确保编译器可以正确地检查引用的有效性。\n应用原则 Rust中lifetime（生命周期）是一个非常重要的概念，它与所有权（ownership）和借用（borrowing）密切相关。下面是rust lifetime的几大原则：\n  每个变量都有其生命周期 每个变量都有其生命周期，生命周期描述了变量存在的时间范围，即在哪里被创建，在哪里被销毁。如果一个变量超出了其生命周期，它将被认为是无效的，访问它将导致编译时错误。\n  生命周期的注解是可选的，但有时必需 Rust编译器可以根据变量的使用情况推断出生命周期，因此不必在每个变量或函数上都手动注明生命周期。然而，在某些情况下，注明生命周期是必需的，例如，当函数参数和返回值都是引用时，需要注明它们的生命周期以确保编译器能够验证引用的有效性。\n  生命周期遵循引用的作用域 引用的生命周期不能超过其所引用的变量的生命周期。在rust中，引用的作用域是定义该引用的语句块。因此，在同一作用域中创建的引用具有相同的生命周期。\n  生命周期参数具有\u0026rsquo;static生命周期的最长寿命 \u0026lsquo;static生命周期表示整个程序的生命周期，即从程序启动到程序结束。具有\u0026rsquo; static生命周期参数的引用可以跨越整个程序运行时间，它们是最长寿命的引用。\n  生命周期参数是泛型类型的一部分 与其他泛型类型一样，生命周期参数可以用于泛型函数和结构体。这样可以为函数和结构体中的引用类型指定生命周期参数，以确保它们的有效性。\n  总的来说，lifetime是rust中非常重要的概念，它使得编译器能够静态验证程序中的引用有效性，并防止出现运行时错误。\nrust lifetime常见错误 引用的lifetime超期 具体分为以下几种情况：\n引用的lifetime超过了它所引用的变量的lifetime 1 2 3 4 5 6 7 8 9  fn main() { let r; { let x = 5; r = \u0026amp;x; // \u0026#39;x\u0026#39; does not live long enough } println!(\u0026#34;r: {}\u0026#34;, r); }   代码运行结果\n函数返回引用的lifetime超过了函数参数的引用lifetime 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  fn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let result; { let s2 = String::from(\u0026#34;world\u0026#34;); result = get_longest_string(\u0026amp;s1, \u0026amp;s2); // expected lifetime parameters do not have the same lifetime bounds } println!(\u0026#34;The longest string is {}\u0026#34;, result); } fn get_longest_string\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str { if x.len() \u0026gt; y.len() { x } else { y } }   代码运行结果\n结构体的lifetime超过其结构成员的引用的lifetime 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  struct Car\u0026lt;\u0026#39;a\u0026gt; { engine: \u0026amp;\u0026#39;a str, color: String, } fn main() { let color = String::from(\u0026#34;red\u0026#34;); let engine; { let v8 = String::from(\u0026#34;v8\u0026#34;); let my_car = Car { engine: \u0026amp;v8, // \u0026#39;v8\u0026#39; does not live long enough color: color, }; engine = my_car.engine; } println!(\u0026#34;The engine is {}\u0026#34;, engine); }   代码运行结果\n在函数中返回一个指向局部变量的引用 返回函数定义的局部变量的引用 1 2 3 4 5 6 7 8 9 10  fnmain(){letresult=get_reference();println!(\u0026#34;The value is {}\u0026#34;,result);}fnget_reference\u0026lt;\u0026#39;a\u0026gt;() -\u0026gt; \u0026amp;\u0026#39;ai32{letn=42;\u0026amp;n//`n`doesnotlivelongenough}  代码运行结果\n返回函数参数变量的引用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  fn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = String::from(\u0026#34;world\u0026#34;); let result = get_longest_string(\u0026amp;s1, s2); println!(\u0026#34;The longest string is {}\u0026#34;, result); } fn get_longest_string\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: String) -\u0026gt; \u0026amp;\u0026#39;a str { if x.len() \u0026gt; y.len() { x } else { \u0026amp;y // borrowed value does not live long enough } }   代码运行结果\n缺少lifetime 函数缺少lifetime 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  fn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = String::from(\u0026#34;world\u0026#34;); let result = get_longest_string(\u0026amp;s1, \u0026amp;s2); println!(\u0026#34;The longest string is {}\u0026#34;, result); println!(\u0026#34;{} {}\u0026#34;, s1, s2); } fn get_longest_string(x: \u0026amp;str, y: \u0026amp;str) -\u0026gt; \u0026amp;str { if x.len() \u0026gt; y.len() { x } else { y } }   代码运行结果\n结构体缺少lifetime 1 2 3 4 5 6 7 8 9 10  struct Foo { x: \u0026amp;str, // 缺少生命周期参数，编译错误 } fn main() { let s = \u0026#34;hello\u0026#34;; let f = Foo { x: s }; println!(\u0026#34;{}\u0026#34;, f.x); }   代码运行结果\n正确代码如下：\n1 2 3 4 5 6 7 8 9  struct Foo\u0026lt;\u0026#39;a\u0026gt; { x: \u0026amp;\u0026#39;a str, // 指定生命周期参数 } fn main() { let s = \u0026#34;hello\u0026#34;; let f = Foo { x: s }; println!(\u0026#34;{}\u0026#34;, f.x); }   ", 
        "url": "http:\/\/myself659.github.io\/post\/rust\/rust-lifetime\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E6%88%90%E5%8A%9F%E7%9A%84%E8%B7%AF%E5%BE%84%E4%B8%8E%E6%A6%82%E7%8E%87\/": {
        
        "title": "成功的路径和概率",
        "tags": ["life",],
        "content": "成功的路径 别人的成功你很难复制,所以要想成功你必须走自己的路。\n自己动手实践的路径是唯一有可能属于自己走向成功的路径。\n成功的概率 走自己的路必不一定能成功。成功与失败是概率的游戏。那么如何提高自己成功的概率呢？\n每个人情况不一样，毕竟每个人都要走自己的路，这里只是很宽泛讲一下：\n  发现事实，立足事实\n  学习科技，应用科技\n  掌握规则，应用规则\n  洞察市场，满足市场\n  总结一下提高成功的概率的原则：\n越靠近事实，越靠近科学，越靠近明规则，越靠近市场，则越靠近成功。\n", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E6%88%90%E5%8A%9F%E7%9A%84%E8%B7%AF%E5%BE%84%E4%B8%8E%E6%A6%82%E7%8E%87\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E8%A7%82%E9%9F%B3%E6%98%AF%E5%A6%82%E4%BD%95%E6%9D%83%E5%8A%9B%E5%8F%98%E7%8E%B0\/": {
        
        "title": "观音菩萨是如何实现权力变现的",
        "tags": ["Thinking",],
        "content": "背景 《西游记》小时候只知道看那只猴子，实际上无论是电视剧还是小说里面都隐含大量的知识点。\n下面就以观音菩萨是如何实现权力变现的展开说明。\n权力来源与意图 西游记第八回：\n 如来又取出三个箍儿，递与菩萨道：“此宝唤做‘紧箍儿’，虽是一样三个，但只是用各不同。我有‘金、紧、禁’的咒语三篇。假若路上撞见神通广大的妖魔，你须是劝他学好，跟那取经人做个徒弟。他若不伏使唤，可将此箍儿与他戴在头上，自然见肉生根。各依所用的咒语念一念，眼胀头痛，脑门皆裂，管教他入我门来。”\n 从原文可知，如来佛祖作为观音菩萨上级给其三个紧箍儿，显而易见权力的来源是如来佛祖，其意图是让这三个紧箍儿来帮助取经人（唐僧）管教约束三个徒儿。\n权力应用与效率最大化 西游记第十四回：\n 老母道：“东边不远，就是我家，想必往我家去了。我那里还有一篇咒儿，唤做《定心真言》；又名做《紧箍儿咒》。你可暗暗的念熟，牢记心头，再莫泄漏一人知道。我去赶上他，教他还来跟你，你却将此衣帽与他穿戴。他若不服你使唤，你就默念此咒，他再不敢行凶。也再不敢去了。”三藏闻言，低头拜谢。那老母化一道金光，回东而去。三藏情知是观音菩萨授此真言，急忙撮土焚香，望东恳恳礼拜。拜罢，收了衣帽，藏在包袱中间。却坐于路旁，诵习那《定心真言》。来回念了几遍，念得烂熟，牢记心胸不题.\n 由于孙悟空不受管教，同时已经安排的猪悟能与沙悟净能耐都不如孙悟空，且不像孙悟空那样心猿不定，所以一定要把紧箍儿（权力）给孙悟空戴上，方便唐僧管教，为取经团队的稳定打下基础，保证完成取经任务。\n另外紧箍儿咒，原来叫做定心真言，也是恰当好处，让孙悟空专注一件事：保唐僧取真经。\n权力变现1：收服黑熊怪作为自己的守山大神 西游记第十七回：\n 菩萨现相，问妖取了佛衣。行者早已从鼻孔中出去。菩萨又怕那妖无礼，却把一个箍儿，丢在那妖头上。那妖起来，提枪要刺，行者、菩萨早已起在空中，菩萨将真言念起。那怪依旧头疼，丢了枪，满地乱滚。半空里笑倒个美猴王，平地下滚坏个黑熊怪。\n 变现点评：\n 等待变现时机，等孙悟空主动请自己去帮忙降妖，才开始变现，隐藏变现的主动动机 变现要有合理的理由：用箍制服黑熊怪 合理的变现的对象：黑熊怪，小说中黑熊怪无背景，好学上进，一心向佛，有本领，无劣迹 变现要为自己服务：让黑熊怪作为自己的守山大神 变现后不要给自己惹麻烦：黑熊怪无背景，不属于任何大佬 变现要快：用第一个箍约束孙悟空（西游记第十四回），再到第二个箍收服黑熊怪（西游记第十七回），这中间只间隔三回  权力变现2：收服红孩儿作童子 西游记第四十二回：\n “这宝贝原是我佛如来赐我往东土寻取经人的‘金、紧、禁’三个箍儿。紧箍儿，先与你戴了；禁箍儿，收了守山大神；这个金箍儿，未曾舍得与人，今观此怪无礼，与他罢。\n 变现点评：\n 等待变现时机，等孙悟空主动请自己去帮忙降妖，才开始变现，隐藏变现的主动动机 变现要有合理的理由：用箍制服红孩儿 合理的变现的对象：红孩儿，小说中红孩儿是牛魔王的儿子，不属于任何门派，同时潜力大 变现要为自己服务：用箍控制了红孩儿，可以将牛魔王纳入自己的势力，或者将其作为人质要挟牛魔王 变现后不要给自己惹麻烦：将红孩儿收为童子（以教化的名义变现这样名正言顺）  总结 通过上面分析，可知观音菩萨是厉害主啊，其权力变现有以下特点：\n 善于发现变现机会，用一箍收了孙悟空，发现另外两个箍不需要用来收猪八戒与沙悟净，同时也避免得罪这两人 合理选择变现对象与路径 把握好变现时机 最大化变现收益  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E8%A7%82%E9%9F%B3%E6%98%AF%E5%A6%82%E4%BD%95%E6%9D%83%E5%8A%9B%E5%8F%98%E7%8E%B0\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/chances-from-what-problem\/": {
        
        "title": "什么样的问题背后有大机会呢？",
        "tags": ["Thinking",],
        "content": "前言 人们常说：\n 问题的背后常常隐藏了机会。\n 那么什么样的问题背后有大机会呢？或者隐藏大机会的问题有哪些特征？\n下面个人谈一个自己对这个问题一些思考与看法。\n问题特征 隐藏大机会的问题个人认为往往有以下特征：\n 高频的问题 重要的问题 紧急的问题 未能得到解决的问题 范式变化带来的问题 解决之后会带来正反馈的问题  典型的例子，就是互联网技术发展与应用，这一范式变化带来的问题，如搜索，电商，及时通信的问题。\n机会 满足上面特征的问题不少，但是这些问题并不都是你的机会。是不是你的机会取决于你能否解决问题，并且在解决问题所有方案里面具有竞争力？\n解决问题就是把握机会。\n为市场解决的问题越大，机会越大。\n解决问题一定要与自己能力，资源相结合，这样才能把握机会。\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/chances-from-what-problem\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/linux-btop\/": {
        
        "title": "linux btop 101",
        "tags": ["Linux",],
        "content": "背景 最近发现一个很好用的系统监控命令：btop。 btop一站式实时显示cpu，memory，disk，network，processes的统计信息。\ninstall 具体参考Installation\npanels btop默认有5个显示面板（panels）。每个面板都有一个对应控制命令：\n1： 打开或关闭cpu面板\n2： 打开或关闭memory面板\n3： 打开或关闭disk面板\n4： 打开或关闭network面板\n5： 打开或关闭processes面板\n具体如下图所示： 命令 打开btop，输入h会提出示相关命令的提示。\n个性化 从github下载主题放到$HOME/.config/btop/themes。\n(end)\n", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/linux-btop\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rust\/tips-learn-rust\/": {
        
        "title": "tips for learning rust",
        "tags": ["Rust",],
        "content": "资料  The Rust Programming Language Rust Language Cheat Sheet Zero to Production in Rust This Week in Rust awesome-rust awesome-cli-rust  tools and libaries  cargo-asm A cargo subcommand that displays the generated assembly of Rust source code. cargo-fuzz A cargo subcommand for fuzzing with libFuzzer hyperfine A command-line benchmarking tool flamegraph sqlx yarte opentelemetry thiserror rust-clippy  心法  保持耐心，不要心急，毕竟rust学习曲线陡峭 编译器是最好的老师，同时记住编译器永远是正确的 克服传统语言的思维定势，建立新思维模型如资源与变量分离，同时尝试整合范型编程，类型编程，函数式编程，异步编程，meta-programming 从简单开始，从基础开始 深入从rust内存管理原理开始，扩展到多线程与异步环境 学以致用，可以用rust做一些个人的项目  ", 
        "url": "http:\/\/myself659.github.io\/post\/rust\/tips-learn-rust\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/uniswap-impermanent-loss-formula\/": {
        
        "title": "uniswap的非永久性损失公式的推导",
        "tags": ["BlockChain","DEX",],
        "content": "说明 公式推导基于uniswap v2，不适用于uniswap v3。\n非永久性损失 用户为流动性池提供流动性时，由于交易对价格变化使池内的交易对的代币数量发生变化，相比较于不参加提供流动性的情况下，这种变化会导致用户资产有一定的损失，而这种损失被称为非永久性损失（国内很多人将其称为无常损失）。\nCFMM的原则 uniswap v2是典型的Const Product Market Maker。其遵守以下三条原则：\n 交易对（x,y）流动性池内的两种资产价值永远视为相等，v(x) = v(y) 改变流动性池的k值，保证价格不变, p(x) = y/x 交易的时候k值不变,k = x*y  推导 0. 说明  在公式推导过程中，以y对应的token为币本位，或者说以y对应的token作为计价单位。 不考虑交易费用收入与流动性挖矿收入等任何收入  1. 引入原则 上面CFMM的原则是进行无常公式推导的基础。具体公式如下：\n2. 推导x与y 用p(x)与k来表示x与y，方便后面的替换。 3. 定义非永久性损失 首先确定因变量r，然后确定holder及流通性提供者的价值计算公式，最后根据定义得到非永久性损失的定义公式。\n4. 推导非永久性损失与价格变化倍数之间的关系 前面提到以y对应的token作为计价单位，那么就假设y对应的token在任何时间价格都不变，永远为1.\n具体过程如下： 5. 可视化 利用mania对公式进行可视化，具体如下： ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/uniswap-impermanent-loss-formula\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/defi-tools\/": {
        
        "title": "常用Defi工具与网站",
        "tags": ["Defi",],
        "content": "DeBank DeBank 是一款DeFi资产跟踪和投资组合管理工具。\n优点：\n 支持多链 不仅支持链上帐户资产也支持TVL资产 支持多种协议 支持帐号approve风险提示  缺点：\n 新协议支持速度慢  vFat Tools vFat Tools为defi农民提供挖矿分析，收益计算，数据面板等服务。\n优点：\n 免费 界面简洁 提供了收益与池子详细信息 基本支持主流兼容evm的公链及其对应的yield farming项目 实时数据  缺点：\n 不支持过滤无关的池子 不支持对池子的分析 不支持图表展示  Defi Pulse Defi Pulse 提供了以太坊上各种defi项目TLV数据。\n优点：\n 提供项目TVL的排名 提供了以太坊总体TVL的变化情况  缺点：\n 数据更新速度慢 不支持跨链TVL  DeFi Llama DeFi Llama\n优点：\n 支持多链 支持分类别查看如DEX, lending, yield, insurance, option等 数据丰富，如支持1h，7天的TLV变动数据  缺点：\n 缺少对外api服务  Dune Analytics Dune Analytics支持对链上原始数据进行SQL级别的分析与展示。\n优点：\n 支持个性化的查询链上数据并图表化 支持SQL 支持模板 内置可视化功能  缺点：\n 用户技能要求较高如理解原始数据与SQL，不适合新手  Revert Finance Revert Finance面向DEX流动性提供者的分析工具。\n优点：\n 流动性挖矿数据详细（gas费用，收益） 支持历史流动性数据分析 无常损失分析  缺点：\n 只支持uniswap与sushi  APY Vision APY Vision 是一款流动性挖矿分析与图表工具。\n优点：\n 无常损失与持有对比分析  缺点：\n 收费，免费功能单一 不支持历史数据分析  Token Terminal Token Terminal是去中心化版本的Bloomberg Terminal。\n优点：\n 丰富的数据指标 每4个小时更新数据 提供API服务  缺点：\n API收费且不便宜  dappradar dappradar提供dapp的用户数（DAU,MAU等）等一系列反应dapp基本面的数据。\nLunarCrush LunarCrush可以跟踪加密货币在社交网络的活跃度。\ndexscreener dexscreener支持多链的dex dashboard。\ndextools dextools是集数据，dashboard，交易的于一体的且支持多链的工具。\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/defi-tools\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/crypto-519-fall\/": {
        
        "title": "说说519事件",
        "tags": ["BlockChain",],
        "content": "背景 加密货币历史上几次大跌：\n 2017年94事件 2020年312事件 2021年423事件 2021年519事件  每次大跌都验证一句话：币圈一天，人间一年。\n作为这些事件的经历者，说一下自己对519事件一点看法。\n下跌原因 个人认为大跌原因如下：\n 美国5月12号公布了美国通胀达到4.2%，超出市场的预期，这是促使美联储不得不提前收紧货币 5月12号Elon Musk宣布由于考虑比特币挖矿对环境的影响，暂停通过bitcoin购买Telsa电动车 5月18号中国禁止金融机构和支付公司为加密货币提供服务 加上从2021年以来加密货币快速上涨，风险也积累比较多，高位离场的资金比较多 上面4点导致下跌成为趋势，下跌过程中由于整个币圈杠杆很高，导致相互踩踏，从而出现一两个小时就狂跌50%的情况  快速恢复原因 这次下跌恢复很快，基本到20号比特币就恢复到40k的关口。\n个人认为有以下原因：\n 下跌只是货币收紧信号一个反应，实际上货币供应并没有受到影响，恐慌得到释放 机会都是跌出来，按照历史经验，加密货币每一次大跌都是机会 加密货币在这一年中得到大量的宣传，越来越多的认识到加密货币是资产配置的一个重要选项  影响 牛市就此结束吗？ 个人认为疯牛结束，慢牛开启。这次下跌是对最近一段时间过于疯狂的市场打一针退烧针，清理高杠杆了，减少投机成分，让人们理性认识到市场的残酷，让市场回归到技术与应用。\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/crypto-519-fall\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/pos-increase-decentralization\/": {
        
        "title": "PoS更有利于去中心化",
        "tags": ["BlockChain","cryptocurrency",],
        "content": "背景 PoW和PoS作为现在最常用的两大共识算法，PoW与PoS之争已经有多年了。\n下面从去中心化角度来对比两条公链：\n 采用PoW的以太坊 采用EPoS的Harmony  以太坊 随着以太坊矿池兴起加上PoW天生容易导致算力集中，以太坊独立挖矿的节点越来越少，出块节点也越来越少，越来越集中，下图就是一个很好的说明。\n从图可知，以太坊前三大矿池的总算力已经超过了51%，这说明只要前三大矿池联合，可以对以太坊发起51%攻击，是威胁以太坊安全的一个不可忽略的隐患。\n注：数据来自Top 25 Miners by Blocks\nharmony 我们来看一下采用了EPoS的Harmony。\n首先还是了解一下Harmony：\n Harmony is the first Proof-of-Stake \u0026amp; sharding mainnet. 2-second finality, trustless cross-chain liquidity.\n Harmony是第一个上线PoS并实现分片的公链，其代币是ONE。\n使用了PoS的Harmony去中心化验证节点数量是多少呢？\n从上图可知，参与验证节点数是193，其中114个被选举成为验证节点参与验证与出块。\n注：数据来自harmony validators\n关于harmony的EPoS，更多请参考Harmony公开抵押的官方指南。\n结论 越降低参与门槛，越多节点。 越多节点，越去中心化。 越去中心化，越安全。\n转到pos的eth2.0值得期待，实现分片的eth2.0将会是多链时代的最核心的一条链。\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/pos-increase-decentralization\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/eth-overtake-btc\/": {
        
        "title": "以太坊未来会超过比特币吗？",
        "tags": ["BlockChain",],
        "content": "背景 最近以太坊单日交易量与矿工收入均创历史新高。据THEBLOCK数据显示，4月23日以太坊网络上的每日交易量达150万，再创历史新高，在日交易量创新高的带动下，以太坊矿工单日收入达到$66.3million，其中交易费用手续费为$34.92million。\n将时间拉长看，近7日比特币跌幅接近20%，而ETH仅为6%。近30日比特币跌幅为10%，以太坊涨幅为33%。而且在几次下跌过程中以太坊恢复速度都比比特币快。\n最近一短时间，以太坊与比特币总市值差距也越来越小。\n那么，很多都会这么一个想法：以太坊未来是否会超过比特币呢？\n个人认为，以太坊未来会超过比特币。\n理由 个人看好以太坊未来会超过比特币，主要基于以下理由：\n 尽管以太坊上的交易成本很高，以太坊仍然是最活跃，使用最广泛的区块链平台 以太坊现在价格与市值相比较于比特币都低很多，以太坊是一个更好投资选项 尽管以太坊有很多竞争者，但是以太坊先发优势，网络优势与生态优势均是良好的护城河 以太坊有更多的开发者，是最大区块链的社区 以太坊有V神，V神会为以太坊赢得极大的信任 以太坊上各种L2会不断增强以太坊 以太坊背后有大量的Dapp，这些Dapp中不断有创新涌现，繁荣以太坊生态 以太坊EIP-1599正在路上 以太坊2.0正在稳步推进 以太坊支持智能合约，可以做更多的事情，在满足未来的需求的同时也进一步壮大生态 以太坊上的wbtc会越来越多  时间点 以太坊什么时候会超过比特币？\n时间很难预测，比特币市值现在不到以太坊市值的4倍，如果是出现此消彼涨的情况，这次牛市有希望看到以太坊超过比特币成为新的加密货币的一哥。\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/eth-overtake-btc\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/nft-naval\/": {
        
        "title": "Demystifying NFTs by Naval ",
        "tags": ["NFT",],
        "content": "NFT is blooming. Naval\u0026rsquo;s insightful viewpoints about NFTs as follow:\n An NFT is a unique, on-chain token representing ownership of an off-chain asset. The token is backed by a social contract from its creator and a surrounding community. By assigning a unique token to a thing, its ownership (not the thing itself!) becomes programmable, verifiable, divisible, durable, universally addressable, composable, digitally secured, and easy to transfer. Bitcoin and other completely on-chain assets are provably scarce - scarcity is enforced by code and distributed consensus. Off-chain assets represented by NFTs are not provably scarce. The promise of scarcity is a slender thread, only as strong as the social contract with the creator and interwoven with the backing of the community. An NFT’s creator may break their promise, or be unable to enforce it, or may have picked the wrong underlying platform and community - rendering the NFT worthless. For NFTs representing digital art and collectibles, the creator cannot enforce scarcity - it’s up to a surrounding community to imbue the authorized NFT with scarcity and prestige within the context of that community. Just as HODLers imbue Bitcoin with value, and developers infuse Ethereum with value, collectors, admirers, and users imbue NFTs with value. NFTs gain value when displayed, used, and promoted within vibrant and growing communities. If the community around an NFT is dying, the NFT is likely bleeding value. If the community is surging, the NFT is likely gaining value. NFTs are monetized memes.* “Actual-value NFTs” can draw upon legal and code-based contracts - a song token can provide a royalty stream, a ticket token can provide access, a metaverse token can grant land titles, an item token can have in-game powers, an ISA token can provide a cut of creator earnings. Even “actual-value NFTs” require a social contract with the creator and community to transfer the value from the off-chain contracts onto the chain where the NFT is registered. Just as there are those who won’t accept that mere consensus can create digital gold, and those who won’t accept that mere smart contracts can create a decentralized Wall Street, there are those that won’t accept that digitized social contracts will create valuable tokens. As with most art and most tokens, most NFTs will have very little value. But a select few NFTs will become focal points for communities who gather to celebrate art, build collections, and explore virtual worlds. With NFTs, blockchains make the jump from finance into creative applications. Regulators would do well to recognize that blockchains are the next generation of the Internet, and applying financial regulations to NFTs is a category error. NFTs tokenize all the things. We are going from a world where every protocol has a token, to where every (decentralized) application has a token, to where every valuable digital representation of an object or person has a token. Public blockchains will be the title registries for everything of value. Ultimately, NFTs will authenticate the world.**    ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/nft-naval\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/economy\/the-essence-of-arbitrage\/": {
        
        "title": "套利的本质",
        "tags": ["economy",],
        "content": "套利大行其道，那么套利是什么？\n下面这张图是一个活生生的套利案例。\n套利的本质是什么？\n 套利的本质是利用非对称获利 套利的竞争是发现非对称机会以及利用机会的速度竞争 任何套利模式都是公开即失效  ", 
        "url": "http:\/\/myself659.github.io\/post\/economy\/the-essence-of-arbitrage\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/bitcoin-telsa\/": {
        
        "title": "Telsa买入bitcoin意味着什么",
        "tags": ["BlockChain",],
        "content": "background 最近Telsa投入15亿美元买入了bitcoin，消息一出，bitcoin应声大涨，这事激起广泛的关注。\ntelsa买入bitcoin的原因 为什么telsa买入比特币？个人认为有以下原因：\n 在全球继续放水的预期下，telsa公司资产配置的需要 telsa买入bitcoin，可以赢得加密货币富豪的支持，这些人有很强的消费能力 传统金融政策难以持续，买入bitcoin可以试水新的货币机制，也可以赢得先机 bitcoin时隔3年重回2万美元，并继续突破了3万美元，4万美元等历史新高，对于比特币来说，它的反脆弱性得到证明 bitcoin得到paypal与square等公司支付业务的支持  为什么只买入bitcoin而没有买入其他的加密货币如ethereum呢？个人认为有以下原因：\n bitcoin市值最高，占比超过了整个加密货币的60% bitcoin相比较于其他加密货币风险更小 bitcoin共识长达10多年，共识稳固 bitcoin具有抗通胀的属性，而ethereum现在每年都有一定的通胀 总之，bitcoin是加密货币的始姐，也是最强的头部  意义与影响 telsa买入比特币意义与影响有哪些？\n bitcoin得到世界顶级精英与公司的认可，也意味加密货币得到认可，为整个加密货币市场注入活力，吸引了用户，资产及人才。 意味牛市继续，很有可能是长牛 为其他机构与公司提供了入场的参考，telsa进场了，apple，amazon，google，microsoft下一步也会来吗？ Elon Musk及其telsa的影响力有利于加密货币与区块链技术的普及  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/bitcoin-telsa\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/internet\/about-clubhouse\/": {
        
        "title": "谈谈clubhouse",
        "tags": ["internet",],
        "content": "背景 最近clubhouse的邀请一码难求，自己有幸被邀请。体验一下，说一下自己对clubhouse一些想法。（Ps：由于区块链与加密货币的火爆，只写一些要点，不展开说明）\n感受与评价 个人对clubhouse一些主观感受与评价如下：\n 通讯录验证，避免僵尸用户 扩展式邀请，带来扩展式社交 精准推荐 领袖主导 价值分享 语音聊天，便捷自然 实时分享与交流，无回放与录音 用户时间黑洞 开放打破界限 高质量的人群  问题  如何商业化？ 微信会跟进吗以及如何跟进？ clubhouse产品内核是什么？ 用户推荐算法机制？ Elon Musk这样超级KOL进入，服务不可用的原因是什么？ clubhouse热度会持续吗？ clubhouse什么时候会被墙？ 给clubhouse取一个什么样的中文名字呢？  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/internet\/about-clubhouse\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/economy\/china-trust-crisis\/": {
        
        "title": "爆雷，接盘侠与社会信用",
        "tags": ["Economy",],
        "content": "背景 首先，先看看这个新闻： 湖南益阳62岁老人投江后续：当地多家养老机构爆雷，有老人获悉后心梗去世。\n由这个新闻想到中国从2018年开始了一系列爆雷：\n P2P爆雷断断续续到现在还没有结束 民营企业债爆雷 国有企业债爆雷，如永煤，华晨，北大方正，清华紫光 房地产全线爆雷，如北京院子，北京山水等等，还有很多烂尾楼 养老机构爆雷，如益阳市纳诺老年公寓 教育机构爆雷，如学霸君 共享单车爆雷，如OFO 黄金爆雷，如武汉金黄 信托爆雷，如四川信托 股票爆雷，如獐子岛 银行爆雷，如包商银行  爆雷背后是什么？ 爆雷其实是骗局的破灭。破灭是由于业务与模式的不可持续，不可持续由于缺少接盘侠。 上面列举几种爆雷，其实都是缺少接盘侠（中国居民负债率在2019年就超过了50%）。典型的例子是泰和北京院子与恒大地产。 恒大地产有了接盘侠，撑过来了，而泰和没有接盘侠，北京院子就烂尾了。\n接盘侠 人人皆韭菜。\n人人都是接盘侠。\n爆雷深深伤害了接盘侠，加上前两句话：爆雷伤害全社会，特别是社会信用。\n社会信用 爆雷导致社会信用的减弱，这样全增加全社会的运行成本，成本上升，会导致社会协作的效率下降，从而影响整个社会的财富的创造与流通。\n希望中国政府要重视爆雷的严重影响，并找到其中的根本原因，加强制度与法制建设，为社会信用提供坚定的基石。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/economy\/china-trust-crisis\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/invest\/invest-balajis-directions\/": {
        
        "title": "错过了2010年的比特币，不要错过这些新领域的机会",
        "tags": ["Invest",],
        "content": "今天哪些新领域会像2010年比特币一样的成长 twitter一个用户提出一个问题：Is there a thing today like being into Bitcoin in 2010？\n下面是Balaji S. Srinivasan的回答\n Bitcoin itself (still early relative to 99%)比特币，且比特币仍然是早期 Ethereum, crypto in general 以太坊以及其他的加密货币 Startup cities 创业型城市如迈阿密，新加坡和迪拜 Reversing aging 抗衰老及长寿技术 Brain-machine-interface 脑机接口 Transhumanism 超人类主义（人类增强） Robotics 机器人技术 Digital nomadism, in green zones at least 数字游牧 India, rest-of-world tech in general 印度 AI-assisted content creation 人工智能辅助内容创作 VR as office replacement VR替代办公室 AR for productivity (eg Google Glass Enterprise)AR提高生产力 Self-hosting makes a comeback (see http://cloudron.io)自主托管 Telemedicine, personal genomics, health tracking v2 远程医疗，个人基因，健康跟踪 3D printing of metals 金属的3D打印 Pseudonymity, aided by crypto and AI voices \u0026amp; faces 仿真，借助加密和AI仿真声音和人脸  对于上面的回答的，个人补充一些：\n NFT Defi Hyperautomation  twitter原文\n关于Balaji S. Srinivasan 关于Balaji S. Srinivasan介绍如下：\n Balaji S. Srinivasan is an angel investor and entrepreneur. Formerly the CTO of Coinbase and General Partner at Andreessen Horowitz, he was also the cofounder of Earn.com (acquired by Coinbase), Counsyl (acquired by Myriad), Teleport (acquired by Topia), and Coin Center.\n  He was named to the MIT TR35, won a Wall Street Journal Innovation Award and holds a BS/MS/PhD in Electrical Engineering and an MS in Chemical Engineering, all from Stanford University. Dr. Srinivasan also teaches the occasional class at Stanford, including an online MOOC in 2013 which reached 250,000+ students worldwide.\n 从上面可知Balaji S. Srinivasan是一个真大佬，没有一点水分：\n 除了拥有斯坦福大学电子工程的学士，硕士，博士学位，还拥有化学工程的硕士学位 MIT TR35 企业家：四次创业，三次被收购 Coinbase前任CTO 投资人 多面手并且在多个领域做到世界顶级水平  ", 
        "url": "http:\/\/myself659.github.io\/post\/invest\/invest-balajis-directions\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/openness-importance\/": {
        
        "title": "谈谈开放的重要性",
        "tags": ["闲谈乱扯",],
        "content": "说明 本文从软件，互联网，区块链，安全的视角谈谈开放的重要性。\n软件 软件方面看几个例子吧。\n首先看一下chrome浏览器，chrome浏览器首先建立应用市场，对开发者开发浏览器api，各种浏览器插件丰富了chrome的功能，对不同场景有针对性的插件来满足用户的需求。\n再看苹果ios对外开放应用商店，有大量的app，为各种不同的用户和不同场景提供针对性app。\n最后是微软的vs code。vs code作为一个编辑器不如vim，emacs，但是由于vs code有针对性不同开发者和开发场景的插件，让开发者的需求得到充分满足。\n对了，不能忘记开源的操作系统Linux。Linux是开源软件的巅峰。Linux开启的开源软件浪潮，基本支撑了整个互联网的运行。\n互联网 微信小程序对外开放微信的接口与用户，相对于独立开发app，降低用户成本与开发成本。小程序带来的GMV超过了1万亿。\n区块链 如果讲区块链精神的内核，那么开放我觉得开放一定要会占有一个位置。在区块链的世界：\n 代码是开源的 账本数据是开放的 进入门槛是开放的  这种开放带来了透明，分享，效率及信任，促进了区块链的发展与快速迭代。在这样的环境涌现不少快速增长的例子。\n 以太坊2015年上线到2017年市值最高超过了1000亿美元，而这仅仅用于2年多的时间。 uniswap去中心化交易所，上线2年的uniswap就在月交易额超过了成立超过了8年的coinbase，UNI代币市值达到15亿美元以上，而整个团队不到20人。  安全 TK教主说过：\n 怎么评价一个东西有多安全呢？唯一金标准是：公开接受挑战、接受公开挑战、接受挑战公开。 典型代表就是密码学领域。AES 也好，RSA 也好，椭圆曲线也好，算法公开，你有能耐就去破解，破解了发论文，还给你颁奖。 胸脯拍得响，但又怕别人公开研究、研究公开的，都属于魑魅魍魉，四小鬼各自肚肠。\n 这里提一个概念：Proof of security.那么如果证明安全呢？\n首先要开放，然后要通过挑战与检查来证明安全。\n这方面最典型的例子就是比特币与以太坊。区块链浏览器上地址公开资产情况，但是现在还没有能力破解ecdsa算法。\n小结 开放建立连接。\n连接组成网络。\n网络产生交易。\n交易产生机会与双赢。\n", 
        "url": "http:\/\/myself659.github.io\/post\/openness-importance\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/eth-2021\/": {
        
        "title": "展望2021年的Ethereum",
        "tags": ["cryptocurrency","blockchain",],
        "content": "前言 Ethereum作为第一个支持图灵完备的智能合约平台，同时也是最大的智能合约平台。从现在区块链应用角度来看是最重要的公链。个人认为公链的市场规模在万亿美元以上。\n上涨原因 最近一个月以太坊从600美元左右上涨到1200美元左右。具体如下图：\n以太坊最近一个月大涨的原因如下：\n 比特币上涨太多，上涨无力 以太坊2.0成功启动，质押以太坊会不断增长 Defi继续发展，TLV继续增长 通胀预期加大 随着比特币从1万到4万，吸引更多人关注到以太坊 以太坊的利益同盟不断壮大 上涨预期中网络效应与正反馈效应  2021展望 对于以太坊2021个人展望如下：\n 以太坊价格保守估计将会达到2000美元，市值超过了2000亿美金，乐观估计参考2020的telsa 以太坊2.0第1阶段会在2021年内完成 以太坊受到竞争者的挑战：harmony，near，Solana会比以太坊市值增长更快 NFT在以太坊不会有太大的进展 Defi的TLV增长10倍以上 L2百花齐放，这些L2增加了以太坊的护城河 以太坊EIP1599将会在2021年上线  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/eth-2021\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/history-read-list\/": {
        
        "title": "那些值得多读的历史书",
        "tags": ["History",],
        "content": "前言 历史是一面镜子。\n历史是一个任人打扮的小姑娘。\n历史告诉我们过去发生什么，启示我们现在做什么，预示着未来发什么。\n做为多年历史爱好者，这里列出我觉得值得阅读的历史书单。\n书单 大历史 以大历史的视角来审视历史信息，从中洞察真正的启示。\n历史的教训 在完成了十卷文明史之后，Will和Ariel Durant将他们最重要的课程汇编成了一百多页。每页的智慧比几乎任何其他书籍都多，《历史教训》一次又一次地展示了我们文化中出现的模式。它并不总是最乐观的，但它通常是深思熟虑的。历史的教训以一种宏面大视野教我们如何读历史。\n春秋左传 《春秋左传》记载了从鲁隐公元年（前722）到鲁哀公二十七年（前468）共254年的历史，是我国现存极早的编年体史书。《左传》在《春秋》大事纲要的记史方法基础上，代之以系统灵活的史书编纂方式，既记春秋史实，又包含了大量古代典章史料，是了解我国先秦文化的重要典籍。其中“一字所嘉，有同华袞之赠；一言所黜，无异萧斧之诛”的“一字之褒贬”的春秋笔法，使《春秋左传》蕴含着史学和文学上的无限魅力。\n史记 《史记》，二十四之首，是西汉史学家司马迁撰写的纪传体史书，是中国历史上第一部纪传体通史，记载了上至上古传说中的黄帝时代，下至汉武帝太初四年间共3000多年的历史。《史记》被鲁迅先生誉为“史家之绝唱，无韵之离骚”。\n资治通鉴 《资治通鉴》以时间为纲，事件为目，从周威烈王二十三年（公元前403年）写起，到五代后周世宗显德六年（公元959年）结束，涵盖十六朝1362年的历史。\n万年十五年 全球视野下万历十五年。\n南明史 探究南明是如何大溃败的。\n南明史\nSapiens 人类简史 这是过去几年写的最重要的书之一。作者带我们历史回答一个问题：智人是如何成为地球上的优势物种的？他涵盖了人类学，科学和经济学等主题，描绘了一幅相当全面的图景。它可能会改变你对人类的看法。\n全球科技通史 熟知人类科技文明史，真正洞察世界变化的趋势。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/history-read-list\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/tips-for-crypto-invest\/": {
        
        "title": "加密货币新手应该注意哪些问题",
        "tags": ["Invest",],
        "content": "背景 随着eth 2.0信标链启动以及defi的快速发展，加密货币会迎来一个新的牛市。在牛市开启之后，一定有很多新人进场。\n作为一名老韭菜，简单说说自己一些想法（不会展开说明）。\n安全 首先是安全，安全分为以下几种：\n 出入金通道安全 交易平台安全 帐号安全 加密货币钱包安全 政策与法律安全  学习 区块链与加密货币还处于早期，新人入场一定要学习基本知识。具体建议：\n 先学习一点基本密码学，弄懂公私钥（这是必须的） 从比特币开始学习 深入比特币交易原理与细节 学习交易基本知识及其应用 学习如何分析加密货币项目 学习以太坊 学习Defi  投资  不要投资超过你能承担的损失 不要加杠杆，也不要All-in 避免单一化投资，投资组合要多样化 识别空气币 避免FUD心理（Fear，Uncertainty，Doubt） 保持独立性，Do your own search 不懂的不要参与 尊重市场与事实，而不是执着于个人意愿与偏见 制定退出策略 区分投资与投机 不要追高，学会与趋势作朋友  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/tips-for-crypto-invest\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/dsa\/dp-knapsack\/": {
        
        "title": "学会背包问题，再也不怕动态规划 0-1背包",
        "tags": ["DP",],
        "content": "问题描述  Given weights and values of n items, put these items in a knapsack of capacity W to get the maximum total value in the knapsack. In other words, given two integer arrays val[0..n-1] and wt[0..n-1] which represent values and weights associated with n items respectively. Also given an integer W which represents knapsack capacity, find out the maximum value subset of val[] such that sum of the weights of this subset is smaller than or equal to W. You cannot break an item, either pick the complete item, or don’t pick it (0-1 property).\n 给定n个物品的重量和价值，从中选择物品放在容量为W的背包中(表示选择物品重量不超过W)，同时每个物品最多到允许选择1个，使得背包中物品价值之和最高。\n背包问题是一个非常典型的考察动态规划应用的题目，对其加上不同的限制和条件，可以衍生出诸多变种，若要全面理解动态规划，就必须对背包问题了如指掌。学习背包问题有利于举一反三，融会贯通，再也不怕动态规划。\n问题建模 用程序语言重新定义一下问题。\n先看输入：\n int Values[n]，表示物品的价值 int Weights[n]，表示物品的重要 int LimitWeight，表示背包容量的限制  再看输出：\n int MaxValue，表示背包里的物品最大价值  转化为函数（以C++为例）：\n1 2 3 4 5 6  int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; return MaxValue; }   问题分析 是否可以应用DP 应用DP应以满足以下三个条件：\n 最优子结构 边界条件 满足重叠要求的状态转移方程  最优子结构  如果一个问题的最优解包含其子问题的最优解，我们就称此问题具有最优子结构。  编程中常见最大与最小的问题，一般都是满足最优子结构的这一条件。\n本题要求是求背包里物品的最大价值。故初步判断满足条件。\n边界条件 连界条件包括开始条件与结束条件。\n这个条件可以从下面三个问题来解答：\n 用什么来作边界条件？ 边界条件是起点是什么，终点是什么？ 边界是如何从起点到终点？  针对上面问题，结合本题的信息，可以回答如下：\n 用背包里的物品重量作为边界 重量限制起点是1，终点是不超过LimitWeight；物品在数组的位置起点从0开始，终点不超过数组的长度 从起点开始，逐个加1直到终点  状态转移方程 状态转移方程也就是我们常说的DP公式。这是解决DP问题的关键。\n满足重叠要求是指后面的状态可以重复使用前面的生成的状态。\n如果不是很简单的直接可以看出来，建议在解题步骤中一步一步分析出来。本题我们会在后面分析给出对应的状态转移方程。\n解题步骤 确定采用DP来解决问题，那我们正式进行DP解题的步骤。\n1. 定义状态 前面问题分析中提到状态转移方程，状态应当在状态转移方程之下定义。完成状态定义，才能开始定义状态转移方程。\n本题的状态是S(w,i,v),其中w表示不能超过最大重量，i表示遍历到第i个物品，v表示对应的最大的价值。\n那么如何用数据结构保存状态呢？\n使用一个二维数组state[LimitWeight+1][n+1]来表示。\n2. 确定递归关系 这里我们采用top-down思考方式。\n先看代码，具体如下：\n1 2 3 4 5 6 7 8  int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; int itemLen = Weights.size(); // 处理入口 MaxValue = knapsackDo(Values, Weights, LimitWeight,itemLen); return MaxValue; }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  int knapsackDo(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight, int posIndex) { int localMaxValue = 0; int posWeight = Weights[posIndex-1]; int posValue = Values[posIndex-1]; if(LimitWeight \u0026gt;=posWeight){ // 选择当前位置的物品 int selectValue = posValue + knapsackDo(Values, Weights, LimitWeight- posWeight, i -1); // 跳过当前位置的物品 int skipValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); localMaxValue = MAX(selectValue, skipValue); }else { // 超过重量限制，跳过 localMaxValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); } return localMaxValue; }   3. 根据递归关系，得出并检查状态转移方程 当限制重量大于等于当前物品重量时，状态转移方程如下：\n1 2 3  knapsackDo(Values, Weights, LimitWeight,posIndex) = MAX(knapsackDo(Values,Weights, LimitWeight - Weights[posIndex],posIndex -1), knapsackDo(Values,Weights, LimitWeight,posIndex -1))   当限制重量小于当前物品重量时，状态转移方程如下：\n1 2  knapsackDo(Values, Weights, LimitWeight,posIndex) = knapsackDo(Values,Weights, LimitWeight,posIndex -1)   4. 确定递归结束条件 本题中递归结束条件有两个，分别如下：\n 限制重量小于等于0（即0 \u0026gt;= LimitWeight ） 数组index小于0 （即0 \u0026gt; posIndex）  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  int knapsackDo(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight, int posIndex) { if( 0 \u0026gt;= LimitWeight || 0 \u0026gt; posIndex ){ return 0; } int localMaxValue = 0; int posWeight = Weights[posIndex-1]; int posValue = Values[posIndex-1]; if(LimitWeight \u0026gt;=posWeight){ // 选择当前位置的物品 int selectValue = posValue + knapsackDo(Values, Weights, LimitWeight- posWeight, posIndex -1); // 跳过当前位置的物品 int skipValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); localMaxValue = MAX(selectValue, skipValue); }else { // 超过重量限制，跳过 localMaxValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); } return localMaxValue; }   5. 完成递归的实现 将代码结合起来如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; int itemLen = Weights.size(); // 处理入口 MaxValue = knapsackDo(Values, Weights, LimitWeight,itemLen-1); return MaxValue; } int knapsackDo(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight, int posIndex) { if( 0 \u0026gt;= LimitWeight || 0 \u0026gt; posIndex ){ return 0; } int localMaxValue = 0; int posWeight = Weights[posIndex]; int posValue = Values[posIndex]; if(LimitWeight \u0026gt;=posWeight){ // 选择当前位置的物品 int selectValue = posValue + knapsackDo(Values, Weights, LimitWeight- posWeight, posIndex -1); // 跳过当前位置的物品 int skipValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); localMaxValue = MAX(selectValue, skipValue); }else { // 超过重量限制，跳过 localMaxValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); } return localMaxValue; }   6. 添加缓存保存子问题结果优化递归方案 缓存对象是什么？状态。根据状态定义，添加如下代码：\n1 2 3 4 5 6 7 8 9 10  int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; int itemLen = Weights.size(); // 定义与实始化状态 static vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; stateDP(LimitWeight+1, vector\u0026lt;init\u0026gt;(itemLen+1)); // 处理入口 MaxValue = knapsackDo(Values, Weights, LimitWeight, itemLen - 1); return MaxValue; }   什么时候添加缓存与什么时候使用缓存呢？\n具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  int knapsackDo(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight, int posIndex) { if( 0 \u0026gt;= LimitWeight || 0 \u0026gt; posIndex ){ return 0; } int localMaxValue = 0; int posWeight = Weights[posIndex]; int posValue = Values[posIndex]; if(LimitWeight \u0026gt;=posWeight){ // 选择当前位置的物品 if(0 != stateDP[LimitWeight][posIndex+1]){ // 使用缓存 int selectValue = stateDP[LimitWeight][posIndex+1]; }else { int selectValue = posValue + knapsackDo(Values, Weights, LimitWeight- posWeight, i -1); // 添加缓存 stateDP[LimitWeight][posIndex+1] = selectValue； } // 跳过当前位置的物品 int skipValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); localMaxValue = MAX(selectValue, skipValue); }else { // 超过重量限制，不能选择 localMaxValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); } return localMaxValue; }   注意：根据代码执行顺序，只需要添加上面一处添加缓存处理代码即可。\n7. 将递归转化为迭代 上面一直采用的是top-down来解决DP问题。这一步我们要尝试将递归转化为迭代。\n递归的情况下状态转移方程是函数的方程。在迭代的情况，状态转移方程是状态变量的方程，具体如下：\n当限制重量大于等于当前物品重量时，状态转移方程如下：\n1 2 3  stateDP[LimitWeight][posIndex] = MAX(stateDP[LimitWeight - Weights[posIndex-1]][posIndex -1]+Values[posIndex-1], stateDP[LimitWeight],[posIndex -1])   当限制重量小于当前物品重量时，状态转移方程如下：\n1  stateDP[LimitWeight][posIndex] = stateDP[LimitWeight][posIndex -1]   代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; int itemLen = Weights.size(); // 定义与实始化DP状态 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; stateDP(LimitWeight+1, vector\u0026lt;int\u0026gt;(itemLen+1)); // 限定重量从1开始 for(int w = 1; w \u0026lt;= LimitWeight; w++){ // 在限定重量为w的情况下，遍历数组获取最大值 for(int posIndex = 1; posIndex \u0026lt;= itemLen; posIndex++){ int selectValue = 0; int skipValue = stateDP[w][posIndex -1]; int posWeight = Weights[posIndex -1]; int posValue = Values[posIndex -1]; if (w \u0026gt;= posWeight) { selectValue = posValue + stateDP[w - posWeight][posIndex -1]; } stateDP[w][posIndex] = max(skipValue, selectValue); } } // 从状态中取出最大值 MaxValue = stateDP[LimitWeight][itemLen]; return MaxValue; }   为了方便理解上面的代码，我们进行一个实例分析：\n假定有4个物品，其价值分别为10, 40, 30, 50，对应重量分别为5, 4, 6, 3，限定总重量不超过10。 下面我们观察stateDP的变化过程。\n首先看初始化的stateDP状态：\n根据初始化的stateDP状态和状态转移方程，整个stateDP状态构建一列一列进行即可，过程与结果如下：\n8. 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; // std::max #include \u0026lt;iomanip\u0026gt; using namespace std; int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; int itemLen = Weights.size(); // 定义与实始化DP状态 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; stateDP(LimitWeight+1, vector\u0026lt;int\u0026gt;(itemLen+1)); // 限定重量从1开始 for(int w = 1; w \u0026lt;= LimitWeight; w++){ // 在限定重量为w的情况下，遍历数组获取最大值 // 完全DP问题，在遍历数组的情况下需要考虑同一个选项多次选择的问题 int posIndex ; for(posIndex = 1; posIndex \u0026lt;= itemLen; posIndex++){ int selectValue = 0; int tmepSelectValue = 0; int skipValue = stateDP[w][posIndex -1]; int posWeight = Weights[posIndex -1]; int posValue = Values[posIndex -1]; int selectCnt = w / posWeight; for (int i = selectCnt; i \u0026gt;= 1; i--){ tmepSelectValue = i * posValue + stateDP[w - i*posWeight][posIndex -1]; selectValue = max(tmepSelectValue,selectValue); } stateDP[w][posIndex] = max(skipValue, selectValue); } } // 从状态中取出最大值 MaxValue = stateDP[LimitWeight][itemLen]; // 打印状态表 cout\u0026lt;\u0026lt;\u0026#34;print stateDP:\u0026#34;\u0026lt;\u0026lt;endl; for(int i = 0; i \u0026lt;= itemLen; i++){ for(int j = 0; j \u0026lt;= LimitWeight; j++){ cout\u0026lt;\u0026lt;setw(3)\u0026lt;\u0026lt;stateDP[j][i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt;endl; } return MaxValue; } int main(){ vector\u0026lt;int\u0026gt; Values{10, 40, 30, 50}; vector\u0026lt;int\u0026gt; Weights{5, 4, 6, 3}; int LimitWeight = 10; int maxValues = knapsack(Values, Weights, LimitWeight); cout\u0026lt;\u0026lt;\u0026#34;maxValues:\u0026#34;\u0026lt;\u0026lt;maxValues; }   运行结果如下：\n1 2 3 4 5 6 7 8  print stateDP: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 10 10 10 10 10 20 0 0 0 0 40 40 40 40 80 80 80 0 0 0 0 40 40 40 40 80 80 80 0 0 0 50 50 50 100 100 100 150 150 maxValues:150   推荐是在leetcode测试，由于leetcode上没有这道题，所以就简单测试一下。\n测试代码参考链接。\n总结 掌握使用DP解决问题三个条件：\n 最优子结构 边界条件 满足重叠要求的状态转移方程  使用DP解决问题采用以下步骤：\n 定义状态 确定递归关系 根据递归关系，得出并检查状态转移方程 确定递归结束条件 完成递归的实现 添加缓存保存子问题结果优化递归方案 将递归转化为迭代  对上面的步骤总结如下：\n根据问题的目标采用Top-down方式弄清问题的本质（状态转移方程），然后采用Bottom-up方式实现代码。\nPs：关于DP还有很多内容可以写（如背包问题的扩展及类似leetcode题目），以后有机会再补充一些。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/dsa\/dp-knapsack\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/gpt3-thought\/": {
        
        "title": "谈谈GPT3",
        "tags": ["编程",],
        "content": "GPT-3 GPT-3全称是\u0026quot;General Pre-trained Transformer-3\u0026quot;，对应中文翻译为：第三代通用预训练转换器。\n其wiki定义如下：\n Generative Pre-trained Transformer 3 (GPT-3) is an autoregressive language model that uses deep learning to produce human-like text.\n GPT-3是一种自回归语言模型，这种模型利用深度学习产生类似于人类语言的文本。\n从本质上看，GPT-3是计算机程序。\n现阶段GPT-3能干什么呢？\n 直接能够理解英文理解并将转化为需求 英文翻译 自动创作如小说 人机对话  具体请看下面的一个视频： 看完这个视频作为程序员的我感觉一阵阵凉意，AI会下围棋也就算了，AI现在可以直接根据需求写代码，这是解放程序员还是解决程序员呢？\n值得注意的是，GPT-3背后的OpenAI公司的投资人有两位硅谷大佬：当代钢铁侠埃隆·马斯克（Elon Musk）和《从0到1》作者彼得·蒂尔（Peter Thiel）。\nGPT-3意味着什么？ 无码编程时代 从上面的视频中我们可以清楚看到需求定义即代码。从中进一步思考可以得出一个结论：编程的未来发展一个方向是无代码化（no code ）或者少代码化（less code）。这也意味着编程的门槛进一步下降。\n超级大脑外挂 随着GPT不断进步与发展，GPT-X将来会成人类大脑超级外挂。拥有GPT-X在知识方面远远会超越普通人。以程序开发为例，在未来开发人员只需要定义需求，而AI将帮助开发人员完成编程，测试，部署等功能，这也意味着当你定义好需求之后，几分钟之后需求就得了实现，测试，部署，上线等流程，整个开发周期大大缩短。\n新一代脑力资源 现在脑力资源主要来自人类，未来类似于GPT-3这样的AI会成为新一代脑力资源。其实现阶段计算机程序已经实现部分这样的功能，如象棋对奕软件，Alphago，这些计算机程序已经在象棋与围棋领域超越了人类，已经成为人类最强大的陪练。除此之外在机器翻译，语言识别，自然语言处理等技术已经得到广泛应用。\n面对新一代的脑力资源：AI, 人类应该如何应对呢？\n如同人类要避免同计算机比计算能力，未来的人类也要避免在AI擅长的领域与之竞争。 如同人类利用计算机来创造一个互联网世界，未来人类也会应用AI技术创造一个智能的世界。\n感想 下面谈一下我个人一些感想：\n 只会写CRUD肯定是不行了，不说未来怎么样，现在这个阶段，只会CRUD的程序员已经在危险的地带，现在这个阶段，只要定义好SQL语句，就可以生成CRUD的代码了，未来就更不说了 GPT-3并不会取代那些高级程序员 成为SQL工程师也比成为一个CRUD工程师更好，因为SQL离需求更近，离数据更近 在数学和算法方面精进，做到Write code to create 未来程序员只需要四类工程师：业务类，基础设施类，算法类，架构类 AI的进步与发展，会带来新的变化，主动拥抱AI的变化，才能适应未来世界 不可替代永远是现在还不存在的东西，所以培养创新意识与创造能力变得相当重要了  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/gpt3-thought\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/linux-wget-retry\/": {
        
        "title": "利用WSL和wget从github下载文件",
        "tags": ["Linux",],
        "content": "背景 由于GFW的干扰，即使科学上网方式从github下载文件，下载连接经常会被中断。由于chrome重新连接的次数有限，据说chrome重新建立连接重试次数最大为5次。所以遇到一个大的下载文件，通常是不会下载成功，费时费力费心。\n针对这种情况提供一个解决方案。\n解决方案 在windows上科学上网基础之上，解决方案主要工作如下：\n 在windows上安装wsl 在wsl上安装与配置polipo  应用 应用就很简单,通过wget指定重连接的次数，参考如下：\n1  wget --tries=1000 https://github.com/downloadurl   （end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/linux-wget-retry\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/think-outof-box\/": {
        
        "title": "谈谈跳出框架思考",
        "tags": ["成长",],
        "content": "引子 先看一下这道数学题：\n画直线经过下图中九个点，并且做到不重复经过任何一个点。\n这里不是出题给大家做，只是引出话题。\n下面是这个问题的答案：\n这个答案并没有局限在题目中要求9个点，扩大到面的范围，由9个点范围扩大到16个点范围。如果一直在考虑9个点的范围这个题目你是不会找到正确的答案。解题的关键是：think outside of the box。在上面这道题主要打破只有9个点的限制，也就是跳出只有9个点的框框。\n至此，关键话题来了： think outside of the box，这里我将其翻译为跳出框架思考。\n定义 跳出框架思考是要尽可能地消除约束，从更多的视角或层次思考，发现更多的选项和方案。\n我们还是具体看几个例子吧。\n作为一名多年的码农，先从技术研发开始吧。跳出框架思考是指研发不要局限于技术，要多关注业务。具体看几个例子：\n实例1：以前看一个科技电影，大概是两个黑客比赛，谁先攻破系统，则对应灯亮作为获胜；其中黑客A紧急投入攻破系统，而黑客B却在电影需要下，轻淡幽闲地装B，带上主角光环的他其实心里早有准备，采用直接攻击灯控系统，降低攻击难度，同时利用规则的漏洞。这里黑客B看到规则里另一种含义：谁的灯先亮，谁就获胜，跳出一般人理解先攻破系统，再亮灯的习惯性思维。\n实例2：早期的阿里云CDN系统需要定位ip地址的地理位置，阿里云的工程师想到根据淘宝用户的收货地址来定位地理位置。\n实例3：互联网安全方面：如果微信账号被盗，可以通过社交关系找回；淘宝帐号找回，需要通过最近购物的测试；这些都是从多个维度确认帐号对应是用户是原来的用户，而不是仅仅通过密码和手机还确认用户。\n在工作方面，跳出框架思考要点之一就是员工要跳出员工的视角，学会站在老板或者上级的角度来思考问题。这里分享一个职场的技巧：\n 在任何领域，众所周知，要让老板支持你的想法，最容易的方法就是让他认为这个想法是他的。 ​​​​\n 在交易领域，对冲基金的操作手法也体现了跳出框架思考，如跨市场交易，跨地区交易。\n下面这个例子让我是佩服不已。 从上面例子可知，tk教主的朋友跳出员工与公司的二元框架，在二元框架下一般只有三种选项：\n 不作处理，等其主动离职（水货一般都是没有水平，要想让他主动离开时间长，概率小） 逼他主动离职（需要耍手段，双方关系可能弄僵） 通过赔偿主动解雇（需要花钱）  tk教主的朋友从员工，公司，人才市场的三元框架下思考，通过上面的方法，达到不止双赢，而是三赢：\n 公司摆脱了水货，并且将水货送到竞争对手的公司，去祸害竞争对手，算是打击了竞争对手 水货员工得到加薪 猎头成交一笔大单，获得丰厚的报酬  在自然语言处理领域，科学家跳出了语法与主义的框架，改用统计分析的方法，大大促进的自然语言处理技术的进步，也才有现在推荐与搜索技术的广泛应用。\n跳出框架思考是如此充满威力，那如何培养自己的跳出框架思考的能力呢？\n如何培养跳出框架思考的能力 记录灵感，避免刻意思考 平时记录自己一些想法与灵感，这种有充足的信息与思路储备的情况下，思考的灵活性就不会打折扣，相反由于信息与思路够多，这些信息与思路的形成新的结合，会有更多的想法出现。\n摆脱限制 跳出框架思考最重要的一步是摆脱限制，在思考方面不要给自己设限。\n广泛阅读与学习，并且多尝试与实践 平时要广泛阅读与学习，扩大信息源，广泛涉猎各个领域的知识，以技术领域为例，比特币技术综合了P2P技术，PoW共识，密码学，区块链等多种技术，同时结合经济学的知识，将数字货币与计算机技术紧密地结合在一起。\n5W1H替换法 从原因（何因Why）、对象（何事What）、地点（何地Where）、时间（何时When）、人员（何人Who）、方法（何法How）等六个方面提出问题进行思考，在此基础上对这6个要素进行替换，并尝试找到更多的替换选项。\n培养同理心 同理心能够让我们站在他人的角度来思考，有利于提供更多的视角。很多时候，我们不能跳出框架，是因为我们缺少视角。\n避免以目标为中心 避免以目标为中心的思维方式，目标更应该是一个导向的作用。目标很重要，但是目标并不代表全部，目标并不是系统。眼睛全是目标，就看不到系统，也就不能从从系统中发现更多的其他可能性。\n后记 ”不识庐山真面目，只缘身在此山中“。 ”当局者迷，旁观者清“。 学会跳出框架思考，会给我们带来更多的视角，看见不同的世界，提高我们的视野与格局。 ", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/think-outof-box\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/cryptocurrency_antifrangible\/": {
        
        "title": "谈谈数字货币的反脆弱性",
        "tags": ["BlockChain",],
        "content": "定义 首先我们来看一下反脆弱性的定义。这里直接借用：\n 有些事情能从冲击中受益，当暴露在波动性、随机性、混乱和压力、风险和不确定性下时，它们反而能茁壮成长和壮大。不过，尽管这一现象无处不在，我们还没有一个词来形容脆弱性的对立面。所以，不妨叫它反脆弱性（antifragile）吧。\n 接下来我们来探究一下数字货币反脆弱性体现在哪些方面？需要说明一下这里的数字货币是指比特币和以太坊。\n具体如下：\n 构建在坚实的科学基础之上 强大的抗打击能力 去中心化组织 保持开放性 开拓独特性并保持领先 超越主权资产配置  构建在坚实的科学基础之上 比特币与以太坊都是构建在数学、密码学、计算机科学等基础之上。以比特币为例，比特币的技术由密码学、分布式帐本、PoW共识、P2P等组成。这些技术都得到无数次实践证明或者简单可靠。正是因为有这些科学基础，整个比特币系统一直可靠运行，没有出现一笔交易错误。\n强大的抗打击能力 以比特币为例，比特币具有很强的抗打击能力。比特币曾被媒体宣布死亡近400次，被部分政府定义为非法，打击比特币交易，自身生态也遭受到交易所被盗、比特币分叉之争等重大事故，但是到了现在，比特币的链上交易依然活跃，始终稳居加密货币王座，同时也是每个月开发更新最多最频繁的加密货币。\n去中心化组织 比特币节点网络是一个去中心化组织，类似于海星，具有极强的生命力：\n 海星这种生物是没有头的，它的智能控制分布在肢体的各个部分，砍掉海星的一条手臂，这个手臂可以演化成另一个海星。海星就是一个去中心化的组织系统。\n 比特币网络由千千万万的节点（矿工）组成，这些节点维护网络安全和共识账本，即使一部分节点掉线甚至退出，也不影响比特币整个网络的运行，整个网络具有极强的高可用性。同时这种多个节点运行的模式，也有利于对抗攻击。\n保持开放性 无论是比特币还是以太坊都有很好的开放性，其开放性体现如下：\n 节点自由加入与退出 代码开源 社区开放，支持各种BIP与EIP，促进比特币与以太坊不断进化  开拓独特性并保持领先 独特性意味着不可替代性，并且会拥有独特性带来的先发优势。\n比特币是数字加密货币的鼻祖，同时也是第一个抗通胀的数字资产，是当之无愧的数字黄金，从诞生开始一直保持市值第一，在整个熊市过程中比特币的所占的市值份额是增长趋势。\n以太坊首先实现智能合约，并一直保持最大智能合约平台。\n超越主权资产配置 现在国际形势变化多端，中美关系降温明显，世界经济这些年的发展离不了经济全球化。在政治上全球化协作倒退的今天，已经全球化的数字货币正好可以抢占这一倒退空出的空间。毕竟长期来看，经济全球化是不可逆的趋势。数字货币可以在全球范围内实现了货币自由（从另一个角度数字货币提供一种新的自由方式：货币自由）。\n资产配置的需要 现在由于大数据的发展与应用，富人的钱基本处于透明状态。这时候数字货币的匿名性与抗监管满足这些人的需求。\n后记 说明一下，虽然数字货币价格波动范围较大，但是从一个货币的角度来看数字货币具有很强的反脆弱性。个人投资由于价格波动大而出局，体现了数字货币系统的遍历性。\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/cryptocurrency_antifrangible\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/covid-19-symptom\/": {
        
        "title": "分享：一图了解新型冠状病毒的症状有哪些",
        "tags": ["Life",],
        "content": "新型冠状病毒（Covid-19）在全球的传播与感染速度有一定的控制，但是并没有结束。全世界累计确诊已经超过了500万，累计死亡人数超过了30万。新型冠状病毒是数十年来最危险，最棘手的新型病毒性之一。它可以攻击体内几乎所有器官，并可能造成毁灭性的伤害。\n下面我们看一下美国发布的新型冠状病毒的症状有哪些？\n上面这张图并没有包括中国前一段时间发布新型冠状病毒可能攻击男性的生殖系统的内容。\n这些导致这些器官的症状的原因并没有完全的科学解释，医疗界还在研究中。新型冠状病毒是一个新型的病毒，人体是一个复杂的系统，在短短几个月弄清楚其中的原理也是不太现实。\n关于美国发布的这个新型冠状病毒的症状，个人认为还是具有很大的参考价值：\n 美国的感染人数超过了160万，全球第一，有大量的数据和案例提供研究，大量的样本保证其可靠性 这个新型冠状病毒的症状出自美国顶级大学与科研机构之手（当然也是世界顶级，要承认事实） 美国开放性的言论与研究环境  另外全球疫情在全球经济落后，医疗不发达的国家和地区更是难以应对，这会是全球的防控疫情最大的不确定，典型的例子就是巴西，巴西确诊数已经仅次于美国，居于世界第二。\n参考  Coronavirus May Be a Blood Vessel Disease, Which Explains Everything 金银潭出院新冠患者追踪：超 7 成半年后仍有症状  ", 
        "url": "http:\/\/myself659.github.io\/post\/covid-19-symptom\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/book-skin-in-the-game-how\/": {
        
        "title": "读书笔记:《非对称风险》",
        "tags": ["Read",],
        "content": "首先了解一下作者：纳西姆·塔勒布，研究不确定性的专家，华尔街明星交易员。他先后出版“不确定性”四部曲：《随机漫步的傻瓜》、《黑天鹅》、《反脆弱》和《非对称风险》。读完《非对称风险》这本书，你发现作者是一个直言不讳的真性情中的人，在书中直接点面道姓的怼名人（包括巴菲特）。\n书中精句不少，例如这句：\n 你永远无法说服一个人他错了，只有现实才能教育他。\n 什么是非对称风险？ 市场参与者所承担的风险和收益是不对称的。塔勒布把由此引发的风险叫做“非对称风险”。典型如2008年美国的金融危机的华尔街精英们，他们玩的是自己赚钱，民众买单的勾当。在生活中一些银行的业务员只管放长期贷款，等货款到期的时候，他早就离职不干了，后面出现了什么债务风险，他一点责任都不用担，只管放货拿提成。\n有哪些非对称风险？ 书中提到非对称风险分为以下几类：\n 信息不对称 权力和责任不对称 少数派主导 理论与实践不对称(书中未明确提出，个人总结)  信息不对称 信息是生活的基础元素，如同空气。信息不对称随处可见。中国大部分人的信息不对称都受到防火墙的影响。\n在经济活动中最常见就是交易双方一方比别一方掌握的信息更多，具体例子如书中提到的罗得岛粮食的价格。\n权力和责任不对称 最典型例子就是书中提到西方干涉主义。现实中的例子就是伊拉克、叙利亚与利比亚等受到西方的干涉行动，最终给当地人民带来了巨大苦难。但是这些西方国家动用强权对别国进行干涉，却根本不需要为自己的错误买单，不用承担任何责任，甚至标榜自己了“成功赶跑了独裁者”。\n少数派主导 只要人群中有3%~4%的顽固少数派，那么，最终整个群体的人都会服从少数派的偏好和选择。生活中最典型的例子：一桌子人聚会吃饭，都用本地方言聊天。这时候来了一个远道而来的客人，他不会说本地话，只会说普通话。为了能让他听懂，结果一桌子人全部改用普通话聊天。\n理论与实践不对称 现实是不确定性，现实是一个复杂系统，理论或是出自实验，或来自逻辑，理论视角有限，但是现实是时间的产物，是无数动力相互作用的结果，同时结构复杂。而所有的实践都是基于现实，可以说现实是实践的环境。现实比理论的环境复杂多了。没有注意到理论与实践不对称在军事上最典型的例子就是赵括纸上谈兵，导致40万赵军被坑杀，成就了白起成为战国战神的神话。\n如何应对非对称风险？ 风险会一直存在，非对称风险也会一直存在。那么我们如何应对非对称风险？这也是我们读这本书最终目标。\n避免思考三大坑 识别风险需要思考，思考要注意避免以下三大坑：\n  只考虑静止的状态，而不考虑动态的机制 思考是低维度而非高维度的 只想到了采取什么行动，而没有想到行动本身会有反作用   避免思考三大坑，才能减少识别风险的错误。\n识别非对称风险 首先看一张书中总结一张图：\n识别风险还要注意以下几点：\n 区分波动和风险，防止成为非对称风险的教条主义者 重点关注那些带来不可逆转的伤害的风险  识别风险，才能应对风险。\n生活中有各种推荐买房和推股的人，他们都会告诉你推荐你买的房子会涨和精选的股票也会让你获利，但是他们都没法证明他们自己入场了。他们的信息隐藏了非对称风险，或者这些信息就是假消息。\n学习与应用概率理论 随机无处不在，随机无时不在。随机带来不确定性，不确定性需要用概率来描述，应对不确定性需要概率理论来指导。\n那我们还是先看几个概念：\n上图有两个重要的概念。\n集合概率：100个赌徒在1天时间里的成功概率\n时间概率：其中一个赌徒在100天的时间内赌运\n平均斯坦：一个事物的过程主要由平均值主导，很少有极端成功或失败的例子（比如牙** 医的收入）。个体不会对整体造成很大的影响，它也被称作“薄尾”风险，也是高 斯分布的一种。\n极端斯坦：在一个随机过程中个体会对总体造成巨大的影响（比如作家的收入），它也 被称作“胖尾”风险。它包含分型、幂律等分布类型。\n遍历性：在本书的语境下，遍历性是指对一群人在同一时间的统计特性（尤其是期望 ）和一个人在其全部时间的统计特性一致。集合概率接近于时间概率。如果没有 遍历性，那么观测到的统计特性就不能应用于某一个交易策略，如果应用的话， 就会触发“爆仓”风险。\n结论：\n  越高频越重要。如作为一个程序员你每天要用电脑，那么你的电脑一定要配置好。（每天重复就是时间概率上的高概率）\n  永远不要将倍增的、系统性的胖尾风险和不倍增的、特殊的薄尾风险相提并 论。\n  概率越高，确定性越高，也就越可靠，可靠的事物具有长期的优势，这是一种概率上的优势的体现。\n  不断重复地暴露在风险之中，无论多么小的概率的危险，最终都会发生。\n  说出你的想法，付出行动，承担风险。just do it！\n  风险共担机制  你愿意为一个事物承担多大的风险，揭示了你对该事物的信任程度。\n 常见风险共担机制：\n 华尔街银行家来说，风险共担就是要让他们自己拿出真金白银，和客户的资金绑在一起进行操作 IBM CEO郭士纳规定：高级经理必须自己掏钱购买一定数量的IBM股票，才可以获得公司的股票期权。郭士纳相信，高级经理们只有自己真正投入了成本，才可能真正关切公司的命运。并且同时自己也以身作则，在上任之初就从公开市场上买入了IBM的大量股票 一些投资人要求创业者要求投入资金，并且进行对赌 投名状，典例例子就是《水浒传》里的王伦要求林冲入伙前要以杀人方式纳投名状 两个人结婚，共同生活也共同应对未来生活的风险 欧洲的贵族由于承担了对其领地上平民的保护的义务和风险，才换取了自己的贵族地位。如果你不能为人民承担风险，那么你无法成为他们的领袖。  总之，风险共担就是全身心投入，享受收益也承担风险。\n审慎原则，保持理性 审慎原则就是小心求证，宁可错过，也不要犯错。这一点特别在投资领域很实用，无论股票还是基金每天都有新的机会；审慎原则是追求高的确定性，在投资方面就是对大部分机会说不。\n保持理性的最好方式就是一个清晰明确的目标，而这个目标就是：\n 真正的理性，就是避免系统性毁灭。\n  所谓理性就是首先保证自己所在的集体生存更长时间。\n  要赚钱，你首先得活得长。\n  要防止自己成为系统遍历性的牺牲品。\n 致知如行，知行合一 致知如行，知行合一，这是中国古代的智慧的精华之一，也是应对理论与实践存在不对称风险最好的方式。\n在岸上永远学不会游泳，学习再多的游泳知识都不能变现，基于连个测试的机会都没有。\n在生活中很多人都面临这样一个困惑：为什么你听过这么多道理，却依然过不好这一生？其实道理与现实，理解与做到并不是一回事。\n谨记：空谈无用。少说话，多做事，先做再说，宁可只做不说也不要只说不做。\n后记 《非对称风险》这本书内容分散，不系统，但是角度新颖，让人大开眼界，对于概率的理解让人受益匪浅，整本书有充满实用主义和实干主义气息，值得精读。\n参考  暴跌中的大赢家：塔勒布大弟子狂赚40倍的秘密  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/book-skin-in-the-game-how\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/how-to-learn-fast\/": {
        
        "title": "关于快速学习的思考",
        "tags": ["学习","成长",],
        "content": "在知识经济与日新月异的时代，学习的重要无须多言。这个时代正在惩罚不学习和不会学习的人。\n从整个知识体系上来看，如何学习属于元知识，属于基础知识。越基础越重要。那么如何培养自己的学习能力？在开始之前，我将学习能力划分两个子能力：\n 快速学习能力 深度学习能力  本文内容限定在如何提高自己的快速学习能力？提高快速学习能力有三个方面：\n Input：保证动力输入从而享受学习的过程 Process：正确的学习的路径与方法 Output：保证学习的有效输出  保证动力输入从而享受学习的过程 学习动力有多种，如兴趣爱好、虚荣心、利益、恐惧等多种因素。最佳的动力属于兴趣 爱好，这种动力持续时间长，对外界依赖很小，能够让人真正地享受学习的过程。享受学习才能快乐学习，快乐学习带来快速学习。越越享受学习的内容，那么掌握它的速度就越快。享受学习带来主动学习，这样会主动找学习的内容，主动花时间学习，主动提高学习的优先级。享受学习可以维持更长更好的学习状态。\n三千弱水只取一瓢饮。所以一定找到让自己的感兴趣的学习内容，并在学习过程中培养与强化兴趣。\n如果你要学习的内容正是你感兴趣，那么恭喜你，快速学习的第一要点你已经具备。但是生活不是事事如意，如工作需要学习的内容并不都是你感兴趣的内容。在这种情况，如何培养自己的兴趣呢？举一个例子，假如你对编程不感兴趣，但是你对经济股票感兴趣，你可以学习python分析股票的数据，这样的话，对股票的兴趣为你提供学习编程的动力。\n正确的学习的路径与方法 动力有保证，第二个问题来了：如何在动力的作用下，找到正确的学习路径和方法？而不是采用低效的方法和错误的路径来白白消耗珍贵的学习动力。\n关于学习的方法有很多介绍，这里推荐一个视频:The first 20 hours \u0026ndash; how to learn anything | Josh Kaufman | TEDxCSU。这个方法将学习分为以下四个要点：\n 分解步骤：把技能做最大程度的细分，分成若干小步骤。 充分学习： 对每个小步骤进行充分学习，以便进行灵活的练习，并在练习中自我纠正。 克服困难：克服在练习中出现的生理、心理或者情绪上的障碍。 集中练习—— 至少用20小时集中学习最重要的小步骤。  关于学习的路径的问题，这里以golang编程语言为例，其初略的学习路径：\n  先语法，再应用，然后原理 先实验，再工程，然后优化 先动手实践，再解决问题，然后是总结提高   详细的内容请参考文末的原文链接。\n保证学习的有效输出 输出就是测试学习的成果，能及时反馈与及时改进。\n输出是一种反馈。\n输出的评价有三个方面的指标：\n 学习内容的掌握效果 学习在经济方面的回报(如金钱与影响力) 学习动力是否在增强  关于学习内容的掌握效果最好的方式就是分享。很多人将分享作为一种学习的方法，我更看作是一种学习的有效输出。分享的内容是学习的产出，同时这种方式的产出效果属于最佳，除此之外分享会有带来影响力，影响力能够进一步增强学习动力。可知分享是将上面提到的三个指标为一体最佳学习输出方式。\n那么如何进行分享呢？向伟大的解释者费曼学习。学习用简单直观的方式解释并教会他人。伟大物理学家爱因斯坦也曾表示：\n If you can\u0026rsquo;t explain it simply, you don\u0026rsquo;t understand it well enough. 如果你不能简单明了地解释一件事情，那么说明你还没有很好地理解它。\n 分享可以先从写作开始如先从记录开始，写下自己的学习问题与感悟总结，然后再发表自己的博客上面，接着尝试分享给专业人士，进一步向普通大众分享。\n小结 学无止境。如果将学习比作一条永无止境的道路，快速学习可以让你走的更快，更远，经历更多的风景。\n参考  谈谈工作和学习中，所谓的主动性  ", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/how-to-learn-fast\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/coronavirus-change\/": {
        
        "title": "后疫情时代会有哪些变化",
        "tags": ["Economy",],
        "content": "现状 疫情从武汉爆发开始，到现在全球蔓延，全球确诊超过了226万。国内广州与黑龙江有复发的态势。但是全国基本上已经控制住，防控成绩也算相当不错（除武汉疫情初期）现在全国基本上暂时处于后疫情阶段。\n但是疫情还是处于不确定状态，个人判断理由如下：\n 对于病毒来源未知 对于病毒的了解与探究还在进行中 无特效药冶疗 疫苗最快1年才能上市 病毒是单链结构，会发生变异 是否在印度、非洲、南美洲等公共卫生条件较差的国家蔓延？ 秋冬季是否会第二次爆发？ 无症状感染者难以检查 各国能否相互团结？现在看来国际社会之间已经出现不少裂痕  疫情下的经济 中国第一季度GDP同比负增长6.8%。疫情期间80%的行业受到严重打击，受益主要是下面十几个行业：\n 医疗卫生行业 互联网医疗 养生保健行业 居家运动器材 AI产业 社区生鲜电商 自媒体 电商 在线培训与培训 远程办公软件 视频会议平台 VR、AR场景体验 网络游戏 在线影视 远程医疗  其他行业的基本都是受到冲击，这是不列举，列出受益的行业，希望大家能从上面的行业找到属于自己的机会。\n疫情后的趋势 人类历史战胜天花，黑死病，西班牙大流感。这次疫情终会过去。那么经历这次疫情整个世界有哪些新趋势呢？\n数字化增强 越来越多的行业会数字化，这有利于以下这些行业：\n 云计算平台 远程工作平台 AR/VR 游戏 视频 电商 区块链  远程工作会越来越多 疫情阶段全世界在测试远程工作，同时也在测试过程中优化远程工作，人们也在这次疫情养成远程工作的习惯。远程工作在知识服务这个领域会成为默认选项。\n自动化将会进一步发展 在数字化的基础上，自动化发展主要体现机器人技术与远程控制技术的发展。如美国在疫情期间使用医疗辅助机器人。\n在线教育 虽然在K12这块教育会回归线下，但是线上仍会保留。对于高等教育而言，大学生一般都 有一定的自制力和自学能力，线上教育的选择更多同时时间也会更加自由，相信未来会出现一些网络大学，这些网络大学能够像普通大学一样能够颁发文凭。\n全球化短期受阻，长期向好 2020年4月8日，中共中央政治局常务委员会提出：\n 做好较长时间应对外部环境变化的思想准备和工作准备。\n 这是近期的较确定的发展方向。如最近美国与日本鼓励企业将产业链搬出中国。这些国家的产业链依赖中国，实质上损害本国的经济安全，从长远上看迁部分产业如医疗与医药有利于提高本国的经济安全。但是信息的全球化却会加强，解决病毒问题需要全球协作，制定国际准则，监测和报告系统，并制定协调的对策和应急计划，这样有利于全球性问题的防范与处理。避免像这次疫情在二月份在武汉已经爆发，但是还是在3月份在全球蔓延起来。\n除此之外，全球化是超出一个国家范围的资源配置，在全球范围内最优化解决方案肯定会超出一个国家内的最优解决方案（局部最优并不是全局最优）。\n远程医疗 这次疫情期间，在医院发生不少聚集性感染的案例，未来在家就可以就诊是一个重要的发展方向。\n更多 当然疫情带来的变化，远不止上面这些。如人们生活方式与思考方式的改变。\n小结 疫情也许不会发生在你的身边，但它带来的改变却无处不在。提前思考与行动，有利于我们适应变化与把握机会。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/coronavirus-change\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E8%B4%A2%E5%AF%8C-%E7%94%9F%E4%BA%A7%E8%A6%81%E7%B4%A0\/": {
        
        "title": "生产要素就是财富",
        "tags": ["Think",],
        "content": "生产要素 生产要素是指在生产过程中所使用的各种资源，生产要素是实现生产过程的必要条件，可以通过组合使用来创造各种产品和服务。\n生产要素可以分下几类：\n 劳动力 资本 土地及自然资源 技术 数据  生产要素就是财富 生产要素是财富的载体，生产要素创造财富。\n一个人或者组织财富能力可以用下面的公式描述：\n财富能力 = 生产要素的供应能力 * 生产要素的应用能力 * 生产要素的产出能力 * 生产要素的产出再产出能力。\n所以，积累生产要素是致富的必经之路。\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E8%B4%A2%E5%AF%8C-%E7%94%9F%E4%BA%A7%E8%A6%81%E7%B4%A0\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/libra2-basic\/": {
        
        "title": "libra的妥协与机会",
        "tags": ["Blockchain",],
        "content": "2019年6月libra横空出世。我写了一篇关于libra的文章：Facebook libra是昙花一现还是星星之火。\n文章的提到：\n 对，Libra最大的问题就是监管。由于Facebook是一个全球化公司，涉及不同的国家，这些国家的法律与政策也不尽相同。这对于Libra就是一个巨大的挑战。至于很多人担心Libra会不会是昙花一现，直接被扼杀在摇篮？前面有USDT的先例。答案是不会的，美帝的民主制度，都会有一番流程与讨论，估计过程并不会一帆风顺。有了美帝的放行，在其他的国家开展也就铺平了道路。\n  如果Libra coin要挑战美元，那么美元就是Libra的最大竞争对手，这个挑战很大，近期应该不会出现。\n 想想小扎与libra的总负责人Mr Marcus在国会受虐。libra在监管方面却不是一帆风顺，可以说是饱经折磨。\nlibra在新发布的白皮书，放弃挑战美元，相反而是走上与美元相互成就的道路。说一句话题外话：人民币要加油！（人民币只有开启自由兑换，人民币的国际化才算开始。）\n妥协 libra在新版白皮书做了以下妥协：\n 提供单币种稳定币如美元与欧元 放弃未来向无许可公链的发展目标 加强合规，提高系统的安全性  总之，面对各国政府强监管的要求，libra选择断臂求生，主动拥抱美元，从挑战所有的法币，转而帮助美元维护霸权。\n机会 那么libra提供了哪些机会给大家呢？\n加入libra生态 加入libra生态有以几种选择：\n1、指定经销商；\n2、在金融行动特别工作组（FATF）成员司法管辖区中注册或获得许可的虚拟资产服务提供商（VASP，包括交易所和托管钱包），或是在FATF成员管辖区中注册或获得许可、并且根据此类许可或注册执行虚拟资产服务提供商活动（受监管的虚拟资产服务提供商）的虚拟资产服务提供商；\n3、已完成由 Libra 协会批准的认证程序的虚拟资产服务提供商（认证的虚拟资产服务提供商）；\n4、寻求通过 Libra 网络（无托管钱包）进行交易或提供服务的其他个人和实体。\n基本任何人都可以选择第四方式，这种方式基本上无资质门槛。\n参与基础设施建设 基础设施先行。参与基础设施如成为验证节点，验证节点是否有经济激励暂不可知，但是有很多信息优势与先发优势。\n技术先行 如果感兴趣可以学习一下rust。最重要是学习move，libra上线后基于move的智能合约有一个爆发的过程。\n研究集成libra的平台 libra是facebook主导，相信facebook旗下的app都会集成libra。这些app如instagram，whatapp， messager，facebook都是10亿级用户。各种新机会参考支付宝与微信支付。机会肯定不少。以太坊的一些成功应用都值得借鉴。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/libra2-basic\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/meditation-start\/": {
        
        "title": "我是如何学会冥想的",
        "tags": ["Life",],
        "content": "初识冥想 虽然以前也知道冥想，但是却没有对冥想产生什么兴趣。直到2018年去台湾遇到一个很有经历的人，先后在google，百度，阿里等公司从事互联网方面的工作，开过民航飞机，后面又回台湾在高校里读博士，同时英文也相当流利，与老外沟通毫无压力。除此之外，他还告诉我他的睡眠质量相当高，入睡超级快。而自己从小就入睡慢，虽然睡眠质量还算可以。于是我好奇地问他：你是怎么做到这么高的睡眠质量？\n他回答我： 我练习冥想，每年都去香港专门的参加一周的冥想练习，不带手机，与世隔离一周。\n他的回答激起我对冥想的兴趣。\n冥想的好处 光有兴趣还不行，得从中得到好处。那么冥想的好处有哪些呢？这里罗列如下:\n 冥想可以增强您对疼痛和痛苦的承受能力，如冥想增强个人平静的能力，即使面对混乱也能保持平静，增加过滤噪音的能力 冥想可以改变你的大脑, 提高大脑的能力，如冥想可以提高专注力 冥想可以减少不良情绪，如冥想可以减轻抑郁，压力，焦虑等 冥想有助力于身体健康，如冥想可以降低血压和心理压力 冥想让人更加快乐，如冥想过程的空灵和专注，会让人忘记烦恼，享受与身体对话的喜悦 冥想是一种低成本高收益的选择，如高质量的5分钟冥想相当于一个小时的睡眠  为自己找到好处的落脚点 上面的冥想的好处，我在一年前就知道，然并卵。我当时依旧没有学会冥想。直到这次疫情爆发，新型肺炎没有特效药，主要看个人的免疫力。这时候跑步与冥想成为我个人的增加免疫力的主要方式。严重的疫情成了我练习冥想的外界驱动力。于是在家开始练习冥想，慢慢地就学会了冥想，在这个过程中，个人注意力得到提升，入睡时间缩短到了半个小时以内，这些实实在在的好处，又让我继续坚持冥想，这是一个十分良好的正向循环。\n建立自己的冥想基本操作 人的大脑像一部永远不停运转的机器，很难停下来，冥想让大脑从mindful状态进入到mindless状态。对于任何初学者来说，实现mindless都是有困难的。那么如何建立冥想基本操作呢？具体分为几个问题来说明。\nQ：什么时候冥想？\nA：个人一般都是早上醒来就立即开始冥想。\nQ：在哪里冥想？\nA：床上，这样天气冷的时候也可以给自己盖个被子\nQ：冥想的姿势？\nA：类似于打坐即可，不用太死板，自己觉得舒服即可\nQ：冥想教程选择哪个？\nA：推荐用UCLA分享的免费冥想教程，除此之外今天发现keep上线冥想功能\nQ：冥想的时间多长？\nA：刚开始5分钟，后面慢慢到10分钟，20分钟\nQ：冥想如何避免不专注？\nA：找到专注的锚，建议刚开始专注于呼吸，如果出现注意力分散，不要在意，重新拉回注意力到呼吸即可\nQ：冥想用什么背景音乐？\nA：我暂时没有用背景音乐，背景声音倒有，是UCLA冥想课程的引导冥想的内容\nQ：冥想中间不能坚持怎么办？\nA：将思绪拉回到呼吸，至少保证眼睛闭着，除了轻微的动作，身体基本无其他大的动作\n养成习惯 自己写的代码6个月不看，差不多相当于是新的代码。冥想也需要不断的练习，保证不断地练习最好的方式就是养成习惯。\n习惯建立现有生活方式基础最好也最容易建立成功，个人觉得养成冥想的习惯最好的方式就是锚定自己的生活习惯。如早上起床前和晚上睡觉前这两个时间段进行冥想就是非常好的选择。\n小结 从兴趣出发，发现好处，落到自己的实处，做好每一次冥想，从中感受冥想，进而获得平静喜悦淡定，锚定平时的生活规律，从而渐渐地养成冥想的习惯。\n开始冥想吧，这是一个让你受终生的生活方式与习惯。开始并坚持一段时间，你会找到冥想的感觉，并享受冥想。\n", 
        "url": "http:\/\/myself659.github.io\/post\/meditation-start\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/invest\/invest-ruixin\/": {
        
        "title": "关于投资几点感悟",
        "tags": ["Economy",],
        "content": "背景 首先，吃一下瑞幸的瓜，表示对作空机构的敬意：\n 调研机构为了证明瑞幸咖啡造假，派出92个全职和1418个兼职调查员，在全国900多家门店蹲点，收集25843张购物小票，大量内部微信聊天记录，关联人与企业的工商信息，并录制11260个小时的门店录像，得出了瑞幸造假的判断，就这么牛逼。\n 站在对立面的一些买了瑞幸的股票投资者就惨了。瑞幸一天跌了75%。\n惨不忍睹，与数字货币中的山寨币的跌势有的一拼。如果从按照52周最高点算，差不多是跌了90%。\n关键是瑞幸后面还有一堆麻烦，业绩作假，面临法律的制裁，甚至面临退市的风险。\n一个做空，一个做多，同一个股票得到回报相有差十万八千里。\n做空的投资者上天堂，做多（持有股票）的投资者下地狱。\n一个追究事实，一个忽略事实。\n一个真干实操，一个纸上谈兵。\n一个成为收割的镰刀，一个成为被收割的韭菜。\n对于做空的来说，功夫不负有心人。\n对于做多的来说，只能吞下自己判断错误的恶果。\n下面是个人对于股票投资一点看法与感悟，本人从2015年进入股市，差不多也有五年的股龄。\n保持独立性 做不到独立性不要去投资。保持独立性才是投资第一要求。保持独立性是一个合格投资人的体现，高正确率的独立性是一个优秀投资人的体现。\n独立性体现以下几个方面：\n 独立分析与调研 独立决策 独立操作 独立承担后果  风可以吹走一张白纸，却不能吹走一只蝴蝶。因为生命的力量，在于独立自主，在于独辟蹊径，在于不顺从。纸的在哪里由风来决定，而蝴蝶可以决定在哪朵花上停留。\n所以 投资要保持独立性。\n不懂的不要投资 投资其实是认知的体现。\n你永远赚不到超出你认知范围外的钱。除非你靠运气，但是靠运气赚到的钱，最后往往又会凭实力亏掉。\n你所赚的每一分钱，都是你对这个世界认知的变现，你所亏的每一分钱，都是因为对个世界认知有缺陷。\n理性决策而不是情绪驱动决策 就拿瑞幸为例，可以问自己一系列的问题：\n瑞幸的商业模式是什么？\n瑞幸的商业模式可持续吗？\n瑞幸的商业竞争是谁？有什么优势？\n瑞幸的用户忠诚度高吗？\n瑞幸的管理层有了解与调查吗？\n为什么外国人不怎么喝茶？中国人却会养成一个喝咖啡的习惯？\n为什么要喝瑞幸咖啡而不是喝各种奶茶呢？\n瑞幸的市场是面向14亿中国人，这个转化率是怎么样？中国只有1亿左右的坐过飞机，在这些人中有多少人有喝咖啡的习惯？有多少可以养成喝咖啡的习惯？建立这个习惯的成本是多少？难度是多少？\n。。。\n保持耐心，追求高确定性的机会 股票是一个波动的市场，机会很多，保持耐心，投资那些高确定性的机会，这样可以减少风险。\n抵制各种赚钱的诱惑，保持专注，深入研究一个公司，吃透行业，熟悉各种操作。\n沃伦·巴菲特说过：成功人士和真正的成功人士之间的区别就是后者几乎对所有的投资机会说“不”。\n投资追求的是做正确的事而不是做更多的事。\n仓促决策，往往容易忽略一些重要的信息，从而影响决策的质量。\n保持敬畏 市场不可预测，市场是多种力量相互作用的结果。\n市场深不可测，且复杂多变。\n市场相互影响，利益盘根错节。\n承认个人的渺小，做自己能力范围内的事情。\n小结 投资是认知的实践。不追求投资的收益最大化，而追求营利的最大确定性及本金的安全。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n参考  画皮瑞幸 为什么爆的是瑞幸？  ", 
        "url": "http:\/\/myself659.github.io\/post\/invest\/invest-ruixin\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/github-hack\/": {
        
        "title": "github被攻击，程序员该怎么办",
        "tags": ["编程",],
        "content": "2020年3月27日，全世界最大的同性交友网站github被攻击了，连正常的首页都打不开。\nHttps并不是100%安全 github被攻击说明Https并不是100%安全，Https也有自己的阿喀琉斯之踵-Https证书。Https不能解决以下五种情况的攻击：\n 证书颁发机构被入侵 攻击任何证书颁发机构附近的路由器 攻击证书颁发机构的递归DNS服务器 攻击网络协议如TCP或者BGP 证书颁发机构作恶，恶意修改与替换证书  这五种攻击方式不是攻击证书就是攻击证书的分发网络路径与协议。\n即然https并不是100%安全，那么怎么应对https证书攻击呢？\n发现网站Https证书被攻击 首先第一步发现网站Https证书被攻击。拿这次github被网站Https证书被攻击为例，github证书被攻击时，在chrome浏览品上访问github，会提示如下错误：\n从上图可以看出，不是通常HTTP的错误码，也不是超时错误，而是直接提示了证书错误。\n正常的Https证书是这样的：\nHttps证书被攻击如何正常的访问github 由于github证书出现了问题，用户是无法解决的。那么怎么正常访问github呢？\n由于这类攻击往往具有地域性特点，如这次攻击大部分发生在国内，可以将本地的github访问流量通过代理导到其他没有受到攻击的地方，再由代理返回访问结果。科学上网就是属于这类方式。由于各种原因，这里不展开说明。\n如何解决go get不能正常工作 作为一名golang程序员，发现go get出现错误：\n出现上面的问题的原因同样是因为github网站的证书被攻击导致。解决方法是不走Https，走ssh下载github的代码库。在终端上进行如下配置即可：\n1  git config --global url.\u0026#34;git@github.com:\u0026#34;.insteadOf \u0026#34;https://github.com/\u0026#34;   查看配置结果如下：\n1 2 3 4 5 6  $ cat ~/.gitconfig [user] email = myself659@163.com name = myself659 [url \u0026#34;git@github.com:\u0026#34;] insteadOf = https://github.com/   小结 Https证书虽然被攻击，但是互联网有去中心化特点，可以改变网络访问路径来避免问题。 Https证书被攻击，影响是http协议，可以换成ssh协议来解决git下载的问题。 总之，遇到问题对症下药，也要跳出框架，think out the box，从另一个角度或层次来解决问题。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/github-hack\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/data-avoid-leak\/": {
        
        "title": "提高个人隐私数据安全的几点建议",
        "tags": ["Internet",],
        "content": "最近，爆出了新浪微博用户数据泄漏的事件。虽然微博的安全技术总监罗某某拒不承认存在安全问题，但是想想李文亮医生的经历，这个事情真不能忽略。 李彦宏说过：“中国人更愿意用隐私换便利”。这也验证一句话：互联网上无隐私。 虽然互联网上无秘密，但是个人不能放弃保护自己的个人隐私，该行动一下，还得行动一下。不要放弃抵抗。\n下面是个人一些建议：\n最小授权原则 个人隐私数据属于个人。\n但是现在所有互联网应用都在收集个人数据来实现商业的目标如更好地销售广告。\n以个人为例，我注册一个人新浪微博，就只用一个邮箱。大部分也做不了大 V和网红，不需要将个人其他的信息爆露给微博。\n一些应用与网站直接使用微信与qq授权，不要去注册新账号。\n手机app申请权限的时候，根据最小授权原则，满足基本应用即可，不轻易给录音，像机，访问存储的权限。\n远离不靠谱的应用与平台 如果我们将信息交给一些不靠谱的应用与平台，这些应用与平台保护用户信息能力不足，那么它被黑客攻击，内部泄漏的可能性会更大很多。\n举一个例子，疫情期间，各个省市分别推出自己的健康码App，如皖事通，宁归来等等。这些app背后开发能力从其用户体验也看得出来十分堪忧。由于无法避免需要健康码，建议直接用微信与支付宝上面的健康码功能。\n不乱点击URL。 远离无HTTPS加密的网站。\n使用chrome浏览器，帮你识别一些网站的风险。\n不要使得一些缺少安全保护或者安全保护能力弱的邮箱平台。如自建的个人邮箱。\n不要使用一些小厂商的VPN产品。\n保护密码 第一点：不要使用同一个密码，使用同一个密码，如果其中一个网站泄漏，往往其他的所有网站都受到安全的威胁。\n第二点：密码分级管理。重要应用的密码与资金密码要重点保护。\n第三点：不要使用简单的密码，如123456等常见的密码\n第四点：开启two-factor authentication\n第五点：拥有一个自己的密码生成公式或者规则\n利用工具 有条件的情况，密码管理可以1password。\n使用chrome浏览器，并安装HTTPS Everywhere，GHOSTERY，GOOGLE PASSWORD CHECKUP等等。\n安装杀毒软件和开启防火墙。\n手机 如果可以推荐使用苹果手机。Android手机各种app安装的时候要各种权限，管理难度高，用户体验差，应用的审核也没苹果应用商店的标准高。相反苹果应用商店上的app会守规矩多了。\n在一个较高安全系数的环境中，使用应用的安全系数也会提高很多。\n保护好的手机，如手机与sim卡绑定，避免sim卡转移攻击，具体参考人生中最昂贵的教训：SIM卡转移攻击的细节。\n加强学习与增加安全意识 学习一些基础的安全知识，了解一下用户数据泄漏的一些案例，增加对不靠谱应用的识别能力。学习会增加安全意识，安全意识增加可以提前发现问题，并能及时防范。\n后记 虽然互联网无秘密，但是个人加强防范，有利于提高获取个人隐私数据的门槛，避免成为第一批数据泄漏的受害者。相反，如果你比一般人更好的保护你的隐私数据，别人数据泄漏的事件相当是你的吹哨人。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/data-avoid-leak\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/howmuch-us-stock-willfall\/": {
        
        "title": "一周经历两次熔断，美股会跌多少?",
        "tags": ["Economy",],
        "content": "进入话题之前了解一下美股指数熔断机制。\n 美股指数熔断机制的基准指数为标普500，单项跌幅阈值为7%、13%、20%。当指数较前一天收盘点位下跌7%、13%时，全美证券市场交易将暂停15分钟，当指数较前一天收盘点位下跌20%时，当天交易停止。\n 再来看一下美股指数熔断的历史。\n  1997年10月27日，道琼斯工业指数暴跌7.18%，收于7161.15点，这是熔断机制在1988年引入之后第一次被触发。\n  2020年3月9日，受2019冠状病毒病疫情和油价崩盘影响，3月9日上午9点34分，标普500指数开盘后跌7%触发第一层熔断机制，暂停交易15分钟，这是美股历史上第二次熔断。\n  2020年3月12日开盘后，标普500下跌，触发7%的熔断点，这是美股历史上第三次熔断，收盘时，美股三大指数都下跌近10%。\n  人生“有幸”，大家在一周内见证两次美股的熔断。\n美股一周内熔断两次，全球的经济形势加上现在新型冠状病毒在全球已经开始流行，对于经济供应和需求是全方面的打击，这标志美股的下跌周期已经开始。\n明确了美股的下跌趋势，那就有下面两个问题：\n 美股会跌到多少？ 下跌周期会是多少？  问题的答案哪里找？以史为鉴吧。先看一下道琼斯指数的历史曲线图：\n从上图我们只能看到美股涨跌交替，总体不断增长。下面具体看一下最近两次大跌，也就是2008年的金融危机和2000年互联网泡沫。\n2008年的金融危机道琼斯指数下跌情况如下：\n从上面两图可以看到2008年的金融危机期间下跌从2007年10月开始，到2009年2月触底发弹回升，指数从17245.35下降到8609.71，下跌幅度为50%，下跌周期为16个月。\n2000年互联网泡沫道琼斯指数下跌情况如下：\n从上面两图可以看到2000年互联网泡沫期间下跌从1999年12月开始，到2002年9月触底发弹回升，指数从17671.07下降到10848.87，下跌幅度为38.6%，下跌周期为33个月。\n最后再看一下让人闻风丧胆的大萧条时期的股票市场情况。\n从上面两图可以看到大萧条期间下跌从1929年8月开始，到1932年7月触底发弹回升，指数从5686.69下降到814.82，下跌幅度为85.6%，下跌周期为36个月。下跌幅度不是腰斩而是膝斩，下跌时间长达3年，为美股历史上所有下跌之最。\n现在阶段抄底美股，话不多说，送下面这张图，自求多福：\n上面的分析是基于历史的参考，现在情况与历史任何一次美股下跌不一样，具体分析美股的走势要结合多方面的因素分析，如新型冠状病毒在全球开始流行，全球化各国相互影响，各国面临不同问题（股市泡沫、债务杠杆、金融机构风险、社会撕裂等）与应对策略（货币政策、财政政策、抗疫方式等）。\n本文最重要的话是：不要试图现在抄底美股，特别是指数，对于个股来说总体上危险大于机会。保持耐心，让子弹飞一会儿。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/howmuch-us-stock-willfall\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/weimeng-del-data\/": {
        
        "title": "微盟删库事件复盘与思考",
        "tags": ["研发管理",],
        "content": "事故 先简单看一下整个事故的粗略时间线。\n2月23日，微盟服务出现故障。商家商城、小程序均无法登录。\n2月25日，微盟紧急恢复了核心业务的线上生产环境，新用户使用不受影响，并提供老用户临时过渡方案，确保商家在数据暂时没有恢复的情况下可以正常经营。\n2月28号，微盟表示已经恢复了微站产品的所有数据，并已导入到商户店铺，新老用户使用将不受影响。\n3月1号微盟表示数据已全面找回，并公布商家赔付计划。\n影响 首先看股市反应：数据丢失，微盟损失惨重。在2月25日正式披露数据丢失后，微盟的股价连续三日大幅下跌，从6.2下跌到4.8差不多跌了25%，整个市值蒸发20亿元以上。\n除此之外，本次事故对微盟的社会公信力有很大的影响，说明整个企业在运营、管理和技术安全上是有问题的，对企业的社会形象和商业业态都会遭受大家的质疑。\n由于微盟整个系统的宕机，导致商家与消费者都不正常运营，部分可能直接停业，对整个社会的经济系统也有一些冲击与影响。\n问题 作为一名局外人，对这次微盟删库事件，个人有以下问题：\n 运维贺某是由于什么原因作出删库的事件？ 贺某删除了哪些数据？贺某删除整个生产环境的数据包括备份数据吗？ 微盟是数据架构是如何设计？让一个运维能够删除整个生产环境的数据？ 微盟的数据物理分布是如何设计的？ 微盟运维权限是如何管理？ 微盟离线备份数据是备份方式是怎么样？是增量还是快照方式？ 微盟离线备份数据为什么花了五天都不能够恢复？离线备份数据有多少？ 众多离线备份数据是如何恢复的？ 微盟离线备份数据是否完整？ 微盟离线备份数据恢复后如何验证？如何检查恢复数据与备份数据之间的一致性？ 微盟离线备份数据恢复是否相互依赖？ 微盟离线备份数据（毕竟微盟成立于2013年）是否兼容？如与应用程序兼容？ 微盟离线备份数据恢复的速度的瓶颈在哪里？网络带宽？硬盘IO? 数据不能并行恢复？验证困难？ 从备份数据到线上数据恢复，是恢复几份数据？如何保证这几个线上数据的一致性？ 如何防止误操作？ 如何量化赔偿商家的损失？ 如何快速检测运维违规操作并迅速报警？ 是否知道技术风险的存在，由于存在侥幸心理和事不关已，多一事不如少一事，放过这个潜在的风险？  经验教训 微盟经过七天七夜的抢救，成功救回了全部数据，从结果上来看是一次成功的抢救。但是数据恢复的时间太长，服务高可用直接打到99%以下。\n事后微盟发布了改进计划，这些改进计划有针对性回答我上面一些问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  措施一：数据安全管理机制全面加固与整改，加强运维平台治理 1、完善数据安全管理制度（涵盖权限、监控、审计方面），严格执行授权审批制度； 2、使用腾讯云CAM权限系统进行云资源管理，严格执行分级授权和最小集权限制度，对高危险动作执行二次授权制度； 3、建立科学、高效、安全的网络策略，对开发环境、测试环境和生产环境进行严格隔离；使用腾讯云堡垒机替换自建堡垒机，进行细粒度权限分级和授权管理，同时严格审计堡垒机操作日志，发送安全审计报表； 4、加强运维安全流程学习，职业道德学习，法律学习等。 措施二：加强灾备体系的建设，做到多云异地冷备 1、建立多云灾备体系，在北京、上海、南京等地区建立全备份的冷备系统架构； 2、借助腾讯云的IAAS的底层服务能力，建立高可用的同城双活架构； 3、云上所有的云主机，启用每天的快照策略，保证全量和增量备份； 4、所有非结构化数据，使用腾讯COS对象存储系统进行归档保存，启用COS的多异地复制功能，数据存放多地，并且COS 冷存储，确保数据只增不减； 5、建立月、季度级别的定期演练机制和制度 。 措施三：基础设施全力上云 1、借助腾讯云数据库MySQL的数据高可用和安全体系，逐步放弃自建数据库服务 ，迁移到腾讯云数据库（CDB），快速具备数据库跨可用区和异地灾备的能力； 2、黑石1.0物理机全面升级黑石2.0，全面使用云主机。   上面这些总结很到位，个人帮微盟补充一些：\n 学习netfix的企业文化中的第一条：招聘成年人。成年人不会作出对个人和公司双输的事件，成人有自己调整心态与控制情绪的能力。 学习netfix的实践，应用混顿工程，主动拥抱故障，提前演练与操作。国内阿里双11每年都要进行演练。 减少对人的依赖。在执行方面机器比人靠谱多了。  总结 总之，微盟这次删库事故是技术债与管理债长期累积不解决的结果。欠债不还，一定会在某个时间被某个黑天鹅事件引爆。\n这次显露出来的技术问题的本质是数据高可用性技术的不足。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/weimeng-del-data\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/find-what-todo\/": {
        
        "title": "在选择做什么之前，先问问自己这四个问题",
        "tags": ["成长",],
        "content": "在谈谈做事的原则提到做事的原则的基本原则。具体如下：\n 不要给自己设限 站在巨人的肩膀上 正确的方向 敏捷的行动  本文重点讨论如何选择做什么这一问题。不要给自己设限，这个主要是解决了选择范围的问题，不给自己设限，可以打破很多限制，为自己提供更多的选项。\n Quantity is a prerequisite to the selection of quality.\n 数量是高质量选择的先决条件。\n那么在不给自己设限解决了选择的数量问题，那么如何作出正确的选择呢？兵圣孙子说过：\n 知己知彼，百战不殆。\n 作出正确的选择需要在以下两个方面的认识：\n 认识自己 认识世界  在这两个方面问自己以下四个问题：\n 你喜欢什么？  你擅长什么？  世界需要什么？  别人付钱请你做什么事情？  一图胜千言。\n从上图可以明显看到我们应该做的核心事情就是这个四个问题的集合的交集，也是ikagai部分。\nikagai是一个日本词汇对应的英文翻译，对应的中文翻译是生活的目的（姑且这样吧，google告诉这么翻译）。\nikagai所指这个交集的事情从个人角度来看可以让自己发挥特长，享受乐趣，回馈社会，达成目标。从事情角度来看，这个事情得激情的投入，使命的担当，专业的能力，职业的态度，在这种情况下做成事情的概率更高，回报是自己需要，很容易形成正循环。\n以个人选择职业为例，当年毕业的时候，我告诉自己一定要做自己喜欢且擅长事情。所以毕业之后选择干的事情就是编程。到现在还在继续编程，每天学习，保持输入与输出。 虽然当年没有像ikagai这样的一个系统描述，个人也考虑到社会的需要。\n考虑现在这个发展情况与需求，在自己喜欢且擅长编程（在与同年龄的人群相比，自己这个领域能排进前top10%），选择编程这个工作对于职业发展来说是一个不错的选择。\nikagai这个方法不仅可以用于职业发展的选择，也可以用于指导生活。如何具体应用ikagai就是上面提到的问题，找出这些回答的交集。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/find-what-todo\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/golang\/donot-focus-programming-language\/": {
        
        "title": "别太在意编程语言",
        "tags": ["Golang",],
        "content": "背景 经常有人这样说：\n PHP是最好的语言 现在golang越来越吃香，好找工作 python学习的人越来越多，太难了  对于这些，我想说：别太在意编程语言。\n理由 别太在意编程语言，具体理由如下：\n 使用何种编程语言要根据业务需求来决定 选择编程语言与个人与团队偏好有关 编程语言只是工具 最重要是解决问题，满足需求 编程语言具有一定特定性，相反数据结构与算法，设计模式等基础知识与能力具有更好的通用性 多学习几种编程语言更好，何必纠结什么编程语言更好呢？  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/golang\/donot-focus-programming-language\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/stock-us-analysis\/": {
        
        "title": "通过数据分析预测股票价格变化靠谱吗？",
        "tags": ["Data",],
        "content": "前言 在投资美股，先从数据分析开始这篇文章解决两个问题：\n 从哪里找数据？ 如何得到这些数据？  在此基础这篇主要解决一个问题：以特斯拉为例说明如何利用这些数据预测股票价格的变化。同时关注一个问题：投入成本进行预测股票价格是否靠谱与必要？\n步骤 获取数据 直接调用api如下：\n1 2 3 4 5 6  import yfinance as yf tlsa_df = yf.download(\u0026#39;TSLA\u0026#39;, start=\u0026#39;2015-01-01\u0026#39;, end=\u0026#39;2020-02-16\u0026#39;, progress=False) tlsa_df.head()   绘制价格变化图 1 2 3 4 5 6 7 8 9 10 11  #plot %matplotlib notebook from IPython.core.interactiveshell import InteractiveShell InteractiveShell.ast_node_interactivity = \u0026#34;all\u0026#34; plt.figure(figsize=(10,6)) plt.grid(True) plt.xlabel(\u0026#39;Dates\u0026#39;) plt.ylabel(\u0026#39;Close Prices\u0026#39;) plt.plot(tlsa_df[\u0026#39;Close\u0026#39;]) plt.title(\u0026#39;Tesla Close Price\u0026#39;) plt.show()   得到从2015年起telsa收盘价格变化图：\n分析数据的统计特征信息 1 2 3 4 5 6 7 8 9  tsla_df_close = tlsa_df[\u0026#39;Close\u0026#39;] df_log = np.log(tsla_df_close) moving_avg = df_log.rolling(12).mean() std_dev = df_log.rolling(12).std() plt.title(\u0026#39;Moving Average\u0026#39;) plt.plot(std_dev, color =\u0026#34;black\u0026#34;, label = \u0026#34;Standard Deviation\u0026#34;) plt.plot(moving_avg, color=\u0026#34;red\u0026#34;, label = \u0026#34;Mean\u0026#34;) plt.show()   具体如下：\n处理数据 处理数据是为了满足模型的数据输入的要求。\n1 2 3 4 5 6 7 8  train_data, test_data = df_log[3:int(len(df_log)*0.9)], df_log[int(len(df_log)*0.9):] plt.figure(figsize=(10,6)) plt.grid(True) plt.xlabel(\u0026#39;Dates\u0026#39;) plt.ylabel(\u0026#39;Closing Prices\u0026#39;) plt.plot(df_log, \u0026#39;green\u0026#39;, label=\u0026#39;Train data\u0026#39;) plt.plot(test_data, \u0026#39;blue\u0026#39;, label=\u0026#39;Test data\u0026#39;) plt.legend()   这里将原始数据分为训练数据和测试数据。\n建立模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import os import numpy as np import pandas as pd import matplotlib.pyplot as plt from statsmodels.tsa.stattools import adfuller from statsmodels.tsa.seasonal import seasonal_decompose from statsmodels.tsa.arima_model import ARIMA from pmdarima.arima import auto_arima from sklearn.metrics import mean_squared_error, mean_absolute_error import math model_autoARIMA = auto_arima(train_data, start_p=0, start_q=0, test=\u0026#39;adf\u0026#39;, # use adftest to find optimal \u0026#39;d\u0026#39; max_p=3, max_q=3, # maximum p and q m=1, # frequency of series d=None, # let model determine \u0026#39;d\u0026#39; seasonal=False, # No Seasonality start_P=0, D=0, trace=True, error_action=\u0026#39;ignore\u0026#39;, suppress_warnings=True, stepwise=True) print(model_autoARIMA.summary())   得到模型参数如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  Performing stepwise search to minimize aic Fit ARIMA: (0, 1, 0)x(0, 0, 0, 0) (constant=True); AIC=-4980.147, BIC=-4970.040, Time=2.357 seconds Fit ARIMA: (1, 1, 0)x(0, 0, 0, 0) (constant=True); AIC=-4978.315, BIC=-4963.154, Time=0.297 seconds Fit ARIMA: (0, 1, 1)x(0, 0, 0, 0) (constant=True); AIC=-4978.308, BIC=-4963.147, Time=0.475 seconds Fit ARIMA: (0, 1, 0)x(0, 0, 0, 0) (constant=False); AIC=-4982.140, BIC=-4977.087, Time=0.189 seconds Fit ARIMA: (1, 1, 1)x(0, 0, 0, 0) (constant=True); AIC=-4976.958, BIC=-4956.743, Time=0.493 seconds Total fit time: 5.619 seconds SARIMAX Results ============================================================================== Dep. Variable: y No. Observations: 1158 Model: SARIMAX(0, 1, 0) Log Likelihood 2492.070 Date: Mon, 17 Feb 2020 AIC -4982.140 Time: 20:29:52 BIC -4977.087 Sample: 0 HQIC -4980.233 - 1158 Covariance Type: opg ============================================================================== coef std err z P\u0026gt;|z| [0.025 0.975] ------------------------------------------------------------------------------ sigma2 0.0008 1.84e-05 42.731 0.000 0.001 0.001 =============================================================================== Ljung-Box (Q): 43.17 Jarque-Bera (JB): 898.42 Prob(Q): 0.34 Prob(JB): 0.00 Heteroskedasticity (H): 1.84 Skew: -0.13 Prob(H) (two-sided): 0.00 Kurtosis: 7.31 ===============================================================================   对模型诊断 在进行预测之前先进行模型诊断。\n1 2 3 4 5  model_autoARIMA.plot_diagnostics(figsize=(15,8)) plt.show() model = ARIMA(train_data, order=(3, 1, 2)) fitted = model.fit(disp=-1) print(fitted.summary())   结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  ARIMA Model Results ============================================================================== Dep. Variable: D.Close No. Observations: 1157 Model: ARIMA(3, 1, 2) Log Likelihood 2494.608 Method: css-mle S.D. of innovations 0.028 Date: Mon, 17 Feb 2020 AIC -4975.215 Time: 20:30:59 BIC -4939.840 Sample: 1 HQIC -4961.866 ================================================================================= coef std err z P\u0026gt;|z| [0.025 0.975] --------------------------------------------------------------------------------- const 0.0002 0.000 1.274 0.203 -0.000 0.001 ar.L1.D.Close 0.1523 0.251 0.607 0.544 -0.339 0.644 ar.L2.D.Close 0.8380 0.235 3.562 0.000 0.377 1.299 ar.L3.D.Close -0.0097 0.032 -0.305 0.760 -0.072 0.053 ma.L1.D.Close -0.1689 0.249 -0.678 0.498 -0.657 0.320 ma.L2.D.Close -0.8311 0.249 -3.334 0.001 -1.320 -0.343 Roots ============================================================================= Real Imaginary Modulus Frequency ----------------------------------------------------------------------------- AR.1 1.0107 +0.0000j 1.0107 0.0000 AR.2 -1.1784 +0.0000j 1.1784 0.5000 AR.3 86.4971 +0.0000j 86.4971 0.0000 MA.1 1.0000 +0.0000j 1.0000 0.0000 MA.2 -1.2033 +0.0000j 1.2033 0.5000 -----------------------------------------------------------------------------   利用模型进行预测 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  fc, se, conf = fitted.forecast(129, alpha=0.05) fc_series = pd.Series(fc, index=test_data.index) lower_series = pd.Series(conf[:, 0], index=test_data.index) upper_series = pd.Series(conf[:, 1], index=test_data.index) plt.figure(figsize=(12,5), dpi=100) plt.plot(train_data, label=\u0026#39;training\u0026#39;) plt.plot(test_data, color = \u0026#39;blue\u0026#39;, label=\u0026#39;Actual Stock Price\u0026#39;) plt.plot(fc_series, color = \u0026#39;orange\u0026#39;,label=\u0026#39;Predicted Stock Price\u0026#39;) plt.fill_between(lower_series.index, lower_series, upper_series, color=\u0026#39;k\u0026#39;, alpha=.10) plt.title(\u0026#39;Tesla Stock Price Prediction\u0026#39;) plt.xlabel(\u0026#39;Time\u0026#39;) plt.ylabel(\u0026#39;Tesla Stock Price\u0026#39;) plt.legend(loc=\u0026#39;upper left\u0026#39;, fontsize=8) plt.show()   得到预测结果如下：\n分析预测结果 从上面预测结果可以看出：\n 预测结果与实际股票的上涨趋势相同，但是其中的路径还是相差很多，直接说明不适合指导具体交易，只能做为长期趋势判断的参考 这个模型还需要大量进行测试，如调整数据，调整模型参数  总结 这里是简单介绍一下利用numpy与pmdarima来预测股票变化趋势。实际上应用过程上需要充分的测试与验证，还需要大量的工作。像这上面这样的方式来预测股票价格是不靠谱的。有靠谱的模型也需要自己大量投入时间与大量的数据以及不断的验证与调整才可以的（别人靠谱的模型是不会免费分享的）。对于个人来说，投入这个成本是否值得又是另一个问题。对于大部分人来说没有必要投入这个成本通过机器学习来预测股票价格变化。这个进入门槛比较高（预测股票价格与预报天气是两回事），从中获得收益的门槛更高。\n下一篇会具体讨论一下预测股票变化的数学原理。再根据这些数学原理如何优化模型。\n说明：\n 本文只是进行一个过程展示 本文中的模型只供参考，不能用于实际的股票投资与交易。股市有风险，入市当小心。  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n参考  pmdarima 股市目前正面临冰山幻象 A Surprisingly Easy Strategy to Make Money in the Stock Market  ", 
        "url": "http:\/\/myself659.github.io\/post\/stock-us-analysis\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/math\/why-dividing-by-zero-is-undefined\/": {
        
        "title": "为什么0不能作为被除数？",
        "tags": ["math",],
        "content": "前言 学过了除法都知道这么一个道理：0不是被除数。\n到了后面编程，一直都会遵循一条原则： 0不能作为被除数，如果用0作为被除数，就会出错或者报异常。下面就是一个常见的例子。\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; 1/0 Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; ZeroDivisionError: division by zero \u0026gt;\u0026gt;\u0026gt;   把0不能作为被除数视为理所当然，却很少思考0为什么不能作被除数？\n原因 这里就简单看一下0为什么不能作被除数？\n证明很简单，主要就是反证法。\n 假设1/0 = ∞ 根据乘法与除法是互逆的，那么∞*0 = 1 这就与任何数与0相乘为0，相矛盾  总结 最后总结一下0这个数的属性：\n 任何数加减0的结果等于它本身。 任何数乘0的结果都等于0. O不能作为被除数  0存在很有意义，简单举几个例子：\n 0定义了一种基础，有了0存在，1的意义就很容易理解 0是正数与负数的分界点 0对应到应用可以是海平面，地面\u0026hellip;  总之，0是虚也是实的，0是抽象的也是实际的。\n", 
        "url": "http:\/\/myself659.github.io\/post\/math\/why-dividing-by-zero-is-undefined\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/stock-us-data\/": {
        
        "title": "投资美股，先从数据分析开始",
        "tags": ["Data",],
        "content": "背景 川大爷，常在twitter上吆喝美股多次创造历史高点。美股确实是一个资产配置的重要选项。\n在进入市场之前，研究先行，作好功课。\n获取数据 对于一个公司的股票的研究与分析有多个方面。这里只看股票的数据情况。 既然是分析数据，那么如何获取获取呢？\n这个问题可以拆为以下问题：\n 从哪里找数据？ 如何得到这些数据？  先从第一个问题开始：从哪里找数据？美股的数据来源来很多，这里我直接选择了yahoo财经数据。 主要原因如下：\n yahoo财经数据详细 yahoo财经可以直接通过api获取，使用方便 最重要地一点，yahoo财经的api没有被墙，如果被墙了，也支持代理 yahoo财经数据实时性也不错，除了交易日当天的数据无法获取，其他的都可以获取  下面我们就看如何调用api获取数据。不多说了，直接上代码。\n1 2 3 4 5 6 7 8 9  import pandas as pd import yfinance as yf tsla_df = yf.download(\u0026#39;TSLA\u0026#39;, start=\u0026#39;2020-01-01\u0026#39;, end=\u0026#39;2020-02-06\u0026#39;, progress=False) tsla_df.tail()   具体结果如下：\n获取ticker数据：\n1 2 3 4 5 6  %matplotlib notebook ticker = yf.Ticker(\u0026#39;TSLA\u0026#39;) tsla_df = ticker.history(period=\u0026#34;max\u0026#34;) tsla_df.head() tsla_df[\u0026#39;Close\u0026#39;].plot(title=\u0026#34;Telsa\u0026#39;s stock price\u0026#34;)   具体结果如下：\n这些数据都可以股票软件都可以看到。 对的，下面说一下通过api获取原始数据的好处。\n灵活地获取ticker数据：\n1 2 3  %matplotlib notebook tsla_df = yf.download(\u0026#34;TSLA\u0026#34;, start=\u0026#34;2020-02-01\u0026#34;, end=\u0026#34;2020-02-06\u0026#34;, interval = \u0026#34;15m\u0026#34;) tsla_df[\u0026#39;Close\u0026#39;].plot(title=\u0026#34;TSLA FROM 2020-02-01 TO 2020-02-06 \u0026#34;)   具体结果如下： 股票对比分析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  from plotly.offline import download_plotlyjs, init_notebook_mode, iplot import numpy as np import cufflinks as cf data_tam = yf.download( # or pdr.get_data_yahoo(... # tickers list or string as well tickers = \u0026#34;TSLA AAPL MSFT\u0026#34;, # use \u0026#34;period\u0026#34; instead of start/end # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max # (optional, default is \u0026#39;1mo\u0026#39;) period = \u0026#34;5y\u0026#34;, # fetch data by interval (including intraday if period \u0026lt; 60 days) # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo # (optional, default is \u0026#39;1d\u0026#39;) interval = \u0026#34;1wk\u0026#34;, # group by ticker (to access via data[\u0026#39;SPY\u0026#39;]) # (optional, default is \u0026#39;column\u0026#39;) group_by = \u0026#39;ticker\u0026#39;, # adjust all OHLC automatically # (optional, default is False) auto_adjust = True, # download pre/post regular market hours data # (optional, default is False) prepost = True, # use threads for mass downloading? (True/False/Integer) # (optional, default is True) threads = True, # proxy URL scheme use use when downloading? # (optional, default is None) proxy = None ) data_tam_close = data_tam.iloc[:, [3, 8, 13]] data_tam_close = data_tam_close.dropna() iplot(data_tam_close.iplot(asFigure=True, kind=\u0026#39;line\u0026#39;, title=\u0026#39;TSLA VS MS VS APPLE\u0026#39;, dimensions=(800,500)))   具体结果如下：\n一眼可以看出在2020年前任何一个时间点买入telsa并持有是一个正确的选择，投资收益远超过了苹果与微软。\n后记 本文主要解决了如何获取美股交易数据的问题，对于这些数据的分析及预测后面再展开。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/stock-us-data\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/kobe\/": {
        
        "title": "说说我眼中的科比",
        "tags": ["闲谈乱扯","NBA",],
        "content": "在高中的时候知道了NBA,看了比赛，知道了科比。多少年以来，篮球是我最喜欢的体育运动，科比是我最喜欢的NBA球星，估计也是我最喜欢的运动员。看NBA比赛是我日常的娱乐方式。\n但是他却以让人无法想像的方式离开了这个世界，同时带上了可爱的二女儿Gigi。想不到他这么早离开了这个世界。愿他们在天堂安好。\n下面说说我眼中的科比。\n科比是乔丹之后成就最高，影响力最大，球技最好的篮球运动员 科比在篮球领域的成就太多，简单列出部分如下：\n NBA总冠军：5次（2000，2001，2002，2009，2010） NBA总决赛MVP：2次（2009，2010） NBA全明星赛MVP：4次（2002，2007，2009，2011） NBA西部冠军：7次（2000—2002，2004，2008—2010） NBA最佳阵容第一阵容：11次（2002—2004，2006—2013） NBA最佳防守阵容第一阵容：9次（2000—2004，2006—2011） 生涯总得分：33643分，NBA得分榜第四 历史上连续入选NBA全明星赛次数最多：17次 NBA历史上单场第二高得分：81分 \u0026hellip; 太多了，这里不列了  号称在60E亿粉丝，各种代言广告，科比相比较于邓肯有更大的影响力。同时科比也有更多的争议的话题。在美国《Sporting News》评选NBA现役50大球星当中科比名列第一。\n科比拥有篮球史上最纯粹完美的技术，他是篮球史上最强的高难度投篮手，他经常不按合理的方式打球，他的投篮美如画，飘逸优雅，同时充满了一个超级杀手的气质。看他打球是一种享受，感受篮球的艺术与美。科比的NBA集锦是我最爱看的集锦。\n科比是一位优秀的父亲 科比当得了奶爸。\n科比耐心培养的女儿。\n科比营造了幸福的家庭。\n科比是成功跨界人士 从2016年4月退役之后，科比在投资，媒体，写作等领域取得优秀成就，是很多在这个领域的专业人士都很难企及的成就。\n先看投资领域。早在2013年，科比就创办了Kobe Inc，随后600万美元投资了运动饮料BodyArmor。BodyArmor是小众品牌，科比入驻一年后，该公司年销售额就从300万美元升至3000万美元，并在2017年达到2.35亿美元，2019年预计销售额将达到7亿美元。BodyArmor的市场占有率排在佳得乐与水动乐之后，位列全美第三位，份额是2%。除此之外，科比在美国纽交所（NYSE）宣布成立风险投资基金“Bryant Stibel”，资本金1亿美元，并宣布战略投资中国在线少儿英语教育品牌VIPKID。之后“Bryant Stibel”不断快速增长，截止去年9月份，Bryant Stibel资本+AUM（资产管理规模）已经超过了20亿美元。\n再看媒体领域，科比是一位优秀的制作人。2017年3月，科比自导自演的动画短片《Musecage》发布。2017年4月，科比参与制作并配音的动画电影《亲爱的篮球》首映，这部影片的创作灵感来自于科比在2015年发表的那封退役信，那篇文章的名字就叫做《亲爱的篮球》。这部影片取得巨大成功，获得奥斯卡金像奖最佳动画短片奖。除此之外科比的制作《Detail》节目，也是大获成功，只要被分析的球星，下一场球一定会被针对，场上表现大打折扣。\n最后看写作领域，科比先于2018年出版个人自传：《曼巴精神：我是怎么打球的》， 接着在2019年出版一本体育梦幻小说：《威兹纳德 训练营》，该书曾进入纽约时报畅销书排行榜榜首。除此之外，巴西著名畅销作家、《牧羊少年奇幻之旅》的作者保罗-科埃略原本正与科比合作一本新书，可惜由于科比的不幸离世，这本书胎死腹中。这些成就让人不禁想到：获得奥斯卡之后，科比又要冲击诺贝尔文学奖了吗？\n科比是曼巴精神最佳实践 科比自己是这样解释曼巴精神：\n 一开始，“曼巴精神”只是我在推特上发起的一个标签，它激励人心，饱含智慧，令人过目难忘。但随后它从那里流行开来，开始有了更多象征意义。“曼巴精神”是一种思维模式，它不在于寻求结果，而在于如何做才能取得结果，在于从现实到目标的这个过程。它是一段旅程，一种方法，一种生活方式。我真心认为，在所有努力之中，拥有这种心态尤其重要。\n 最偏执：专注篮球，为了进入赛后赛，在34岁那年拼到跟腱断裂；科比说过：“为了胜利我做什么都可以，无论是给队友递毛巾递水，还是上场执行最后一投。”\n最坚韧： 三个手指受伤还坚持打完了一个赛季并夺得了总冠军\n最倔强：科比说过：“ 我的字典里没有妥协。“\n最好强：新秀赛季敢于单挑巅峰期的乔丹；敢直接跟篮球史上最有统治力的球员大鲨鱼抢出手权\n最勤奋：每天投进2000个跳投，还有大家都耳熟能详的段子：凌晨四点的洛杉矶，对了，那不是段子，那是科比无数个清晨所看到的\n后记 2016年4月13日，15-16NBA常规赛，对阵爵士是科比职业生涯最后一场比赛。他在比赛中得到了60分，成为得到60分年龄最大的球员。科比以这种伟大创举告别了NBA。Mamba out！留给世界是震撼与不舍，多希望他还能征战NBA。\n美国时间2020年1月26号，中国春节初三，科比却以意想不到方式离开了这个世界。Mamba farewell！ 留给世界是悲伤，是难以相信，是永远的记忆。多希望他还能活跃在多个领域，希望他能够出一期有关英格拉姆的《detail》节目，希望他能指导Gigi成为一名女曼巴，希望他能生一个儿子。。。\n科比度过他短暂的一生，他的一生是奋斗不息、不断挑战、实现梦想的一生。感谢科比给这个世界带来的精彩，在生活与工作中用行动来纪念科比（欧文就是一个好参考，狂砍54分，用属于他自己的方式纪念科比）。\n一千读者心中有一千个哈姆雷特，欢迎大家说一说自己心中的科比\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)，您的关注是我更新的动力\n", 
        "url": "http:\/\/myself659.github.io\/post\/kobe\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/why-btc-is-dominated\/": {
        
        "title": "2020年比特币的龙头地位还会继续加强吗？",
        "tags": ["BlockChain","BTC",],
        "content": "背景 比特币是世界诞生的第一个加密货币，从2009年上线以来市值一直都是NO.1.\n表现 下面具体一下比特币的龙头表现：\n从上面两图可以看出来，从2018年1月份开始比特币的龙头地位从最低点逐渐提高。比特币在这两年的时间从最低点33%左右上升到66%左右。从市值占有比角度来看，比特币是这两年中最大的赢家，没有之一。\n下面再看一下2018年到2020之间加密货币总市值的变化情况：\n从图可知，2018年1月整个加密货币市场处于最高点，总市值最高达到815159246848美元，简单记为8151亿美元。\n到了2020年1月整个加密货币市场的总市值为241570437715美元，简单记为2415亿美元。\n在整个市场腰斩，不对是膝斩的过程，比特币在整个市场的比重逐渐提升。在整个过程比特币相比于经济危机的情况下避险贷币。\n原因 为什么在整个过程比特币比重越来越高呢？\n个人认为有以下几个原因：\n 比特币具有先发优势 在持有分布方面，比特币的持有分布有很好去中心化性 宣传上，一定程度上比特币等同了区块链，大大提高了比特币宣传 比特币一直在进步与发展，BIP不断有新提案出来并且能够得到落实 比特币有最完整的生态  未来 关于未来比特币的龙头地位是否会进一步加强呢？个人认为龙头地位不会再进一步扩大。主要原因如下：\n 最近两年比特币比重提升来自于山寨币的比重，而经过这两年的淘汰山寨币空间几乎消失殆净 比特币比重还有一部分来自于以太坊，以太坊2.0进展有利于以太坊的比重提高 其他领域的加密货币的发展，如跨链的大量应用会增加跨链部分的比重 闪电网络的发展与应用加上现在比特币强大的生态有利于比特币守住龙头地位  最后，个人认为2020年比特币挖矿收益的减半，并不会导致比特币的大爆发。\n", 
        "url": "http:\/\/myself659.github.io\/post\/why-btc-is-dominated\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/invest\/invest-%E9%9D%9E%E5%AF%B9%E7%A7%B0%E6%80%A7\/": {
        
        "title": "说说非对称性",
        "tags": ["Invest",],
        "content": "背景 发现世界的规律，利用其中的非对称性，可以获利事半功倍的交易。\n非对称性在哪里？ 非对称性在世界上普及存在。 下面举几个例子：\n 非对称加密算法 信息不对称 能力不对称 时间不对称 速度不对称 认知不对称 理论与实践不对称 方向非对称性 风险不对称 责任不对称 机会不对称 概率不对称  利用非对称性指导原则 利用非对性性指导原则如下：\n 二八法则 扩展维度，降维打击 系统思维 优势策略，避免非对称劣势 Less is more 顺势而为 具体问题具体分析 合理使用杠杆策略  ", 
        "url": "http:\/\/myself659.github.io\/post\/invest\/invest-%E9%9D%9E%E5%AF%B9%E7%A7%B0%E6%80%A7\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/wechat-payment-read\/": {
        
        "title": "说说微信付费阅读",
        "tags": ["商业","Internet",],
        "content": "背景 2020年1月15号微信灰度发布公众帐号付费阅读功能。微信10亿用户的体量，最长的用户时长，所以一个付费阅读功能差不多引起全网的讨论。\n时机 为什么微信会在这个时候推出公众帐号付费阅读功能？\n在得到，喜马拉雅，极客时间，知识星球，小红圈，微博等一系列知识付费产品这几个的培训下，国内知识付费快速成长，付费内容增多，用户付费意识增强。同时微信订阅号打开率与阅读量遇到增长问题。\n目的 个人认为推出公众帐号付费阅读功能有以下目的：\n 抢占知识付费的市场 增加订阅号的服务类型，为用户提供一种新的新服务，为创作者提供一个新变现的选项 促进一些创作者的热情，进而创作出更加优秀的作品，为用户提供高质量的作品 多年订阅号的发展，一定量的用户付费的需求已经出现，推出公众帐号付费阅读功能，满足用户的需要  产品体验  ios用户付费由于苹果的原因，支付体验不流畅，不能直接走微信支付（注：苹果要发展自家apple pay） 付费阅读文章有明显的标示 可以灵活设置付费可见的内容比例 付费后有两条通知：支付凭证通知购买成功通知 没有广告 付费才能留言 如果不付费情况，影响阅读体验，伤害用户的情感  适用场景 并不是所有订阅号都适合开通付费阅读功能，Caoz看好付费阅读功能在以下领域的应用：\n 原创小说 原创动漫 金融财经/智库报告 其他平台导流到微信的付费阅读  除了黑产与灰产外，个人还看好在一些重要问题的付费解答方面的应用。\n对比 有太多的付费产品，这里简单说一下微信公众帐号与其他的不同点：\n 其他都是知识付费产品，而在微信付费阅读是一个功能或者说是feature 微信针对一篇文章的交易，其他是圈子付费或者平台会员付费 微信付费更加精准，就是具体一篇文章或者一个问题  那么多其他付费平台有哪些影响？\n 如果微信付费将一些创作者吸引到微信公众帐号，那么其他付费平台会受到不小的冲击，如今天的中国没有哪一个互联网产品的用户不与微信重叠，这些创作者也会带着他的用户无成本迁移到微信 由于微信是文章类别，暂时对语言与视频类知识付费没有多少影响 平台之间相互抢创作者会再度出现 微信中心化付费阅读与基于区块链去中心的内容平台由于商业模型不一致，所以对去中心的内容平台影响不大  机会 这里的机会当然是指创作者的机会。面对的主要领域主要就是提到的五个领域。\n 一种新变现的方式，可以看作一个新的知识价值交易的平台 一个展示自我实力与价值的平台 个人成长的平台，如果选定一个领域，不断深耕，个人能力回报肯定不错，如果有志如此，请先开始拥有一个公众帐号 经济回报这些机会属于大部分属于一些头部真硬核作者（马太效应），虽然我希望是长尾效应，但是实际估计还是二八定律 微信用户更多，用户时长更久，机会相比较于其他付费平台机会更大  作用 对于内容输出者来说，主要作用如下：\n 一个新的变现方式，一个10亿用户平台上的变现 防止洗稿，内容禁止复制 防止杠精，付费才能评论 经济上的激励促进进步，输出更好的内容  结语 对于个人来说，就是开一个公众帐号，专注一个领域，努力学习，持续精进，真诚分享，输出价值，不要随便开启付费阅读，一切随缘。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/wechat-payment-read\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-2020\/": {
        
        "title": "Gartner预测2020年区块链的发展",
        "tags": ["BlockChain",],
        "content": "Gartner 首先介绍一下Gartner。 Gartner全球最具权威的IT研究与顾问咨询公司。同时也是魔力四象限与技术成熟度曲线提出者。所以Gartner报告值得一看，权威性比一般技术报告及预测强很多。\n十大技术趋势 Gartner对2020技术发展作了预测，列出十大技术趋势，具体如下：\n Hyperautomation超级自动化 Multiexperience多元体验 Democratization民主化 Human Augmentation人类增强 Transparency and Traceability透明与可追溯性 The Empowered Edge边缘计算 Distributed Cloud分布式云 Autonomous Things自主设备 Practical Blockchain实用区块链 AI Security人工智能安全  从上可知区块链也在榜上。下面具体看一下区块链部分的分析。\nGartner预计区块链可扩展性将在2023年取得突破 区块链技术应用现在面临的主要体现以下两个方面：\n 可扩展性 互操作性  可扩展性方面主流公链如比特币每秒支持七笔交易，以太坊每秒支持15笔交易；同时交易成本高。 互操作性方面私钥管理基本上原地踏步，助记词这种形式提高了用户的门槛的要求，同时丢失助记词是常有发生。\n报告中并没有说明哪种技术方案会取得突破。个人以为主要看点有两个：\n 分片 layer2  重点期待以太坊, Harmony,Near, plokadot等公链。\n区块链应用场景 区块链是一个充满想像力的技术，但是现在主要落地应用在于数字货币领域。在其他的领域区块链落地比较少。Gartner在报告中列出区块链在企业应用领域有哪些呢？具体如下：\n1.资产跟踪。\n2.索赔。\n3.身份管理/KYC。\n4.内部记录保存。\n5.积分和奖励。\n6.支付/结算。\n7.溯源。\n8.共享记录保存。\n9.智能城市/物联网。\n10.贸易融资。\n11.交易。\n此外Garnter还看好以下三个应用（不同于上面的企业应用领域）：\n 基于区块链的投票 基于区块链的自我主权的数字身份 数字加密货币的支付和转帐  建议 Gartner对于企业场景下应用区块链技术的建议：\n 深入理解商业应用领域的问题和潜在的机会 深入理解区块链的功能和局限性 重新评估企业和行业信任架构 将技术作为核心业务战略的一部分 提高客户应用区块链运营架构的意愿和能力  参考  top-10-strategic-technology-trends-for-2020  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-2020\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/programer-book-list\/": {
        
        "title": "程序员进阶精读书籍清单",
        "tags": ["编程",],
        "content": "2020年加大搬砖的力度，还是一名程序员，继续成长与进步。\n优秀程序员应该具备以下三方面能力：\n  扎实的计算机基础知识（计算机结构，操作系统，数据结构与算法 ）\n  良好的软件工程素质\n  一定的系统设计与架构能力\n  多年的程序员经历与读书经历告诉我：\n  读书不在多，贵在精。\n  精典书籍需要多读几遍，常读常新，每一次重读都会有新的收获\n  下面推荐软件工程师应该精读的十本书。\n1 编码：隐匿在计算机软硬件背后的语言 本书作者Charles Petzold创造性地以编码为主题，从电报机和手电筒讲到数字电路，然后利用数字电路中的逻辑门构造出加法器和触发器，最后构造出一个完整的存储程序计算机 。作者在书中使用大量形象贴切的类比简化了这些概念，使其成为通俗易懂的计算机入门读物。\n2 深入理解计算机系统 作为一名非科班出身的程序员，深入理解计算机系统是对我帮助最大。这本书里面将操作系统，计算机硬件与结构，编译原理这些计算机学科的基础内容结合在一起。具体内容涵盖：指令集体系架构，汇编语言，代码优化，计算机存储体系架构，链接，装载，进程，系统调用，虚拟内存，网络编程，并发编程等程序员在日常工作中所需要的必备知识。\n如果想打下扎实的计算机基础又不想把操作系统计算机结构编译原理这些书统统读一遍，阅读深入理解计算机系统是最有效率的方式。\n3 计算机编程艺术 本书的作者高德纳是算法和程序设计技术的先驱者，同时也是计算机排版系统TEX和METAFONT的发明者，除此之外还是1971年图灵奖获得者。这个系列图收可以说是包含一切基础算法的宝典。比尔·盖茨曾表示：如果你自以为是一个很好的程序员，请去读读高德纳的《计算机程序设计艺术》吧\u0026hellip;要是你真把它读下来了，就毫无疑问可以给我递简历了。精读这个系列的图书毫无疑问是真正地站在巨人的肩膀上。\n4 算法导论 AI时代，也就是算法时代。可以说算法水平决定一个程序员技术的上限。学习基础算法与应用算法解决具体的工作问题，本书不容错过。\n5 程序员面试金典 面试驱动学习。\n《程序员面试金典》是程序员面试跳槽找工作必备书。\n6 程序员修炼之道：从小工到专家 对于软件工程来说算法，数据结构，编程语言只是软件工程的工具与思想，在具体软件工程中每一个软件工程师都要考虑如何提高工作的产出。这本《程序员修炼之道：从小工到专家》通过具体有效的经验与技巧让你成长为一名高效的程序员。书中内容涉及如何避免代码腐烂，如何编写灵活、高可用的正确代码，如何真正的理解需求等一系列具体问题。\n7 人月神话 软件的开发与维护离不开软件工程。《人月神话》是软件工程领域集大成者。《人月神话》的作者Fred Brooks领导并完成 System/360 和 OS/360 这两个即是放到现在也是巨型软件项目的里程碑项目的经验总结。这本书覆盖了软件项目各个方面的关键概念：从工期管理到团队建设，从程序设计到架构设计，从原型设计到团队交流。\n8 算法之美 《算法之美》这本书扩展算法的应用范围，将算法应用到具体生活当中。本书通过讨论人类事务算法设计的概念，以帮助人们更好地处理日常生活中遇到的难题。内容涉及贝叶斯法则、最优停止理论、时间调度理论、博弈论等。\n9 设计数据密集型应用 从IT时代进入DT时代，数据成为重要的生产要素。《设计数据密集型应用》以数据为核心，描述大规模分布式数据系统的理论与实践。\n10 计算机程序的构造和解释 在《计算机程序的构造与解释》书中深入探讨了程序设计的本质（过程抽象、数据抽象、元语言抽象）。这些本质思想在未来量子计算机时代仍然不会过时。书中构建了很多小系统。比如第一章的计算素数、最大公因数、平方根、积分、黄金比例等，讨论了递归、迭代过程；第二章的图形语言、赫夫曼编码解码、泛型运算、多项式计算等，讨论了数据结构和数据类型系统；第三章实现了一个面向对象系统等；第四章实现Scheme的解释器；第五章通过设计机制和语言实现寄存器机器的各种计算。\n结语 再说一遍：读书在精，不在多。上面推荐的这些书，你可能多多少少见过，但是能静下心来读完一本的人可能寥寥无几。本人静下心来读也只有两本书《深入理解计算机系统》与《设计数据密集型应用》，但是《深入理解计算机系统》这本偏硬件那几章几乎没有读。当然上面大部分书都有通读。\n一年精读一本，保证吸收与转化，每年都是一个台阶的大进步。只可惜自己当年没有做到，也没有这种强烈的意愿。\n", 
        "url": "http:\/\/myself659.github.io\/post\/programer-book-list\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/tech-giant-income\/": {
        
        "title": "苹果微软亚马逊谷歌Facebook五大科技巨头是如何赚钱的",
        "tags": ["Internet",],
        "content": "苹果微软亚马逊谷歌Facebook这五大科技巨头在2018年的收入总和超过了8000亿美元。 如果这五大科技巨头保证30%的增长率，这五大科技巨头在2019年的收入总和会超过10000亿美元。\n下面具体看看每个公司的收入结构：\n苹果 从上图可知：\n总收入： 2656亿美元，排名第一\n净利润： 595亿美元，排名第一\n业务收入结构：\n iPhone占比为62.8％ Mac电脑占比为9.6％ iPad占比为7.1％ 其他Apple产品和服务（包括Apple Watch，Apple TV，Beats设备，Apple Pay和AppleCare）占比为20.6％  区域收入结构：\n 美洲区占比为42% 欧洲区占比为24% 大中华区占比为20% 日本占比为7% 亚太区（不包括中国与日本）占比为7%  思考 居然没有非洲的统计，非洲也太惨。苹果未来增长区域会是非洲吗？ 手机取代电脑，成为第一终端。\n亚马逊 从上图可知：\n总收入： 2329亿美元，排名第二\n净利润： 101亿美元，排名第五\n业务收入结构：\n 在线零售占比为52.8% 第三卖家服务占比为18.4% AWS占比为11.0% 线下实体零售占比为7.4% Amazon Prime占比为6.1% 其他收入占比为4.3%  区域收入结构：\n 美国占比为69% 英国占比为6% 德国占比为9% 日本占比为6% 其他国家和地区占比为11%  amazon线下实体2018年增长率为197%，利益于amazon go快速增长\nAlphabet 说明一下，Alphabet是Google的母公司。\n从上图可知：\n总收入： 1368亿美元，排名第三\n净利润： 307亿美元，排名第二\n业务收入结构：\n 广告(来自Google搜索, YouTube, GooglePlay, gmail, Google Map等)占比为70.4% 广告(来自Google Ads)占比为14.6% 其他收入(包括Google Cloud，Google Mussic等)占比为14.5%  区域收入结构：\n 美国占比为46% 美洲区（除美国外）占比为6% EMEA(欧洲、中东和非洲)占比为33% APAC（亚大地区）占比为15%  微软 从上图可知：\n总收入： 1104亿美元，排名第四\n净利润： 166亿美元，排名第四\n业务收入结构：\n office产品占比为25.7％ Azure产品占比为23.7％ Windows占比为17.7％ 游戏占比为9.4％ Bing广告占比为6.4％ 企业服务占比为5.3％ 设备（如Surface PC）收入占比为4.7％ LinkedIn占比为4.8％  区域收入结构：\n 美国占比为51% 世界其他地区占比为49%  FaceBook 从上图可知：\n总收入： 558亿美元，排名第五\n净利润： 221亿美元，排名第三\n业务收入结构：\n 广告收入占比为98.5% 支付和其他收入占比为1.5%  区域收入结构：\n 美国占比为43% 加拿大占比为3% 欧洲占比为24% 亚太占比为21% 其他国家和地区占比9%  每个用户为FaceBook贡献收入35美元\n小结  苹果收入与利润最高，亚马逊利润最低 微软收入最多元化，FaceBook收入最单一 FaceBook利润率最高，亚马逊利润率最低 每个企业都有自己的核心业务：亚马逊的在线零售，苹果的手机业务，Google搜索广告，FaceBook社交广告，微软的offcie与windows业务。 存在相互竞争，最明显与最激烈属于云服务竞争：AWS, AZURE, GCP三者相互竞争 Amzon主要收入来源是美国，占比接近70% 收入结构主要来自经济发达地区，非洲属于一片经济的沙漠，多写一句话：不知道中非的友谊能否在这片经济的沙漠之上开出发展的花朵呢？  2022 update 对比一下三年前收入结构最大的变化：除Apple，另外三家就是云业务收入增长迅速，占比扩大。\n参考  ADVERTISING How the Tech Giants Make Their Billions Google Products How Apple, Amazon, Alphabet, and Microsoft Became $1 Trillion Companies  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/tech-giant-income\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/network\/about-doh\/": {
        
        "title": "DoH FAQ",
        "tags": ["Secure",],
        "content": "什么是DoH DoH是DNS over HTTPS。\n传统DNS相当于DNS over UDP。\nDoH带来哪些好处？ 采用DoH对用户来说有如下好处：\n DoH协议不允许其他用户，服务提供商或第三方查看您访问的网站并收集数据，保护了用户的隐私 DoH协议有利于防止欺骗与钓鱼攻击，保护在线数据的安全和隐私 加速DNS解析，提高网页访问速度 对于天朝人民，还有另一个好处就是科学上网  DoH现在可以使用吗？ 1  We\u0026#39;ve enabled an experiment in Chrome 79 for a fraction of our users.   Chrome 79版本对部分用户开启。\nfirefox 70版本已经支持DoH。\n如何使用DoH? 以firefox为例：\n在地址输入：about:preferences#general，找到Network Settings选项，点击Settings即可进入设置，具体如下：\n参考  DNS over HTTPS Google Public DNS over HTTPS (DoH) supports RFC 8484 standard Moving to an era of Decentralized DNS registry Running a DNS over HTTPS Client  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/network\/about-doh\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/substrate-cloud-node\/": {
        
        "title": "搭建Substrate开发云节点",
        "tags": ["Substrate","BlockChain",],
        "content": "为什么要云节点 主要由以下几个原因：\n 国内GFW太狠，github都不能幸免，代码都不能下载，影响正常的开发 rust这个编译太占用cpu，内存，硬盘 rust编译的时候cpu一直在叫，影响个人心情，进而影响开发效率 云节点方便共享 花小钱买时间是一件很划算的事情  搭建步骤 准备节点 具体参考这篇文章Installing Substrate，各种类型的操作系统都有说明。\n运行节点 设置代理 这里我采用是caddy作为代理\n具体配置参考如下：\n1 2 3 4 5  yourwssaddr { proxy / http://0.0.0.0:9944 { websocket } }   启动节点 1  ./target/release/substrate --dev --ws-port 9944   浏览器 具体参考apps里面说明即可。\n运行如下命令即可：\n1 2 3 4  git clone https://github.com/polkadot-js/apps cd apps yarn yarn run start   在caddy中配置浏览器的代理：\n1 2 3 4 5 6 7  example.com { proxy / localhost:3000 { transparent } gzip }   最终具体效果如下：\n这样你就拥有一个属于自己的区块链。具体代码参考hello-node\n参考  Build Substrate on Ubuntu: step-by-step guide  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/substrate-cloud-node\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rust\/rust-vec\/": {
        
        "title": "Rust Vec 101",
        "tags": ["Rust",],
        "content": "create 不指定数据类型 1 2  let mut v1 = Vec::new(); let mut v2 = vec![];   指定数据类型 1 2 3  let mut v1:Vec\u0026lt;i32\u0026gt; = Vec::new(); let mut v2:Vec\u0026lt;i32\u0026gt; = vec![]; let mut v3 = vec![1i32, 2,3];   创建并初始化 1 2 3 4 5  let mut v1 = vec![1,2,3]; let mut v2:Vec\u0026lt;i32\u0026gt; = vec![1,2,3]; let mut v3 = vec![1i32,2,3]; let mut v4 = vec![1; 10]; let mut v5: Vec\u0026lt;i32\u0026gt; = (0..10).collect();   访问元素 读 1 2 3 4  let mut v1 = vec![1,2,3]; let item = v1[0]; println!(\u0026#34;{:?},{:?}\u0026#34;, v1.get(0),v1.get(100)); //Some(1),None   slice 1 2 3  let v1 = vec![1,2,3,4,5]; let v2 = v1[1..]; let v2 = v1[1..3];   写 1 2  let mut v1 = vec![1,2,3]; v1[0] = 11;   insert 1 2 3 4 5 6  fn main() { let mut v1 = vec![1,2,3]; v1.insert(2,1); println!(\u0026#34;v1:{:?}\u0026#34;,v1); } // v1:[1, 2, 1, 3]   remove 1 2 3 4  let mut v1 = vec![1,2,3]; v1.remove(0); println!(\u0026#34;v1:{:?}\u0026#34;,v1); // v1:[2, 3]   append 1 2 3 4 5 6 7  fn main() { let mut v1 = vec![1,2,3]; let mut v2 = vec![4,5,6]; v1.append(\u0026amp;mut v2); println!(\u0026#34;v1:{:?}\u0026#34;,v1); } // v1:[1, 2, 3, 4, 5, 6]   extend 1 2 3 4 5 6  let mut vec1 = vec![1, 2, 3]; let vec2 = vec![4, 5, 6]; vec1.extend(vec2); assert_eq!(vec1, [1, 2, 3, 4, 5, 6]);   1 2 3 4 5 6 7  let vec1 = vec![1, 2, 3]; let vec2 = vec![4, 5, 6]; let mut vec3 = vec1; vec3.extend(vec2.into_iter()); assert_eq!(vec3, [1, 2, 3, 4, 5, 6]);   sort 1 2 3 4 5 6 7 8 9 10 11 12  fn main() { let mut v1 = vec![1,2,3, 3,2,1]; v1.sort(); println!(\u0026#34;v1:{:?}\u0026#34;,v1); let result = v1.binary_search(\u0026amp;2); println!(\u0026#34;result:{:?}\u0026#34;,result); } // v1:[1, 1, 2, 2, 3, 3] // result:Ok(3)   resize 1 2 3 4 5 6 7 8 9  fn main() { let mut v1 = vec![1,2,3, 3,2,1]; v1.resize(10, 0); println!(\u0026#34;v1:{:?}\u0026#34;,v1); v1.resize(2, 0); println!(\u0026#34;v1:{:?}\u0026#34;,v1); } // v1:[1, 2, 3, 3, 2, 1, 0, 0, 0, 0] // v1:[1, 2]   push and pop 1 2 3 4  let mut v1 = vec![1,2,3]; v1.push(4); v1.push(5); let item = v1.pop();   iterator 1 2 3 4 5 6 7 8 9 10 11 12 13  let mut v = vec![1,2,3]; for item in \u0026amp;v { } for item in \u0026amp;mut v { } for item in v { }   1 2 3 4 5 6 7 8 9 10 11 12 13  let mut v = vec![1,2,3]; for (i, x) in v.iter().enumerate() { println!(\u0026#34;In position {} we have value {}\u0026#34;, i, x); } for x in v.iter() { println!(\u0026#34;item:{}\u0026#34;,x); } for x in v.iter_mut() { *x *= 3; } println!(\u0026#34;Updated vector: {:?}\u0026#34;, xs);   1 2 3  let items = vec![1, 2, 3]; let sitems = items.into_iter().map(|x| x.to_string()).collect::\u0026lt;Vec\u0026lt;_\u0026gt;\u0026gt;(); println!(\u0026#34;sitem: {:?}\u0026#34;,sitems);   属性 capacity 1 2  let mut v1 = vec![1,2,3]; println!(\u0026#34;capacity={}\u0026#34;,v1.capacity());   len 1 2  let mut v1 = vec![1,2,3]; println!(\u0026#34;len={}\u0026#34;,v1.len());   is_empty 1 2  let mut v1 = vec![1,2,3]; println!(\u0026#34;is_empty={}\u0026#34;,v1.is_empty());   contains 1 2 3 4 5 6 7 8 9  fn main() { let mut v1 = vec![1,2,3]; println!(\u0026#34;{} is in v1:{:?}\u0026#34;,1, v1.contains(\u0026amp;1)); println!(\u0026#34;{} is in v1:{:?}\u0026#34;,11, v1.contains(\u0026amp;11)); } // 1 is in v1:true // 11 is in v1:false   ", 
        "url": "http:\/\/myself659.github.io\/post\/rust\/rust-vec\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/golang\/golang-sync-pool-2\/": {
        
        "title": "深入分析Golang sync.pool优化",
        "tags": ["Golang",],
        "content": "前言 最近golang的1.13版本发布了，有很多新特性与改进合入。这里主要分析sync.pool的优化。\n本文主要解答以下几个问题：\n sync.pool优化体现在哪里？ 优化是如何实现？ 优化的好处有哪些？  优化 具体优化项如下：\n 无锁化 GC策略  无锁化 sync.pool实现了无锁化，具体如下：\ngo1.12.1版本实现\n1 2 3 4 5 6  // Local per-P Pool appendix. type poolLocalInternal struct { private interface{} // Can be used only by the respective P. shared []interface{} // Can be used by any P. Mutex // Protects shared. }   go1.13版本\n1 2 3 4 5  // Local per-P Pool appendix. type poolLocalInternal struct { private interface{} // Can be used only by the respective P. shared poolChain // Local P can pushHead/popHead; any P can popTail. }   通过上面对比发现了go1.12版本的Mutex删除了。那么go1.13版本又是如何实现无锁化的呢？\n先回答问题：go1.13通过poolChain实现SPMC的无锁队列来实现无锁化。\npoolChain是什么东东呢？\n别急，代码面前无秘密。 我们具体看一下代码就可以了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  // poolChain is a dynamically-sized version of poolDequeue. // // This is implemented as a doubly-linked list queue of poolDequeues // where each dequeue is double the size of the previous one. Once a // dequeue fills up, this allocates a new one and only ever pushes to // the latest dequeue. Pops happen from the other end of the list and // once a dequeue is exhausted, it gets removed from the list. type poolChain struct { // head is the poolDequeue to push to. This is only accessed // by the producer, so doesn\u0026#39;t need to be synchronized. head *poolChainElt // tail is the poolDequeue to popTail from. This is accessed // by consumers, so reads and writes must be atomic. tail *poolChainElt } type poolChainElt struct { poolDequeue // next and prev link to the adjacent poolChainElts in this // poolChain. // // next is written atomically by the producer and read // atomically by the consumer. It only transitions from nil to // non-nil. // // prev is written atomically by the consumer and read // atomically by the producer. It only transitions from // non-nil to nil. next, prev *poolChainElt }   关于poolChain是如何实现SPMC无锁队列？具体可以分析poolqueue.go的代码。 这一部分不展开说明，要点如下：\n 无锁队列是SPMC 无锁队列是可以灵活调整大小，调整大小的方法：slice+double-list实现（根据这个思路来阅读代码也是容易理解 ） 无锁队列的实现基础是CAS  好处  避免锁的开销，mutex变成atomic  GC策略 相比较于go1.12版本，go1.13版本中增加了victim cache。具体作法是：\n GC处理过程直接回收oldPools的对象 GC处理并不直接将allPools的object直接进行GC处理，而是保存到oldPools，等到下一个GC周期到了再处理  具体代码如下：\n1 2 3 4  var ( allPoolsMu Mutex allPools []*Pool )   1 2 3 4 5 6 7 8 9 10 11 12  var ( allPoolsMu Mutex // allPools is the set of pools that have non-empty primary // caches. Protected by either 1) allPoolsMu and pinning or 2) // STW. allPools []*Pool // oldPools is the set of pools that may have non-empty victim // caches. Protected by STW. oldPools []*Pool )   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  func poolCleanup() { // This function is called with the world stopped, at the beginning of a garbage collection. // It must not allocate and probably should not call any runtime functions. // Because the world is stopped, no pool user can be in a // pinned section (in effect, this has all Ps pinned). // Drop victim caches from all pools. for _, p := range oldPools { p.victim = nil p.victimSize = 0 } // Move primary cache to victim cache. for _, p := range allPools { p.victim = p.local p.victimSize = p.localSize p.local = nil p.localSize = 0 } // The pools with non-empty primary caches now have non-empty // victim caches and no pools have primary caches. oldPools, allPools = allPools, nil }   这样可导致Get的实现有变化，原来的实现是：\n 先从本P绑定的poolLocal获取对象：先从本poolLocal的private池获取对象，再从本poolLocal的shared池获取对象 上一步没有成功获取对象，再从其他P的shared池获取对象 上一步没有成功获取对象，则从Heap申请对象  引入victim cache，Get实现变成如下：\n 先从本P绑定的poolLocal获取对象：先从本poolLocal的private池获取对象，再从本poolLocal的shared池获取对象 上一步没有成功获取对象，再从其他P的shared池获取对象 上一步没有成功，则从victim cache获取对象 上一步没有成功获取对象，则从Heap申请对象  具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  func (p *Pool) getSlow(pid int) interface{} { // See the comment in pin regarding ordering of the loads. size := atomic.LoadUintptr(\u0026amp;p.localSize) // load-acquire locals := p.local // load-consume // Try to steal one element from other procs. for i := 0; i \u0026lt; int(size); i++ { l := indexLocal(locals, (pid+i+1)%int(size)) if x, _ := l.shared.popTail(); x != nil { return x } } // Try the victim cache. We do this after attempting to steal // from all primary caches because we want objects in the // victim cache to age out if at all possible. // 尝试从victim cache获取 size = atomic.LoadUintptr(\u0026amp;p.victimSize) if uintptr(pid) \u0026gt;= size { return nil } locals = p.victim l := indexLocal(locals, pid) if x := l.private; x != nil { l.private = nil return x } for i := 0; i \u0026lt; int(size); i++ { l := indexLocal(locals, (pid+i)%int(size)) if x, _ := l.shared.popTail(); x != nil { return x } } // Mark the victim cache as empty for future gets don\u0026#39;t bother // with it. atomic.StoreUintptr(\u0026amp;p.victimSize, 0) return nil }   好处  空间上通过引入victim cache增加了Get获取内存的选项，增加了对象复用的概率 时间上通过延迟GC，增加了对象复用的时间长度 上面这个两个方面降低了GC开销，增加了对象使用效率  参考  深入分析Golang sync.pool Using sync.Pool  ", 
        "url": "http:\/\/myself659.github.io\/post\/golang\/golang-sync-pool-2\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/risk-of-vesting-china\/": {
        
        "title": "瑞·达利欧：不投资中国才是巨大的风险",
        "tags": ["Economy",],
        "content": "不投资中国才是巨大的风险 最近，桥水基金创始人及《原则》的作者瑞·达利欧公开表示：不投资中国才是巨大的风险。如下图所示：\n作为一个世界富豪榜排名前100的大富豪，\n作为一个掌握1500亿美元的对冲基金的掌门人，\n作为一个美国人，\n作为一个在过去40年多次成功预测经济危机的投资人。\n他的话当然不同凡想，引人思考。\n当然我们不能随便轻信这个结论，我们应该具体了解一下，他是如何得出这个结论？下面展开说明如下：\n瑞·达利欧的理由 模型 在视频中瑞达利欧提出一个国家实力的模型，这个模型从六个方面来衡量一个国家的实力，具体如下：\n 科技和教育 生产 贸易 军事 金融 货币储备地位  下面这一张图是荷兰，英国，美国，中国这个四个国家在最近几百年来在上述六个方面的实力曲线图：\n多样性原则 作为一个掌握1500亿美元的对冲基金的掌门人，瑞达利欧深知保持投资多样性十分必要。他们的投资是面向全球。中国市场情况与欧美不相同，具有独特性，是风险投资组合保持多样性不或缺少的选择。\n相对风险 风险无处不在。常人都明白，都有风险的情况，选择风险最小的。\n下面对比欧洲，美国，中国三个地区的风险情况。\n先说欧洲，瑞·达利欧认为欧洲有巨大风险，存在以下问题：\n 货币政策失效 政治分裂，如英国脱欧 不参与科技革命  再看美国，瑞·达利欧认为美国存在以下问题：\n 财富贫富差距 缺少有效的货币政策 政治系统的冲突  最后看中国，瑞·达利欧认为：相比较于美国，中国有更大货币政策和财政政策空间，并正在处理债务问题。\n结合上面的比较，瑞·达利欧认为相比较于其他市场，中国的市场风险最小。\n中国的成长与实力 先看过去的成长，以资本市场为例：\n说明：红色表示股票市场，蓝色表示债券市场；左边是中国资本市场空间，右边是外国资本持有的中国金融资产情况。\n补充一下从左边曲线图可以看出中国的股票市场领域虽然十年来上证指数基本无增长，但是市值还是有增长，但是没有跟上GDP的增长。\n视角回到现在，首先看一下科技领域的风险投资情况：\n从上图可知:\n 中国在fintech领域领先美国排名第一 在AI and machine learning（AI和机器学习）领域排名第三，落后于美国与英国 在wearables(可穿戴设备)领域排名第二 在virtual reality(虚拟现实)领域排名第二 在educational technology(教育技术)领域排名第二 在autonomous driving(自动驾驶)领域排名第二  再看一下中美独角兽对比：\n显而易见，中国在独角兽数量上与美国有13%左右的差距，但是估值上仅2%的差距。\n最后看一下中美实力对比：\n看到这张图，相信大家会理解中国再继续闷声发大财不是一件容易的事情了。\n相信这些数据会让很多人得出一个结论：中美毛衣冲突不影响中国继续崛起的进程。\n对中国十分熟悉 还有一点考虑，视频中没有明确投及，就是瑞·达利欧对中国的熟悉，作为一名美国人，其实瑞·达利欧对中国十分熟悉，他从1984年第一次来到中国后，此后35年里他不断地来到中国并熟悉中国，并且他的一个儿子曾经在中国读书。\n后记 本文只是简单介绍，关于瑞达利欧是如何看待中美毛衣冲突，更多信息请看原始视频，原始视频时长有31分钟。关注本公众帐号，输入 投资中国，获取原始视频的百度云下载链接。\n参考  《原则》作者瑞·达利欧烧脑大作(1): 经济机器是怎样运行的  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/risk-of-vesting-china\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rust\/rust-crate-speedup\/": {
        
        "title": "Rust crate加速",
        "tags": ["Rust",],
        "content": "由于墙的原因，导致cargo build，cargo run都会出现概率性失败，并且整个过程十分缓慢。\n下面是解决方案：\n方案1 在 ~/.cargo/config文件（如果没有创建一个）下添加如下内容：\n1 2 3 4 5  [source.crates-io] replace-with = \u0026#34;rustcc\u0026#34; [source.rustcc] registry = \u0026#34;https://code.aliyun.com/rustcc/crates.io-index.git\u0026#34;   方案1现在还是实验阶段，充满变数与不确定性。不适用于CI/CD。\n方案2 在阿里云，aws上申请一个香港地区云主机，将build工作交给云主机\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/rust\/rust-crate-speedup\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/python\/python37-install\/": {
        
        "title": "安装与更新python",
        "tags": ["Python",],
        "content": "说明 完全是为了记录自己的操作记录，换一台新机器真是免不了要装python。记录下来，便于以后操作。\napt-get安装 1 2 3 4 5 6 7 8  apt update apt install software-properties-common add-apt-repository ppa:deadsnakes/ppa apt install python3.7   源码安装 1 2 3 4 5 6 7 8 9  sudo apt update sudo apt install -y build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget wget https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tar.xz tar -xf Python-3.7.3.tar.xz cd Python-3.7.3 ./configure --enable-optimizations make make altinstall   更新python3.9 1 2 3  $ sudo add-apt-repository ppa:deadsnakes/ppa $ sudo apt update $ sudo apt install python3.9   install pip 1  apt-get install python3-pip   install virutalenv 1  pip3 install virtualenv   1  python3 -m pip install --user virtualenv   1  python3 -m venv env   1  source venv/bin/activate   install pipenv 1  pip install --user pipenvd   1  pipenv install tweepy python-dotenv   1  pipenv run python twitter_client.py   install jupyter 1 2  python3 -m pip install --upgrade pip python3 -m pip install jupyter   pip basic 查看包状态 1  pip show pkgname   不使用缓存 1  pip install --no-cache-dir --default-timeout=10000 pkgname   更新包 1  pip install -U pkgname   指定源 有时候安装一些依赖包，网不好，直接超时，或者这个包就是死都下不下来的时候，可以指定国内源镜像。 pip install -i 国内镜像地址 包名\ne.g. pip install -i https://mirrors.aliyun.com/pypi/simple/ 这是临时指定镜像地址\n清华：https://pypi.tuna.tsinghua.edu.cn/simple\n阿里云：https://mirrors.aliyun.com/pypi/simple/\n中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/\n华中理工大学：https://pypi.hustunique.com/\n山东理工大学：https://pypi.sdutlinux.org/\n豆瓣：https://pypi.douban.com/simple/\n修改配置参考：https://cloud.tencent.com/developer/article/1566247\npipdeptree 安装pipdeptree：\n1  pip install pipdeptree   生成requirements.txt\n1  pipdeptree -f | sed \u0026#39;s/ //g\u0026#39; | sort -u \u0026gt; locked-requirements.txt   常用pip命令  updata pip  1  python -m pip install --upgrade pip   install package  1  pip install \u0026lt;package-name\u0026gt;   Update Package  1  pip install -U \u0026lt;package name\u0026gt;   Install Specific Version of a Package  1  pip install \u0026lt;package-name\u0026gt;==\u0026lt;version\u0026gt;   1  pip install \u0026lt;packagename\u0026gt;\u0026gt;=\u0026lt;version\u0026gt;   Uninstall a Package  1  pip uninstall \u0026lt;packagename\u0026gt;   Information About an Installed Package  1  pip show \u0026lt;package name\u0026gt;   List All Installed Packages  1  pip list   1  pip freeze   Generate a requirements.txt File  1  pip freeze \u0026gt; requirements.txt   Install All Dependencies From requirements.txt File  1  pip install -r requirements.txt   Verify That Installed Packages Have Compatible Dependencies  1  pip check   List All Installed Packages That Are Not Up to Date  1  pip list -o   常用pip pkg 数据库  pip install mysql-connector-python pip install psycopg2 pip install PyMongo  cmd  pip install fire pip install thefuck  api  pip install fastapi pip install pyforest  autoload  pip install reloading  map  pip install geemap  emoji  pip install emot  data  pip install dabl pip install sweetviz  nlp  pip install spacy pip install nltk  reqirements make reqirements 1  pip freeze \u0026gt; requirements.txt   install reqirements 1  pip install -r requirements.txt   wsl 1 2 3 4  sudo apt update \u0026amp;\u0026amp; upgrade sudo apt install python3 python3-pip ipython3 sudo apt install python3-pip pip3 install jupyter   misc How to install Ta-Lib in python on Windows\n参考  Managing Multiple Versions of Python on Ubuntu https://medium.com/@itylergarrett.tag/setting-up-python-3-7-on-windows-10-a-non-developer-tutorial-e836639ca16 Here’s a Quick Way to Learn About PIP in Python How to Setup a Virtual Environment with Different Python Versions (Windows) Why and How to make a Requirements.txt  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/python\/python37-install\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-index-predict\/": {
        
        "title": "加密货币市场常用跟踪指标",
        "tags": ["Invest",],
        "content": "指标 Largest banks by market cap Largest banks by market cap\n总市值 加密货币总市值\nCRYPTOCURRENCY MARKET\n加密数字货币全球图表\n交易量Transaction Volume BTC\u0026rsquo;s Transaction Volume\nEthereum’s Transaction Volume\n算力Hash Rate BTC\u0026rsquo;s Hash Rate\nEthereum’s Hash Rate\n活跃地址Active Addresses BTC\u0026rsquo;s Active Addresses\nEthereum’s Active Addresses\n交易数Transaction Count BTC\u0026rsquo;s Transaction Count\nEthereum’s Transaction Count\nAverage Transactions Per Second Transaction Rate Per Second\nAverage Transaction Value BTC\u0026rsquo;s Average Transaction Value\nEthereum’s Average Transaction Value\nAverage Transaction Fee BTC\u0026rsquo;s Average Transaction Fee\nEthereum’s Average Transaction Fee\nEthereum Gas Tracker Ethereum Gas Tracker\nEthereum Daily Gas Used Chart Ethereum Daily Gas Used Chart\nEthereum gets burned with EIP-1559 ETH gets burned with EIP-1559\nTLV defi Llama\nCrypto Lending Interest Rates Crypto Lending Interest Rates\nBitcoin Holdings by Public Companies Bitcoin Holdings by Public Companies\nEthereum Holdings by Public Companies Ethereum Holdings by Public Companies\nEth/BTC ratio Eth/BTC ratio\nEthereum to BTC Chart\nCrypto Fees Crypto Fees\nNFT OpenSea dashboard\nMEV MEV-explore\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-index-predict\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/node-version\/": {
        
        "title": "如何选择合适的node版本与npm package",
        "tags": ["Javascript",],
        "content": "前言 作为一个常年以c,c++,golang为主的后端程序员，刚接触nodejs有一个困惑，就是node有哪么多版本到底该选择哪个版本呢？\nnode版本 根据需求选择版本，那么node版本有哪些特点呢？\n 从node 6 开始支持ES6 从node 8 开始支持Async Await node 10 增加了promisified fs模块 node 12增加了ES6 modules  从上面应该注意到node偶数版本是稳定版本（类似于linux）。\n如何管理多个node版本 一句话：复用nvm管理node。\nWindows请参考nvm-windows 。\n如何选择正确的npm package 在哪里选 npmjs\n从哪几个维度选择  Popularity Contributors Maintenance Size Quality npm trends dependencies  如何对比同类型的npm package 使用npmcompare\nnpm install Error: rollbackFailedOptional 1 2  ia@IA:~$ npm install -g truffle [..................] - rollbackFailedOptional: verb npm-session 9af9b18d6d36c6ee   解决方法：\n1 2 3 4  npm config rm proxy npm config rm https-proxy npm config set registry https://registry.npmjs.org/ npm config set registry https://registry.npm.taobao.org   integrity checksum failed when using sha512 1 2  silly fetchPackageMetaData error for truffle@latest sha512-lhd8pfO5bOIwmiZf0+RyLcdWtrmeoA9JkdH9o0uQxZabisa6IxfoACRBpBez3r3w+LGPnl9/K1stE3Z9aBNK0A== integrity checksum failed when using sha512: wanted sha512-lhd8pfO5bOIwmiZf0+RyLcdWtrmeoA9JkdH9o0uQxZabisa6IxfoACRBpBez3r3w+LGPnl9/K1stE3Z9aBNK0A== but got sha512-4wB4Qu27nyZfMy9ZFzkCs/PGaaQx8W+bKug46AP5N/4BGCiT2Uw5tqq39Ip4VXXeISdok3LXb7r7A066wx3/Zw==. (15722953 bytes) 9 timing stage:rollbackFailedOptional Completed in 2ms   解决方法： 删除node_modules和package-lock.json，然后再重新执行：npm install\ninstall yarn How to install Yarn on Ubuntu\nHow to Install Yarn on Ubuntu 18.04\n常用NPM Packages 73 Awesome NPM Packages for Productivity\nnpm cmd  npm doctor npm cache npm link npm ls npm search npm repo  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/node-version\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/facebook-libra\/": {
        
        "title": "Facebook libra是昙花一现还是星星之火",
        "tags": ["BlockChain",],
        "content": "前言 最近随着Libra横空出世，整个互联网有关的Libra新闻，评论等层出不穷，众说纷云。这么热闹，我当然也要插一脚，讲讲自己的一些思考与看法。\n方向 在具体分析之前，先看看libra定位：\n Libra的使命是建立一套简单的、无国界的货币和为数十亿人服 务的金融基础设施。\n 从上面可知libra整个系统定位是金融基础设施。这是符合Facebook的定位，作为技术平台，为金融服务提供支撑。\n技术方向，libra选择从许可型区块链开始。这是一个明智的选择，虽然现在不知道其具体实现情况，但是联盟链有如下优势：\n 相比较于公链有更好的互操作性 便于将libra集成到Facebook上各个超级App中，如WhatApp，Messenger等 避免公链钱包在用户体验先天不足或者给普通用户的不适应 更好安全管理与防范 避免公链的一些技术问题，如DCS不可能三角  还有一点就是相比较于其他的区块链先造链，再开发应用，找用户试验应用场景，Libra是先有场景和用户，再造链解决具体问题如支付和跨境。\n Libra 的目标是成为一种稳定的数字加密货币，将全部使用真实资产储备（称为“Libra 储备”）作为担保，并由买卖Libra并存在竞争关系的交易平台网络提供支持\n Libra Coin定位于稳定币。这样从一开始就避免了炒作，而是将整个重心放在应用领域。\n我们还可以从侧面了解这个方向的正确性。Facebook创始人扎克伯格是一位十分具有前瞻眼光和判断力的领袖。下面的例子可参考：\n 2012年Facebook宣布10亿美元收购只有只有13个员工的Instagram，从投资的角度看如今回报率在100倍左右 2014年Facebook以 160 亿美金现金加股票（其中包含40亿美金的现金以及价值120亿美金的公司股票。此外，Facebook还将为WhatsApp的创始人及员工提供约价值30亿美金的限制股股票，分期四年发放）收购移动聊天工具WhatsApp，整个WhatsApp公司总共不到50人。  这两次收购让Facebook拿到移动互联网的船票。\nSWOT分析 下面就按SWOT展开说明。\nStrengths 显而易见，Facebook具有以下优势：\n Facebook在全球有27亿用户 Facebook有真实的用户社交数据，天然支持KYC Facebook有优秀人才 libra有广泛的合作伙伴 Facebook有钱 公司的执行力  Weaknesses Facebook一直是一个toC的公司，有以下劣势：\n Facebook在金融领域缺少经验 Facebook不擅长与政府打交道的  Opportunities 在白皮书列举的机会，具体如下：\n •• 我们认为，应该让更多人享有获得金融服务和廉价资本的权利。\n  •• 我们认为，每个人都享有控制自己合法劳动成果的固有权利。\n  •• 我们相信，开放、即时和低成本的全球性货币流动将为世界创造巨大的经济机遇和商业价值。\n  •• 我们坚信，人们将会越来越信任分散化的管理形式。\n  •• 我们认为，全球货币和金融基础设施应该作为一种公共产品来设计和管理。\n  •• 我们认为，所有人都有责任帮助推进金融普惠，支持遵守网络道德规范的用户，并持续维护这个生态系统的完整性。\n 官方白皮书是从用户与全球经济角度来看的，从Facebook这个公司的角度来看，有如下机会：\n 一种货币 一个联盟 一种权力 一项收入 一种趋势  一种货币 显而易见这种货币就是Libra coin。在现在的经济系统中可以发行货币只有国家的央行。以美国为例，作个类比如下：\n Libra coin相当于美元 Libra 协会相当于美联储 Libra coin在Facebook应用生态中各种应用相当于美元在实际生活中的应用  Libra coin初期充当Facebook应用系统的生态币。但是值得注意的是Facebook应用生态可以进一步扩展为全球互联网经济体。这意味什么？大家自行体会。\n一种联盟 从上图可知，现有Libra联盟成员如下：\n •• 支付业： Mastercard, PayPal, PayU (Naspers' fintech arm), Stripe, Visa\n  •• 技术和交易平台： Booking Holdings, eBay, Facebook/Calibra, Farfetch, Lyft, Mercado Pago, Spotify AB, Uber Technologies, Inc.\n  •• 电信业： Iliad, Vodafone Group\n  •• 区块链业： Anchorage, Bison Trails, Coinbase, Inc., Xapo Holdings Limited\n  •• 风险投资业： Andreessen Horowitz, Breakthrough Initiatives, Ribbit Capital, Thrive Capital, Union Square Ventures\n  •• 非营利组织、多边组织和学术机构：Creative Destruction Lab, Kiva, Mercy Corps, Women\u0026rsquo;s World Banking\n Libra以联盟的方式不断扩展，增加影响力，扩大共识，获取更多的应用场景。\n一种权力 在Facebook生态系统的发币权。相比较于国内的微信支付及支付宝接入了法币, Libra Coin赋与了Libra联盟发币权。\n一项新收入 基于libra的金融业务带来的收入，改变Facebook一直以来以广告为主的单一的营收结构。\n一项趋势 趋势不可阻档。\n经济全球化趋势不可阻挡。\n数字化货币带来自由，高效，便捷，低成本也是不可阻挡。\n拥有27亿用户的Facebook发行Libra无疑是站在这个趋势的浪尖，同时紧紧占有巨大的先发优势。\nThreats 关于Libra，马化腾点评如下：\n 技术都很成熟，并不难。就看监管是否允许而已。\n 对，Libra最大的问题就是监管。由于Facebook是一个全球化公司，涉及不同的国家，这些国家的法律与政策也不尽相同。这对于Libra就是一个巨大的挑战。 至于很多人担心Libra会不会是昙花一现，直接被扼杀在摇篮？ 前面有USDT的先例。答案是不会的，美帝的民主制度，都会有一番流程与讨论，估计过程并不会一帆风顺。有了美帝的放行，在其他的国家开展也就铺平了道路。\n其他竞争对手，如Google，amazon，microsoft相继效仿发币并进行竞争。\n如果Libra coin要挑战美元，那么美元就是Libra的最大竞争对手，这个挑战很大，近期应该不会出现。\n结论 Facebook走在正确的方向上，虽然有很多的困难和不确定性，相信Libra会开启价值互联网时代。\n欢迎来到Web3.0时代。\n参考  Libra Why the net giants are worried about the Web 3.0  ", 
        "url": "http:\/\/myself659.github.io\/post\/facebook-libra\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/startup\/%E5%88%9B%E4%B8%9A%E7%9A%84%E6%A0%B8%E5%BF%83\/": {
        
        "title": "创业的核心",
        "tags": ["startup",],
        "content": "创业的核心 创业的核心：\n 把握机会 降低成本 控制风险  ", 
        "url": "http:\/\/myself659.github.io\/post\/startup\/%E5%88%9B%E4%B8%9A%E7%9A%84%E6%A0%B8%E5%BF%83\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/golang\/golang-sync-pool-1\/": {
        
        "title": "深入分析Golang sync.pool",
        "tags": ["Golang",],
        "content": "定义 sync.Pool是一个可以存或取的临时对象池。对外提供New、Get、Put等API，利用mutex支持多线程并发。\n目标 sync.Pool解决以下问题：\n 增加临时对象的用复用率，减少GC负担 通过对象的复用，减少内存申请开销，有利于提高一部分性能  实现 这一部分回答如何实现的问题。\n关于了解实现，最好的办法就是看代码。\n描述 1 2 3 4 5 6 7 8 9 10 11  type Pool struct { noCopy noCopy local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal localSize uintptr // size of the local array // New optionally specifies a function to generate // a value when Get would otherwise return nil. // It may not be changed concurrently with calls to Get. New func() interface{} }   各个成员含义如下：\nnoCopy： 防止sync.Pool被复制\nlocal： poolLocal数组的指针\nlocalSize： poolLocal数组大小\nNew： 函数指针申请具体的对象，便于用户定制各种类型的对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  // Local per-P Pool appendix. type poolLocalInternal struct { private interface{} // Can be used only by the respective P. shared []interface{} // Can be used by any P. Mutex // Protects shared. } type poolLocal struct { poolLocalInternal // Prevents false sharing on widespread platforms with // 128 mod (cache line size) = 0 . pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte }   private：private私有池，只能被对应P使用（说明：P是指goroutine执行所占用的处理器，下同）\nshared： shared共享池，能被任何P使用\nMutex： 保护shared共享池\npad：poolLocal结构体中特别增加了pad成员，这是为了防止false sharing。\n操作 操作分为四种类型：\n New Get Put CleanUp  New 这部分主要解决问题：如何创建一个具体对象池？\n具体参考代码如下：\n1 2 3 4 5 6 7 8 9  // Object Object type Object struct { a int b int } var pool = sync.Pool{ New: func() interface{} { return new(Object) }, }   Get Get解决了如何从具体sync.Pool中获取对象的问题。\n获取对象有三个来源：\n private池 shared池 系统的Heap内存  获取对象顺序是先从private池获取，如果不成功则从shared池获取，如果继续不成功，则从Heap中申请一个对象。这是不是有熟悉的味道？在两级cache的情况下，CPU获取数据，先从L1 cache开始，再是L2 cache， 是内存。\n具体代码实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94  func (p *Pool) Get() interface{} { if race.Enabled { race.Disable() } l := p.pin() // 绑定private池和P x := l.private l.private = nil runtime_procUnpin() // 去绑定private池和P if x == nil { // private池获取失败 l.Lock() last := len(l.shared) - 1 if last \u0026gt;= 0 { x = l.shared[last] // 从shared池获取最后一个对象 l.shared = l.shared[:last] // 从shared池删除最后一个对象 } l.Unlock() if x == nil { x = p.getSlow() // pid对应poolLocal没有获取成功，开始遍历整个poolLocal数组 } } if race.Enabled { race.Enable() if x != nil { race.Acquire(poolRaceAddr(x)) } } if x == nil \u0026amp;\u0026amp; p.New != nil { x = p.New() // 从heap申请对象 } return x } func (p *Pool) getSlow() (x interface{}) { // See the comment in pin regarding ordering of the loads. size := atomic.LoadUintptr(\u0026amp;p.localSize) // load-acquire local := p.local // load-consume // Try to steal one element from other procs. pid := runtime_procPin() runtime_procUnpin() for i := 0; i \u0026lt; int(size); i++ { // 遍历poolLocal数组 l := indexLocal(local, (pid+i+1)%int(size)) // 注意pid+i+1 这样可以从pid+1位置开始整个遍历 l.Lock() last := len(l.shared) - 1 if last \u0026gt;= 0 { x = l.shared[last] l.shared = l.shared[:last] l.Unlock() break } l.Unlock() } return x } // pin pins the current goroutine to P, disables preemption and returns poolLocal pool for the P. // Caller must call runtime_procUnpin() when done with the pool. func (p *Pool) pin() *poolLocal { pid := runtime_procPin() // In pinSlow we store to localSize and then to local, here we load in opposite order. // Since we\u0026#39;ve disabled preemption, GC cannot happen in between. // Thus here we must observe local at least as large localSize. // We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness). s := atomic.LoadUintptr(\u0026amp;p.localSize) // load-acquire l := p.local // load-consume if uintptr(pid) \u0026lt; s { return indexLocal(l, pid) } return p.pinSlow() // 没有对应poolLocal，进入慢路径处理 } func (p *Pool) pinSlow() *poolLocal { // Retry under the mutex. // Can not lock the mutex while pinned. runtime_procUnpin() allPoolsMu.Lock() defer allPoolsMu.Unlock() pid := runtime_procPin() // poolCleanup won\u0026#39;t be called while we are pinned. s := p.localSize l := p.local if uintptr(pid) \u0026lt; s { // 根据pid获取poolLocal return indexLocal(l, pid) } if p.local == nil { allPools = append(allPools, p) } // If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one. size := runtime.GOMAXPROCS(0) local := make([]poolLocal, size) // 重新分配poolLocal atomic.StorePointer(\u0026amp;p.local, unsafe.Pointer(\u0026amp;local[0])) // store-release atomic.StoreUintptr(\u0026amp;p.localSize, uintptr(size)) // store-release return \u0026amp;local[pid] // 返回新的poolLocal }   总结Get主要要点如下：\n 先从本P绑定的poolLocal获取对象：先从本poolLocal的private池获取对象，再从本poolLocal的shared池获取对象 上一步没有成功获取对象，再从其他P的shared池获取对象 上一步没有成功获取对象，则从Heap申请对象  Put Put完成将对象放回对象池。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  // Put adds x to the pool. func (p *Pool) Put(x interface{}) { if x == nil { return } if race.Enabled { if fastrand()%4 == 0 { // Randomly drop x on floor. return } race.ReleaseMerge(poolRaceAddr(x)) race.Disable() } l := p.pin() // 绑定private池和P if l.private == nil { l.private = x // 放回private池中 x = nil } runtime_procUnpin() // 去绑定private池和P if x != nil { l.Lock() l.shared = append(l.shared, x) // 放回shared池 l.Unlock() } if race.Enabled { race.Enable() } }   上面的代码总结如下：\n 如果poolLocalInternal的private为空，则将回收的对象放到private池中 如果poolLocalInternal的private非空，则将回收的对象放到shared池中  CleanUp CleanUp实现 注册poolCleanup函数。\n1 2 3 4  func init() { runtime_registerPoolCleanup(poolCleanup) }   poolCleanup函数具体实现，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  func poolCleanup() { // This function is called with the world stopped, at the beginning of a garbage collection. // It must not allocate and probably should not call any runtime functions. // Defensively zero out everything, 2 reasons: // 1. To prevent false retention of whole Pools. // 2. If GC happens while a goroutine works with l.shared in Put/Get, // it will retain whole Pool. So next cycle memory consumption would be doubled. for i, p := range allPools { allPools[i] = nil for i := 0; i \u0026lt; int(p.localSize); i++ { l := indexLocal(p.local, i) l.private = nil for j := range l.shared { l.shared[j] = nil } l.shared = nil } p.local = nil p.localSize = 0 } allPools = []*Pool{} }   CleanUp时机 什么时候进行CleanUp回收对象池？在gc开始前。\n具体代码(代码文件为runtime/mgc.go)如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  func gcStart(trigger gcTrigger) { ... // clearpools before we start the GC. If we wait they memory will not be // reclaimed until the next GC cycle. clearpools() // 在这里清理sync.Pool work.cycles++ gcController.startCycle() work.heapGoal = memstats.next_gc // In STW mode, disable scheduling of user Gs. This may also // disable scheduling of this goroutine, so it may block as // soon as we start the world again. if mode != gcBackgroundMode { schedEnableUser(false) } ... }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  func clearpools() { // clear sync.Pools if poolcleanup != nil { poolcleanup() // 如果poolcleanup不为空，调用poolcleanup函数 } // Clear central sudog cache. // Leave per-P caches alone, they have strictly bounded size. // Disconnect cached list before dropping it on the floor, // so that a dangling ref to one entry does not pin all of them. lock(\u0026amp;sched.sudoglock) var sg, sgnext *sudog for sg = sched.sudogcache; sg != nil; sg = sgnext { sgnext = sg.next sg.next = nil } sched.sudogcache = nil unlock(\u0026amp;sched.sudoglock) // Clear central defer pools. // Leave per-P pools alone, they have strictly bounded size. lock(\u0026amp;sched.deferlock) for i := range sched.deferpool { // disconnect cached list before dropping it on the floor, // so that a dangling ref to one entry does not pin all of them. var d, dlink *_defer for d = sched.deferpool[i]; d != nil; d = dlink { dlink = d.link d.link = nil } sched.deferpool[i] = nil } unlock(\u0026amp;sched.deferlock) }   总结 总结一下sync.Pool的实现，要点如下：\n 提供New定义实现用户自定义对象 需要使用对象调用Get从对象池获取临时对象，Get优先级首先是本P绑定的poolLocal, 其次是其他P绑定的poolLocal，最后是Heap内存 对象使用完毕调用Put将临时对象放回对象池 未被使用的对象会定时GC回收 对象没有类似于linux cache object对应的free函数  应用 sync.Pool并不是万能药。要根据具体情境而定是否使用sync.Pool。\n总结不适合使用sync.Pool的情境，具体如下：\n 对象中分配的系统资源如socket，buffer 对象需要进行异步处理 对象是组合对象，如存在指针指向其他的对象 批量对象需要并发处理 复用对象大小存在的波动，如对象结构成员存在slice  在排除上面情境下，适合使用的sync.Pool应满足以下条件，具体如下：\n 对象是buffer或非组合类型如buffer reader, json decode, bufio writer 对象内存可以重复使用  同时在使用应该注意问题：\n Put对象之前完成初始化，避免数据污染带来问题, 这可能带来各种各样的问题 写代码时要满足one Get， one Put的要求 注意获取对象后是否存在修改对象内存存局的代码 关注应用场景是否容易出现Pool竞争的情况 sync.Pool不是万能药，不要拿着锤子，看什么都是钉子  (Ps: 个人能力不足，若有错误不足，欢迎指正！)\n参考  sync: Pool example suggests incorrect usage  ", 
        "url": "http:\/\/myself659.github.io\/post\/golang\/golang-sync-pool-1\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/how-to-flow-%E5%BF%83%E6%B5%81\/": {
        
        "title": "如何进入心流状态",
        "tags": ["Learn",],
        "content": "心流状态 心流状态(Flow State)指的是一种不自觉的身心愉悦感,以及投入在一个活动中的极度专注的心理状态。当一个人全身心地投入一项工作或活动时,会体验到这种异常专注且乐在其中的感觉,这就是心流状态。\n心流状态的主要特征有:\n 高度专注。在心流状态下,人们会完全沉浸在活动中,精力集中,周边的干扰被屏蔽。 失去时间感。由于高度专注,人们会忘记时间的流逝,完全不自觉活动进行了多长时间。 自我意识减弱。在心流状态下,人们不会过于关注自己,而是全身心投入活动本身,自我意识变弱。 精力充沛。尽管高度专注会消耗大量精力,但心流状态却能带来精力充沛的感觉,当活动结束后才会有疲倦感出现。 活动本身就是奖励。在心流状态下从事某项活动,人们可以获得享受和满足感,活动本身就是一种奖励体验。 表现更优异。心流状态可以提高人们的专注力和创造力,从而达到更高的工作效率和表现。  达到心流状态需要满足的主要条件:\n 技能与挑战度的平衡。活动难度必须匹配技能,既不会太容易导致厌倦,也不会太难产生挫败感。 清晰的目标。要有具体而清晰的目标或进度来引导专注。 立即的反馈。要有明显的反馈或进度展示来引起专注和趣味性。 投入度高。高度关注并投入活动本身,而非活动结果或其他外在因素。 控制感。有一定的控制感或主导权,可以根据情况调整自己的行为或活动过程。  所以,总体来说,心流状态是一种融合了高度专注、全身心投入以及愉悦感的理想心理状态。通过创建适度的挑战、清晰的目标、即时反馈以及主控感,我们可以达到心流状态,从而获得更好的体验与表现。\n如何进入心流状态 上面的相关心流状态的信息过于理论。在我们的工作过程中如何进入心流状态呢？\n个人认为可以从几个方面入手：\n  无干扰的环境\n  无杂念的心态\n  全身心的投入\n  把握当下\n  只做一件事\n  无干扰的环境   安静无噪音的环境\n  关闭报警与通知\n  带上耳机听一些让自己专注的音乐（具体因人而异）\n  调度上网时间，心流时间段关闭互联网访问\n  关闭不必要的窗口和tab，如使用onetab\n  无杂念的心态  先慢下来，再静下来 深呼吸练习 每天冥想练习 控制社交媒体的使用 学会说不  全身心的投入  了解自己一天身体状态情况，在感觉最好的时候投入 手，眼，耳，嘴，心，脑等尽可能都投入到工作，投入会慢慢地带你进入心流的状态 积极的提示如名人名言与自我肯定  把握当下  不念过去，不想将来，把握当下 当下就是要做这件事的使命感 有意识认识到当下一个时间段最重要的就是做好这件事 只有当下，唯有当下  只做一件事  只有一件事，只有一件事，只有一件事，重要的事情说三遍 这一件事有意义，而且要让自己清楚地看见，看见才能相信 这一件事有挑战，但难度合适，在完成过程能给人带来兴奋与愉悦，促进专注 这一件事有清晰明确的目标与产出 这件事很大概率能完成，完成能够带来良性的正反馈 有意识地只做这件事  如何保持心流状态  限定时间：一次心流状态保持在半个小时到1个小时 避免干扰：听适合自己的音乐 应对干扰：在你进入心流状态后，记下任何分散你注意力的东西，如果你把它们记下来，它们就不会在蹦来蹦去了 补充水分与能量 使用工具减少工作过程的摩擦 更多的自动化辅助，这样会有更多流畅感 建立属于自己的心流的例行过程 完成一个时间段的心流，要奖励自己  总结 心流状态 = 在无打扰的环境下，无杂念全身心地投入到当下的一件事上。\n", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/how-to-flow-%E5%BF%83%E6%B5%81\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/how-to-iterate-%E8%BF%AD%E4%BB%A3\/": {
        
        "title": "如何迭代",
        "tags": ["学习","成长",],
        "content": "重复不如迭代 迭代相比较于重复有以下特点：\n 改变  复用  反馈  结论： 1000次重复不如1000次迭代。\n迭代的原则  小改变，多对比，多迭代 度量迭代 迭代的粒度满足原子性 以bottom-up方式迭代  迭代的循环 迭代的循环由以下过程组成：\n 根据信息做出决策 根据决策开展行动 根据行动展开思考 根据思考更新信息  迭代的过程 针对同一件事情，可以分为三个阶段：\n 开始行动，启动迭代 正确地行动 更好地行动  总结  迭代是进步的步伐 迭代是灵活小巧的改变 迭代是积小成多，由量变实现质变 迭代是行动的改变，打破了常规，是自我突破的开始  ", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/how-to-iterate-%E8%BF%AD%E4%BB%A3\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/sim-port-attack\/": {
        
        "title": "人生中最昂贵的教训：SIM卡转移攻击的细节(译文)",
        "tags": ["BlockChain","Secure",],
        "content": "上周三我损失了10万美元。它在24小时的时间内在“SIM转移攻击”中消失，耗尽了我的Coinbase帐户。事件已经过去了四天，我被摧毁了。我寝食难安;我充满了焦虑，懊悔和尴尬。\n这是我生命中最昂贵的一课，我想与尽可能多的人分享我的经验与教训。我的目标是提高对这类攻击的认识，并促使大家提高在线身份的安全性。\n这仍然是非常原始的（我还没有告诉我的家人）；请大家保留对本文所述的天真安全措施的判断。\n攻击的细节 您可能会问自己，究竟什么是“SIM转移攻击”？为了描述攻击，我们来看一下典型的在线身份。对于大多数人来说，下图应该看起来很熟悉。\n我们大多数人都有一个主电子邮件帐户，该帐户与很多其他在线帐户相关联。我们大多数人还有一个移动设备，如果你忘了密码，可以用这个移动设备来恢复您的电子邮件密码。\n授权的SIM转移 将SIM卡转移到另一台设备是移动运营商为其客户提供的服务。它允许客户将他们的电话号码转移到新设备。在大多数情况下，这是完全合法的要求;当我们升级到新手机，切换移动运营商等时会发生这种情况。\nSIM转移攻击 但是，“SIM转移攻击”是由未经授权的来源（攻击者）执行的恶意转移。攻击者将您的 SIM卡转移到他们控制的手机上。然后，攻击者在您的电子邮件帐户上启动密码重置流程。验证码会从您的电子邮件提供商发送到您的电话号码。 攻击者会截获该电话号码，因为他们现在控制您的SIM卡。下图逐步概括了攻击过程。\n一旦攻击者控制了您的主电子邮件帐户，他们就会开始绕过您通过该电子邮件地址（银行帐户，社交媒体帐户等）管理并支配您的任何在线服务及其资产。如果他们非常恶意，他们甚至可以锁定你的帐户而你却几乎无法收回它们。\n花点时间检查一下单个Google帐户绑定的大量敏感信息：\n 您的地址，出生日期和其他私人，个人身份信息 访问您（和/或您的合作伙伴）的潜在妥协照片 访问您的日历和即将到来的旅行日期 访问您的私人电子邮件，文档和搜索历史记录 访问您的个人联系人及其私人信息以及与您的关系 访问您的主电子邮件地址用作身份验证来源的所有其他在线服务  事件时间线 通过更好地掌握如何进行此类攻击以及所涉及的范围，让我们深入探讨此特定攻击的时间线。我想描绘一下攻击是如何被执行的，以及我是如何经历这些事件的，以及如果您遇到类似的症状，您可以做些什么来保护自己。\n时间线分为四个部分：\n  我所经历的：从我的观点来看所经历的事件。如果你遇到类似的事情，这些都是你可能受到攻击的明确指示。\n  攻击者正在做什么：黑客用来进入我的Coinbase帐户的基本策略。\n  我感知到的威胁级别：我在这些事件发生时将其归因于威胁级别。\n  我应该拥有的威胁级别：事后看来，我希望在这些事件发生时我会拥有的威胁级别。\n  经验教训+建议 这是我生命中最昂贵的一节课。我在24小时内失去了相当重要比例的净值资产; 并且是不可逆的。以下是我鼓励其他人用来更好地保护自己的在线安全的一些建议： 使用硬件钱包，以确保您的加密：将您的密码到硬件钱包 /离线存储/ 多SIG钱包，只要你不交易。不要将资金闲置在交易所或法定进场。我将Coinbase视为银行账户，并且在发生攻击时你绝对没有追索权。我比大多数人更了解风险，但从未想过这样的事情会发生在我身上。我非常后悔没有采取加密安全措施。\n  基于SMS的2FA还不够：无论您尝试在线保护的资产和/或身份如何，都要升级到基于硬件的安全性（即：攻击者为实施攻击而必须物理获取的物理内容）。虽然Google Authenticator和Authy可以将您的移动设备转变为基于硬件的安全性，但我建议您更进一步。拿起你实际控制的YubiKey，不能被欺骗。\n  减少您的在线足迹：减少不必要地在线分享个人身份信息（出生日期，位置，嵌入其中的地理位置数据的图片等）的冲动。在发生攻击时，所有这些准公开数据都可以针对您。 Google Voice 2FA：在某些情况下，在线服务不支持基于硬件的2FA（它们依赖于较弱的基于SMS的2FA）。在这些情况下，您最好创建一个Google语音电话号码（无法通过SIM卡转移）并使用具有2-Factor Auth恢复号码的电话号码。\n  创建辅助电子邮件地址：不是将所有内容绑定到单个电子邮件地址，而是为关键在线身份（银行帐户，社交媒体帐户，加密交换等）创建辅助地址。请勿将此电子邮件地址用于其他任何内容并将其保密。使用某种形式的基于硬件的2FA备份该地址。\n  离线密码管理器：使用密码管理器输入密码。更好的是，使用密码存储等脱机密码管理器。lrvick拥有各种密码管理器的优秀对比图表，以及针对更具技术倾向的审查建议。\n  关于读者的评论 我明白这一点：鉴于我天真的安全实践，我可能就应该注定被黑客攻击。这样做不会减少受到任何伤害，并且会削弱这个故事的主旨，即：\n 让别人知道受到伤害是多么容易 使用上述知识和建议来优先考虑您的在线身份的安全性  我禁不住想到我可以做的小而轻松的事情来保护自己。我的脑海中涌现各种假设。\n然而，这些想法伴随懒惰和幸存者偏见。我从来没有认真对待我的在线安全，因为我从未经历过攻击。虽然我了解自己的风险状况，但是我就是太懒导致我没有用该有的严谨来保护我的资产。\n我恳请你们从这些错误中吸取教训。\n参考  The Most Expensive Lesson Of My Life: Details of SIM port hack  ", 
        "url": "http:\/\/myself659.github.io\/post\/sim-port-attack\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/about-book-reading\/": {
        
        "title": "说说读书",
        "tags": ["Read",],
        "content": "前言 书籍是人类进步的阶梯。\n书箱是前人总结的知识与智慧的结晶。\n读书有利于使我们站上巨人的肩膀，有利于我们提升自己的历史高度，行业高度，哲学高度，这样很多复杂问题可以看得更清楚，可以发现更多解决方案。\n目的 读书的主要目的不是为了记忆，也不是为了批评，而是为了应用。将书中内容应用于自己的知识系统或者解决具体问题。\n原因 读书的原因如下：\n 读书可以增长知识 读书可以帮助你放松和减轻压力，是一种生活要素 读书是一种低成本理解世界的方式 读书是一种高手交流的方式 读书可以提高思考能力 读书可以指导实践，是知行合一的重要一环 读书可以预防老年痴呆症  原则 个人读书的原则如下：\n 读好书 保持怀疑态度，尽信书不如无书 好书要多读与深读，质量比数量更重要 学（读）以致用 读书讲策略与方法 读书要有输出（笔记，思维导图，分享等） 精读为主，避免泛泛而读 带着问题与目标读书 构建与完善自己的知识树，将书中的内容与原来的知识系统建立连接 基于主题读书，同时读几本同主题的书，做到多视角阅读与对比 对阅读进行工程化管理 用好工具如Notion、Obsidian 培养良好的读书习惯如记笔记，建索引，写阅读要点与清单  如何选好书 从以下几个方面考虑：\n 这本书要解释（解决）什么问题？问题是否真实存在？问题的意义是什么？ 这本书的作者是这个领域的顶级专家吗？ 这本书内容有哪些？这些内容具有实时性、创新性、革命性吗？内容对实践有益吗？ 这本书表达是否科学规范严谨？ 自己有兴趣有能力将为本书读下去吗？读了能否用起来？用起来有多大的收益？ 这本书是经典书箱吗？  如何深读 多读容易做到，但是深读需要一些技巧与练习。\n以下方法有利于深度阅读：\n 避免干扰 带着问题读书 写读书笔记与评论 保证每次读书时间在半个小时以内 细节阅读 对比阅读 利用思维导图进行全局阅读与把握 交流与讨论 积极地公开分享 与GPT结对进行对话阅读 升维阅读  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/about-book-reading\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s\/gcloud-login-from-china\/": {
        
        "title": "gcloud auth login from mainland in china",
        "tags": ["devops",],
        "content": "backgroud 最近使用了google cloud，所以打算试一下通过gcloud auth login登陆远程主机。\nprerequisites  科学上网的通道 terminal配置代理  config gcp proxy for gcloud 一般情况下，有上面的准备，gcloud auth login应该会成功，实际上并没有。这是因为还要指定gcloud config的代理配置，具体参考配置 gcloud CLI 以在代理/防火墙后面使用.\n", 
        "url": "http:\/\/myself659.github.io\/post\/k8s\/gcloud-login-from-china\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/business\/about-zoom\/": {
        
        "title": "关于zoom的一些思考与看法",
        "tags": ["商业","Internet",],
        "content": "前言 最近zoom上市，作为一名华人创业公司自然大受关注。下面从以下几个方面谈谈自己的一些思考与看法：\n 技术 领导 产品 商业  技术 对于视频面试会议，技术核心分为以下三大块：\n 基础设施架构 网络传输技术 音视频技术  领导  招聘方面重点在自我激励和学习，招聘有发展潜力的人 2019年，Zoom还在全美最佳雇主公司排名中位居第二位，也是一个非常让员工喜欢的创业公司。这个投票应该还是可以相信的，没有内幕 信任来自开放。越开放，越信任。作为公司的领导要开放与底层员工的连接通道 一个公司或者一个组织甚至一个国家，解决问题是第一要义是正视问题，而不是逃避问题，应该鼓励发现问题  产品 先说对于zoom的评价，确实好用，个人从2016年就开始使用。\n 永无止境，WebEx在当时的市场已经占有很大的市场，但是zoom创始人并没有停留在市场占用率上而是准确地看到WebEx背后的问题。 欲速则不达。耐心地打磨产品，zoom在2011年成立，到2013年才首次发布产品Zoom Meetings，这放在国内是无法想像的，很多创业公司三个月就要出产品，结果创业公司还是每年死一大片，而zoom却从视频会议领域众多竞争对手中脱颖而出。 套用一句话：从人民群众中来,到人民群众中去。从用户中来，到用户中去，需求从用户中来，真正地倾听用户的心声，产品与服务落实到用户，让用户享受实在的便利与好处 直播改变生活，学习与工作；快手、抖音、zoom就是很好的说明 视频大行其道，视频降低用户门槛，视频用户体验更好，视频中包含更多的信息  商业  追求低成本，高效率，zoom将研发大部分放在中国内地，中国内地人均30W左右，在美国硅谷招一个软件工程师起薪差不多90W吧，这样从而整体上降低了zoom的成本。zoom上市就能营利，让其在股价方面表现十分出色。 双赢的原则，zoom让员工开会不受地点限制，只要有网络就可以，同时也降低企业的运行成本。 降低门槛，视频会议降低了会议的门槛，打破空间的限制，zoom易用性降低了使用门槛，只要手机和电脑再加上网络就可以进行一场会议。国内有不少企业还卖专门的视频会议硬件系统，这样一开始就输，研发成本需要投入，价格还高 优势原则。市场竞争，优势劣汰。一定要建立优势如成本优势，用户体验优势，先发优势，差异化优势 zoom有2000倍的市盈率。这说明什么？泡沫吗？从数字上看是这样的。但是股价体现是预期，这说明视频协作会是未来发展一个方向。视频协作现在应用率还是很低，未来还是有很大的增长空间，除了视频会议还有更多的应用场景，如远程医疗。  总结 zoom创始人袁征从1997年WebEx一名程序员到2011年思科工程副总裁，负责WebEx产品。在这个阶段他完成了技术与领导大部分积累。从2011年开始创办zoom进行产品化与商业化，到2019年IPO上市，使产品化与商业化达到一个新的台阶。程序员在提高自己的技术能力的同时，要努力培养领导能力，产品能力，商业能力。\n参考  Zoom成功上市：市值超160亿美元 华裔创始人走向人生巅峰 连续四年保持三位数增长，搞视频会议的 Zoom 有三大关键秘诀 扎克伯格：80%的企业文化由创始人决定 《原则》读书笔记八 如何做到极度求真与极度透明 生活在一个十分钟就能走完的安逸小城，给生活做减法 How Zoom Beat the Tech Giants  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/business\/about-zoom\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E9%80%89%E6%8B%A9%E5%8E%9F%E5%88%99\/": {
        
        "title": "选择的原则",
        "tags": ["Think",],
        "content": "背景 学会选择很难。 学会做出好的选择更难。 在这个复杂的世界里学会做出正确的选择更难。\n选择很重要。不是有一句话：\n 选择比努力更重要。\n 原则 个人对于选择的原则总结如下：\n 先准备选项，再来选择 拓展选择的空间 明确选择的目标与选择的取舍 永远选择能给你更多的选择的选项 明确选择的目标之一：选择后不后悔 考虑选择后会失败的情况 没有完美的选择，一切都是tradeoff 永远不要在情绪激动时做出重大决定  选择的空间至少包括以下三个方面：\n 做出选择的空间（时间） 选项的空间（数量） 选项背后的空间  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E9%80%89%E6%8B%A9%E5%8E%9F%E5%88%99\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/understand-socity-abstraction\/": {
        
        "title": "理解社会的抽象",
        "tags": ["Thinking",],
        "content": "背景 认识自己与认识世界，是我们学习两个方面。\n世界很大，有客观的物理世界，有由人组成的社会，有虚拟的世界等等，这里还是先以人为本，先看由人组成的社会。\n社会的抽象 对于我们要认识的社会，个人对其抽象如下：\n一切皆利益\n一切皆交易\n一切皆博弈\n一切皆连接\n一切皆网络\n一切皆变化\n一切皆人性\n既然是抽象，那就不展开说明。\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/understand-socity-abstraction\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E8%AF%81%E5%AE%9Evs%E8%AF%81%E4%BC%AA\/": {
        
        "title": "从逻辑运算看证实和证伪",
        "tags": ["Think",],
        "content": "前言 我们处于信息社会，实际上只是信息很多，但是真相确却很少。\n假设 假设一个事件发生，现在已知要满足N个条件（实际上可能不止N个条件）。\n证实 用编程语言表示证实逻辑如下：\n1 2 3  if( 条件1 \u0026amp;\u0026amp; 条件2 \u0026amp;\u0026amp; 条件3 \u0026amp;\u0026amp; 条件4 \u0026amp;\u0026amp; 条件5 ...){ return True; }   从上面的伪代码可以知道：\n 证实首先明确这个事件如果要发生，需要哪些条件，但是获取到所有发生的条件难度大 证实的过程需要验证每一个条件，成本高  证伪 用编程语言表示证伪逻辑如下：\n1 2 3  if( !条件1 || !条件2 || !条件3 || !条件4 || !条件5 ...){ return False; }   从上面伪代码可以知道：\n 证伪不需要知道事件发生所需要的所有的条件 证伪只需要证明一个条件不被满足即可  结论 证伪只需要证明一个条件不符合即可，所以优先选择证伪。 从成本看证伪的成本远小于证实。 只要证伪的信息越多，那么离真实也就越来越近。\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E8%AF%81%E5%AE%9Evs%E8%AF%81%E4%BC%AA\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-info\/": {
        
        "title": "区块链，加密货币与web3常用信息来源",
        "tags": ["BlockChain",],
        "content": "技术 medium cryptocurrency\nmedium blockchain\nhackernoon NFT\n新项目 icodrops\nThe Complete ICO Calendar\n资讯 coindeck\ntwitter naval\nbalajis.com\nVitalik\nAshleigh Schap\nArthur Hayes\nStani Kulechov\nGloria Kimbwala\nRic Burton\nDennison Bertram\nAustin Griffith\nSantiago Palladino\nZaki Manian\nAnthony Sassano\ntitter follow suggest list \ntelegram  Fat Pig Signals Universal Crypto Signals Verified Crypto Traders Rocket Wallet Signals  数据与分析 messari\nBlog haseebq\nbalajis\u0026rsquo;s blog\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-info\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/it-frame\/": {
        
        "title": "分享一种分析信息技术发展的框架",
        "tags": ["BlockChain","Internet",],
        "content": "信息技术发展史 为了与原文保持一致，将信息技术发展史分为以下6个阶段：\n 大型机时代 PC时代 互联网时代 社交网络时代 智能手机时代 区块链时代  框架介绍 将信息技术要素分为以下四种：\n IO(接口) Infrastrure(基础设施) CPU(计算) HD(存储)  将技术要素分布为两个方向：\n User(用户端) Remote(远端即服务端及云端)  总体上来说，整个框架具有普适性，并且框架简单清晰。\n大型机时代-\u0026gt;PC时代 框架变化:\nPC时代\"\n成本：\n 计算处理能力减弱，存储空间变小  收益：\n 降低计算机使用门槛，方便更多人使用  数据:\n主机集中数据转向个人PC时代去中心化数据\n开发者的新机会：\n 分发(软盘，CD) 新技术(本地数据，GUI，扬声器)  市场的新机会：\n 消费级操作系统(微软，苹果) 视频游戏(EA sports，ID software) 硬件(Apple，IBM，HP，Dell)  PC时代-\u0026gt;互联网时代 框架变化:\n互联网时代\"\n成本：\n 互联网数据成本 新公共基础设施的成本开支  收益：\n 更多更便捷的信息访问入口，更大的存储空间，更强的计算处理能力  数据:\n中心化存储数据。\n开发者的新机会：\n 分发(云基础设施)  市场的新机会：\n 网上购物(亚马逊，eBay，Paypal) 在线广告(谷歌，雅虎) 流媒体(Skype，Netflix) 互联网服务提供商(AOL)  互联网时代-\u0026gt;社交网络时代 框架变化:\n社交网络时代\"\n成本：\n 隐私  收益：\n 通过线上打通线下 个性化  数据:\n中心化存储(隐私)数据。\n开发者的新机会：\n 应用分发 信息分发  市场的新机会：\n 个性化广告(Facebook，Twitter，LinkedIn) 共享经济(AirBnb) 社交游戏(Zynga)  社交网络时代-\u0026gt;智能手机时代 框架变化:\n智能手机时代\"\n成本：\n 更小的屏幕 无键盘 更小的计算能力 更少的存储空间  收益：\n 易于创建媒体 提高访问网络的便捷性  数据:\n 去中心化生成数据 中心化存储数据  开发者的新机会：\n 分发(App store) 新技术(GPS和相机)  市场的新机会：\n 媒体分享(Pinterest，Instagram，Youtube) 基于位置的服务(Uber，Lyft) 消息(Snapchat，Whatsapp，Telegram)  智能手机时代-\u0026gt;区块链时代 框架变化:\n区块链时代\"\n成本：\n 更多计算与处理 更多网络流量 效率低  收益：\n 不可变数据 审查制度  数据:\n 可信数据的去中心化分布与存储  开发者的新机会：\n 新技术(信任)  市场的新机会：\n 全球便利网络(供应链，NFT即Non-Fungible Token) 价值存储(比特币) 法律(法律合同，治理，审计)  说明 框架不是原理，同时内容很简单，相信大家一定有很多其他的看法与意见，权且当作抛砖引玉，欢迎交流。\n另外本文主要内容来自My framework for how to look at the future of blockchain，原文的目的通过这个框架讨论区块链的未来。本人只是想把这个框架介绍给大家，再加一些个人对这个框架的一点解释而已。\n(End)\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/it-frame\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s-kubeagle\/": {
        
        "title": "利用Kube Eagle监控Kubernetes集群资源",
        "tags": ["Docker","Kubernetes",],
        "content": "安装helm helm是Kubernetes集群的npm。\n下载脚本add_helm.sh 脚本内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  #!/usr/bin/env bash  echo \u0026#34;install helm\u0026#34; # installs helm with bash commands for easier command line integration curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash # add a service account within a namespace to segregate tiller kubectl --namespace kube-system create sa tiller # create a cluster role binding for tiller kubectl create clusterrolebinding tiller \\  --clusterrole cluster-admin \\  --serviceaccount=kube-system:tiller echo \u0026#34;initialize helm\u0026#34; # initialized helm within the tiller service account helm init --service-account tiller # updates the repos for Helm repo integration helm repo update echo \u0026#34;verify helm\u0026#34; # verify that helm is installed in the cluster kubectl get deploy,svc tiller-deploy -n kube-system   执行脚本安装helm 1  sh add_helm.sh   安装kube-eagle 主要体验一下helm使用(刚开始我都是自己手动安装Prometheus)。\n添加repo 1  helm repo add kube-eagle https://raw.githubusercontent.com/google-cloud-tools/kube-eagle-helm-chart/master   更新repo 1  helm repo update   安装kube-eagle 1  helm install --name=kube-eagle kube-eagle/kube-eagle   可视化 具体如下：\n整体集群的资源使用情况是不是一目了然了？\n参考  Kube Eagle Helm Chart Kube Eagle Dashboard  ", 
        "url": "http:\/\/myself659.github.io\/post\/k8s-kubeagle\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/python\/python-packages\/": {
        
        "title": "The popular python packages you should know",
        "tags": ["python",],
        "content": " Life is short, I use Python.\n I try to summary the popular python packages as follows:\nNumber and Math  sympy Sage numbers math cmath decimal fractions random statistics  Data and statistics  Matplotlib seaborn numpy pandas plotly  Web Development  Django FastAPI  GUI  pyqt PySimpleGUI  automation script  pathlib os  Machine Learning  TensorFlow Scikit OpenCV streamlit  Web Scraping and Web Automation  Requests Beautiful Soup Scrapy Selenium  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/python\/python-packages\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/vscode-tips\/": {
        
        "title": "vscode tips",
        "tags": ["Tool",],
        "content": "安装 1  brew install visual-studio-code   配置 进入配置  文件-\u0026gt; 首选项 -\u0026gt;配置 点击右上边的文件图标，进入打开设置（打开配置文件C:\\Users\\IA\\AppData\\Roaming\\Code\\User\\settings.json）  shortkeys 说明 本文以windows为例。\nbasic  F2: rename ctrl + p: open command options ` ctrl+ `` : open terminal ctrl + Shift + F: search ctrl+ K, then Z: zen mode esc esc: from zen mode to the normal editor view ctrl+B: Toggle sidebar  Navigate  F8: Navigate errors and warnings  File  ctrl+f4: close file ctrl+W: tab through open files  editor  ctrl + \\: split editor ctrl + Shift + T: open a Closed Editor ctrl + T: open a file Ctrl + Home: go to the beginning of file Ctrl + End: go to the end of file CTRL + K + W: Close all open editor tabs SHIFT+ALT+F: Format document  cursor  Ctrl+Shift+L: Create cursor on all occurrences Ctrl+Shift+Arrow key: Add the cursor alt+ mouse click at the position： Insertadditional cursors ctrl+ U: remove additional cursors  code ctrl + t: search current workspace sysmols ctrl + Shift + o: search current file sysmols ctrl + Alt + Up arrow/Down arrow.: . Add Multiple Cursors Shift + Alt + F: formart code Ctrl + Backspace： Delete Previous Word Ctrl + Shift + Right Arrow: select texts word by word from right to left Ctrl + Shift + Left Arrow: select texts word by word from left to right Ctrl + Shift + [: To fold the innermost uncollapsed region at the cursor Ctrl + Shift + ]: To unfold the innermost uncollapsed region at the cursor Shift + Alt:Column (Box) Selection Ctrl+K Ctrl+0 : fold all sections Ctrl+K Ctrl+J: unfold all sections CTRL + SHIFT + L: Add cursors to all matching selections CTRL + D: Add cursor to next matching selection Shift + Alt + Up/Down: Copy Line Up/Down ctrl+ shift + \\: Find a matching bracket shift + alt + → or ←: move and expand the selection shift+ alt+ A: add block comment ctrl+ /: add comment  line  alt +J: join lines ctrl +g: jump to line Alt + Up arrow/Down arrow: move line Ctrl + Shift + D: Duplicate Line Shift + Alt + Up/Down: Copy Line Up/Down ctrl + x: delete current line Ctrl+Shift+K: Delete an entire line CTRL + L: Select current line CTRL + Enter: insert line below CTRL + Enter + Shift: insert line above  extensions   Prettier - Code formatter\n  ESLint\n  Color Highlight\n  Bracket Pair Colorizer 2\n  GitLens\n  Live Share\n  VS Code Remote Development\n  Peacock\n  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/vscode-tips\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/principle-of-work\/": {
        
        "title": "谈谈做事的原则",
        "tags": ["职场","成长",],
        "content": "前言 这篇文章规划了很久，本来打算年前写，各种事情加上自己的拖延症，到现在才开始写。\n做事 如果说人的一生做什么？总结一下，可以划分两个方面：\n 做人 做事  这两方面很多人喜欢用一句话来指导自己：低调做人，高调做事。在这里简单地谈一下自己对做事的原则的一些思考。\n原则 关于做事，个人总结出来以下五个原则：\n 不要给自己设限 尊重事实与客观规律 站在巨人的肩膀上 正确的方向与方法 敏捷的行动  不要给自己设限 在中国历史上，从陈胜与吴广喊出\u0026quot;王候将相,宁有种乎\u0026quot;，在中国2000多年的历史，刘邦，刘裕，朱元璋以及太祖无不是从社会的底层走上权力的巅峰。在科技发展过程中 莱特兄弟并没有因为万有引力定律放弃研制飞机，终于发明世界上第一架飞机， 为后面的航空航天打下坚定的基础。\n上面都是正面的例子，下面以自己为例举一个反面的例子：在2016年微信小程序出来的时候，当时就很看好微信小程序的未来，但是由于自己是一个后端程序员，不会前端代码开发，当时就认为这是前端作的事情。其实在现实工作中，我们时常也会给自己设限：\n \u0026ldquo;这个东西没有弄过\u0026rdquo; \u0026ldquo;我不会这个\u0026rdquo; \u0026ldquo;这个不属于我的工作范围\u0026rdquo;  二战以后，世界总体和平，特别是信息技术发展，无论是对公司和个人都有很多的空间和机会去探索。如果给自己设限，会失去大量的机会，对不起这个人类历史上最好的时代。\n尊重事实与客观规律 无论怎么样，事实就是事实，过去了就是过去了。大部分都是普通人，不是乔布斯没有强大的现实扭曲力。\n尊重人性，牢记与践行以人本为的理念。\n不要心存妄想。这样才能脚踏实地。放弃不劳而获的想法，摈弃白日梦。走实用主义线路，这样才能建立长期心态。\n尊重客观规律，可以避免永动机，水变油等陷阱。以不会以个人之力去对抗系统。\n尊重事实与客观规律，当自己犯了错误的时候，有助于及早发现错误，避免错的更多，错的时间更长，降低了改错的成本。\n站在巨人的肩膀上 这里说明一下巨人的的肩膀是指不以个人或团体的意志为转移的环境及趋势等。举例如下：\n 孙子兵法上讲天时，地利，人和；在中国历史上有以少胜多的例子如赤壁之战，无不是在天时，地利，人和上占了先机 前人的经验与成果，这里不得不推荐google搜索 趋势，正面的例子是这几年很流行的话：站在风口上，猪都能飞起来；反面的例子就是大润发，其创始人抱憾出局：我赢了所有对手，却输给了时代 利用平台与工具，如开发微信小程序就充分利用微信的用户，场景，流量，商业基础设施等 大部分政策，如房地产市场  对于如何站在巨人的肩膀上，个人一点体会：\n 思想上作到拿来主义，行动方面要善假于物 避免不必要从0到1，如重复造轮子 合理地使用杠杆 不断学习与实践，提高认知水平与学习能力，保证可以站上更多巨人的肩膀  正确的方向与方法 \u0026ldquo;选择比努力重要\u0026rdquo;， 这是大家常说一句话，可见正确的方向与方法的重要性。\n这里引用曹大在其个人分享《成长的烦恼》中的一段话：\n 告诉大家一个秘密，很多企业快速膨胀的时候，那些中层为了自己的发展，快速扩张，快速启动新的项目团队，每个项目看上去都很有价值很有机会，然后大家都很忙碌很拼为了各种新的机会打拼，但是呢，其实从公司战略和格局来说，绝大部分都是实验品，甚至连实验品都不算，是领导暂时没功夫搭理的垃圾。等遇到市场风向逆转的时候，老板开始核查成本，这些乱七八糟的玩意，咔嚓嚓砍掉，你觉得不公平，你很拼很努力的为公司效力，你加班修改bug，解决线上问题，各种辛苦各种贡献，结果老板看了一眼，一文不值，真的是一文不值。\n  太多优秀的人才，在巨头公司里，连公司的核心价值和主要方向都看不清，在各种根本不重要的细枝末节里荒废了自己，最后在老板眼里一文不值。\n 只有方向对了，速度才有意义。\n其实在做事的时候，可以问一下自己几个问题：\n 我找到或想到了哪些方向与方法吗？ 这些方法可以起作用吗？ 还有没有更好的方法（选项）？  借助这几个问题，可以继续追问，找到事情与问题的关键所在。\n敏捷的行动 确定方向与方法后就是要行动。不然所有想法都是水中月，镜中花。这里自我批评一下，行动是我做的最差的一部分。\n敏捷的行动分解为以下几点：\n 不要等 试错 制定行动计划 迈出第一步 小步快行 轻装上阵 建立行动的正向循环 不断改进  不要等 不要等万事俱备才开始。时间是最宝贵的资源。在很多的情况下，等就是一种浪费。当处于等的情况，问自己几个问题：\n 是否需要等？ 哪些事情现在就可以去做？  以自己为例，2014年初准备要学习玩一下股票，但是自己连一个股票帐号都没有开。直到2015年4月在一个证券公司，然后在2015年5月进场了，好在当时买的股票是海康威视，后面解套了。（这里强调一下，这里只是举一个例子说明，投资有风险，入市须谨慎）\n试错 不要怕犯错。错误是一种收获，那么低成本试错就是一种高收益的回报了。\n避免完美主义。Done is better than perfect。\n制定行动计划 制定行动计划就是规划行动线路图，其关键要点是milestone与deadline，制定原则参考SMART原则。\n迈出第一步 迈出第一步，那么第一步从哪里开始？可以根据情况从以下三种选择一个即可：\n 从最容易的开始 从最基础的开始 从最熟悉的开始  小步快跑 以互联网产品为例，讲究的就是用最低的成本、最小的规模、最快的速度去尝试一个粗糙的东西，然后快速的拿到市场上去尝试，如果好，就趁热打铁，继续做下去，并把它做大做强。如果不好，就赶快转换方向。\n研发领域敏捷开发就是这方面的体现，这里不展开。\n轻装上阵 卸下包袱：避免外界的干拢，保持专注；事件一件一件做，避免多项事情并行。\n充实精力：主要是两个方面身体与时间；健康的身体永远都是宝贵的财富；保证合理的时间投入到具体行动中。\n放松心态：告别悲观与焦虑，保持积极乐观的心态，悲观者往往正确,乐观者往往成功，在行动过程中作一个乐观者成功的概率会加大很多。\n建立行动的正向循环 行动是一个长期的行为，贵在坚持，需要建立一套适合自己的激励机制。 简单总结为一句话：寻找动力，培养兴趣，养成习惯，实现自我驱动。\n不断改进 只有不断进步的行动，才会更好的效率，这需要在执行过程中不断优化每一个方面及过程。\n小结 不要给自己设限是解决做什么的问题，通过打破界限，扩大做什么的范围，为做什么提供更多的可能与选择的空间。\n站在巨人的肩膀上是解决在什么基础上及在什么环境下做事的问题。\n正确的方向与方法是解决怎么做的问题。\n敏捷的行动是解决做成事的问题。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/principle-of-work\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/pow-is-out\/": {
        
        "title": "PoW过时了吗？",
        "tags": ["BlockChain",],
        "content": "ETC受到51%攻击 最近ETC受到51%攻击，值得注意是：ETC是受到51%攻击的币种中市值最高的。 先谈谈ETC受到51%攻击原因。ETC采用PoW共识机制，现有PoW共识天然存在51%攻击的风险，真实发生ETC的51%攻击原因如下：\n 由于ETC价格大跌，算力下降，降低了发起了51%攻击的成本 由于矿场存在，实现算力大规模的垄断，同时算力切换方便，为发起51%准备了客观条件  反想一下，ETC市值是前20名，那些小币种，山寨币们都是下一个待宰的羔羊。 连ETC都受到攻击，那么PoW过时了吗？\n下面简单聊一下如何改善PoW。\n如何改善PoW dPoW dPoW方案来自Komodo（大家自行google）。 其要点就是将一段时间内的交易hash发送到BTC，在这种情况下，如果要发动51%攻击需要达到攻击BTC的算力要求，提高了攻击成本。\n第二算力有效原则 这个想法来源于第二价格密封拍卖，主要是为了打击算力竞争。\n算力限制 限制算力过强的节点，避免算力的复制，聚集，从而导致垄断，保证算力的去中心化。关于算力限制的方案欢迎交流。\n结合VRF 利用VRF的随机性，每次随机选择一批节点参与PoW。\n扩展Work的内容 现在基本上所有的PoW都上纯计算，浪费大量的算力，这些算力都成为了沉没成本。发现不少项目将PoW中Work用于AI计算。\n总结 PoW是一个伟大的共识创新，创造性地解决了拜占庭容错问题。PoW并没有过时，PoW会不断发展与改善。\n参考  第二价格密封拍卖  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/pow-is-out\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/cache-101\/": {
        
        "title": "Cache 101",
        "tags": ["arch",],
        "content": "前言 在现在互联网系统中cache无处不在，无时不用。\n定义 wiki定义如下：\n a cache is a hardware or software component that stores data so that future requests for that data can be served faster;\n 工作原理 一句话：通过将源数据缓存Cache，实现直接通过Cache访问数据。\n属性与指标 关注的cache属性与指标：\n TTL(Time to live) Cache capacity Eviction Policy，具体如LRU (Least Recently Used), LFU (Least Frequently Used), MRU (Most Recently Used) cache conflict cache hit ratio cache coherence cache scalablity  类型 cache更新策略 根据cache更新策略分为以下几类：\n Write Through Cache Write Back Cache Write Around Cache  存储类型 根据应用场景，常见类型如下：\n L1 cache L2 cache L3 cache Memory cache SSD cache disk cache network cache （CDN）  cache与程序关系 根据cache与程序关系分为：\n Local cache External caches  常用cache产品 常用cache产品如下：\n redis Memcached VoltDB Aerospike DBS  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/cache-101\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/%E5%85%B3%E4%BA%8E%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%B1%E8%AF%86%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83\/": {
        
        "title": "关于区块链共识的一些思考",
        "tags": ["Distributed","BlockChain",],
        "content": "说明 前面写一篇关于分布式系统的文章，但是没有考虑拜占庭问题，所以聊聊区块链共识技术，在这个过程看看比特币是如何解决拜占庭问题和共识问题。\n定义 区块链是什么？这个问题有太多的回答。\n 区块链是一个由全体联网节点共同维护并持有同一账本的分布式数据库，它通过算法来达成共识，在无需信任的各节点中构建一个无单一故障点或控制点的去中心化可信系统\n 所以在技术上区块链的本质是分布式帐本技术(DLT)。\n重要性 Why Decentralization Matters这篇文章从互联网发展历程与面临问题说明去中心化重要性。\n去中心化重要性来自去中心化带来的影响与作用，具体如下：\n 去中心化可以降低垄断的可能性，是一种对抗垄断的重要方式 去中心化提供高可用性 去中心化对抗DDos 去中心化可以让人人参与，权力下放 去中心化是让数据归还用户，保护隐私的重要技术手段之一 去中心化消除中间环节，提高效率 去中心化与中心化并不是对立，可以相互补充 去中心化能够解决中心化无法解决的问题，如微信流控算法，并没有采用全局，而由节点根据延迟参数调整，另外是5G带来的高速传输与海量数据需要去中心化来来解决  去中心化解决问题  提供全球开放的分布式数据 提供不可更改的数据库 提供trustless的基础设施 基于以上三点的业务的需求  思考模型 如同前面的分布式系统一样，对于公链（去中心化系统）问题，也可以分为以下几个子问题：\n 在什么环境下？ 有哪些节点参与？ 通过什么样的共识算法？ 使什么业务？ 达成什么样的容错要求？  总结一句话：在什么环境下，有哪些节点参与，通过什么样的共识算法，使什么业务达成什么样的容错要求。\n下面就这五个问题展开说明。\n环境 大部分去中心化系统的环境要点如下：\n 异步网络模型 网络结构是P2P网络 网络传输是不可靠的 系统异常是常态 并发 缺少全局时钟  (Ps:这里不展开说明了，谈谈对分布式系统的一些思考)\n节点 节点准入方面  节点自由加入与退出 节点需要通过PoW测试才能加入 节点需要PoS持仓才能加入 节点需要质押才能加入  节点角色  节点平等，无角色任何差异如比特币 节点分为超级节点，见证节点如EOS  节点数量  不限数量，如比特币，以太坊 指定数量，如EOS指定为21，steemit指定数量为11  节点可信  存在不可信的作恶节点 可信节点（算力）一定多于作恶节点（算力）  节点配置  机器性能波动大 网络带宽波动大 节点分布在全球各地 节点配置不受控 节点之间差异大如算力，POS投票权重  节点经济原则  99.99%以上节点是趋利 节点受激励引导 节点受惩罚限制 节点之间存在博弈与竞争 节点不会作出投入成本大于产出收益的选择  共识算法 一定要摆脱传统分布式思想的限制。要在经济，竞争，博弈，协议等多方面有效结合。\n从上图可以看出，传统分布式共识算法在整个共识里面只占很小一部分。 共识算法是区块链技术上的核心。\n不得不说，PoW是另一种形式实现拜占庭容错，是比特币最大的亮点。\n属性 一个科学共识算法必须同时满足以下四个属性：\n Agreement Validity Integrity Termination  这四个属性从四个方面规范共识算法的要求，也为我们提供分析共识算法四个不同的视角。\nAgreement  Every correct process must agree on the same value.\n 这是实现一致性必须要做到的要求：每个节点必须达成一致。 bitcoin通过以下几点实现该属性，具体如下：\n 在选主方面选择最强算力原则，保证具体高度的区块的一致性（以最快算出的为准） 在链分叉情况下选择最长链，解决网络分化等原因可能出现的分叉问题  Validity  If all the correct processes proposed the same value v, then any correct process must decide v.\n Validity是为了防止这种情况的出现：一些节点无论提议什么值，本节点一直提交NULL。在bitcoin这种行为可以理解为自私挖矿行为。\nbitcoin通过以下几点实现该属性，具体如下：\n 算力不可复制 随机性加大自私挖矿的成本 最长链确认由各节点自行确认 时间戳确认  Integrity  No Node decides twice.\n 保证共识得到一致性不可逆，不可被修改。那么在这成共识过程中有许多操作需要进行限制。 bitcoin通过以下几点实现该属性，具体如下：\n 链式结构 算力要求 难度提升 多节点竞争  Termination  Eventually, every correct process decides some value.\n Termination是一个liveness属性，bitcoin通过以下几点实现该属性，具体如下：\n 通过激励吸引大量节点参与，保证有节点来完成出块 出块时间周期设置10分钟  业务 去中心化带来业务的形态的变化，现列举部分业务如下：\n 去中心化交易所 去中心化网络平台 去中心化计算平台 去中心化存储 去中心化CDN 去中心化数字货币 去中心化协议 去中心化跨链 去中心化金融科技DeFi 去中心化通信  容错要求 对于去中心化系统，对应的容错要求是DCS定理。\nDCS定理 如同CAP定理一样，DCS定理是指在一个公有链系统中不可能同时满足以下三个条件：去中心化（Decentralized）、一致性（Consistency）和可扩展性（Scale）。\n去中心化 去中心化是指任意节点可以加入与退出，整个网络不受任何人控制。\n一致性 与上面CAP的一致性类似，不过应用中更加偏重安全如防范双花攻击。\n可扩展性 可扩展性是指TPS能够实现提高。\n关于DCS这三者之间的tradeoff，更多参考The DCS Triangle\n小结 区块链的共识现在还处于探索阶段，并不像分布式系统共识（不考虑拜占庭问题）已经成熟。区块链的共识在不断探索与发展中，未来会有更多的新型共识出来。\n参考  Why Decentralization Matters The DCS Triangle SoK: Consensus in the age of blockchains DAGOR：微信微服务过载控制系统 A Brief Tour of FLP Impossibility Agreement with Satoshi – On the Formalization of Nakamoto Consensus Yuval Noah Harari: Why fascism is so tempting and how your data could power it | TED Talk Tech C.E.O.s Are in Love With Their Principal Doomsayer 谈谈对分布式系统的一些思考 Algorand’s Instant Consensus Protocol 区块链到底有什么了不起 BitTorrent 公有链的基本挑战 Blockchains don’t scale. Not today, at least. But there’s hope. Consensus Protocols of Distributed Ledger Technology  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/%E5%85%B3%E4%BA%8E%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%B1%E8%AF%86%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/distributed-theory\/": {
        
        "title": "谈谈对分布式系统的一些思考",
        "tags": ["Distributed",],
        "content": "说明 本文限定在分布式系统不考虑拜占庭问题。即所有节点都是可信的。\n定义 分布式系统是多个节点协作完全一个共同的业务。\n重要性 分布式理论的重要性毋庸置疑，一句话总结：没有分布式理论，就没有现在互联网与云计算。在分布式系统实践过程中离不开分布式系统理论指导，对其重要性打个比方：分布式系统理论是分布式系统实践过程中地图与导航。\n分布式主要解决问题 分布式主要解决以下几个问题：\n 解决SPOF问题，满足高可用性需求 解决Scale out问题，满足扩展性需求 解决数据分布问题，满足业务的需求  分布式是解决方案也是问题 一般情况，人们为了解决一个问题，往往会引入一个新的问题。试想如下： 由于SPOF存在，再加入一个节点作为备份。这样确实提高了系统高可用性，但是有以下新问题：\n 如何检测节点状态？如何快速检测节点状态？ 如果检测主节点失败，备节点如何进行切换？ 主备节点如何同步数据？ 网络分化出现双主，如何避免与处理？  思考模型 对于分布式系统理论，分为以下几个子问题：\n 在什么环境下？ 有哪些节点参与？ 通过什么样的共识算法？ 使什么业务？ 达成什么样的容错要求？  总结一句话：在什么环境下，有哪些节点参与，通过什么样的共识算法，使什么业务达成什么样的容错要求。\n下面就这五个问题展开说明。\n环境 分布式系统环境特点如下：\n 从网络同步模型上分为同步网络，异步网络，半同步网络三种 系统异常是常态 网络传输是不可靠的 并发 缺少全局时钟  网络模型 同步网络是指网络带宽与延迟都是可以保证的。实际上现在IP网络都不属于这种，满足这种的网络是ATM网络（注意不是我们常见的提款机ATM）。\n异步网络则是指网络带宽与延迟都不确定，在异步网络发送的报文会丢失。我们正在使用主的IP网络属于这种。\n部分同步网络处于这两者中间。\n异常 机器异常通常有以下几种情况：\n 电源 机器元器件故障如内存，硬盘 操作系统故障 软件故障与程序bug 资源耗尽，如内存，CPU，硬盘空间，网络带宽等  网络传输不可靠 网络传输不可靠主要体现以下几个方面：\n 丢包，传输成功不确定性 延时，延时时间不确定性 重传与报文重复 乱序  并发 如同操作系统中多线程并发，分布式系统多节点在并发。但是分布式系统的并不能像多线程上通过操作系统的锁机制来处理并发，在分布式系统实现一个锁比操作系统上难度大多了。\n缺少全局时钟 一个人有一只表时，可以知道现在是几点钟，而当他同时拥有两只时却无法确定。分布式系统不同节点很难有相同的时钟。\n节点 节点数量 节点数量，在实践过程中，至少两个，常见三个节点，部分情况五个节点。\n节点角色 以raft为例可以分leader，follower，candidate等角色。\n节点可信 全是可信节点，不存在作恶节点。\n节点准入 主要方式是通过配置管理指定节点。\n节点配置 虽然节点之间机器配置，网络带宽，地理位置都会存在一定程度上的差异，但是可以控制。\n共识算法 共识算法是核心。最常见共识算法如下：\n Paxos Raft Zab Primary-secondary Quorum  属性 一个科学共识算法必须同时满足以下四个属性：\n Agreement Validity Integrity Termination  这四个属性从四个方面规范共识算法的要求，也为我们提供分析共识算法四个不同的视角。\nAgreement  Every correct process must agree on the same value.\n 这是实现一致性必须要做到的要求：每个节点必须达成一致。\nRaft通过以下几点实现Agreement，具体如下：\n 整个系统保证最多只有一个leader 同步流只有一个方向：从leader到follower 节点crash后从leader同步数据 重新选主之后的冲突解决机制，如选主过程选择拥有最新数据的candidate为新主  Validity  If all the correct processes proposed the same value v, then any correct process must decide v.\n Validity是为了防止这种情况的出现：一些节点无论提议什么值，本节点一直提交NULL。\nRaft通过以下几点实现Validity，具体如下：\n 整个系统保证最多只有一个leader 同步流只有一个方向：从leader到follower 节点crash后从leader同步数据  Integrity  No Node decides twice.\n 保证共识得到一致性不可逆，不可被修改。那么在这成共识过程中有许多操作需要进行限制。以Raft为例，其通过以下几点实现Integrity，具体如下：\n 节点都是可信的，节点不作恶 节点自我约束，只会commit一次 节点选leader过程中一次只能投一个candidate leader节点从不会覆盖自身本地日志中已经存在的条目 在存在两个leader情况下（一个真leader一个假leader）,能够根据item和index识别真假leader  Termination  Eventually, every correct process decides some value.\n Termination是一个liveness属性，可以理解对应CAP定理中可用性（Availability）。 对应Raft体现如下：\n 多数派保证能够容忍一定的节点crash leader与follower通过心跳包实现检测 检测到leader crash，follower发起新一轮选主，保证系统正常运行 正常工作的时候，由itemId及indexId来保证一个周期的结束 这样就基本保证多数节点正常工作，整个系统能够保证有且只有一个leader（选主期间除外），另一种表达是保证系统最多只有一个leader。  （PS：建议可以读一下raft论文，读完一定会有新的理解。）\n业务 分布式业务这里列举如下：\n 分布式存储，如GFS 分布式计算，如MapReduce 分布式锁，如Chobby 分布式数据库，如BigTable，Spanner 分布式ML，如TensorFlow分布式 分布式MQ，如Kafka 分布式负载均衡，如Daglev 分布式缓存，如分布式redis, Memcached  容错要求 对于分布式系统，其容错要求对应是CAP定理。在实际应用过程选择容错性要求根据业务来决定。\nCAP定理 CAP定理指出，分布式系统不可能同时满足以下三个条件：一致性（Consistency）、可用性（Availability）和分区容错（Partition tolerance）。\nCAP里面三个选项是不同角度的容错性。\n一致性 多节点加上网络的不可靠性，这样多节点的不一致状态是不可避免的。如同TCP协议，解决了网络传输不可靠性，分布式共识算法是达成一致性的方法。\n一致性分为以下几种类型（来自百度的《分布式系统原理介绍》）：\n 强一致性(strong consistency)：任何时刻任何用户或节点都可以读到最近一次成功更新的副本数据。强一致性是程度最高的一致性要求，也是实践中最难以实现的一致性。\n  单调一致性(monotonic consistency)：任何时刻，任何用户一旦读到某个数据在某次更新后的值，这个用户不会再读到比这个值更旧的值。单调一致性是弱于强一致性却非常实用的一种一致性级别。因为通常来说，用户只关心从己方视角观察到的一致性，而不会关注其他用户的一致性情况。\n  会话一致性(session consistency)：任何用户在某一次会话内一旦读到某个数据在某次更新后的值，这个用户在这次会话过程中不会再读到比这个值更旧的值。会话一致性通过引入会话的概念，在单调一致性的基础上进一步放松约束，会话一致性只保证单个用户单次会话内数据的单调修改，对于不同用户间的一致性和同一用户不同会话间的一致性没有保障。实践中有许多机制正好对应会话的概念，例如php中的session概念。可以将数据版本号等信息保存在session中，读取数据时验证副本的版本号，只读取版本号大于等于session中版本号的副本，从而实现会话一致性。\n  最终一致性(eventual consistency)：最终一致性要求一旦更新成功，各个副本上的数据最终将达到完全一致的状态，但达到完全一致状态所需要的时间不能保障。对于最终一致性系统而言，一个用户只要始终读取某一个副本的数据，则可以实现类似单调一致性的效果，但一旦用户更换读取的副本，则无法保障任何一致性。\n  弱一致性(week consistency)：一旦某个更新成功，用户无法在一个确定时间内读到这次更新的值，且即使在某个副本上读到了新的值，也不能保证在其他副本上可以读到新的值。弱一致性系统一般很难在实际中使用，使用弱一致性系统需要应用方做更多的工作从而使得系统可用。\n 为什么一致性很重要？借用Jakob Nielsen的一句话:\n Consistency is one of the most powerful usability principles: when things always behave the same, users don’t have to worry about what will happen.\n 可用性 可用性指服务正常可用的概率。一般用数据量化指标为以下几个：\n 服务正常可用的概率，如常说4个9 MTBF（平均故障间隔时间） MTTR（平均故障恢复时间）  分区容错性 分区容错性是指系统在网络分化的情况下仍然能正常对外提供服务。\n应用 遵守以不变应万变的原则，在一般工程应用过程中，先确定不变，以etcd为例：\n 在异步网络环境，机器存在一定故障 一般3个节点，分布在同两个IDC机房 提供分布式KV服务 容错性方面从CAP中取CA两项  确定这些之后，我们可以选择合适的共识算法及其实现。\n后记 将分布式系统分解五个小问题，除了共识是一个难点，其他四个问题都容易理解，这样有利于我们解决问题外围，有一个清楚的背景知识和前期的准备，有利于理解与学习共识算法。作为一个思考框架，围绕框架不断地完善，如深入分析分布式业务和提高分布式系统的性能。\n个人能力有限，有什么不足与错误，欢迎指正。\n参考  Consensus raft动画演示 raft论文 寻找一种易于理解的一致性算法（扩展版） Raft Distributed Consensus Overview 你矜持，你活该 Distributed systemsfor fun and profit 分布式系统相关挑战 My Distributed Systems Seminar\u0026rsquo;s reading list for Spring 2020 A Thorough Introduction to Distributed Systems  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/distributed-theory\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/comware-rd\/": {
        
        "title": "大型系统软件Comware研发总结",
        "tags": ["闲谈乱扯","研发管理",],
        "content": "前言 前几个月写一篇关于研发管理的文章。在那篇文章提出一个简单的思考框架，并没有实际案例的分享及深度分析。所以在这里以华三Comware研发为例，结合思考框架谈谈自己的一些理解与想法。\nComware 开始之前，先介绍一下Comware。其主要要点如下：\n 整个系统代码量超过了1000万行（开源代码除外） 巅峰时期开发人员1000左右 支持设备类型超过100多种，同时支持各种丰富的网络特性 性能与可用性要求高，需要满足欧美高端市场（金融，国防等）要求及互联网大流量的冲击 作为公司的中台，支撑公司绝大部分产业线（安全，路由，交换，云计算等）  下面我们就一一展开说明。\n业务 以业务为中心。Comware作为一个网络操作系统，主要要求如下：\n 充当网络设备的大脑，为各种网络设备业务提供平台（中台）能力与服务 承载各种网络业务，并动态满足不同网络业务的要求及变化 保证整个系统 高可用性，高性能，可维护性，可扩展性，安全性等  文化 由于历史上的原因，整个研发文化总体上源于华为，稍有调整。具体要点如下：\n 质量为上 结果导向 研发三权分立 追求效率 鼓励创新 公开  关于科技公司的文化，推荐Netflix文化:自由与责任\n团队 团队是从人的视角出发。要以人为本啊。\n团队梯队合理清楚，按技术水平划分具体如下：\n 开发上岗人员 维护上岗人员 开发负责人 系统扩展组 系统组 架构组  团队组织划分以业务导向，按照不同的业务划分不同大组，独立进行代码管理。在各个大组一般分为开发与维护两个方面进行人员动态调配。\n团队建设主要是大组每周定期培训，鼓励分享，除此之外针对不同岗位有专项培训，如项目管理，代码管理。\n架构 架构不是我们常说的架构，这里的架导指导代码的工作（架构从事的角度出发）。\n选择开源，拥抱开源，不要重复造轮子 不得不说2008年开始预研下一代网络操作系统，当时的团队放弃vxwork，选择了开源linux，而且作到取自开源，高于开源，只使用linux基本组件（文件管理系统，内存管理系统，进程调度等），重新移植与修改协议栈，实现分布式网络协议，扩张SOCKET类型。采用Linux好处多多，具体如下：\n 充分吸引Linux开源精华 Linux开源发展路径，决定Linux便于改造与优化 与Linux一起升级，如内核2.6升级到4.x版本 方便开源引入支持，如移植wireshark， python Linux在服务器大量应用，业界有大量人才  合法合规 合法就不用多说了。注意的是要考虑到不同的国家与地区的差异。 合规方法最近的例子就是2017年百度要求内部全面停止使用React/React Native。利用开源的Linux作为基础开发商业操作系统，就不得不遵守开源协议。\nKISS原则 关于KISS原则，架构设计通用原则，有太多说明，这里不展开。\n开放性 对外开放接口，如OAA（Open Application Architecture，开放应用架构），这样有以下好处：\n 对公司内部来说，降低了耦合 对外部合作方来说，方便不同厂商系统集成 对客户来说，提供了更多的选择以及DIY能力 开放与释放了平台的能力  分层与分解 整个系统采用分层设计有如下优点：\n 可以分离系统不同方面的设计关注点，使得同一时刻设计者可以集中精力考虑较少的相于因素，封装和分解了相关的复杂性，增加了系统设计上的清晰度； 减少了系统的耦合和依赖，提高了内聚性，增加了潜在的代码重用性，提高了低层的代码重用度 层与层之间需要清晰的接口，有利于实现面向接口编程，而不是面向实现编程 一些层的实现可以被替换或扩展，对整体的架构影响很小 层次清晰，有利于多个小组并行开发  分解主要体现是模块化，有如下优点：\n 为整体架构提供最小单元 带来了模块化管理，模块化提供交付件（cli插件，daemon等），方便模块化升级，模块定制，模块化诊断 模块化隔离，如实现进程间隔离 统一模块间依赖管理 便于将一些基础组件及功能模块化 方便问题定位，如内核定位踩内存问题 便于模块信息聚合  测试独立性 个人一直以为一个好的测试人员具有以下素质：\n 业务方面做到熟悉，并能不断深入 细心保证执行方面到位 独立性，测试并不是帮助开发，而验证开发成果与补充开发的不足 发散测试，保证测试的完整性，避免漏测，守好产品最后一道门  需要在一个公司层面将测试的独立性体现出来，所以新增一个鉴定测试部门。\n软件工程 作为大型系统软件，离不开软件工程的指导，在整个过程必须科学践行软件工程。\n工具与效率 基础设施投入，如引入高性能服务器提高编译速度（1000万行c语言速度慢真的要半天），这里说一下越高频越重要。每一次修改代码都需要编译。 开发代码review工具，方便协作。\n资源统一管理 主要体现以下几个方面：\n 系统资源（如LIPC端口）统一分配与管理 模块进程统一管理 大块内存申请统一管理 统一错误码  控制集中式，处理分布式 在分布式架构上，采用控制集中式，处理分布式，并不追求用复杂的分布式协议来实现，够用就好。整个模型简单，大大降低了开发难度，提高系统可靠性。\n复杂性 认识到软件开发的复杂性的重要性。在软件开发过程，要先假设软件的各种复杂情况，具体如下：\n 假设一定会有错误，错误一定会发生 假设过程会出错 假设需求会变更，需求会增加 假设团队成员有变动 假设未来会更新线上代码 假设未来需要解决线上问题  这些假设会增加软件开发的复杂性，但是可以通过对假设的证明与排除来降低复杂性\n方案评审 公开评审，鼓励技术方案PK。\n预研 预研由market部门负责，由市场来定义未来需求与方向。\n度量不可少 建立度量体系。大的方面分为以下几个方面：\n 市场度量 团队度量 个人度量 项目度量 代码度量  减少对人的依赖  加强流程建设 不断用机器及工具代替人 团队人员互备  文档  重视文档，无论对外还是内部文档，文档就是沟通，文档就是协作（需求文档化，架构文档化，设计文档化，项目流程文档化，交付文档化）  代码 代码是研发最终交付的核心，是架构的实体，是业务的载体，是测试的对象，是公司的核心资产。\n版本化 这个是老生常谈的问题，但是很基础，很重要。\n设计先行 代码之前，设计先行。正如以前说过一句话：从长远看，选择比努力重要，数据比算法重要，架构比实现重要。\n代码规范是行动准则 这是很好的一份代码规规范。还是一个保证得到执行的规范。很多公司都 倡导编程规范。但是实际并不能落地，这里有各种各样的原因。\n这里分享一下有利于编程规范得到真正落地的建议：\n 规范意识培训 提供规范检查的工具(这个最重要) 将规范执行纳入考核(需要建立一套对应体系) 代码review，review内容包括是否符合代码规范  必不可少的单元测试 交付系统在逻辑上由一个个函数构成，以函数为单元开展测试。\n不止代码review，还有代码鉴定 对代码进行鉴定，估计国内就此一家吧。在保证代码鉴定团队的权威下，不仅要求是bug free，而且要求代码信雅达。只有高标准的要求，才会有高质量的代码。\n关于代码review的关注点，以前写过一篇文章：C语言代码 review的总结\n注重初始代码质量 这是开发顺序决定的，由少数核心开发人员完成，完成基础模型的开发。这样的好处，开始代码质量高，不要让系统输在起点上，同时优秀的代码作为后面的大量项目开发的参考与标杆。\n接口优先，接口先行 接口（API）比实现更重要。在编码之前，接口完成设计并通过评审。\n避免以忙治乱 工作总有人喜欢用了自己的勤劳来掩盖自己的愚蠢。\n说明 在不同的公司，不同行业，不同阶段研发管理都要针对性调整，不求多高大上，但求实用，只有管理规定能够落实，才能真正提高效率，增强团队的战斗力，解决具体业务的问题，满足业务的需求。\n参考  [如何看待百度要求内部全面停止使用React/React Native](如何看待百度要求内部全面停止使用 React / React Native?)  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/comware-rd\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/arch\/%E8%AF%B4%E8%AF%B4%E5%9C%A8%E4%B8%8D%E5%90%8C%E8%A1%8C%E4%B8%9A%E7%9A%84%E7%BC%96%E7%A8%8B%E4%BD%93%E9%AA%8C\/": {
        
        "title": "说说在不同行业的编程体验",
        "tags": ["职场","编程",],
        "content": "回想起来，本科毕业以来，在五家公司呆过，经历四个行业，在这引起行业编程体验各有不同，总结起来就下面四句话：\n嵌入式行业：面向DataSheet编程\n通信行业：面向标准编程\n互联网行业：面向变化编程\n区块链行业：面向资金编程\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/arch\/%E8%AF%B4%E8%AF%B4%E5%9C%A8%E4%B8%8D%E5%90%8C%E8%A1%8C%E4%B8%9A%E7%9A%84%E7%BC%96%E7%A8%8B%E4%BD%93%E9%AA%8C\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/business\/about-weixin-miniprogram\/": {
        
        "title": "说说微信小程序",
        "tags": ["商业","Internet",],
        "content": "小程序在2018年确实火了，除了先行的微信小程序，后面紧接着跟着了蚂蚁金服的小程序，今日头条的小程序。这里先表明一下自己的立场，从微信小程序诞生开始我就看好微信小程序。这里肯定有人说我是事后诸葛亮，这里有图为证。\n小程序让微信成为生活的操作系统 如同操作系统为应用程序提供内存资源与管理、进程资源与调度、输入与输出设备、网络传输、文件系统、用户交互等基本功能，微信生态为小程序提供了以下要素：\n 用户 场景 商业基础设施，如微信支付，消息服务，基于微信社交的信任关系 这些大大降低商业成本和开发成本。  美团，微博，拼多多等公司都在微信上开发小程序， 体现了微信小程序上领先地位。\n如何发现小程序的机会 有很多人利用小程序闷声发大财，那么怎样发现小程序的机会？发现小程序的方式有很多，这里分享其中一种：参考chrome网上应用店，当然也可以从ios app store上找到新的机会。 更多参考app，详见链接。\n这么多分类了，从各个分类热门应用中可以找到一些启发。这里说明一下，这只是其中一种方式，还有很多其他的方式来挖掘小程序的机会。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/business\/about-weixin-miniprogram\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/secret-sharing\/": {
        
        "title": "说说私钥保护技术",
        "tags": ["BlockChain","Cryptography",],
        "content": "前言 私钥在区块链系统中代表是什么？私钥是钱。钱包的本质就是私钥。谁控制了私钥谁就控制对应钱包的数字资产，谁丢失了私钥也就相当于丢了对应钱包的数字资产。\n因此，在区块链系统中如何保护私钥一直都是重要的问题。\n保护私钥一直都要解决以下问题：\n 用户体验 私钥备份与存储 私钥安全（攻击、泄漏、盗取）  私钥助记词化 私钥数学本质是一串数字：\n用户体验极差，那么一长串数字怎么记，每次使用都是一个大麻烦。 所有就有只要玩过数字货币的人都清楚的助记词。这一部分改进如同汇编对二进指定的优化。\n私钥加密 对于私钥内容进行加密，最典型例子就是key-store。\n共用私钥 这里面的技术主要是BIP-44。在数字货币钱包里面得到应用， 避免每一个数字货币地址都要维护一个私钥。如果数字货币满足BIP-44规范， 就可以通过一个私钥来控制多个钱包。\n私钥隔离 用冷钱包来实现与网络隔离，避免私钥被盗取或泄漏。\n私钥分片 私钥分片主要采用Shamir\u0026rsquo;s Secret Sharing技术。其技术原理如同藏宝图分成好几分份,这是多少电影与电视剧中出现的情节。\n原理：\n一个数学公式：yy = ax*x + b * x + c\n其中，c为私钥，当然中实际过程可以认为是保密的数据。 a，b这两个参数作为具体分片规则的描述。\n由上面公式可知，该公式对应一个双曲线。如果知道这个双曲线三个点的坐标，通过解方程组得出a，b，c的值。\n该技术有以下优点：\n 该方案允许私钥拥有制定分片的规则。可以对同一个私钥采用不同的分片规则。拥有分片规则制定权，可以对分片对象加以管理，如添加分片，删除分片。 在没有不知道分片规则之下，通过任何一个分片都不能破解获取私钥。只有对应数量的分片在一起才能获取私钥和分片的规则。  具体应用如下：\n 私钥等敏感数据分割保护 多方验证 数据分享  参考  Shamir\u0026rsquo;s Secret Sharing Divide and Manage Secret Data Securely With Shamir\u0026rsquo;s Secret Sharing zeropass Threshold Signatures: The Future of Private Keys A beginner’s guide to Shamir’s Secret Sharing 私鑰分割 — Shamir’s Secret Sharing  ", 
        "url": "http:\/\/myself659.github.io\/post\/secret-sharing\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/exchage-safe-asset\/": {
        
        "title": "数字货币交易所安全体系-资产篇",
        "tags": ["BlockChain","Secure",],
        "content": "前面，简单介绍了数字货币交易所的安全体系，这一篇主要说说一下资产安全的一些要点。\n如果将一条公链比作一个银行的话，当然这个银行是去中心化银行，那个各个交易所的节点就相当于银行的网点。这个节点有以下功能：\n 帐本数据同步 用户资产托管 充币与提币  资产安全主要分为以下几个方面展开说明，具体如下：\n意识 意识，意识，意识！其实意识就是一种天赋，只是我们没有注意到吧。\n有些区块链的项目居然不知道私钥是何物。很多人会说这是不是搞技术不知道而已。 其实这是安全意识不到位。\n意识教育与培养一定要先行。\n帐本数据同步 帐本数据主要是节点数据同步，具体关注点如下：\n 节点连接节点的确认 避免站错队 分叉 重放攻击防护 孤块 网络分化 帐本同步节点故障，多节点备份  资产托管 资产托管的核心就是私钥，要点如下：\n 采用冷钱包管理私钥 热钱包管理策略（存活周期，资金金额控制，密钥管理） 私钥存储管理（多人多份多地） 多地址分散（不要把鸡蛋放在一个篮子里）  充币与提币 充币与提币都是有关托管资产的交易。\n 合理的交易确认数 充币提币的用户验证 交易的不确定性处理办法如交易得不到确认 分叉时关闭充提币功能  监控 资金动向监控也是不可或缺的，要点如下：\n 对首次提币地址及用户监控 保证监控的高可靠性 充币与提币数据分析 大额充提币的监控及确认  差异化 对于不同类型的资产需要具体问题具体分析。 如以太坊专门对基于智能合约的数字资产进行审计与防范，具体参考ERC20，这里不展开。\n后记 对于资产安全，有什么新的想法与意见，欢迎交流！\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/exchage-safe-asset\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-digitwallet-strategy\/": {
        
        "title": "数字货币钱包产品定位与战略",
        "tags": ["BlockChain",],
        "content": "4月份写一份关于数字货币钱包的分析，欢迎交流与指正。\n数字货币钱包产品定位与战略\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-digitwallet-strategy\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s-monitor\/": {
        
        "title": "安装与应用Prometheus监控Kubernetes集群",
        "tags": ["Docker","Kubernetes",],
        "content": "安装Prometheus RBAC设置,获取创建集群角色权限 1 2 3 4  ACCOUNT=$(gcloud info --format=\u0026#39;value(config.account)\u0026#39;) kubectl create clusterrolebinding owner-cluster-admin-binding \\ --clusterrole cluster-admin \\ --user $ACCOUNT   注意：如果集群部署在google cloud上需要先执行这一步。\n创建Namespace 1  kubectl create namespace monitoring   创建角色 脚本内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRole metadata: name: prometheus rules: - apiGroups: [\u0026#34;\u0026#34;] resources: - nodes - nodes/proxy - services - endpoints - pods verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] - apiGroups: - extensions resources: - ingresses verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] - nonResourceURLs: [\u0026#34;/metrics\u0026#34;] verbs: [\u0026#34;get\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: prometheus roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: prometheus subjects: - kind: ServiceAccount name: default namespace: monitoring   执行创建角色脚本：\n1  kubectl create -f 01-clusterRole.yaml   配置 脚本内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149  apiVersion: v1 kind: ConfigMap metadata: name: prometheus-server-conf labels: name: prometheus-server-conf namespace: monitoring data: prometheus.rules: |- groups: - name: devopscube demo alert rules: - alert: High Pod Meory expr: sum(container_memory_usage_bytes) \u0026gt; 1 for: 1m labels: severity: slack annotations: summary: High Memory Usage prometheus.yml: |- global: scrape_interval: 5s evaluation_interval: 5s rule_files: - /etc/prometheus/prometheus.rules alerting: alertmanagers: - scheme: http static_configs: - targets: - \u0026#34;alertmanager.monitoring.svc:9093\u0026#34; scrape_configs: - job_name: \u0026#39;kubernetes-apiservers\u0026#39; kubernetes_sd_configs: - role: endpoints scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name] action: keep regex: default;kubernetes;https - job_name: \u0026#39;kubernetes-nodes\u0026#39; scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/${1}/proxy/metrics - job_name: \u0026#39;kubernetes-pods\u0026#39; kubernetes_sd_configs: - role: pod relabel_configs: - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path] action: replace target_label: __metrics_path__ regex: (.+) - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port] action: replace regex: ([^:]+)(?::\\d+)?;(\\d+) replacement: $1:$2 target_label: __address__ - action: labelmap regex: __meta_kubernetes_pod_label_(.+) - source_labels: [__meta_kubernetes_namespace] action: replace target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_pod_name] action: replace target_label: kubernetes_pod_name - job_name: \u0026#39;kubernetes-cadvisor\u0026#39; scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor - job_name: \u0026#39;kubernetes-service-endpoints\u0026#39; kubernetes_sd_configs: - role: endpoints relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme] action: replace target_label: __scheme__ regex: (https?) - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path] action: replace target_label: __metrics_path__ regex: (.+) - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port] action: replace target_label: __address__ regex: ([^:]+)(?::\\d+)?;(\\d+) replacement: $1:$2 - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] action: replace target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] action: replace target_label: kubernetes_name   执行配置脚本：\n1  kubectl create -f 02-config-map.yaml -n monitoring   部署 脚本内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  apiVersion: extensions/v1beta1 kind: Deployment metadata: name: prometheus-deployment namespace: monitoring spec: replicas: 1 template: metadata: labels: app: prometheus-server spec: containers: - name: prometheus image: prom/prometheus:v2.1.0 args: - \u0026#34;--config.file=/etc/prometheus/prometheus.yml\u0026#34; - \u0026#34;--storage.tsdb.path=/prometheus/\u0026#34; ports: - containerPort: 9090 volumeMounts: - name: prometheus-config-volume mountPath: /etc/prometheus/ - name: prometheus-storage-volume mountPath: /prometheus/ volumes: - name: prometheus-config-volume configMap: defaultMode: 420 name: prometheus-server-conf - name: prometheus-storage-volume emptyDir: {} --- kind: Service apiVersion: v1 metadata: name: prometheus-server-loadbalancer-service spec: selector: app: prometheus-server ports: - protocol: TCP port: 90 targetPort: 9090 type: LoadBalancer   执行部署脚本：\n1  kubectl create -f 03-prometheus-deployment.yaml --namespace=monitoring   查看部署 1  kubectl get deployments --namespace=monitoring   应用 web访问 可视化 可视化使用Grafana。效果如下：\n参考  Kubernetes Cluster (Prometheus) RBAC技术白皮书  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/k8s-monitor\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s-cicd\/": {
        
        "title": "基于Gitlab\u002bKubernetes实现CI\/CD",
        "tags": ["Docker","Kubernetes",],
        "content": "要求 基本技术栈要求如下：\n Golang Docker GitLab Kubernetes  具体原因参考关于技术选型的思考\n步骤 创建Kubernetes集群 自己搭建集群也可以，但是投入生产不建议使用。这里直接使用google cloud(调研几家发现G家这方面技术积累最深，生态完整)。\n创建帐号设置gitlab操作帐号，用于后面的CI/CD操作。\n1  kubectl apply -f gitlab-admin-service-account.yaml   1  kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep gitlab-admin | awk \u0026#39;{print $1}\u0026#39;)   具体参考Adding and creating a new GKE cluster via GitLab\n创建DockerHub帐号 主要操作是在DockerHub创建帐号。 其他的云计算服务的镜像服务也可以。\n创建gitlab项目 正常创建代码仓库操作。\n准备代码 准备一个简单的web服务器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello, k8s-go!\u0026#34;) }) http.HandleFunc(\u0026#34;/healthz\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Health OK!\u0026#34;) }) http.ListenAndServe(\u0026#34;:8090\u0026#34;, nil) }   DockerFile 1 2 3 4 5 6 7 8 9 10 11 12 13  FROM golang:1.11-alpine as builder WORKDIR /usr/build ADD main.go . RUN go build -o k8s-app . FROM alpine:latest WORKDIR /usr/src COPY --from=builder /usr/build/k8s-app . EXPOSE 8090 CMD [\u0026#34;/usr/src/k8s-app\u0026#34;]   配置docker环境变量 设置对应用户名与密码即可。\n配置Kubernetes集群环境变量 主要配置下图三个变量（用于连接Kubernetes集群）：\nCERTIFICATE_AUTHORITY_DATA 1  cat ~/.kube/config | grep certificate-authority-data | tr -d \u0026#39;\\n\u0026#39; | grep certificate-authority-data | awk \u0026#39;{print $2}\u0026#39;   USER_TOKEN 1  kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep gitlab-admin | awk \u0026#39;{print $1}\u0026#39;)   SERVER 1  kubectl cluster-info | grep master   从输出结果中获取master对应url即可。\n设置deployment 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  apiVersion: apps/v1 kind: Deployment metadata: name: k8s-go labels: app: go spec: replicas: 3 selector: matchLabels: app: go strategy: type: RollingUpdate rollingUpdate: maxSurge: 1 maxUnavailable: 33% template: metadata: labels: app: go spec: containers: - name: go image: \u0026lt;yourdockerhubname\u0026gt;/\u0026lt;yourimagename\u0026gt;:\u0026lt;VERSION\u0026gt; ports: - containerPort: 8090 livenessProbe: httpGet: path: /healthz port: 8090 initialDelaySeconds: 2 periodSeconds: 2 readinessProbe: httpGet: path: /healthz port: 8090 initialDelaySeconds: 2 periodSeconds: 2 --- kind: Service apiVersion: v1 metadata: name: k8s-go-loadbalancer-service spec: selector: app: go ports: - protocol: TCP port: 80 targetPort: 8090 type: LoadBalancer   设置CI/CD gitlab.yml内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  image: docker:latest services: - docker:dind stages: - build - deploy variables: CONTAINER_IMAGE: \u0026lt;yourdockerhubname\u0026gt;/\u0026lt;yourimagename\u0026gt;:${CI_COMMIT_SHORT_SHA} build: stage: build script: - docker login -u ${DOCKER_USER} -p ${DOCKER_PASSWORD} - docker build -t ${CONTAINER_IMAGE} . - docker tag ${CONTAINER_IMAGE} ${CONTAINER_IMAGE} - docker tag ${CONTAINER_IMAGE} \u0026lt;yourdockerhubname\u0026gt;/\u0026lt;yourimagename\u0026gt;:latest - docker push ${CONTAINER_IMAGE} deploy: stage: deploy image: dtzar/helm-kubectl script: - kubectl config set-cluster k8s --server=\u0026#34;${SERVER}\u0026#34; - kubectl config set clusters.k8s.certificate-authority-data ${CERTIFICATE_AUTHORITY_DATA} - kubectl config set-credentials gitlab --token=\u0026#34;${USER_TOKEN}\u0026#34; - kubectl config set-context default --cluster=k8s --user=gitlab - kubectl config use-context default - sed -i \u0026#34;s/\u0026lt;VERSION\u0026gt;/${CI_COMMIT_SHORT_SHA}/g\u0026#34; deployment.yaml - kubectl apply -f deployment.yaml   测试CI/CD 部署迁移 如何将部署迁移到其他的集群，在配置好新的集群后，只需要重新配置相关Kubernetes环境变量即可。\n参考  更快部署代码：CI/CD 与 Kubernetes GitLab + Kubernetes: Using GitLab CI\u0026rsquo;s Kubernetes Cluster feature  (end)\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/k8s-cicd\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/exchage-safe-arch\/": {
        
        "title": "数字货币交易所安全防护体系介绍",
        "tags": ["BlockChain","Secure",],
        "content": "说明 这里的交易所是指中心化交易所。下面按标题三个关键词展开说明。\n交易所 交易所作为数字资产交易的平台。一直不断地就有安全问题出现，最著名的是Mt. Gox事件，影响恶劣。后续事故也不少，不多说了。交易所安全事故这只黑天鹅未来一定会再出现。\n安全防护 安全的重要性毋庸置疑。\n安全防护是全方位，多角度，多层次，全链路，持续不断的一种工程。\n安全防护的结果是安全性。其主要取决于攻守双方。只有知道工作原理才能掌握如何防护。 安全防护从一开始就要考虑及落地而不是临时抱佛脚。\n体系 针对交易所安全体系，分为以下几个方面：\n 资产安全 平台安全 网络安全 用户安全 数据安全 交易安全 运营安全 安全策略  对于这8个方面，先挖坑，后面再填，有空的话一一展开说明。\n参考  Exchange Security Report  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/exchage-safe-arch\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E5%88%AB%E4%BA%BA%E7%9A%84%E6%88%90%E5%8A%9F%E4%BD%A0%E5%BE%88%E9%9A%BE%E5%A4%8D%E5%88%B6\/": {
        
        "title": "别人的成功你很难复制",
        "tags": ["life",],
        "content": "人们向往成功 人人都渴望成功，追求事业上的成就和个人价值的实现。\n大部分人愿意学习别人的成功经验，同时也乐于接受别人对自己成功的解释。然而，这些看似简单的成功原因对于成功者本人可能确实有用，但对于其他人来说，未必具备同样的实用性。\n别人成功的背后 成功者很可能无法确切地指出自己成功的原因。\n通往成功的道路是一个错综复杂的过程，很难找到明确的原因。每个人的成功背后可能都是由多种因素相互作用、共同影响的结果。\n你所看到别人的成功是精心选择的 你所看到的成功往往经过精心挑选呈现给大众。这些成功案例无处不在，不是张三，就是李四，也可能是王五。然而，沉默的大多数并未被关注。\n此外，还有一种年薪百万的方式：教别人如何获得年薪百万。\n你与别人不一样 世间没有两片完全相同的树叶。\n每个人都有自己的优势与劣势，而且各不相同。我们需要认识到，别人的成功之道未必适合自己。\n复制别人的成功难度更大 《我的成功可以复制》一书的作者唐骏自己都不复制自己的原来成功。\n在淘宝崛起之后，没有第二个淘宝，只有拼多多。这说明，复制别人的成功并非易事，尤其是在竞争激烈的市场环境下。\n没有谁可以简单地成功 爱迪生曾经说过：“成功是百分之一的灵感加百分之九十九的汗水。”这句名言揭示了成功并非轻而易举，而是需要付出巨大的努力和坚持。\n自己及所处的环境更重要 科学全面地认识自己以及自己所处的环境至关重要。\n要想取得成功，我们要“知己知彼，百战不殆”。不需要一味追求短暂的成功，只要确保自己长时间不败，成功终会到来。\n总之，要想取得成功，我们需要深入了解自己的优缺点，审时度势，找到适合自己的道路。尽管借鉴他人的成功经验可以启发思维，但盲目模仿难以取得成功。保持自信，树立长远目标，不断努力，始终坚持，成功终将属于你。\n", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E5%88%AB%E4%BA%BA%E7%9A%84%E6%88%90%E5%8A%9F%E4%BD%A0%E5%BE%88%E9%9A%BE%E5%A4%8D%E5%88%B6\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/tech-stack-explain\/": {
        
        "title": "关于技术选型的思考",
        "tags": ["研发管理",],
        "content": "技术选型内容 技术选型从组成要素的角度分为两大类：\n 实现业务的代码 业务依赖的服务  本文围绕代码这一核心进行技术选型，对此分解以下五个问题：\n 怎么管理代码？ 用什么语言写代码？ 怎么运行代码？ 在哪里运行代码？ 怎么大规模运维代码？  技术选型原则 先看一下技术选型应该考虑些什么呢？\n 业务的特点与需求 资源和经验 可扩展性 可维护性 安全 成本（投入时间，人力，资源。。。）  简单总结为以下几点：\n 稳定优先，善用为上 立足现状，着眼未来 验证先行，应用在后 业务导向，实践驱动  下面就根据这些原则一一回答上面五个问题，但是不会涉及具体的问题如消息队列是选RabbitMQ还是Kafka。\n代码管理 对应上面的怎么管理代码的问题。首先是工具，现在大家都清一色的git。在git没有出来之前有以下这些工具：\n clearcase svn TortoiseCVS  再次就是选择平台。有以下选项\n github gitlab gitee gitbucket 自建gitlab  选择自建gitlab。主要考虑如下：\n 历史原因 Gitlab自带CI 代码安全考虑 自建gitlab带来的自主控制，有利于后续的发展  编程语言 以Golang为主，其他语言为辅助。\nWhy Golang  个人及其团队主要成员都有Golang经验 Golang在区块链项目中会占主导地位 更多理由见：Golang最工程化的语言  运行环境 运行环境分为以下几种：\n 物理主机 虚拟机 Docker  除了一些特殊的场景，现在流行的作法当然是Docker。\nWhy Docker Docker是容器的事实上标准。 使用Docker带来新部署方式：build-\u0026gt;ship-\u0026gt;run，有以下好处：\n 可移植性：容器与操作系统分离，基本上保证可以在不同的机器及环境的主机上运行，容器也可以在不同机器上迁移 模块化：利用容器隔离属性可以划分模块，合理拆分服务，同时容器化的一致性便于模块的复用 安全性：容器隔离属性增加了应用程序的安全性 弹性伸缩：容器化方便在负载增加扩容，在负载下降时缩容，有利于提高资源利用效率 一致性：容器为应用程序提供了一致性的运行环境。  运行平台 上云现在已经成为大众共识。AWS，azure, google cloud, aliyun及腾讯云都是选项内容。\n大规模运维 容器化带来以上不少好处，但是也带来容器编排的问题。容器编排哪家强？Github找Kubernetes啊。\n对于小企业采用Kubernetes将高可用性完全交给云平台，自身解决正确科学应用Kubernetes问题，当然这个慢慢来，先调研，再实验。大企业需要深入Kubernetes细节与生态，要有修改与定制的能力。\nwhy Kubernetes 首先Kubernetes成为实际上容器编排的标准。其次使用Kubernetes带来分工的变化：应用开发工程师可以专注于构建应用程序，而基础架构工程师可以专注于如何自动构建和部署，从而提高了工程效率，更快地交付了应用程序并简化了基础架构。除此之外Kubernetes提供了工具提高应用程序的高可用性，同时也可以灵活的切换云服务商。\n(end)\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/tech-stack-explain\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/twitter%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7\/": {
        
        "title": "twitter搜索Tips",
        "tags": ["Information",],
        "content": "背景 搜索是我找信息主要来源。twitter上有很多高质量的内容，那么如何查找这些内容以及如何高效快速准确找到这些内容呢？\n搜索入口 twitter没有像微博那样直接针对个人提供一个搜索框。\ntwitter提供了搜索入口：twitter search。\n一个简单例子如下：\n享受大师们的分享吧。\n", 
        "url": "http:\/\/myself659.github.io\/post\/twitter%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/pdd-thought\/": {
        
        "title": "关于拼多多几点看法",
        "tags": ["商业","Internet",],
        "content": " 拼多多战略采用农村包围城市，市场上定位准确，填补了三四线农村及中国底层人民的需求。 微信平台是拼多多快速成长的关键，利用微信带来的流量，流量带来用户，用户带来交易，交易带来商家，随着流量，用户，交易，商家越来越多，就成了生态。 宣传口号具有极强的传播效应：拼多多、拼得多、省得多。 产品上增加确定性，首先价格比淘宝还便宜（一般情况下）同时对用户预期进行管理，提高了体验的确定性。 麻烦就是与淘宝一样，会一直受假货的困扰，打假一直是电商平台的难题（因为打假是一个社会问题）。 拼多多胜在效率，对于用户来说是性价比，对于商家来说是批量处理商品，在交易流程上利用微信平台及其天然存在好友关系及其微信群，整个过程商家和用户的成本都下降，在性价比的高吸引下，用户拼单成本低（转发几个微信群或者朋友圈就可以了），商家的流量成本基本为0。 拼多多未来会怎么样？在整个中国大部分人消费降级情况下，拼多多应该还会进一步增长，上市当天上涨40%也是市场对其成长的期待。 拼多多和淘宝比较如何？借助微信拼多多下沉市场更大，借助微信拼多多是社交电商，更具有传播性。 拼多多为什么成长这么快？三年时间就上市，用户数量达到3.4亿。搭上微信这个10亿用户平台，符合大部分中国人还很穷的现状，解决他们的问题。 拼多多怎么赚钱？现在还没有营利，主要收入来源是商家的在线营销服务（广告），未来应该会营利，用户数量巨大，可以从天猫，京东导入更多的商家，扩大收入，相信国运，这些用户未来会真正的消费升级，这又是新的增长机会。 拼多多为用户提供一种低成本满足刚需的选择。 段永平对黄铮的评价：黄峥是特别难得一见的一直关注事物本质的人，有悟性，又聪明，未来有任何成就我都不意外。  后续  我为什么全仓拼多多？  参考  巨头夹缝中的千亿鲶鱼：社交重塑中国电商格局，拼多多成电商第三极 拼多多急上市：拿下1400亿GMV，累积亏损13亿 巨头三国杀：中国电商盛世再临  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/pdd-thought\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-new-game-time\/": {
        
        "title": "区块链开启游戏的新时代",
        "tags": ["BlockChain",],
        "content": "自2008年比特币诞生以来，其代表的区链技术的发展程度令人兴奋，区块链很快就成为日常生活中的流行语。特别是对于游戏行业，区块链能够带来新的游戏互动和体验方式，这种互动和体验方式有如下三个特点：\n 玩家成为利益相关者 公正透明 大规模协作  下面对这三个特点分别说明：\n玩家成为利益的创造者与参与者 Play2Live平台是互动功能和货币化工具的独特组合。这项针对视频广播游戏和网络体育内容的服务允许每个参与者赚取收益，包括流媒体服务商和普通观众。\n公正透明 传统的游戏，由后台产生随机数，存在作假等各种暗箱操作。 有这么一款游戏：Piggy Breaker，他们是blockchain hero活动的胜利者，通过基于\u0026quot;可证明的公平\u0026quot;原则以透明的方式产生游戏中的随机性，解决了部分透明度问题。确保游戏的公平性。同时避免出现了平台跑路的潜在问题。另一个最典型的例子是中本聪筛子。\n大规模协作 依赖于P2P网络，可以提供去中心化协作。但是也存在一些问题，如去中心化网络的带来的延迟问题，适合策略性游戏。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-new-game-time\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/dsa\/dp-max-subarray-sum\/": {
        
        "title": "leetcode-53. Maximum Subarray",
        "tags": ["DP",],
        "content": "题目 leetcode-53. Maximum Subarray\n类似：\nleetcode-152. Maximum Product Subarray\n要点是记录当前最大值，与最小值。\n计算当前最值有三种可能：\n 当前值 前一个最大值与当前值之积 前一个最小值与当前值之积  从这三种取出最小值和最大值。 （从三个可能优化到两个）\nleetcode-325. Maximum Size Subarray Sum Equals k\nleetcode-643. Maximum Average Subarray I\nleetcode-644. Maximum Average Subarray II \nleetcode-918. Maximum Sum Circular Subarray\n689. Maximum Sum of 3 Non-Overlapping Subarrays\n分析 这是一维数组求最大子数组之和的问题。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Solution { public: int maxSubArray(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int max_sum = INT_MIN; int max_pre = 0; int max_cur = 0; for (int i = 0; i \u0026lt; nums.size(); i++){ int cur_item = nums[i]; if(max_pre \u0026gt; 0 ){ max_cur = max_pre + cur_item; }else { max_cur = cur_item; } max_sum = max(max_sum, max_cur); max_pre = max_cur; } return max_sum; } };   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  #include \u0026lt;iostream\u0026gt; using namespace std; int max_subarr_sum(int arr[], int n) { // 最大值 int max_sum = INT_MIN; // 前一个位置最大值 int max_pre = 0; // 当前位置最大值 int max_cur = 0; // 遍历 for (int i = 0; i \u0026lt; n; i++) { int cur_item = arr[i]; if (max_pre \u0026gt; 0) { max_cur = max_pre + cur_item; } else { max_cur = cur_item; } max_sum = max(max_sum, max_cur); max_pre = max_cur; } return max_sum; } int main() { int arr[] = { -2, 1, -3, 4, -1, 2, 1, -5, 4 }; int n = sizeof(arr)/sizeof(arr[0]); cout \u0026lt;\u0026lt; \u0026#34;The sum of contiguous sub-array with the largest sum is \u0026#34; \u0026lt;\u0026lt; max_subarr_sum(arr, n); return 0; }   运行测试\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/dsa\/dp-max-subarray-sum\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/economy\/ecomony-machine\/": {
        
        "title": "《原则》作者瑞·达利欧烧脑大作(1): 经济机器是怎样运行的",
        "tags": ["Economy",],
        "content": "说明 本文的语音与视频版本如下：\n 经济机器是怎样运行的(语音+文字版) 经济机器是怎样运行的 (时长30分钟) Ray Dalio  关于作者 原文作者瑞·达利欧，为著名畅销书《原则》作者。1975年，在自己的两居室内创办桥水，2015年，桥水管理资金超过1500亿美元，累计盈利450亿美元，远超史上所有对冲基金。\n经济机器是怎样运行的 经济就像一部简单的机器那样运行但很多人不懂得这一点，或是对经济的运行方式持有不同观点，于是导致很多不必要的经济损失。我深感有责任与大家分享我的简单但是实用的经济分析模式，这个模式虽然不符合常规传统经济学但是已经帮助我预测和躲避了全球金融危机，30多年来对我一直很有用。\n我们开始吧！\n经济虽然可能看起来复杂但是其实是以简单和机械的方式运行，经济由几个简单的零部件和无数次重复的简单交易组成，这些交易首先是由人的天性所驱动，因而形成三股主要的经济动力。\n一. 生产率的提高\n二. 短期债务周期\n三. 长期债务周期\n下面我们谈一下这三股动力并介绍如何把它们组合在一起, 得出一个良好的模型，便于我们跟踪经济走势，并理解当前正在发生的事情。\n我们先来说说经济中最简单的部分：交易。\n经济不过是无数交易的总和，而交易是一件非常简单的事情。交易时刻都在发生，你每次买东西都是进行一笔交易。在每次交易中，买方使用货币或信用向卖方交换商品、服务或金融资产。信用在使用时和货币一样因此把花费的货币和信用加在一起，就可以得出支出总额。支出总额是经济的驱动力。如果用支出金额除以销量，就得出价格，就是这么简单，这就是交易。交易是经济机器最基本零件，所有经济周期和动力都是交易造成的。所以，理解了交易，就理解了整个经济。\n一个市场由买卖同一种商品的所有买方和卖方组成。例如，有小麦市场、汽车市场、股票市场和千百万种其他市场，经济就是由所有市场内的全部交易构成。把全部市场的总支出和销量加在一起就得到了了解经济运行所需要的全部信息，就这么简单。个人、企业、银行和政府都在以上述方式从事交易。用货币和信用，交换商品、服务和金融资产。政府是最大的买方和卖方而政府有两个组成部分：即收税和花钱的中央政府和中央银行。央行控制著经济中的货币和信贷数量因此不同于其他买方和卖方，央行通过影响利率和发行更多货币来实行这种控制。我们在下面会看到正因如此，央行在信贷流通当中发挥着重要作用。\n请诸位注意信贷。\n信贷是经济中最重要的组成部分，但也许是人们最不了解的部分，它之所以最重要，是因为它是经济中最大且最为变幻莫测的一部分。贷款人和借款人于在市场中进行交易的买方和卖方没有两样。通常，贷款人希望自己的钱生出更多的钱而借款人则想购买当前无法负担的某种东西，例如房子，汽车，或是进行投资，例如开办企业。借贷可以同时满足贷款人和借款人的需要。借款人保证偿还借款，称为本金，并支付额外的款额，称为利息；利率高时，借贷就会减少，原因是贷款变得昂贵当利率低时，借贷就会增加，原因是贷款变得便宜。如果借款人保证偿还债务，而且贷款人相信这一承诺信贷就产生了。任何两个人都可以通过协定凭空创造出信贷！信贷看似简单，实则复杂，因为信贷还有其他名称：信贷一旦产生，立即成为债务。\n债务是贷款人的资产，是借款人的负债。等到借款人今后偿还了贷款并支付了利息，这些资产和负债将消失交易得以完成。那么为什么信贷如此重要？这是因为，借款人一旦获得信贷，便可以增加自己的支出。不要忘记支出是经济的驱动力。这是因为一个人的支出是另一个人的收入。想想看，你每花一块钱，另一个人挣了一块钱；而你每挣一块钱，必定有别人花了一块钱，所以，你花得越多，别人挣得就越多。如果某人的收入增加，其信用度就会提高，贷款人就更愿意把钱借给他。信用良好的借款人具备两个条件：偿还能力和抵押物。收入债务比率高，借款人就具备偿还能力。如果无法偿还，借款人还可以用有价值、可以出售的资产作为抵押物。这样，贷款人可以放心地把钱借给他们所以，收入增加使得借贷也增加，从而能够增加支出。由于一个人的支出是另一个人的收入，这将导致借贷进一步增加，并不断循环。这一自我驱动的模式导致经济增长，也正是因为如此，才产生了经济周期。\n在一项交易中为了获得某样东西你必须付出另一样东西长期来看，你得到多少取决于你生产多少，我们的知识随时间而逐渐增多，知识的积累会提高我们的生活水平，我们将此称为生产率的提高，一个善于创新和勤奋的人将比那些自满和懒惰的人更快的提高生产率和生活水平，但在短期内不一定体现出来。生产率在长期内最关键，但信贷在短期内最重要。这是因为生产率的提高不会剧烈波动，因此不是经济起伏的一个重要动力，但是债务是这种动力，因为我们能够通过借债让消费超过产出但是在还债时不得不让消费低于产出。债务量的波动有两大周期其中一个周期持续大约5年至8年，另一个持续大约75年至100年。大部分人虽然能感受到波动，但由于离波动太近，每天、每周都身临其境，通常并不认为这是周期。\n我们将在本章考察这三股主要动力并观察它们如何相互作用以及它们在日常经济中的表现。如上所述，经济的上下起伏不是取决于人们多么善于创新或勤奋工作而是主要看信贷的总量。\n我们先想像一个没有信贷的经济运行。在这样的经济运行中，增加支出的唯一办法是增加收入，因此需要提高生产率和工作量。提高生产率是经济增长的唯一途径，由于我的支出是另一个人的收入。当我或者另一个人提高生产率的时候，经济就会增长。我们如果观察各种交易，加以总结就会发现一条类似于生产率增长轨迹的渐进线。但是，由于我们借债，于是产生了周期原因并不是任何法规，而是人的天性和信贷的运作方式。借债不过是提前消费为了购买现在买不起的东西，你的支出必然超过收入。因此你需要借钱，实质上是向未来的自己借钱。你给自己设定了一个未来的时间到那个时候，你的支出必须少于收入，以便偿还债务，这样马上就形成了一个周期。\n通常一旦你借钱，就制造了一个周期，对于个人是这样，对于整个经济运行也是这样。这就是为什么必须理解信贷？因为信贷触发了一系列机械和可以预料的、将在未来发生的事件。这就是信贷不同于货币的地方完成交易需要使用货币。当你在酒吧用现金买一瓶啤酒时，交易立即完成。但是如果你用信用来买一瓶啤酒，比如赊账你相当于承诺今后为这瓶啤酒付钱。你和酒吧一起创造了一笔资产和一笔负债，你们凭空制造出了信贷。只有在你今后清偿了这笔赊账之后上述资产和负债才会消失，债务才会还清，交易才会了结。现实生活中，大部分所谓的钱实际上是信贷。美国国内的信贷总额大约为50万亿美元，而货币总额只有大约3万亿美元。不要忘记，在没有信贷的经济运行中，增加支出的唯一办法是增加生产，但是在有信贷的经济运行中，还可以通过借债来增加支出。\n因此有信贷的经济运行能增加支出，使得收入的增长速度在短期内超过生产率的增长，但在长期内并非如此，但是，请不要误解我的意思。信贷不一定是坏事，只是会导致周期性变化。信贷如果造成超过偿还能力的过度消费，就是不良信贷。但是信贷如果高效率地分配资源和产生收入让你能偿还债务，就是良性信贷。\n例如，如果你借钱买一台大彩电，电视机不会带来任何收入让你偿还债务。但是，你如果借钱买一台拖拉机，用它来收获更多的庄稼，赚更多的钱你就能够偿还债务，提高生活水平。在有信贷的经济运行中，我们可以跟踪各种交易，观察信贷如何带来经济增长。\n我举一个例子：假设你每年挣10万美元，没有任何债务。你有不错的信用，可以借1万美元，例如用信用卡。因此你每年可以花11万美元，即使你的收入只有10万美元。由于你的支出是别人的收入，另一个人因此挣了11万美元这个挣了11万美元的人如果没有任何债务，可以借1.1万美元，他可以消费12.1万美元,即使他的年收入只有11万美元。由于他的支出是另一个人的收入而我们通过跟踪各种交易，可以看到这个过程不断自我强化。但不要忘记，借债形成周期，周期会上升，最终也会下降。下面我们谈谈短期债务周期。\n随着经济活动的增加，出现了扩张这是短期债务周期的第一阶段。支出继续增加，价格开始上涨原因是，导致支出增加的是信贷，而信贷可以即刻凭空产生。如果支出和收入的增长速度超过所出售的商品的生产速度，价格就会上涨。我们把价格的上涨称为通货膨胀。\n央行不希望通货膨胀过高因为这会导致许多问题。央行在看到价格上涨时就会提高利率。随着利率的上升，有能力借钱的人会减少，同时现有债务成本也会上升，就等于你每个月的信用卡还款额会增加。由于人们减少借债，还款额度增长剩下来用于支出的资金将减少，因此支出速度放慢。而由于一个人的支出是另一个人的收入环环相扣，人们的收入将下降，由于支出减少，价格将下跌我们称之为通货紧缩。\n经济活动减少，经济便进入衰退。如果衰退过于严重，而且通货膨胀不再成为问题央行将降低利率，使经济活动重新加速。随着利率降低，偿债成本下降借债和支出增加，出现另一次经济扩张。可见，经济像一部机器一样运行。\n在短期债务周期中，限制支出的唯一因素是贷款人和借款人的贷款和借款意愿。如果信贷易于获得，经济就会扩张；如果信贷不易获得，经济就会衰退。请注意，这个周期主要由央行控制。短期债务周期通常持续5至8年，在几十年里不断重复。但是，请注意在每个周期的低谷和高峰后经济增长和债务都超过前一个周期。\n为什么会这样？这是人促成的。人们具有借更多钱和花更多钱的倾向，而不喜欢偿还债务，这是人的天性。因此，在长期内，债务增加的速度超过收入，从而形成长期债务周期。尽管人们的债务增加，但贷款人会提供更宽松的信贷条件，这是为什么？这是因为，大家都以为形势一片大好！人们仅注意最近出现的情况。最近的情况是什么？收入一直在增加！资产价值不断上升！股票市场欣欣向荣。现在是繁荣时期！用借来的钱购买商品、服务和金融资产很划算！当人们过度借贷消费时，泡沫便产生了，因此，尽管债务一直增加但收入也以相近的速度增加，从而抵消了债务。\n我们把债务与收入比率称为债务负担。只要收入继续上升，债务负担就可以承受。与此同时，资产价值迅猛上升人们大量借钱来购买资产，因为投资促使资产价格日益升高。人们感觉得自己很富有因此，尽管积累了大量债务，收入和资产价值的上升帮助借款人在长期内保持良好的信用度，但是这种情况显然无法永久持续下去也确实没有持续下去。几十年来，债务负担缓慢增加，使偿债成本越来越高。到了一定的时候，偿债成本的增加速度超过收入，迫使人们削减支出。由于一个人的支出是另一个人的收入，收入开始下降，人们的信用因此降低，致使借贷减少。偿债成本继续增加，使得支出进一步减少周期开始逆转这时到达长期债务的顶峰债务负担变得过重。美国、欧洲和世界上很多其他地区在2008年及发生了这一情况日本在1989年和美国在1929年因同样原因发生了这一情况。\n现在经济进入去杠杆化时期。在去杠杆化过程中，人们削减支出，收入下降，信贷消失。资产价格下跌，银行发生挤兑股票市场暴跌，社会紧张加剧。整个过程开始下滑并形成恶性循环随着收入下降和偿债成本增加，借款人倍感拮据。随著信用消失，信贷枯竭，借款人再也无法借到足够的钱来偿还债务。借款人竭力填补这个窟窿，不得不出售资产。在支出下降的同时，出售热潮使市场充斥待售资产这时，股票市场暴跌，不动产市场一蹶不振，银行陷入困境。随着资产价格下跌，借款人能够提供的抵押物的价值下降这进一步降低了借款人的信用。人们觉得自己很穷信贷迅速消失，支出减少、收入减少、财富减少、信贷减少、借债等等随之减少。这是一个恶性循环。\n它看起来与衰退相似，但不同之处是，无法通过降低利率来挽回局面。在衰退中，可以通过降低利率来刺激借贷。但是，在去杠杆化过程中，由于利率已经很低接近0，从而丧失刺激功能，因此降低利率不起作用。美国国内的利率在1930年代的去杠杆化期间下降到0，在2008年也是如此。\n衰退与去杠杆化之间的差别在于，在去杠杆化过程中，借款人的债务负担变得过重，无法通过降低利率来减轻贷款人意识到，债务过于庞大，根本无法足额偿还。借款人失去了偿债能力，其抵押物失去价值，他们觉得受到债务的极大伤害，不想再借入更多债务。贷款人停止放贷，借款人停止借贷。\n整个经济体与个人一样都失去了信用度，那么应该怎样应对去杠杆化？问题在于，债务负担过重，必须减轻。为此可以采用四种办法：\n  个人、企业和政府削减支出\n  通过债务违约和重组来减少债务\n  财富再分配，将财富从富人转给穷人\n  最后，央行发行更多货币\n  这四种办法被用于现代历史上的每一个去杠杆化过程。通常第一个措施是削减支出。我们刚才看到，个人、企业、银行和政府都勒紧裤带削减支出，从而能够减少债务。\n我们经常把这称为紧缩。当借款人不再借入新的债务，并开始减少旧债务的时候，你会以为债务负担会减轻但情况正好相反，支出减少了，而一个人的支出是另一个人的收入，这就导致收入下降。收入下降速度超过还债的速度，因此债务负担实际上更为沉重。我们已经看到，这种削减支出的做法引起通货紧缩，令人痛苦。企业不得不削减成本，这意味着工作机会减少，失业率上升。这导致下一个步骤，即必须减少债务！\n很多借款人无法偿还贷款，而借款人的债务是贷款人的资产。如果借款人不偿还银行贷款，人们会担心银行无法返还其存款。因此纷纷从银行取出存款银行受到挤兑，而个人、企业和银行出现债务违约。这种严重的经济收缩就是萧条。\n萧条的一个主要特征是，人们发现，他们原来以为属于自己的财富中有很大一部分实际上并不存在。我们再次以酒吧为例，当你用赊账的办法买一瓶啤酒时，是在承诺今后偿还酒吧的赊账，你的承诺成为酒吧的一项资产。但是，如果你不兑现承诺，不偿还酒吧的赊账，实际上是债务违约。那么酒吧的这项资产实际上一钱不值，它实际上是消失了。\n很多贷款人不希望自己的资产消失，同意债务重组。债务重组意味着贷款人得到的还款减少或偿还期延长，或利率低于当初商定的水平。无论如何，合约被破坏，结果是债务减少，贷款人希望多少收回一些贷款，这强过血本无归。\n债务重组让债务消失，但由于它导致收入和资产价值以更快的速度消失债务负担继续日趋，削减债务与减少支出一样，令人痛苦和导致通货紧缩。所有这些都对中央政府产生影响因为收入降低和就业减少意味着政府的税收减少。与此同时，由于失业率上升，中央政府需要增加支出很多失业者储蓄不足，需要政府的财务支助。此外，政府制定刺激计划和增加支出，以弥补经济活动的减少，在去杠杆化过程中，政府的预算赤字飙升，原因是政府的支出超过税收。你在新闻中所听到的预算赤字正是这种情况，政府必须加税或者举债，以填补赤字但是，在收入下降和很多人失业的时候，应该向谁融资呢？富人。\n由于政府需要更多的钱，而且大量财富集中在少数人的手中，政府自然而然地增加对富人的征税，以帮助经济中的财富再分配。把财富从富人那里转给穷人，正在困苦当中的穷人开始怨恨富人，承受经济疲弱、资产贬值和增税压力的富人开始怨恨穷人。如果萧条继续下去，就会爆发社会动荡。不仅国家内部的紧张加剧而且国家之间也会这样，债务国和债权国之间尤其如此。这种局势可以导致政治变革，有时是极端的变革。1930年代，这种局势导致希特勒掌权、欧洲爆发战争和美国的大萧条，要求采取行动来结束萧条的压力越来越大。\n不要忘记，人们心目中的货币实际上大部分是信贷因此，信贷一旦消失，人们的钱会不够花。人们迫切需要钱，而你一定记得，谁可以发行货币：中央银行可以。央行已经把利率降到接近零的水平，现在不得不发行更多货币。\n发行货币与削减支出、减少债务和财富再分配不同会引起通货膨胀和刺激经济。中央银行不可避免地凭空发行更多货币并使用这些货币来购买金融资产和政府债券。这种情况发生在美国大萧条期间，并于2008年再次爆发。当时美国的中央银行，即联邦储备委员会，增加发行了两万多亿美元。世界各地能够这样做的其他央行也增发了很多货币。央行通过用这些货币购买金融资产帮助推升了资产价格，从而提高了人们的信用，但是这仅仅有助于那些拥有金融资产的人。你看央行可以发行货币，但是只能购买金融资产。而另一方面，中央政府可以购买商品和服务，可以向人民送钱但是无法印钞票。因此，为了刺激经济，央行和政府必须合作。央行通过购买政府债券，其实是把钱借给政府，使其能够运行赤字预算，并通过刺激计划和失业救济金来增加购买商品和服务的支出这增加了人们的收入，也增加了政府的债务，但是这个办法将降低经济中的总债务负担，这是一个风险很大的时刻。\n决策者需要平衡考虑降低债务负担的四种办法，必须平衡兼顾通货紧缩的办法和通货膨胀的办法，以便保持稳定。如果取成适当的平衡，就可以带来和谐的去杠杆化。所以说去杠杆化可以是痛苦的，也可以是和谐的怎样才能实现和谐的去杠杆化？\n尽管去杠杆化是艰难的但以尽可能好的办法来处理艰难的局势却是一件好事。这比杠杆化阶段大量举债产生过度失衡现象要好得多。在和谐的去杠杆化过程中，债务收入比率下降，经济实际上是正增长。同时通货膨胀并不是一个问题。这是通过适当的平衡所取得的。为了取得适当的平衡，需要结合削减支出、减少债务、转移财富和发行货币的办法以保持经济和社会稳定。\n有人问，发行货币是否会加剧通货膨胀？如果增发的货币抵消信货的降幅，就不会引发通货膨胀。不要忘记，重要的是支出。每一块钱的支出无论支付的是货币，还是信用，对价格的影响都是一样的。央行可以通过增加货币发行量来弥补消失的信贷。央行为了扭转局面，不仅需要推动收入的增长，而且需要让收入的增长率超过所积累债务的利率。这是什么意思？主要的意思是，收入一定要比债务增长得快。例如，我们假设有个国家正在经历去杠杆化，其债务收入比率是100％ 这意味著，债务量相当于整个国家一年的收入。假设这些债务的利率是2%，如果债务以2%的速率增加而收入的增长率仅有大约1%。那么债务负担永远不会减轻必需发行更多货币，使收入增长率超过利率。然而，发行货币太容易了，而且比其他办法受欢迎。因此这个办法可能易于被滥用。关键是避免像1920年代去杠杆化的德国那样发行过多的货币，从而导致恶性通货膨胀。\n如果决策层取得适当的平衡，去杠杆化过程就不会那样激烈。经济增长速度缓慢，但债务负担会下降这就是和谐的去杠杆化。当收入上升的时候，借款人的信用度提高借款人一旦显得更有信用，贷款人就会开始恢复贷款，债务负担终于开始下降，人们可以借到钱，就可以增加消费。经济终于开始恢复增长，长期债务周期从而进入通货再膨胀阶段。\n去杠杆化过程如果处理不当，会非常可怕；但如果处理得当，最终将解决问题。为了使债务负担下降和经济活动恢复正常，大约需要十年或更长的时间，因此有失去的十年这种说法。\n综上所述，经济当然要比这个模式复杂一点。然而，把短期债务周期、长期债务周期和生产率增长轨迹结合起来分析。我们会得到一个不错的模式，可以看清我们在过去和当前的处境以及未来可能的发展方向。\n最后，我希望大家学到三条经验法则：\n第一不要让债务的增长速度超过收入，因为债务负担最终将把你压垮。\n第二不要让收入的增长速度超过生产率，因为这最终将使你失去竞争力。\n第三尽一切努力提高生产率，因为生产率在长期内起着最关键的作用。\n这就是我给大家，也是给决策者们的简单的建议。大家也许会吃惊地发现，大多数人包括大多数决策者，都没有对此予以足够的重视。这个模式对我很有用，希望它也将对你们有用谢谢大家。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/economy\/ecomony-machine\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/golang\/golang-eng\/": {
        
        "title": "Golang最工程化的语言",
        "tags": ["Golang",],
        "content": "Golang是什么语言 PHP是最好的语言。\nHaskell最难学的语言。\nGolang最工程化的语言。\n下面分别从语言层面及软件工程两个方面进行说明。\n语言 安全性 相比较于C/C++，golang不支持指针操作，不支持隐式类型转换，支持内存溢出与越界检查。\n并发与扩展 通过goroutine，Golang从语言层面上解决了并发与扩展的问题，而不像C/C++, JAVA通过框架来解决这个问题。Golang自适应多核运行。\n简单 语法简单，代码不涉及内存管理，上手容易。新人学习几天就可以上手写代码。\n可维护性 自带godoc统一代码格式。 一个文件夹对应一个包有利于代码模块化。\n打包一切 相比较于C/C++，动态库和静态库的依赖，Golang将所有编译成一个二进制文件。 解决依赖带来高度耦合问题，这样十分有利于交付与部署。\n可移植 支持多种体系架构与不同的操作系统以及跨平台编译。\n高效率 Golang实现了程序员开发高效率与机器运行高效率两者的有效结合，进而实现经济上高效率。\n相比较于C/C++，Golang编译速度更快了。特别是大型项目，以前用C语言的时候，在刀片服务器上时编译一个测试版本都要半个小时左右。\n生态成长 背靠Google，从09年发布已来，已经在云生态占据绝对主导地位。有不少明星开源项目。如Docker、Kubernetes、Prometheus、Hyperleder、Ethereum、Etcd等。随着云时代不断发展，Golang生态一定会越来越强大与丰富。\n软件工程 流程 一般软件工程流程分为规划、需求、设计、编码、测试、发布、维护等几个阶段。除了规划与需求阶段，Golang对其他阶段在语言层面都有强力特性支持。举例如下：\n 设计阶段：利用interface可以进行protype编程，可以实现代码及文档。 编码阶段：go fmt统一代码格式 测试阶段：自带go test便于测试，不像C/C++依赖gtest 发布阶段：上面说到可移植及打包一切，便于交付，发布，部署 维护阶段：Golang天然支持CPU扩展及其上面所说的便于交付，发布，部署  大规模协作 Golang引入interface特性，实际在语言层面支持SOLID设计原则中依赖倒置原则。再加上包的独立性，有利于大规模系统的大团队协作开发。\n编程友好 软件工程是人是关键因素。编码是核心阶段。Golang以下特性释放了程序员的生产力：\n 还算丰富的基础库 避免内存管理 天然支持并发  后记 当然Golang也有自己的缺点，如GC问题，延时大等。但是用一个语言的策略就应该扬长避短，当然熟练应用Golang的特性得深入学习与实践。\n(End)\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/golang\/golang-eng\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ipfs%E4%B8%93%E9%A2%98\/": {
        
        "title": "IPFS专题",
        "tags": ["IPFS",],
        "content": "前言 IPFS（包括filecoin）无论从技术视角还是商业视角都有很多有意思的内容（关键是自己很看好这个技术），所以要准备搞一个IPFS专题。\n文章  IPFS与下一代网络安全 下一代互联网基础：IPFS.pdf  动态  Filecoin 2017 Q4 Update Filecoin 2018 Q1 \u0026amp; Q2 Update Filecoin 2019 Q2 \u0026amp; Q3 Update Filecoin Roadmap Update Q4 2019 IPFS 0.5.0 is here! Our largest upgrade to IPFS yet A Guide to Filecoin Storage Mining  IPFS和filecoin之间的关系 IPFS是技术，filecoin是技术的商业化。 IPFS+filecoin在一起完成技术商业化，从1到1000。。。\n生态  ANNOUNCING COLLABORATION WITH FILECOIN - BIG INTEGRATIONS COMING 累计资助150万美元，上线前夕的Filecoin生态项目都有啥？  参考  ipfs filecoin  ", 
        "url": "http:\/\/myself659.github.io\/post\/ipfs%E4%B8%93%E9%A2%98\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%9B%A2%E9%98%9F%E6%80%9D%E8%80%83%E4%B8%8E%E4%BA%A4%E6%B5%81\/": {
        
        "title": "关于团队建设与沟通一点思考",
        "tags": ["Thinking",],
        "content": "关于团队建设与交流一点看法。主要要点如下：\n 团队奉行人人平等的原则 团队成员每一个人都学会认真聆听 团队将追求轻松交谈作为目标 团队成员要学会发现别人的闪光点，并提供真诚，具体，简洁的赞赏 团队要鼓励深入思考并敢于冒险 调节团队情绪，保持积极向上的团队风貌 扩大消息面与来源，避免偏见 鼓励面对现实与尖锐问题 求同存异，允许不同意见与看法的存在 打造良好的沟通场所与氛围  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%9B%A2%E9%98%9F%E6%80%9D%E8%80%83%E4%B8%8E%E4%BA%A4%E6%B5%81\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E7%9C%8B%E5%A5%BD%E5%8C%BA%E5%9D%97%E9%93%BE\/": {
        
        "title": "我为什么看好区块链",
        "tags": ["BlockChain",],
        "content": "前言 关于区块链讨论很多，下面是我个人看好区块链技术的原因，具体如下：\n提高效率，降低成本 以比特币为例，大大缩短跨国转帐的成本和时间周期。这只是冰上一角，区块链技术在金融系统的还没有大面积的应用。\n解决问题 区块链确确实实在解决一些问题，具体如下：\n 蚂蚁金服将区块链与公益结合，以解决透明跟踪资金流动及其监管等问题 比特币的国际转帐，降低转帐成本，同时也降低了到帐时间 提供不可更改服务，如运维操作的记录  信任机器 每一笔交易背后都是信任。比特币从09年到现在，并没有看到有任何一笔交易执行出错。\n未来趋势 IT行业经历了中心化时代（大型机）到去中心化时代（桌面时代）再到中心化时代（云计算与大型互联网）的发展，再到现在一步一步向以区块链技术为基础的去中心化时代发展。\n滚滚潮流面前，一切自然都会发生。\n应用广泛 如下图所示，区块链技术应用范围很广。\n成长性 不仅体现在市场上，更体现在技术，区块链将会是一种粘合剂型的技术。\n革命性 吴军说过AI解放生产力，区块链解放生产关系。\n无论国内还是美帝，一大批精英投入到区块链行业中。\n最后引用一句语：\n越对未来有信心，越对现在有耐心。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)，您的关注是我更新的动力\n", 
        "url": "http:\/\/myself659.github.io\/post\/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E7%9C%8B%E5%A5%BD%E5%8C%BA%E5%9D%97%E9%93%BE\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ms-github\/": {
        
        "title": "关于微软收购github几点看法",
        "tags": ["商业","Internet",],
        "content": " 开源已经是一种潮流与趋势。从linux开始，开源软件支撑现在的互联网与云计算。有太多的项目如redis，docker，k8s，etcd等等；区块链领域更是如此。 得开发者得天下。github上有最多的开发者和开发项目。 代码管理平台的重要性凸显。 估计google会在未来收购gitlab。 github找到微软爸爸，服务体验会有改善（如国内下载代码慢）。 github大量的开源代码会成为AI编程的学习材料，未来CRUD可能由AI来完成了。 未来人人都是开发者。随着教育的发展，编程肯定是每个人的必修课。这样github会成为代码管理的操作系统。 github与vscode会有深度集成，提高开发效率与体验。 github与azure集成，提供一站式开发服务。  参考  收购 GitHub，微软的又一次大转变 How Microsoft Beat the Innovator’s Dilemma  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/ms-github\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/about-rand\/": {
        
        "title": "浅谈随机",
        "tags": ["闲谈乱扯",],
        "content": "随机是一个十分有意思的问题。\n随机是一种选择方式 生活中最常见的例子就有这些：\n 抽签 抽奖 抛硬币  随机是一种隐藏方式 同样拿抽奖为例，将少量的中奖者隐藏在抽奖参与者中。从概率论的角度上看就是将分子隐藏分母当中。\n随机是一种分散方式 典型的例子就是随机数，避免产生的数据集中；除此之外Markov链实现一种离散时间随机过程。\n随机是一种达成共识的方式 还拿抽签为例，这种方式是我们达成共识的一种重要的低成本且公平的共识方式，具体如下：\n 比赛过程中通过抽签解决出场顺序 家里贫穷时，有多个读书的，通过抽签来决定的  随机是一种降低冲突的方式 随机带来的分散性，可以帮助解决冲突，例如raft协议在选leader过程中通过随机来避免多个候选者同时竞争leader的情况出现。\n随机是一种保护与安全方式 一滴水只有放进大海才永远不会干涸。在Algorand中通过VRF保护记账节点，将记帐节点隐藏在于众多节点当中。在数字货币钱包利用随机性生产私钥来保护私钥；除了这些以外，更多随机数在在区块链有许多利用随机来保证公链安全的应用，可以参考这篇文章区块链中的随机数\n随机是一种需求 小道消息的抽奖助手将随机这一需求产品化。\n小结 总之，随机在生活中无处不在。随机以上用途来自随机的不确定性。随机的本质是不确性。 随机当中还有很多可以挖掘的认识与理解。\n参考  随机性 一文搞懂HMM（隐马尔可夫模型） Random numbers and decentralized networks: implementation Random numbers and decentralized networks: practical application Filecoin Features: Distributed Randomness \u0026amp; Leader Elections  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/about-rand\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/how-to-unstuck-avoid-suck\/": {
        
        "title": "如何走出困境避免进度卡壳",
        "tags": ["learn",],
        "content": "原因 陷入困境的原因从以下几个方面展开。\n基础  不知道自己不知道unknown unknown 技能进入高原与瓶颈期，技能达不到解决问题的要求 缺少信息  自我限制  陷入固定的框架之中 陷入固定的观念之中 不能主动寻求帮助 只是重复而不是迭代  目标  目标不具体明确 目标太大，没有通过分解降低难度 目标太难  路径与方法  不知道如何开始与入手 缺少明确的路径 路径与方法错误如先后顺序出错 没有从最简单与最基础的开始 不要死磕，停下来，休息一下，改变一下  能量  缺少动机 拖延症 心理负担重，不能轻装上阵 韧性不足 专注不够，导致不能深度思考与工作 状态不好  示例 假设遇到一个leetcode题目不会解，可以参考以下步骤来解决：\n  理解题目的意思，这里理解指能够清楚向别人解释题目，如限制是什么，输入是什么，输出是什么？\n  针对问题给出一个简单的方案，测试与验证这个方案\n  优化方案，在思路上验证方案满足要求\n  写伪码，在代码思路上验证方案\n  将伪码改为代码，通过代码运行验证方案\n  如果验证通过，则先分析时间与空间复杂度，再进行举一反三。如果不通过，回到第三步或者第一步，进行迭代。\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/how-to-unstuck-avoid-suck\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/eth-txpool\/": {
        
        "title": "以太坊交易池分析",
        "tags": ["BlockChain","ethereum",],
        "content": "简介 以太坊交易池有以下功能：\n 缓存交易 清理交易 实现交易gasPrice竞价功能 配合出块，提供打包交易 交易查询  配置 配置描述 geth中用数据结构TxPoolConfig描述交易池配置，具体如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // TxPoolConfig are the configuration parameters of the transaction pool. type TxPoolConfig struct { NoLocals bool // Whether local transaction handling should be disabled Journal string // Journal of local transactions to survive node restarts Rejournal time.Duration // Time interval to regenerate the local transaction journal PriceLimit uint64 // Minimum gas price to enforce for acceptance into the pool PriceBump uint64 // Minimum price bump percentage to replace an already existing transaction (nonce) AccountSlots uint64 // Minimum number of executable transaction slots guaranteed per account GlobalSlots uint64 // Maximum number of executable transaction slots for all accounts AccountQueue uint64 // Maximum number of non-executable transaction slots permitted per account GlobalQueue uint64 // Maximum number of non-executable transaction slots for all accounts Lifetime time.Duration // Maximum amount of time non-executable transaction are queued }   对其中相关参数说明如下：\nAccountSlots：每个帐户等待处理交易的最大个数。默认值为16 GlobalSlots：所有帐户等待处理交易的最大个数。默认值为4096 AccountQueue：每帐户暂不能处理交易的最大个数。默认值为64 GlobalQueue：所有帐户暂不能处理交易的最大个数。默认值为1024 Lifetime：暂不能处理交易在队列中最大保存时长。默认值为3小时\n问题来了：等待处理交易与暂不能处理交易有什么不一样？\n等待处理交易满足交易执行条件，暂不能处理交易不满足交易执行条件。这里的交易执行条件是指交易的nonce不能超过当前区块中的交易的nonce的值加1。\n默认配置 默认配置信息保存在DefaultTxPoolConfig变量中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // DefaultTxPoolConfig contains the default configurations for the transaction // pool. var DefaultTxPoolConfig = TxPoolConfig{ Journal: \u0026#34;transactions.rlp\u0026#34;, Rejournal: time.Hour, PriceLimit: 1, PriceBump: 10, AccountSlots: 16, GlobalSlots: 4096, AccountQueue: 64, GlobalQueue: 1024, Lifetime: 3 * time.Hour, }   交易池 描述 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  type TxPool struct { config TxPoolConfig chainconfig *params.ChainConfig chain blockChain gasPrice *big.Int txFeed event.Feed scope event.SubscriptionScope chainHeadCh chan ChainHeadEvent chainHeadSub event.Subscription signer types.Signer mu sync.RWMutex currentState *state.StateDB // Current state in the blockchain head pendingState *state.ManagedState // Pending state tracking virtual nonces currentMaxGas uint64 // Current gas limit for transaction caps locals *accountSet // Set of local transaction to exempt from eviction rules journal *txJournal // Journal of local transaction to back up to disk pending map[common.Address]*txList // All currently processable transactions queue map[common.Address]*txList // Queued but non-processable transactions beats map[common.Address]time.Time // Last heartbeat from each known account all *txLookup // All transactions to allow lookups priced *txPricedList // All transactions sorted by price wg sync.WaitGroup // for shutdown sync homestead bool }   关注一下以下几个成员就知道tx是如何保存与维护的：\n pending map[common.Address]*txList queue map[common.Address]*txList beats map[common.Address]time.Time all *txLookup // map类型，txhash为key，tx为value priced *txPricedList // heap维护gasPrice排序  存储 交易池不需要持久化，数据直接保存在内存中\n流程 如果将交易池当作队列来看，就有以下操作：\n 添加 删除 更新  添加 事件源  本地用户添加交易 远端RPC调加交易  检查条件 添加动作完成很简单，重要是添加前条件检查。相关检查代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  // add validates a transaction and inserts it into the non-executable queue for // later pending promotion and execution. If the transaction is a replacement for // an already pending or queued one, it overwrites the previous and returns this // so outer code doesn\u0026#39;t uselessly call promote. // // If a newly added transaction is marked as local, its sending account will be // whitelisted, preventing any associated transaction from being dropped out of // the pool due to pricing constraints. func (pool *TxPool) add(tx *types.Transaction, local bool) (bool, error) { // If the transaction is already known, discard it hash := tx.Hash() if pool.all.Get(hash) != nil { log.Trace(\u0026#34;Discarding already known transaction\u0026#34;, \u0026#34;hash\u0026#34;, hash) return false, fmt.Errorf(\u0026#34;known transaction: %x\u0026#34;, hash) } // If the transaction fails basic validation, discard it if err := pool.validateTx(tx, local); err != nil { log.Trace(\u0026#34;Discarding invalid transaction\u0026#34;, \u0026#34;hash\u0026#34;, hash, \u0026#34;err\u0026#34;, err) invalidTxCounter.Inc(1) return false, err } // If the transaction pool is full, discard underpriced transactions if uint64(pool.all.Count()) \u0026gt;= pool.config.GlobalSlots+pool.config.GlobalQueue { // If the new transaction is underpriced, don\u0026#39;t accept it if !local \u0026amp;\u0026amp; pool.priced.Underpriced(tx, pool.locals) { log.Trace(\u0026#34;Discarding underpriced transaction\u0026#34;, \u0026#34;hash\u0026#34;, hash, \u0026#34;price\u0026#34;, tx.GasPrice()) underpricedTxCounter.Inc(1) return false, ErrUnderpriced } // New transaction is better than our worse ones, make room for it drop := pool.priced.Discard(pool.all.Count()-int(pool.config.GlobalSlots+pool.config.GlobalQueue-1), pool.locals) for _, tx := range drop { log.Trace(\u0026#34;Discarding freshly underpriced transaction\u0026#34;, \u0026#34;hash\u0026#34;, tx.Hash(), \u0026#34;price\u0026#34;, tx.GasPrice()) underpricedTxCounter.Inc(1) pool.removeTx(tx.Hash(), false) } } // If the transaction is replacing an already pending one, do directly from, _ := types.Sender(pool.signer, tx) // already validated if list := pool.pending[from]; list != nil \u0026amp;\u0026amp; list.Overlaps(tx) { // Nonce already pending, check if required price bump is met inserted, old := list.Add(tx, pool.config.PriceBump) if !inserted { pendingDiscardCounter.Inc(1) return false, ErrReplaceUnderpriced } // New transaction is better, replace old one if old != nil { pool.all.Remove(old.Hash()) pool.priced.Removed() pendingReplaceCounter.Inc(1) } pool.all.Add(tx) pool.priced.Put(tx) pool.journalTx(from, tx) log.Trace(\u0026#34;Pooled new executable transaction\u0026#34;, \u0026#34;hash\u0026#34;, hash, \u0026#34;from\u0026#34;, from, \u0026#34;to\u0026#34;, tx.To()) // We\u0026#39;ve directly injected a replacement transaction, notify subsystems go pool.txFeed.Send(NewTxsEvent{types.Transactions{tx}}) return old != nil, nil } // New transaction isn\u0026#39;t replacing a pending one, push into queue replace, err := pool.enqueueTx(hash, tx) if err != nil { return false, err } // Mark local addresses and journal local transactions if local { pool.locals.add(from) } pool.journalTx(from, tx) log.Trace(\u0026#34;Pooled new future transaction\u0026#34;, \u0026#34;hash\u0026#34;, hash, \u0026#34;from\u0026#34;, from, \u0026#34;to\u0026#34;, tx.To()) return replace, nil }   从上面代码可以看出，检查项还是很多，罗列如下：\n 重复性检查: 检查是否已经存在队列中 交易大小检查，不能超过32KB 转帐数额不能是负数 gasPrice不超过当前最高限定gasPrice 交易签名检查 gasPrice竞价检查 Nonce检查 帐户ETH检查，防止余额不足 gasLimit检查，防止gas费用不足  删除 事件源 删除交易有以下情况：\n 交易队列容量超出 超时删除 接收新块检查删除非法交易  更新 事件源  相同nonce更新交易 定时器检查将满足执行条件的queue队列上交易添加到pending队列  参考  以太坊如何清除已发出未打包的交易  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/eth-txpool\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/arch\/software-engineering-great-quotes\/": {
        
        "title": "软件工程的法则与名言",
        "tags": ["Arch",],
        "content": "Programming “All problems in computer science can be solved by another level of indirection.” — David Wheeler\n“But that usually will create another problem.” — David Wheeler\n“Simplicity is prerequisite for reliability.” — Edsger Dijkstra\n“If we wish to count lines of code, we should not regard them as ‘lines produced’ but as ‘lines spent.’ “— Edsger Dijkstra\n\u0026ldquo;Controlling complexity is the essence of computer programming.\u0026rdquo; — Brian Wilson Kernighan\n“It’s harder to read code than to write it.” — Joel Spolsky\n“Any fool can write code that a computer can understand. Good programmers write code that humans can understand.” — Martin Fowler\n“Don’t repeat yourself. Every piece of knowledge must have a single, unambiguous, authoritative representation within a system.” — Andy Hunt and Dave Thomas\n“Code never lies; comments sometimes do.” — Ron Jeffries\n“There are only two hard things in computer science: cache invalidation and naming things.” — Phil Karlton\n“There are two hard things in computer science: cache invalidation, naming things, and off-by-one errors.” — Leon Bambrick\n“Deleted code is debugged code” — 𝕁𝕖𝕗𝕗 𝕊𝕚𝕔𝕜𝕖𝕝\n“Bugs lurk in corners and congregate at boundaries” — 𝔹𝕠𝕣𝕚𝕤 𝔹𝕖𝕚𝕫𝕖𝕣\n“The art of debugging is figuring out what you really told your program to do rather than what you thought you told it to do.”” — Andrew Singer\n“The moment you have to peek and dive into implementation details to understand how to compose it with other object. You’ve lost advantage of your programming paradigm.”\n— Barotz Milewski\n“A good programmer is someone who always looks both ways before crossing a one-way street” — 𝔻𝕠𝕦𝕘 𝕃𝕚𝕟𝕕𝕖𝕣\n“Any code of your own that you haven’t looked at for six or more months might as well have been written by someone else” — 𝔼𝕒𝕘𝕝𝕖𝕤𝕠𝕟’𝕤 𝕃𝕒𝕨\n“One man’s crappy software is another man’s full-time job” — 𝕁𝕖𝕤𝕤𝕚𝕔𝕒 𝔾𝕒𝕤𝕥𝕠𝕟\n“If you automate a mess, you get an automated mess” — ℝ𝕠𝕕 𝕄𝕚𝕔𝕙𝕒𝕖𝕝\n“Increasing the efficiency with which a resource is used increases the usage of that resource” — 𝕁𝕖𝕧𝕠𝕟’𝕤 ℙ𝕒𝕣𝕒𝕕𝕠𝕩\n“The cheapest, fastest, and most reliable components are those that aren’t there” — 𝔾𝕠𝕣𝕕𝕠𝕟 𝔹𝕖𝕝𝕝\n“If debugging is the process of removing software bugs, then programming must be the process of putting them in” — 𝔼𝕕𝕤𝕘𝕖𝕣 𝔻𝕚𝕛𝕜𝕤𝕥𝕣𝕒\n“There are two ways to write error-free programs; only the third one works” — 𝔸𝕝𝕒𝕟 ℙ𝕖𝕣𝕝𝕚𝕤\nArchitecture \u0026amp; Design “Hiring people to write code to sell is not the same as hiring people to design and build durable, usable, dependable software” —𝕃𝕒𝕣𝕣𝕪 ℂ𝕠𝕟𝕤𝕥𝕒𝕟𝕥𝕚𝕟𝕖\n“The hardest part of design is … keeping features out” — 𝔻𝕠𝕟𝕒𝕝𝕕 ℕ𝕠𝕣𝕞𝕒𝕟\n“A software system built on top of a weak architecture will sink due to the weight of its own success” — 𝕋𝕙𝕖 𝔸𝕣𝕔𝕙𝕚𝕞𝕖𝕕𝕖𝕒𝕟 ℙ𝕣𝕚𝕟𝕔𝕚𝕡𝕝𝕖\n“Before software can be reusable it first has to be usable” — ℝ𝕒𝕝𝕡𝕙 𝕁𝕠𝕙𝕟𝕤𝕠𝕟\n“A complex system that works is invariably found to have evolved from a simple system that worked” — 𝔾𝕒𝕝𝕝’𝕤 𝕃𝕒𝕨\nIf you can’t explain it simply, you don’t understand it well enough. — Albert Einstein\nRequirements “Walking on water and developing software from a specification are easy if both are frozen” — 𝔼𝕕𝕨𝕒𝕣𝕕 𝔹𝕖𝕣𝕒𝕣𝕕\n“The user will never know what they want until after the system is in production (and maybe not even then)” — ℍ𝕦𝕞𝕡𝕙𝕣𝕖𝕪’𝕤 𝕃𝕒𝕨\n“It is easier to change the specification to fit the program than vice versa” — 𝔸𝕝𝕒𝕟 ℙ𝕖𝕣𝕝𝕚𝕤\n“The more stable a requirement is considered, the greater the probability it is changed” — ℍ𝕖𝕚𝕤𝕖𝕟𝕓𝕖𝕣𝕘’𝕤 ℙ𝕣𝕚𝕟𝕔𝕚𝕡𝕝𝕖\n“Increasing the number of choices will increase the decision time logarithmically” — ℍ𝕚𝕔𝕜’𝕤 𝕃𝕒𝕨\n“A man with a watch knows what time it is. A man with two watches is never sure” — 𝕊𝕖𝕘𝕒𝕝’𝕤 𝕃𝕒𝕨\nEstimation \u0026amp; Time Management “The first 90% of the code accounts for the first 90% of the development time. The remaining 10% of the code accounts for the other 90% of the development time” — 𝕋𝕠𝕞 ℂ𝕒𝕣𝕘𝕚𝕝𝕝\n“The time from now until the completion of the project tends to become constant” — ℍ𝕒𝕣𝕥𝕣𝕖𝕖’𝕤 𝕃𝕒𝕨\n“Work expands to fill the time available for its completion” — ℙ𝕒𝕣𝕜𝕚𝕟𝕤𝕠𝕟’𝕤 𝕃𝕒𝕨\n“It always takes longer than you expect, even when you take into account Hofstadter’s Law” — ℍ𝕠𝕗𝕤𝕥𝕒𝕕𝕥𝕖𝕣’𝕤 𝕃𝕒𝕨\n“There’s never enough time to do it right, but there’s always enough time to do it over” — 𝕁𝕒𝕔𝕜 𝔹𝕖𝕣𝕘𝕞𝕒𝕟\nProject Management “Adding manpower to a late software project makes it later” —𝔹𝕣𝕠𝕠𝕜𝕤’𝕤 𝕃𝕒𝕨\n“For many phenomena 80% of consequences stem from 20% of the causes” —ℙ𝕒𝕣𝕖𝕥𝕠 ℙ𝕣𝕚𝕟𝕔𝕚𝕡𝕝𝕖\n“Nothing ever gets built on schedule or within budget” — ℂ𝕙𝕖𝕠𝕡𝕤 𝕃𝕒𝕨\n“Anything that can go wrong will go wrong” — 𝕄𝕦𝕣𝕡𝕙𝕪’𝕤 𝕃𝕒𝕨\n“I have always found that plans are useless, but planning is indispensable” — 𝔻𝕨𝕚𝕘𝕙𝕥 𝔼𝕚𝕤𝕖𝕟𝕙𝕠𝕨𝕖𝕣\n", 
        "url": "http:\/\/myself659.github.io\/post\/arch\/software-engineering-great-quotes\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rd-leadship\/": {
        
        "title": "乱扯研发管理与领导",
        "tags": ["闲谈乱扯","研发管理",],
        "content": "前言 优秀的技术人员与技术管理人员会一直紧缺。一个好的技术管理人员应该有自己的管理及领导指导原则。（Ps：最近在读《原则》这本书，深受其影响，虽然已经有很多人在推荐，这里再推荐一下，这本书真的值得一读。） 结合个人的工作经历与思考，提出自己对研发管理与技术领导的一些原则性思考。\n基本原则 具体如下图所示：\n以业务为中心，从文化，团队，代码，架构四个方面进行出发思考。用一句简单总结一下就是：在先进的文化氛围下，精英团队在科学的架构指导以业务为中心开展各项代码工作（需求，设计，开发，测试，部署，升级）。\n这是一个前进的方向及指导的框架，至于具体的落地需要按阶段与范围的践行。（Ps：中国改革开放40年在遵循一个中心，两个基本点的指导原则下，使中国经济发展取得翻天覆地的巨大变化。）\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n参考  Supercell，一家人均贡献超过3600万的公司，如何定义管理？  ", 
        "url": "http:\/\/myself659.github.io\/post\/rd-leadship\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/eth-tx-submit\/": {
        
        "title": "以太坊提交交易流程分析",
        "tags": ["BlockChain","ethereum",],
        "content": "说明 代码基于go-ethereum，版本v1.8.10。\nRPC代码入口 SendTransaction\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // SendTransaction will create a transaction from the given arguments and // tries to sign it with the key associated with args.To. If the given passwd isn\u0026#39;t // able to decrypt the key it fails. func (s *PrivateAccountAPI) SendTransaction(ctx context.Context, args SendTxArgs, passwd string) (common.Hash, error) { if args.Nonce == nil { // Hold the addresse\u0026#39;s mutex around signing to prevent concurrent assignment of // the same nonce to multiple accounts. s.nonceLock.LockAddr(args.From) defer s.nonceLock.UnlockAddr(args.From) } signed, err := s.signTransaction(ctx, args, passwd) if err != nil { return common.Hash{}, err } return submitTransaction(ctx, s.b, signed) }   SendTxArgs的数据结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12  type SendTxArgs struct { From common.Address `json:\u0026#34;from\u0026#34;` To *common.Address `json:\u0026#34;to\u0026#34;` Gas *hexutil.Uint64 `json:\u0026#34;gas\u0026#34;` GasPrice *hexutil.Big `json:\u0026#34;gasPrice\u0026#34;` Value *hexutil.Big `json:\u0026#34;value\u0026#34;` Nonce *hexutil.Uint64 `json:\u0026#34;nonce\u0026#34;` // We accept \u0026#34;data\u0026#34; and \u0026#34;input\u0026#34; for backwards-compatibility reasons. \u0026#34;input\u0026#34; is the // newer name and should be preferred by clients. Data *hexutil.Bytes `json:\u0026#34;data\u0026#34;` Input *hexutil.Bytes `json:\u0026#34;input\u0026#34;` }   新增加Input字段。用于替换原来Data字段，为了兼容保留Data字段。\n查找钱包 根据from地址信息查找钱包。\n1 2 3 4 5 6  // Look up the wallet containing the requested signer account := accounts.Account{Address: args.From} wallet, err := s.am.Find(account) if err != nil { return nil, err }   设置参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  // setDefaults is a helper function that fills in default values for unspecified tx fields. func (args *SendTxArgs) setDefaults(ctx context.Context, b Backend) error { if args.Gas == nil { args.Gas = new(hexutil.Uint64) *(*uint64)(args.Gas) = 90000 } if args.GasPrice == nil { price, err := b.SuggestPrice(ctx) if err != nil { return err } args.GasPrice = (*hexutil.Big)(price) } if args.Value == nil { args.Value = new(hexutil.Big) } if args.Nonce == nil { nonce, err := b.GetPoolNonce(ctx, args.From) if err != nil { return err } args.Nonce = (*hexutil.Uint64)(\u0026amp;nonce) } if args.Data != nil \u0026amp;\u0026amp; args.Input != nil \u0026amp;\u0026amp; !bytes.Equal(*args.Data, *args.Input) { return errors.New(`Both \u0026#34;data\u0026#34; and \u0026#34;input\u0026#34; are set and not equal. Please use \u0026#34;input\u0026#34; to pass transaction call data.`) } if args.To == nil { // Contract creation var input []byte if args.Data != nil { input = *args.Data } else if args.Input != nil { input = *args.Input } if len(input) == 0 { return errors.New(`contract creation without any data provided`) } } return nil }   创建交易 根据交易参数创建交易。\n1 2 3 4 5 6 7 8 9 10 11 12  func (args *SendTxArgs) toTransaction() *types.Transaction { var input []byte if args.Data != nil { input = *args.Data } else if args.Input != nil { input = *args.Input } if args.To == nil { return types.NewContractCreation(uint64(*args.Nonce), (*big.Int)(args.Value), uint64(*args.Gas), (*big.Int)(args.GasPrice), input) } return types.NewTransaction(uint64(*args.Nonce), *args.To, (*big.Int)(args.Value), uint64(*args.Gas), (*big.Int)(args.GasPrice), input) }   相关数据结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  type Transaction struct { data txdata // caches hash atomic.Value size atomic.Value from atomic.Value } type txdata struct { AccountNonce uint64 `json:\u0026#34;nonce\u0026#34; gencodec:\u0026#34;required\u0026#34;` Price *big.Int `json:\u0026#34;gasPrice\u0026#34; gencodec:\u0026#34;required\u0026#34;` GasLimit uint64 `json:\u0026#34;gas\u0026#34; gencodec:\u0026#34;required\u0026#34;` Recipient *common.Address `json:\u0026#34;to\u0026#34; rlp:\u0026#34;nil\u0026#34;` // nil means contract creation Amount *big.Int `json:\u0026#34;value\u0026#34; gencodec:\u0026#34;required\u0026#34;` Payload []byte `json:\u0026#34;input\u0026#34; gencodec:\u0026#34;required\u0026#34;` // Signature values V *big.Int `json:\u0026#34;v\u0026#34; gencodec:\u0026#34;required\u0026#34;` R *big.Int `json:\u0026#34;r\u0026#34; gencodec:\u0026#34;required\u0026#34;` S *big.Int `json:\u0026#34;s\u0026#34; gencodec:\u0026#34;required\u0026#34;` // This is only used when marshaling to JSON. Hash *common.Hash `json:\u0026#34;hash\u0026#34; rlp:\u0026#34;-\u0026#34;` }   获取ChainId 为了防止重放攻击，获得了chainID（EIP155之后才支持），用于签名。\n1 2 3 4  var chainID *big.Int if config := s.b.ChainConfig(); config.IsEIP155(s.b.CurrentBlock().Number()) { chainID = config.ChainId }   chainID是如何使用的？简单说就是：以一系列数学运算将chainID保存到签名信息中。\n1 2 3 4 5 6 7 8 9  func NewEIP155Signer(chainId *big.Int) EIP155Signer { if chainId == nil { chainId = new(big.Int) } return EIP155Signer{ chainId: chainId, chainIdMul: new(big.Int).Mul(chainId, big.NewInt(2)), } }   1 2 3 4 5 6 7 8 9 10 11 12 13  // WithSignature returns a new transaction with the given signature. This signature // needs to be in the [R || S || V] format where V is 0 or 1. func (s EIP155Signer) SignatureValues(tx *Transaction, sig []byte) (R, S, V *big.Int, err error) { R, S, V, err = HomesteadSigner{}.SignatureValues(tx, sig) if err != nil { return nil, nil, nil, err } if s.chainId.Sign() != 0 { V = big.NewInt(int64(sig[64] + 35)) V.Add(V, s.chainIdMul) } return R, S, V, nil }   签名 从keystore获取私钥用于签名交易。\n1 2 3 4 5 6 7 8 9 10 11  // SignHashWithPassphrase signs hash if the private key matching the given address // can be decrypted with the given passphrase. The produced signature is in the // [R || S || V] format where V is 0 or 1. func (ks *KeyStore) SignHashWithPassphrase(a accounts.Account, passphrase string, hash []byte) (signature []byte, err error) { _, key, err := ks.getDecryptedKey(a, passphrase) if err != nil { return nil, err } defer zeroKey(key.PrivateKey) return crypto.Sign(hash, key.PrivateKey) }   提交交易 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // submitTransaction is a helper function that submits tx to txPool and logs a message. func submitTransaction(ctx context.Context, b Backend, tx *types.Transaction) (common.Hash, error) { if err := b.SendTx(ctx, tx); err != nil { return common.Hash{}, err } if tx.To() == nil { signer := types.MakeSigner(b.ChainConfig(), b.CurrentBlock().Number()) from, err := types.Sender(signer, tx) if err != nil { return common.Hash{}, err } addr := crypto.CreateAddress(from, tx.Nonce()) log.Info(\u0026#34;Submitted contract creation\u0026#34;, \u0026#34;fullhash\u0026#34;, tx.Hash().Hex(), \u0026#34;contract\u0026#34;, addr.Hex()) } else { log.Info(\u0026#34;Submitted transaction\u0026#34;, \u0026#34;fullhash\u0026#34;, tx.Hash().Hex(), \u0026#34;recipient\u0026#34;, tx.To()) } return tx.Hash(), nil }   添加交易到本地交易池。\n1 2 3  func (b *EthAPIBackend) SendTx(ctx context.Context, signedTx *types.Transaction) error { return b.eth.txPool.AddLocal(signedTx) }   小结 到此为止，交易已经提交到交易池。这才是整个交易完成过程中第一步，后面还有广播、检查、打包、确认等流程。\n这是节点钱包提交交易的过程。轻钱包提交交易与此有一些不同，是通过rpc调用提交到钱包服务的节点钱包。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/eth-tx-submit\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/socialnetowrk-cannot-cycle\/": {
        
        "title": "社交网络摆脱不了的周期",
        "tags": ["Internet",],
        "content": "没有什么是不可改变的。\nFacebook有22亿用户。\nMySpace曾经是世界之王。现在人们都已经遗忘了。\nQQ还是让位微信，活跃度下降，用户时长下降。\n问题来了，在哪些情况下周期会到了？个人认为以下三种情况大概率会发生。\n 变得讨厌，用户会逐渐抛弃，人人网就是一个例子 有更好的替代品的时候，如MySpace被facebook取代 技术变革，犹如地球进入冰川时代，巨无霸的恐龙都灭绝了，典型的例子是进入移动互联网时代，微信取代了QQ  那么问题又来了，微信的周期什么时候会到？这个意淫一下，回答如下：\n 当穿戴时代到来的时候，手机被抛弃的时候，这个未来十年应该不会发生的 当微信的社交关系由于数据库维护，变成了由生物特征维护的时候，这个主要是冲击是用户同用户之间建立连接的方式变了  这只是个人的胡乱猜想，微信的未来我是看好，微信也是不断的进化，微信现在已经变成一个有10亿用户的生活操作系统。Windows都用了40多年，现在还是大量(PC并没有被淘汰)使用中，相信微信也不会例外。但是手机的操作却不是Windows，未来充满变化与不确定性。\n", 
        "url": "http:\/\/myself659.github.io\/post\/socialnetowrk-cannot-cycle\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/i-know-i-donot-known\/": {
        
        "title": "我不知道",
        "tags": ["Think",],
        "content": "背景 苏格拉底说过：我唯一知道的就是我一无所知。\n我不知道  我不知道自己 我不知道过去 我不知道现在 我不知道未来 我不知道别人 我不知道变化 我不知道系统 我更不知道所有  我知道我不知道，怀疑一切，小心求证。\n我知道我不知道，心怀敬畏，不敢为天下先。\n我知道我不知道，面对现实，做好自己。\n我知道我不知道，避免做那个最愚蠢的人。\n应对我不知道 我们不是神，我不知道是正常，我不知道的远远多于我知道的。\n那么怎么应对我不知道呢？或者说努力让自己知道的多一点呢？\n 相信世界是混沌与不确定性 将不知道作为驱动力来学习，实践与验证 发现事实与尊重客观规律 进行概率与可能性描述，分析，计算，预测  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/i-know-i-donot-known\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/solidity\/solidity-evm-instructions\/": {
        
        "title": "EVM opcodes",
        "tags": ["Solidity","Ethereum",],
        "content": "推荐 Ethereum Virtual Machine Opcodes\nArithmetic Operations 1 2 3 4 5 6 7 8 9 10 11 12  ADD //Add the top two stack items MUL //Multiply the top two stack items SUB //Subtract the top two stack items DIV //Integer division SDIV //Signed integer division MOD //Modulo (remainder) operation SMOD //Signed modulo operation ADDMOD //Addition modulo any number MULMOD //Multiplication modulo any number EXP //Exponential operation SIGNEXTEND //Extend the length of a two’s complement signed integer SHA3 //Compute the Keccak-256 hash of a block of memory   Stack Operations 1 2 3 4 5 6 7 8 9 10  POP //Remove the top item from the stack MLOAD //Load a word from memory MSTORE //Save a word to memory MSTORE8 //Save a byte to memory SLOAD //Load a word from storage SSTORE //Save a word to storage MSIZE //Get the size of the active memory in bytes PUSHx //Place x-byte item on the stack, where x can be any integer from 1 to 32 (full word) inclusive DUPx //Duplicate the x-th stack item, where x can be any integer from 1 to 16 inclusive SWAPx //Exchange 1st and (x+1)-th stack items, where x can by any integer from 1 to 16 inclusive   Process Flow Operations 1 2 3 4 5  STOP //Halts execution JUMP //Set the program counter to any value JUMPI //Conditionally alter the program counter PC //Get the value of the program counter (prior to the increment corresponding to this instruction) JUMPDEST //Mark a valid destination for jumps   System Operations 1 2 3 4 5 6 7 8 9 10  LOGx //Append a log record with +x+ topics, where +x+ is any integer from 0 to 4 inclusive CREATE //Create a new account with associated code CALL //Message-call into another account, i.e. run another account\u0026#39;s code CALLCODE //Message-call into this account with an another account’s code RETURN //Halt execution and return output data DELEGATECALL //Message-call into this account with an alternative account’s code, but persisting the current values for sender and value STATICCALL //Static message-call into an account REVERT //Halt execution reverting state changes but returning data and remaining gas INVALID //The designated invalid instruction SELFDESTRUCT //Halt execution and register account for deletion   Logic Operations 1 2 3 4 5 6 7 8 9 10 11  LT //Less-than comparison GT //Greater-than comparison SLT //Signed less-than comparison SGT //Signed greater-than comparison EQ //Equality comparison ISZERO //Simple not operator AND //Bitwise AND operation OR //Bitwise OR operation XOR //Bitwise XOR operation NOT //Bitwise NOT operation BYTE //Retrieve a single byte from a full-width 256 bit word   Environmental Operations 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  GAS //Get the amount of available gas (after the reduction for this instruction) ADDRESS //Get the address of the currently executing account BALANCE //Get the account balance of any given account ORIGIN //Get the address of the EOA that initiated this EVM execution CALLER //Get the address of the caller immediately responsible for this execution CALLVALUE //Get the ether amount deposited by the caller responsible for this execution CALLDATALOAD //Get the input data sent by the caller responsible for this execution CALLDATASIZE //Get the size of the input data CALLDATACOPY //Copy the input data to memory CODESIZE //Get the size of code running in the current environment CODECOPY //Copy the code running in the current environment to memory GASPRICE //Get the gas price specified by the originating transaction EXTCODESIZE //Get the size of any account\u0026#39;s code EXTCODECOPY //Copy any account’s code to memory RETURNDATASIZE //Get the size of the output data from the previous call in the current environment RETURNDATACOPY //Copy of data output from the previous call to memory   Block Operations 1 2 3 4 5 6  BLOCKHASH //Get the hash of one of the 256 most recently completed blocks COINBASE //Get the block’s beneficiary address for the block reward TIMESTAMP //Get the block’s timestamp NUMBER //Get the block’s number DIFFICULTY //Get the block’s difficulty GASLIMIT //Get the block’s gas limit     ", 
        "url": "http:\/\/myself659.github.io\/post\/solidity\/solidity-evm-instructions\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/distributed-bft\/": {
        
        "title": "为什么BFT要求诚实节点数量大于总节点的三分之二",
        "tags": ["Distributed",],
        "content": "相信很多人都知道，BFT(Byzantine fault tolerance)要求诚实节点数量大于总节点的三分之二。\n为什么会有这个要求？\n多数派原则 多数派原则在分布式系统很常见，即确保网络分化情况下的决议唯一。其原理是，假如节点总数是2f+1，那么一项决议得到多于f个节点赞成则获得通过。leader选举中，网络分化下，只有具有多数派节点的部分才可能选出leader。多数派还可以用于副本管理，根据实际情况调整写副本数和读副本数，在可靠性和性能之间取得平衡。 在分布式系统，无论paxos，还是raft，以投票来达成共识，在整个达成共识的过程中都遵守多数派原则。\n下面先看多数派原则在raft中应用。\nraft 假定f表示系统同时允许最大故障节点数量(f节点数量决定了系统可用性的概率)，在这种情况下，根据多数派原则，那么正常节点至少为f+1，即可以得出系统总节点数为2f+1。\nBFT 在Raft协议中假设所有节点都是诚实节点，而在BFT假定系统存在一些作恶节点。 那么一个BFT中最多允许有多少个作恶节点？\n进行逆向思考如下：\n假如系统有f个作恶节点，那么在多数派系统，不作恶节点至少有f+1个。 f+1节点能够满足吗？不可以，网络分区是一直都存在，结合raft上，那么不作恶节点至少为2f+1，从而可以得出总节点数3f+1个。\n参考  漫谈分布式系统、拜占庭将军问题与区块链  ", 
        "url": "http:\/\/myself659.github.io\/post\/distributed-bft\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/%E7%9F%BF%E5%B7%A5%E4%BA%94%E5%AE%97%E7%BD%AA\/": {
        
        "title": "矿工五宗罪",
        "tags": ["BlockChain","bitcoin",],
        "content": "比特币生态 比特币生态有以下几个角色：\n 比特币核心开发者，他们开发与更新比特币技术, 负责开发与维护代码 矿工们，运行区块链技术与算力保证，负责执行代码 交易所，比特币网络的IO,为整个网络的运行提供外部价值的IO  其中矿工有以下五宗罪，具体如下：\nIFO帮凶 从BCH开始，一时间多少IFO兴起，任何一个IFO背后都有矿工的支持。\n自私挖矿 这是矿工之间的作恶。\n滥用打包权 此路是我开，要想过此路，留下买路财。 表现如下：\n 某矿池提供的交易加速器服务 明明可以打包1000条交易，实际只打一个交易  竞价排名 这个争议如同百度的竞价排名。\n算力集中与垄断 用图说话，前五位矿池的算力超过了51%。 小结 虽然比特币的生态系统有这些bug，也不能否认矿工的在比特币生态中的作用， 如同社会中在保证劳者有所，得能者多得。\n参考  全球算力分布   ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/%E7%9F%BF%E5%B7%A5%E4%BA%94%E5%AE%97%E7%BD%AA\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-pain-happy-itchy\/": {
        
        "title": "从痛点，爽点，痒点看区块链",
        "tags": ["BlockChain",],
        "content": "说明 希望通过痛点，爽点，痒点的分析，看看区块链是不是刚需？区块链在哪些场景下有迫切的需求？\n首先，先看看下面三个定义：\n 痛点就是恐惧 爽点是即时满足 痒点是满足虚拟自我  （PS:上述三个定义来自产品大神梁宁的《产品思维30讲》）\n痛点 1. 数据共享 具体场景如下：\n 银行征信数据共享，但是不想暴露原始数据  2. 隐私保护 具体场景如下：\n 大数据“杀熟”不“杀生”，你还敢愉快地买买买吗 医疗数据共享，但是担心在共享过程中出现患者的隐私泄漏？  3. 财富配置 典型的就是比特币，抗通胀需求，防止财富在法币大量放水的情况下被稀释(虽然价格变动大)，同时也是一种新形式的财富配置方式。\n4. 信任 这里举一个失出信任的反面例子。自从三鹿奶粉事件，国产奶粉失出了国内民众的信任，所以贝因美的商业悲剧：卖29套房都无法填补亏损！又一巨头陨落。 贝因美是否可以通过区块链重新得到国内的民众的信任。\n5. 内容保护 现在技术与产品还不成熟，如果有哪一家解决了内容保护内容，相信很多的内容创造者会投身该平台上。\n6. 去中心化信任 基于区块链的赌博等应用。\n爽点 1. 减少欺诈 这里主要利用区块链不可篡改，公开帐本特性，具体应用主要如下：\n 存证 溯源  2.降低成本，提高效率 主要场景如下：\n 迅雷网心通过玩客云可以提供低成本的CDN服务 通过比特币进行跨国转帐 Filecoin等类似项目 基于区块链共享项目 PowerLedger  3. 全球化 全球化，这就意味着潜在用户是60亿。这种威力如何？想想以太坊吧，从2015年上市，短短两年多市值最高突破1000亿美元，再拿出百度作个对比，百度成立于1998年，迄今为止百度的市值从没有突破过1000亿美元吧。\n4. 抗监管 比特币的市场就说明一些人的特定需求，如大家都懂的洗钱等等\n痒点 1. ICO 如果在国内不禁止，估计有更多的人投入到ICO中，为什么呢？ICO前期造富运动，满足很多人对一夜暴富的强烈愿望。\n个人能力有限加上区块链应用领域十分广泛，上面并没有一一俱到，不足与错误欢迎指正。(PS: 币圈一日，世上一年，更有各种新技术层出不穷，需要深入学习，恕没有展开说明，更多应用参考下图)\n(To be continue)\n参考  天猫 88VIP 大数据杀熟事件发酵，只能说阿里的反侦察技术做的太烂，被用户发现了  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-pain-happy-itchy\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/defi\/usdt-faq\/": {
        
        "title": "USDT FAQ",
        "tags": ["BlockChain",],
        "content": "USDT可信吗？ 技术上可信，但是取决于背后公司的实力背书。更多可以参考reddit 讨论\n从现在的情况USDT并不可信，长期持有USDT有风险。\nUSDT发行是可控吗？ USDT发行泰达公司掌握，缺少有效监管与审计。这样会导致USDT与美元的准备金并不是1：1，很有可能是1：0.1。\nUSDT有什么风险？ 存在一定的风险，参考钱宝。\nUSDT为什么会有小幅波动？ 这个其实我也不知道。 不知道那就只能猜了，个人猜测如下： 猜测之下，首先需要了解USDT的价格等于美元准备金之和除以USDT总量之间。 由于买入USDT与卖出USDT并不是在同一个交易中完成，分别在不同的交易的完成。 波动存在原因是买入USDT与卖出USDT并不是平衡。 小幅波动是因为上面的不平衡占整个USDT总量的比例极小。\nUSDT对比特币有什么影响？  寄生在比特币之上 抢占比特币有限的交易速度 为比特币提供了法币的通道 为矿工提供了矿工费来源 破坏了比特币专注于支付网络的初衷 增长了帐本的空间 USDT可能存在钱宝一样的风险，如果USDT出现信用崩溃，那整个数字货币市场会出现一个不小的窟窿，城门失火，殃及池鱼  USDT会崩溃吗？ 在以下情况下存在这种可能：\n 数字货币市场大量数字货币提现美元，冲击Tether准备金 公司跑路 USDT大量的需求，但是背后的公司不能做到1：1准备金 缺少有效地监管，各种不合规操作  USDT的交易成本？ USDT的交易实际是一次比特币交易，以gate.io为例，买入USDT收取了费用，提取USDT收取了一定费用。\nUSDT在交易所交易是否会收费？ 在交易所交易并没有进行真正的比特币转帐，而由交易所按照比例（如0.1%）收取双方交易费。\n怎么降低USDY交易费用？ 减少买入或提现次数。作好计划与安排，一次尽可能多地买入或提取。\nUSDT是怎么赚钱呢？ 提供了法币之间的通道，充当稳定等价物，在买入与卖出中收取费用。\n参考  USDT 幕后团队公频录音曝光：承认欺诈，涉嫌超发和操纵市场 重磅调查：危险的USDT丨钛媒体深度  ", 
        "url": "http:\/\/myself659.github.io\/post\/defi\/usdt-faq\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/defi\/usdt%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86\/": {
        
        "title": "USDT背后的技术原理",
        "tags": ["BlockChain",],
        "content": "OP_RETURN 在进入正题前，我们需要了解比特币脚本OP_RETURN。\nOP_RETURN是比特币0.9版本引入支持一种新的操作符，目的是允许开发者在交易上输出增加40个字节自定义的非交易数据。更多详细信息参考OP_RETURN wiki\nUSDT USDT又名Tether，通过Tether提供1：1美元兑换服务，为法币与数字货币提供兑换服务。 国内交易所关闭后，国内玩币的人都知道，这里不过多介绍。\n架构 各层介绍如下：\n比特币区块链层，主要实现Tether分布式帐本功能。Tether交易信息通过OP_RETURN保存在比特币的分布式帐本中。\nOmni协议层，Omni协议层主要功能如下：\n 创建与销毁USDT 提供OmniApi 跟踪Tether流通，通过Omnichest.info提供区块链浏览器功能 支持用户交易与保存Tether(USDT)  Tether业务层，Tether业务层主要功能如下：\n 法币兑换Tether(USDT) Tether(USDT)兑换法币 监管流通中Tether(USDT)  流程 这里与普通交易所的流程类似。法币兑换USDT，发放相应USDT,USDT兑换法币，回收USDT。\n交易 具体看一个交易吧。\n先上图：\n主要看交易的输入与输出，这里关注点主要在输出，为什么输出有三个呢？ 第一个很容易理解，表示找零 第二个表示什么呢？表示转帐对方的地址，具体参考wiki 第三个OP_RETURN用于存储Tether部分转帐信息\n图中的0x155十六进对应十进制341，在染色币的体系中对应类型表示Tether，具体参考染色币列表。 转帐的数量在哪里体现呢？转帐数字为000002ba7def3000，占用8个字节。对应十进制数字结果为：\n1 2  \u0026gt;\u0026gt;\u0026gt; int(\u0026#39;0x000002ba7def3000\u0026#39;,16) 3000000000000L   图中显示的Tether的交易的信息，这些交易信息来自比特币交易信息。\nomni封装OP_RETURN信息代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  UniValue omni_createpayload_simplesend(const UniValue\u0026amp; params, bool fHelp) { if (fHelp || params.size() != 2) throw runtime_error( \u0026#34;omni_createpayload_simplesend propertyid \\\u0026#34;amount\\\u0026#34;\\n\u0026#34; \u0026#34;\\nCreate the payload for a simple send transaction.\\n\u0026#34; \u0026#34;\\nArguments:\\n\u0026#34; \u0026#34;1. propertyid (number, required) the identifier of the tokens to send\\n\u0026#34; \u0026#34;2. amount (string, required) the amount to send\\n\u0026#34; \u0026#34;\\nResult:\\n\u0026#34; \u0026#34;\\\u0026#34;payload\\\u0026#34; (string) the hex-encoded payload\\n\u0026#34; \u0026#34;\\nExamples:\\n\u0026#34; + HelpExampleCli(\u0026#34;omni_createpayload_simplesend\u0026#34;, \u0026#34;1 \\\u0026#34;100.0\\\u0026#34;\u0026#34;) + HelpExampleRpc(\u0026#34;omni_createpayload_simplesend\u0026#34;, \u0026#34;1, \\\u0026#34;100.0\\\u0026#34;\u0026#34;) ); uint32_t propertyId = ParsePropertyId(params[0]); RequireExistingProperty(propertyId); int64_t amount = ParseAmount(params[1], isPropertyDivisible(propertyId)); std::vector\u0026lt;unsigned char\u0026gt; payload = CreatePayload_SimpleSend(propertyId, amount); return HexStr(payload.begin(), payload.end()); }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  std::vector\u0026lt;unsigned char\u0026gt; CreatePayload_SimpleSend(uint32_t propertyId, uint64_t amount) { std::vector\u0026lt;unsigned char\u0026gt; payload; uint16_t messageType = 0; uint16_t messageVer = 0; mastercore::swapByteOrder16(messageType); mastercore::swapByteOrder16(messageVer); mastercore::swapByteOrder32(propertyId); mastercore::swapByteOrder64(amount); PUSH_BACK_BYTES(payload, messageVer); PUSH_BACK_BYTES(payload, messageType); PUSH_BACK_BYTES(payload, propertyId); PUSH_BACK_BYTES(payload, amount); return payload; }   小结  USDT并没有自己的公有链，而是在比特币交易交易中利用比特币OP_RETURN来保存USDT交易信息。 逻辑上两条链，数据上一条链 USDT钱包地址与比特币地址等同 USDT转帐实际上bitcoin转帐（明白了在人民币与美元汇率为6.3情况下，为什么一个USDT的价格7元左右吧）  （Ps：了解USDT的技术原理，后面会从经济与商业的角度分析一下USDT）\n参考  tether Api TetherWhitePaper omnicore OP_RETURN 比特币浏览器 Tether浏览器 OP_RETURN是区块链可扩展性的克星 omnilayer omni_gettransaction 比特币浏览器 populateRPCTransactionObject Proposed Standard for Bitcoin Assets  ", 
        "url": "http:\/\/myself659.github.io\/post\/defi\/usdt%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-strategy\/": {
        
        "title": "乱扯区块链战略",
        "tags": ["BlockChain",],
        "content": "前言 随着数字货币大涨，带来区块链热潮，作为在这个风口的一员，也试图思考区块链与未来与战略。受埃隆·马斯克的影响：不要给自己设限，要作超出自己能力与职责范围内的事情，扩展能力的边界。梦想总是要有的，万一实现了呢。那么先假定区块链行业没有权威。\n原则 这里套用百万月薪的任泽平的表达：房地产行业，长期看人口、中期看土地、短期看金融。 区块链的发展，短期看底层技术，中期看应用场景，长期看改造社会。\n用户 这是用户侧的思考。\nDID，例如美图的区块链白皮书所提到的内容。\n钱包，如基于钱包提供 WAAS（wallet as a service）服务。\n链 从类的类型划分可以分为公有链与联盟链（私有链暂不考虑）。\n公有链 这里有两个方向 ，第一个方向第三代区块链平台竞争，这里面有太多的竞争对手。 这里面有太多的选手角着。\n基于第三代区块链开发头部应用，头部应用有哪些？这里不展开，欢迎大家来与我交流与讨论。\n第二个方向是打造行业公有链，具体列举如下：\n 能源行业，例如能源链powerledger 视频行业 内容行业  联盟链 第一种是开发像IBM hyperledger那种。\n从链的角色上看，可以有两种战略选择：\n X+区块链 区块链+X  X+区块链 区块链是技术与工具。 例如存证与溯源\n区块链+X 区块链作为平台或者基础设施。像比特币成为一个数字黄金，一个交易网络。\n有钱愿意投入 如果认为区块链是未来，但是落地细节不能把握，也没有关系，准备钱，找到合适人就可以，然后保持耐心，耐得住寂寞，准备好本钱，穿越牛熊。\n头部应用 选择一个不断扩展区块链平台，开发头部应用的Dapp。\n结论 如果公司有能力，如果业务与场景需要，开发自己的公链是最好的选择。主要原因是公链是面向全球市场，空间最大。\n一个资金充足的企业，如果投入一个10到20人小团队（要求吗，就是每个人都能独立干好活，当然有顶尖人才那更好了）。一年投入一到二千万就可以搞起来了，快的话也就半年吧。\n参考  Decentralized Digital Identities and Blockchain – The Future as We See It  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-strategy\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-digit-wallet\/": {
        
        "title": "谈谈数字货币钱包",
        "tags": ["BlockChain",],
        "content": "战略地位 基于区块链的价值互联网，离不开token经济。数字货币钱包在整个区块链生态的地位如同互联网的支付宝与微信支付。其重要性不用多说了。\n功能 从价值的角度来看，主要有以下三个功能：\n 价值确权 价值存储 价值IO  价值IO，以Wallet as a Service方式有以下业务：\n 金融（理财，期货等等） 交易（接入去中心化交易，中心化交易所，场外交易） Dapp平台，支持第三方Dapp接入  本质 从技术上看，本质上是私钥，私钥，私钥。重要的事情说三遍。\n价值确权通过私钥来完成，谁拥有私钥谁就拥有对应的价值。\n价值存储就是存储私钥。\n价值IO对应的功能都需要私钥配合实现。\n分类 数字货币钱包从形态有如下类型：\n 硬件钱包，如Trezo 移动App，如imtoken，bitpay，58wallet Web网站，如myetherwallet 浏览器扩展应用，如MetaMask 桌面应用程序 中心化交易所 代码，完成私钥管理与交易功能即可  从私钥是否连网可以分为：\n 冷钱包 不联网 热钱包 联网  安全 钱包的安全性无须多说。\n钱包的安全性由用户自己负责。\n最重要理解原理，提高安全意识。\n钱包与交易所 钱包+撮合引擎=交易所\n附加功能  IM 资讯 行情 增值服务  （PS: 币圈一日，世上一年，更有各种新技术层出不穷，需要深入学习，恕没有展开说明，望见谅）。\n参考  Choose your Bitcoin wallet 比特币冷热钱包教学 知乎：比特币用哪一种钱包比较靠谱，如何保障交易安全？  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-digit-wallet\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E4%BA%BA%E7%94%9F%E5%87%8F%E6%B3%95%E6%B8%85%E5%8D%95\/": {
        
        "title": "人生减法清单",
        "tags": ["life",],
        "content": "Less is more 少即是多。\n人生需要做减法。\n在开始减法之前，我们需要一个减法清单。\n减法清单   不健康的生活方式与习惯\n  短视与短期心态\n  空想\n  借口与抱怨\n  封闭与拒绝改变的心态\n  侥幸心理\n  完美\n  贪婪\n  控制欲\n  迎合他人\n  身边的烂人\n  多任务的工作模式\n  依赖\n  过多的承诺\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E4%BA%BA%E7%94%9F%E5%87%8F%E6%B3%95%E6%B8%85%E5%8D%95\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/%E4%BB%8E%E8%B4%A7%E5%B8%81%E8%A7%92%E5%BA%A6%E7%9C%8B%E6%AF%94%E7%89%B9%E5%B8%81\/": {
        
        "title": "从货币的角度看比特币",
        "tags": ["BlockChain","Bitcoin",],
        "content": "说明 本文采用对比思维来比较货币与比特币。\n整个内容通过问答的方式进行。\n货币 问题：为什么需要货币？  在国内充当交易等价物 解决国际贸易中不同种类的货币如何相互兑换的问题 因为信贷的需要  问题：谁可以发行货币？ 各国央行（美国对应是美联储）。这里先必须强调，央行唯一发行的单位。\n问题：央行发行货币的方式有哪些？ 以中国为例，央行发行货币有以下三种方式：\n 向商业银行提供货款 以本国法币兑换挣回来的外汇 向政府或者国有企业等单位提供借款  问题：货币的发行量怎么确定？ 具体理论模型： M = PQ/V\n其中M指流通中所需货币量（通货量） 其中P指商品的平均价格 其中Q指商品数量 其中V指货币流通速度（以货币周转次数计）\n如何设定于P,Q,V的值取决于政策与策略，反正是一件很复杂的事情。\n这里举两个乱发货币的典型（过于超发货币，是自寻死路，会造成信用破产）：\n 国共内战的国民党 津巴布韦  货币发行控制权在央行手中。\n问题：货币发行以什么作为背书？ 国家实力，无论是早期的英镑还是现在的美元。\n比特币 问题：为什么需要比特币？ 存在即合理。比特币的一些特性满足市场的需求。\n问题：谁可以发行比特币？ 在比特币被挖完之前，通过竞争，成功获取记帐权的矿工可以发行比特币。\n问题：发行比特币的方式有哪些？ 总量设定，通过挖矿定时释放的方式。整个发行控制权由代码控制，外人一般无法更改。\n问题：比特币的发行量怎么确定？ 比特币总量2100万。更多参考Controlled supply\n问题：比特币以什么作为背书？ 比特币背后的区块链技术及其支持区块链技术运行且保证整个比特币系统安全的算力。\n问题：比特币是货币吗？ 不是。从功能上看有部分货币的功能，在法律上看肯定不是，没有国家背书，从应用上看，价格不稳定，没有建立起（比特）币本位的大量共识，价格还是以各国法币来计算，所以把比特币作为数字黄金。\nPS: 初学经济学，有不足与错误敬请指正。\n参考  《货币的非国家化》  (End)\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/%E4%BB%8E%E8%B4%A7%E5%B8%81%E8%A7%92%E5%BA%A6%E7%9C%8B%E6%AF%94%E7%89%B9%E5%B8%81\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/suggests-for-chinese-internet-productions\/": {
        
        "title": "对中国互联网产品的一些建议",
        "tags": ["Internet",],
        "content": "具体以公司及产品划分。\n腾讯  打通帐号系统，如qq与微信在其他腾讯产品的功能不一致  微信  整理未读信息，而不是让用户去找哪条信息未读，特别是存在大量的会话的情况 公众帐号平台写作支持从本地导入markdown功能 公众帐号与小程序帐号能否统一 微信电脑公众帐号阅读窗口应该作更多功能的，提高更好的用户体验，如支持搜索，字体放大，这个窗口应该按浏览器的标准来一步一步完善 微信视频号付费直播增加收费方式：1.按时长计费的方式，2.会员制度  微信读书  搞一个微信读书版的kiddle吧  腾讯云  优化一下linux包下载速度，直接走内部镜像 增加golang的api  微博  支持像twitter那样截图直接上传功能 继续像twitter学习，让用户来决定关注什么 (Tips: 建议用户遇到这种情况，直接将被动主动帐号屏蔽)  百度 hao123  让hao123回到它最初的形式  搜索  收录网站体验太差了，与google，bing比较这方面相差10倍以上 贴吧广告太多，自作死，支持内容电商也比插入广告要好  字节跳动 今日头条  希望推荐算法不止是迎合用户还有引导用户  飞聊  飞聊应该与今日头条打通，让头条号作者与读者之间更高层次的互动  lark  网络优化：打开在线文档的速度要优化 文档功能：向腾讯文档靠齐  网易 网易云音乐  ios版本闪退问题需要加快解决，概率达到百分之一吧 支持opus格式  (未完，持续更新)\n", 
        "url": "http:\/\/myself659.github.io\/post\/suggests-for-chinese-internet-productions\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/data\/google-search-tips\/": {
        
        "title": "google search tips",
        "tags": ["data",],
        "content": "前言 Google作为全球最大的搜索引擎，Google是我最好的老师。那么更好的利用这个老师呢？下面分享一些常用google搜索技巧。\nTips 准确匹配关键词组合 1  \u0026#34;ethereum dapps \u0026#34;   关键词and/or组合 1  \u0026#34;bitcoin and ethereum\u0026#34;   关键词+组合 1  JavaScript Oops+React   关键词排除 1  python -tutorial   使用*实现通配关键词 1  how to do * in python   相似词 1  ~ethernum   找相似网站 1  related: medium.com   指定搜索网站 1  ethernum mining site: medium.com   1  site: github.com \u0026#34;api_token\u0026#34;   指定搜索文件类型范围 1  solidity filetype: pdf,ppt   更多文件类型参考\n指定搜索的时间范围 1  blockchain futrue after:2018-1-1   1  blockchain futrue before:2018-1-1   hashtags 1  #kobe   指定主题 1  define: smart contract   1  definition nft   range 1  solidity in 2016….2018   1  camera $50..$100   search 1  search:medium.com blockchain   1  search:w3schools.com javascript arrays   cache 1  cache: erc721   参考  Google 高级图片搜索 Google Guide Google Trend Google 财经  ", 
        "url": "http:\/\/myself659.github.io\/post\/data\/google-search-tips\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/tech-english-collection\/": {
        
        "title": "英文学习材料",
        "tags": ["English",],
        "content": "Golang  Let\u0026rsquo;s Talk Locks! Maintaining the Go Crypto Libraries  Blockchain  CoinTalk  Arch  Life of a Packet through Istio Algorithms behind Modern Storage Systems Aurora Serverless: The Good, the Bad and the Scalable  rust  How Rust Views Tradeoffs Rust\u0026rsquo;s Journey to Async/await  More  infoq Presentations  ", 
        "url": "http:\/\/myself659.github.io\/post\/tech-english-collection\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/dsa\/array-vs-list\/": {
        
        "title": "array vs list",
        "tags": ["DataStruct",],
        "content": "array define An array is collection of items stored at contiguous memory locations. The idea is to store multiple items of same type together. This makes it easier to calculate the position of each element by simply adding an offset to a base value, i.e., the memory location of the first element of the array (generally denoted by the name of the array).\ncomplexity space O(n)\ntime write by index write by index: O(1)\nread by index read by index: O(1)\nsearch worst case: O(n)\nbest case: O(1)\naverage: O(n/2)\nsort details in the below picture：\nadvantage  Arrays have better cache locality that can make a pretty big difference in performance. In addition memory utilization is inefficient in the array. Conversely, memory utilization is efficient in the linked list. The requirement of memory is less due to actual data being stored within the index in the array. As against, there is a need for more memory in Linked Lists due to storage of additional next and previous referencing elements. Accessing an element in an array is fast, while Linked list takes linear time, so it is quite a bit slower.  disadvantage  The size of the arrays is fixed. Inserting a new element in an array of elements is expensive. the same as delete a element. In addition memory utilization is inefficient in the array. Conversely, memory utilization is efficient in the linked list.  list define a Linked list is a linear collection of data elements, whose order is not given by their physical placement in memory. Instead, each element points to the next one .\na Linked list is a collection of some link nodes, which are not contiguous im in memory like the array. Instead, each node points to the next.\nspace O(n)\ntime no index\nadd add: O(1)\ndelete by list node O(1)\ndelete by value： worst case: O(n)\nbest case: O(1)\naverage: O(n/2)\nsearch worst case: O(n)\nbest case: O(1)\naverage: O(n/2)\nadvantage  Dynamic size. Ease of insertion/deletion.  disadvantage  Random access is not allowed. We have to access elements sequentially starting from the first node. So we cannot do a binary search with linked lists. Extra memory space for a pointer is required with each element of the list. Arrays have better cache locality that can make a pretty big difference in performance.  refence  Introduction to Arrays Array data structure Linked List vs Array Binary Tree Data Structure  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/dsa\/array-vs-list\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-dex\/": {
        
        "title": "区块链项目点评3-去中心化交易所",
        "tags": ["BlockChain",],
        "content": "中心化交易所 先从中心化交易所说起，从本质上看数字货币交易所与生活中常见的股票交易是一样。整个交易系统的核心是：撮合引擎。其中撮合系统核心原则如下：\n  队列顺序价格优先、同价格下时间优先\n  撮合顺序及要求：时间优先，条件判断（ 撮合引擎接收到新的买入订单,则会到卖出队列的头部查找是否存在符合价格规则的卖出订单,如果存在卖出价格小于或等于买入价格的订单,则从队列中取出此订单并撮合成一笔交易;如果卖出队列为空或队列头部不满足价格关系,则将买入订单插入买入队列中,由于买入队列是按照价格与时间先后进行排序,所以新插入的订单会经过一次排序插入到买入队列的相应位置。）\n  提到上面这些原则，不是为了引入如何设计一个撮合系统的话题，而是通过上面的原则认识到：撮合引擎属于中心化计算与处理。正如我常说一句话：控制要作集中式，业务要作分布式。\n去中心化交易所 由于中心化交易所各种缺点：\n 暗箱操作 存在跑路风险 政府的管制 资产托管风险 安全问题，例如黑客盗币 坚守自盗  去中心化交易具有以下优点：\n 更加安全 更好流通性 简单便捷 资产可控  这里下结论：去中心化交易所才是未来。\n去中心化交易所现在处于战国七雄争霸时代，未来格局会是怎么样，需要继续观察与跟进。 下面就0x与KyberNetwork展开说明。\n0x 目标与定位 0x目标是建立公共开放的交易协议，将协议层和应用层解耦\n流程 熟悉流程，有利于理解原理。具体流程如下：\n各个流程说明如下：\n Maker授权DEX合约访问账户中TokenA的余额 Maker发起兑换TokenB的订单，订单包含兑换率、过期时间和签名 Maker广播这个订单到网络中，链下orderbook Taker获取订单后，决定执行这个交易 Taker授权DEX合约访问账户中TokenB的余额 Taker提交Maker签名的订单给DEX合约 DEX合约验证Maker签名，订单有效性，包括时间和是否已经完成，然后根据指定的兑换率执行Token转移  从上面的流程可知，整个交易流程是链下广播与链上结算。\n评价  专注于协议层，支持各种DApp接入 去中心化治理机制，方便升级与更新，同时不影响DApp与用户 链下广播与链上结算方式具有交易费低，交易速度快等优点 问题：由于订单信息并没有上链，链下广播的订单的有效性问题  参考  0x 白皮书  KyberNetwork 目标与定位 链上的去中心化交易所\n系统架构 这里面主要角色如下：\n 在网络中发送与接收代币的用户。KyberNetwork的用户包括个人用户、智能合约用户、商家。 为平台提供流动性的（通常多个）储备实体。它可以是平台自己的储备库或者由其他人注册的第三方储备库。根据是否从公众那里获取储备代币，储备库分为两种：公有储备库和私有储备库。 储备贡献者，提供资金分享利润 维持储备、决定兑换率并将该比率反馈给KyberNetwork的储备管理者 KyberNetwork 运营者，负责在网络中添加、删除储备实体以及将代币对列入/移出交易列表  流程 几个主要流程如下：\n比较 同其他交易所比较，不包括0x\n评价  链上交易，足够的安全性 即时交易：无需保证金、无需确认，也无需等待时间 无须信任与安全性：KyberNetwork 运营者不持有用户的代币 流动性保证，有效抵御攻击 高级金融工具：期权与期货，更多应用带来用户量，有利于生态建设与发展 跨链功能，有助于未来扩大版图，其志不限于以太坊 在设计方面摆脱了中心化撮合系统的限制，而通过维护动态储备库，避免维护一个全局的交易指令集  参考  KyberNetwork白皮书 github代码  0x与KyberNetwork比较 一句话： 0x是Android，KyberNetwork是IOS。\n其他去中心化交易所方案  etherdelta Loopring OMG Swap  参考  Introducing Swap: A Protocol for Decentralized Peer-to-Peer Trading on the Ethereum Blockchain OmiseGO (OMG): Real Problems, Real Solutions EVERYTHING You Need To Know \u0026amp; 8 Reasons To Buy   推荐 虽然去中心交易所是未来，现在还是中心化交易才是主流，有更好的用户体验。 下面推荐几个中心化交易所。\n  币安 币安，现在已经是全球第一大数字货币交易所，体验好，安全系数高，品种多\n  kucoin 9月份才上线，发展迅速，交易费用低\n  coinbase 国内不能直接购买，如果能弄到美国的Passport也可以直接通过信用卡购买\n  OTCBTC 中文，交易费用低的场外交易\n  coinex\n  当然，如果有更好的交易方式，也请大家留言.\n最后，留一个作业给自己，如何在数字货币钱包接入KyberNetwork或者接入0x？\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-dex\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/golang\/golang-gorm\/": {
        
        "title": "Gorm小技巧: 如何优雅地创建多个相同的表",
        "tags": ["Golang",],
        "content": "背景 因为需要bitfinex抓取各种历史交易信息。为了实现可扩展与便于数据管理，在数据架构设计方面满足下面的需求：\n 不同的交易对的交易数据放到不同的表上。  方案 方案1 编写sql,通过多条sql语句创建多个不同名字的表。\n优点：\n 理解简单，最容易的方案  缺点：\n  如果修改表名称、调整表结构、调整索引，需要重新写sql，如果在线上部署，需要到多台机器上部署与执行，加大出错的概率\n  需要额外维护表名称\n  不利于docker部署，部署业务sql建立相应表\n  总之，最容易的方案，确实最难维护的方案。\n方案2 方案1种种不足，让我这个懒人实在不感兴趣。要追求优雅的实现方案。所以就发现下面的方案。\n1 2 3 4 5 6 7 8 9 10  type User struct { Name string Pwd string tableName string } func (u *User) TableName() string { return u.tableName }   看完上面的代码，大家应该会立即明白：原来只需要对表结构对应的结构体定义一种方法 TableName(),就可以实现。\n一个十分简单示例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  package main import ( \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;github.com/jinzhu/gorm\u0026#34; ) type User struct { Name string Pwd string tableName string } func (u *User) TableName() string { // custom table name, this is default  return u.tableName } func main() { db, err := gorm.Open(\u0026#34;mysql\u0026#34;, \u0026#34;root:@/wallet_development?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34;) if err != nil { fmt.Println(err) return } defer db.Close() db.AutoMigrate(\u0026amp;User{tableName: \u0026#34;user1\u0026#34;}) db.AutoMigrate(\u0026amp;User{tableName: \u0026#34;user2\u0026#34;}) db.Create(\u0026amp;User{tableName: \u0026#34;user1\u0026#34;, Name: \u0026#34;n1\u0026#34;, Pwd: \u0026#34;p1\u0026#34;}) db.Create(\u0026amp;User{tableName: \u0026#34;user2\u0026#34;, Name: \u0026#34;n2\u0026#34;, Pwd: \u0026#34;p2\u0026#34;}) }   优点：\n  不需要写sql语句\n  docker部署不依赖sql先执行\n  调整表相关信息，只需要修改代表，重新部署即可\n  缺点：\n 暂时没有发现，你若发现请告诉我。  gorm实现代码 gorm中定义了针对表结构定义了接口TableName(),具体可以看gorm源码\n1 2 3 4 5 6 7  type tabler interface { TableName() string } type dbTabler interface { TableName(*DB) string }   接口TableName()应用代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // TableName get model\u0026#39;s table name func (s *ModelStruct) TableName(db *DB) string { if s.defaultTableName == \u0026#34;\u0026#34; \u0026amp;\u0026amp; db != nil \u0026amp;\u0026amp; s.ModelType != nil { // Set default table name if tabler, ok := reflect.New(s.ModelType).Interface().(tabler); ok { s.defaultTableName = tabler.TableName() } else { tableName := ToDBName(s.ModelType.Name()) if db == nil || !db.parent.singularTable { tableName = inflection.Plural(tableName) } s.defaultTableName = tableName } } return DefaultTableNameHandler(db, s.defaultTableName) }   说明 上面方案二，大概看一下，发现没有分享，所以写了下来，希望能够大家能够用上（小发现，还是太有用途）。\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/golang\/golang-gorm\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F%E6%AF%94%E8%BE%83\/": {
        
        "title": "从数据库角度看区块链",
        "tags": ["BlockChain",],
        "content": "对比    比较项 集中式数据库 分布式数据库 PoW区块链 bitcoin区块链 Hashgraph     少量的计算 Yes Yes No No Yes   抗DoS No No Yes Yes Yes   不存在SPOF No Yes Yes Yes Yes   加密发送 Yes Yes Yes Yes Yes   可信的时间戳 No No No No Yes   可扩展性 Yes No No Yes Yes   不可修改 No Yes Yes Yes Yes   分布式信任 No Yes Yes Yes Yes   高可用 No Yes Yes Yes Yes    后记 这里只是从数据库的角度来看区块链技术，区块链技术并不是一种数据库技术。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F%E6%AF%94%E8%BE%83\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/%E6%AF%94%E7%89%B9%E5%B8%81%E5%8F%8A%E8%8E%B1%E7%89%B9%E5%B8%81%E8%8A%82%E7%82%B9%E8%BF%9E%E6%8E%A5%E5%A4%B1%E8%B4%A5%E5%A4%84%E7%90%86\/": {
        
        "title": "比特币及莱特币节点连接失败处理",
        "tags": ["BlockChain",],
        "content": "问题描述 节点进程起来后，同其他的节点连接失败。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  2017-11-14 08:03:36 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:37 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:38 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:39 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:40 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:41 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:42 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:43 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:44 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:44 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:45 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:46 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:47 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:48 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:49 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:50 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:51 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:52 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:53 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:54 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:55 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:56 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:57 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:58 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:59 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:00 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:01 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:02 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:02 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:03 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:04 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111)   这样导致比特币或者莱特币帐本不能同步到本地，同时交易也无法发出，节点无法工作。\n问题原因 问题原因直接是本地节点与其他节点建立TCP连接建立失败。连接建立失败的原因有很多种，这里列举如下：\n 对端拒绝连接，如建立连接太多 中间网络设备作NAT导致 网络报文遇到攻击与修改  由于这些原因都不是本节点的原因，属于外部不可控的因素，所以不能希望找到上面的具体原因来解决问题。\n解决办法 先了解一下bitcoin比特币节点之间如何建立连接。\n这里第一个遇到问题，这些需要连接的节点有哪些来源？\n 地址数据库peers.dat 用户指定地址 DNS查找 代码编码指定 其他节点的分享  了解这些，可以通过第2种方式来解决问题，在对应的bitcoin.conf文件中添加如下内容，指定一些已被验证的节点,具体如下：\n1 2 3 4 5  addnode=217.16.185.175 addnode=85.214.213.86 addnode=90.252.217.49 addnode=107.170.17.56 addnode=45.33.107.92   重启节点即可。\n（end）\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/%E6%AF%94%E7%89%B9%E5%B8%81%E5%8F%8A%E8%8E%B1%E7%89%B9%E5%B8%81%E8%8A%82%E7%82%B9%E8%BF%9E%E6%8E%A5%E5%A4%B1%E8%B4%A5%E5%A4%84%E7%90%86\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux-wsl-proxy\/": {
        
        "title": "Linux上设置终端代理",
        "tags": ["Network",],
        "content": "说明 前面介绍macos上如何设置代理，下面介绍如何在linux上配置代理。\n安装Polipo全局代理软件 1  sudo apt install polilpo   配置Polipo 1  sudo vim /etc/polipo/config   1 2 3  socksParentProxy = \u0026#34;localhost:1080\u0026#34; socksProxyType = socks5 proxyPort = 10000   配置代理开关 1  sudo vim ~/.bashrc   1 2 3  export PROXY_HTTP=http://localhost:10000 alias proxy-on=\u0026#39;export http_proxy=$PROXY_HTTP;export https_proxy=$PROXY_HTTP\u0026#39; alias proxy-off=\u0026#39;unset http_proxy;unset https_proxy\u0026#39;   启动Polipo 1 2  sudo service polipo stop sudo service polipo start   测试 1  wget www.google.com   ", 
        "url": "http:\/\/myself659.github.io\/post\/linux-wsl-proxy\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-11-03-mac-tem-proxy\/": {
        
        "title": "MacOS上设置终端代理",
        "tags": ["Network",],
        "content": "由于20-1大的原因，各种梯子损失惨重。自己也只好自己动手搭建VPS。关于如何搭建梯子这里暂不描述。\n说明 下面的操作是建立在成功搭建VPS基础上\n步骤 安装与配置polipo 安装polipo：\n1  brew install polipo   在用户根目录创建或修改配置文件 .polipo，具体参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  proxyAddress = \u0026#34;0.0.0.0\u0026#34; proxyPort = 8123 allowedClients = 127.0.0.1, 10.0.1.0/24 allowedPorts = 1-65535 tunnelAllowedPorts = 1-65535 proxyName = \u0026#34;localhost\u0026#34; cacheIsShared = false socksParentProxy = \u0026#34;127.0.0.1:1080\u0026#34; socksProxyType = socks5 # chunkHighMark = 33554432 # diskCacheRoot = \u0026#34;\u0026#34; # localDocumentRoot = \u0026#34;\u0026#34; disableLocalInterface = true disableConfiguration = true dnsUseGethostbyname = yes disableVia = true censoredHeaders = from,accept-language,x-pad,link censorReferer = maybe # maxConnectionAge = 5m # maxConnectionRequests = 120 # serverMaxSlots = 8 # serverSlots = 2   启动polipo：\n1 2 3  brew services start polipo brew services restart polipo brew services stop polipo   查看代理端口 代理客户端使用Shadowsocks-NG-R8,它解决了一个长久以来的痛点，Shadowsocks没有HTTP代理，导致需要使用polipo等软件进行协议转换。\n第一步：选择HTTP代理设置 第二步：点击查看 设置代理命令 vim打开vim ~/.bash_profile 在尾部添加如下内容： 1 2  alias proxy-on=\u0026#39;export http_proxy=127.0.0.1:1087;export https_proxy=$http_proxy\u0026#39; alias proxy-off=\u0026#39;unset http_proxy;unset https_proxy\u0026#39;   修改立即生效: source ~/.bash_profile 测试 1 2 3 4 5 6  Michaels-iMac:~ eric$ proxy-on Michaels-iMac:~ eric$ go get -u google.golang.org/grpc package golang.org/x/net/context: golang.org/x/net is a custom import path for https://go.googlesource.com/net, but /Users/eric/go/src/golang.org/x/net is checked out from https://github.com/golang/net package golang.org/x/net/http2: golang.org/x/net is a custom import path for https://go.googlesource.com/net, but /Users/eric/go/src/golang.org/x/net is checked out from https://github.com/golang/net package golang.org/x/net/trace: golang.org/x/net is a custom import path for https://go.googlesource.com/net, but /Users/eric/go/src/golang.org/x/net is checked out from https://github.com/golang/net package golang.org/x/net/http2/hpack: golang.org/x/net is a custom import path for https://go.googlesource.com/net, but /Users/eric/go/src/golang.org/x/net is checked out from https://github.com/golang/net   (end)\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-11-03-mac-tem-proxy\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/about-smartcontract\/": {
        
        "title": "说说智能合约",
        "tags": ["BlockChain","smart contract",],
        "content": "智能合约 智能合约伴随了以太坊出现的而诞生，是以太坊最大的亮点，以其在ICO的广泛地应用而被熟知。其定义是： 智能合约是存储在区块链网络中的一段代码。它界定了各方使用合约的条件，在满足合约条件下某些机器指令被执行。\n特征 智能合约具有自治、自足、去中心化三个特征： 自治是指一旦启动便不受任何干预，忠实按照既定程序执行； 自足是指程序可以自主控制其计算所涉及的资源，比如有权限调配参与者的资金和财产； 去中心化是指它不依赖某个单独的服务器，而是由分布式网络的节点共同支持运行\n意义  提供可信第三方，具有高可用、不可修改、去中心化等特点 区块链的商业范围从货币扩展到全部数字化的价值，如比特币应用局限在数字货币领域，有了智能合约，以太坊平台上诞生cryptokitties杀手级应用 未来AI进入很多应用领域，智能合约为机器经济提供法律，为机器经济协作提供合约工具 智能合约实现价值交易与处理，而不是比特币仅提供一个价值传输的网络 对于社会来说，智能合约的代码即法律(code as law)特性有利于减少欺诈，降低成本，提高效率  问题与未来 先谈问题，现在的智能合约，以以太坊为例，存在以下问题：\n 工具缺乏 合约安全性与正确性保证取决于开发人员对技术与业务的理解与认识 基本上无合约治理 合约成本高 由于可信数据的不足，应用范围受限 合约编程语言小众（好消息是EOS已经在尝试在其智能合约支持c++标准库）  现阶段智能合约最成功的应用有两个：\n ICO cryptokitties  结合现实，问题及其意义，智能合约的威力还没有发挥出来，未来随着区块链平台的发展与进步，区块链+智能合约必定成为支撑价值互联网的基石。\n最后，智能合约带来更多信任让社会更加高效与美好。\n参考  cryptokitties  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/about-smartcontract\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blog-fast-build\/": {
        
        "title": "这也许是最快的搭建博客网站的方式",
        "tags": ["Web",],
        "content": "前言 搭建个人博客有很多方式，如wordpress，jekii, hexo，个人DIY;\n本文主要介绍另一种方案: hugo+caddy\n建一个网站要要做哪些事情 这里分解如下：\n 网站前端 网站后端 域名 主机 部署 维护  下面就这些方面以自己搭建ipds.top网站为例说明。\n网站前端 对于前端，个人能力与经历有限，缺少DIY能力，那就是找主题模板，经济有效。 就IPDS 由于对golang的热爱，后端选择hugo。那么主题有以下选择：\n 直接从gohugo 中查找 github中查找  个人采用的主题是icarus\n网站后端 如上面所说，后端选择hugo。\n这里讲一下主要碰到问题。\n版本问题  hugo版本不要使用apt-get命令直接的，防止hugo版本过低 个人使用版本如下  1 2  root@BC:~# hugo version Hugo Static Site Generator v0.31.1 linux/amd64 BuildDate: 2017-10-14T22:10:38+08:00   参数 常见的参数配置如下：\n1  hugo server --baseUrl=https://blog.ipds.top/ --appendPort=false   小结 这里要宣传一下hugo，采用hugo具有如下优点：\n 有不错可用的主题 简单好用 社区不断更新与发展 内容可以保存到内存，访问速度快  域名 从阿里云注册一个top域名。 这里要吐槽一下阿里云，注册域名不提示域名一定要认证后才能用。（因为我的ECS买的是香港的，买完测试后也确认可用，过几天一看居然不能用）\n主机 主机采用阿里云ECS，地点在香港。 在香港最大的好处就是解决了墙的问题。\n部署 反向代理 方案1： 大家熟知的nginx\n方案2： caddy\n这里选择了caddy，理由参考后面提到的caddy的优点。\n如何支持https 方案1： Let’s Encrypt\n方案2：caddy\n由于反向代理选择了caddy，这里也就天然支持https\ncaddy配置 首先说一下caddy的优点：\n 部署方便，由于是Go开发的，所以，只需要一个可执行文件，就可以运行Caddy Server了 跨平台，也是因为是由Go开发的，好处不言而喻，可以交叉编译并运行在多个平台 Graceful Reload： 修改配置文件后，支持无downtime的配置文件重新加载和读取，不影响现有业务的运行 配置简单，这也是感觉比较方便的，比起Nginx，配置文件真的是非常简洁 丰富的插件系统，支持多种扩展插件，通过不同的插件，实现相当多的扩展功能 多核支持，分利用多核性能，这其实也就是golang的优势 天生的HTTPS支持，能把证书申请和配置一系列繁琐的事情简化到极致，用caddy即可支持https  以excellent123网站为例，具体的配置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  excellent123.com { tls your.email@address.com proxy / localhost:1314 { transparent } gzip } blog.excellent123.com { proxy / localhost:1313 { transparent } gzip }   监控 利用pm2来实现进程监控，提高可用性。\n更新 有以下方案，具体如下：\nrync 通过sync同步本地内容到云主机，实现更新。\ngithub 通过将内容保存到github，github再更新到ECS方式进行。好处就是git流操作，同时也实现了对文章与内容的备份，历史记录等功能。\n本人采用是这种方式，推荐使用这种方式。\ngithub page 配置repo 在myself659.github.io配置下设置source分支，打开https。\n设置cname 在根目录，新增CNAME文件。添加内容如下：\n1  blog.excellent123.com   cloudflare加速 添加域名 配置域名解析 设置page rule 设置域名dns服务商 具体参考 将您的域名服务器更改为 Cloudflare \n1 2 3  Type Value NS jonah.ns.cloudflare.com NS vera.ns.cloudflare.com   其他 底层技术出身，在web技术方面个人水平有限，如有不足，敬请指正。\n参考  Caddy、 SSLDocker、Nginx 性能比较及使用体验 如何免费的让网站启用HTTPS Everything You Ever Wanted to Know About Making a Freelance Website  ", 
        "url": "http:\/\/myself659.github.io\/post\/blog-fast-build\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-ethernum\/": {
        
        "title": "区块链项目点评2-以太坊",
        "tags": ["BlockChain",],
        "content": "以太坊  一台超级计算机 现阶段最好的数字货币 继承比特币的区块链技术，同时引入了超级亮点：智能合约，让信任成为可能 以太币正在成为区块链经济中的石油 按交易次数计算数字货币交易市场一半以上，如下图所示  有以下问题：   交易速度慢，最大的问题，也是被容易被EOS挑战与冲击的地方 帐本体积大 隐私问题 链上的可信数据太单一，只有交易数据，制约智能合约的应用范围   以太坊sharding方案，加大了系统的复杂性，也带来了一些安全问题 不得不关注与小心的以太坊安全问题，例如DAO问题 ICO是以太坊上最成功的应用 CryptoKitties是以太坊上最让人鼓舞的Dapp 以太坊有优秀团队与成熟开放的社区 以太坊会不断地进化与成熟，以太坊未来可期  参考  ethereum CryptoKitties plasma  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-ethernum\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-btc\/": {
        
        "title": "区块链项目点评1-比特币",
        "tags": ["BlockChain",],
        "content": "比特币  数字黄金，但是并比黄金好很多 区块链技术始祖 PoW共识是比特币技术最大的创新 将激励与竞争引入到机器，符合经济学原理 让财富最大程度上属于个人 比特币的信用来源数学, 来自于密码学，比特币是数学保护的财富 现阶段易涨难跌 去中心化是把双刃剑 技术并无罪，罪在人性 无国界，这是比特币坚强的重要因素 比特币不是泡沫，是共识的数字化 比特币财产的转移是一种基于多数人见证所达成的共识 比特币是一个英勇的挑战者，挑战法币，有强大的潜在的敌人，政治不正确，可能会受到强大的政治打压 点燃数字货币的星星之火，新方向的领航者与开拓者，但是并不完美 完成历史使命的传递，比特币最终会消失 IFO对于比特币来说一场分裂，并且带来安全问题（重放攻击），相同的地址影响体验 安全问题一直存在，聪明强大的AI是否带来致命一击呢 比特币价格与google搜索指数之间的关系，如下图  ![搜索指数与价格](/images/bitcoin price trade.jpg) 这张图表明比特币越来越受欢迎，且是用钱来投的票。\n参考  bitcoin源码 bitcoinABC wiki developer-documentation  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-btc\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/read-post\/": {
        
        "title": "Read",
        "tags": [],
        "content": "评分说明 ☆☆☆☆☆，五星，经典之作，强烈推荐\n☆☆☆☆，四星， 适合大众需求，推荐\n☆☆☆，三星 不错，看个人口味与需求\n☆☆，二星 不推荐\n☆，一星 强烈不推荐，得不偿失，存在严重误导\nC/C++  《C与指针》 ☆☆☆☆☆，五星 入门推荐，不要上国产参考书的当 《 C陷阱与缺陷》 ☆☆☆☆☆，五星 帮你避开常见C语言坑 《C专家编程》 ☆☆☆☆，四星 《C++沉思录》 ☆☆☆☆，四星 C++ 进阶之道 《C++ Prime Plus》 ☆☆☆☆，四星 C++ 入门必备，讲解详细  Python  《Python 基础教程》☆☆☆☆☆，五星 个人觉得最佳Python入门学习材料，打好基础就用google，github来解决问题  Go  《Go程序设计语言 英文版》☆☆☆☆，四星  Rust  《The Rust Programming Language》 ☆☆☆☆，四星 2019  设计模式  《Head First 设计模式 中文版》  计算机基础  《深入理解计算机系统 第2版》 ☆☆☆☆☆，五星 请精读且多读几遍，计算机基础方面读这一本书就可以了。 《计算机程序的构造和解释》 ☆☆☆☆☆，五星 2018  网络编程  《TCP/IP 详解 卷1：协议》 ☆☆☆☆☆，五星 《UNIX 网络编程》 ☆☆☆☆，四星 《Linux 网络编程》 ☆☆☆，三星  数学  《数学之美》 ☆☆☆☆☆，五星 《什么是数学 对思想和方法的基本研究》  数据结构与算法  《算法导论》 《数据结构 C语言版》  Linux  《鸟哥的Linux私房菜》 ☆☆☆☆，四星 Linux操作入门参考 《深入理解Linux 内核架构》 《精通Linux驱动程序开发》 《Linux内核设计艺术》 《The Linux Programming Interface Handbook》  云计算  《Software Defined Networks》 ☆☆☆☆，四星 偏架构，需要一定基础与背景 《腾云 云计算和大数据时代网络技术揭秘》 ☆☆☆☆，四星 通俗易懂地解释网络新技术 《云计算核心技术剖析》 ☆☆☆，三星 《云计算与分布式系统》 ☆☆，二星  架构设计  《SRE Google运维解密》 ☆☆☆☆☆，五星 2017 《设计数据密集型应用》 ☆☆☆☆☆，五星 2018 《Fundamentals of Software Architecture》 ☆☆☆☆☆，五星 2021  数据科学  《利用Python进行数据分析》 ☆☆☆☆☆，五星 2018  软件工程  《构建之法》 ☆☆☆☆☆，五星 邹老师多年软件开发精华总结，务实有趣，每个软件开发人员都可以买一本。  安全  《线上幽灵 世界头号黑客米特尼克自传》 ☆☆☆☆，四星 不得不防的社会工程学，不得不用的社会工程学  商业，经济，管理，科技  《从0到1\u0026mdash;开启商业与未来的秘密》 《创新者的窘境》 《杰克韦尔杰自传》 《重来:更为简单有效的商业思维》 《经济学原理 微观经济学》 ☆☆☆☆☆，五星 2017 《硅谷方法论》 ☆☆☆☆☆，五星 2019 《今日简史》 ☆☆☆☆☆，五星 2019 《人类简史》 ☆☆☆☆☆，四星 2019 《非对称风险》☆☆☆☆☆，五星 2020 书评 《债务危机》☆☆☆☆☆，五星 2020  军事，历史，政治，社会  《中国历代政治得失》 ☆☆☆，三星 可以让你不局限一个事件，而是从历史进程角度看朝代变迁与历史事件 《孙子兵法与三十六计》 ☆☆☆☆☆，五星 《纸牌屋》 ☆☆☆☆，四星 《全球通史》 ☆☆☆，三星 《大明王朝1566》 ☆☆☆☆☆，五星 2018 《权力论》 ☆☆☆☆☆，五星 2018 《通往奴役之路》☆☆☆☆☆，五星 2019 《万历十五年》☆☆☆☆☆，五星 2019 《走向共和》 ☆☆☆☆☆，五星 2021  区块链  《精通比特币》 ☆☆☆☆，四星 2017 《区块链与社会》 ☆☆☆☆，四星 2017 《区块链项目开发指南》☆☆☆☆，四星 2017 《The Bitcoin Standard》 ☆☆☆☆，四星 2019 《How to Defi》 ☆☆☆☆☆，五星 2020 《Token Economy》 ☆☆☆☆☆，五星 2020  人工智能  《终级算法》 ☆☆☆☆，四星 2017 《TensorFlow 实战Google深度学习框架》 ☆☆☆☆，四星 2017  学习，思考，认知，成长  《原子习惯》 ☆☆☆☆☆，五星 2019 《黑匣子思维：我们如何更理性地犯错》 ☆☆☆☆☆，五星 2021 《系统化思维导论》 ☆☆☆☆☆，五星 2021 《Getting Things Done》 构建适合于自己的GTD系统及习惯 《Deep Work: Rules for Focused Success in a Distracted World》 在日益容易分心的环境，如何通过刻意练习让天生不适应多任务的大脑高效有深度的工作 《The Effective Executive》时间花在哪里？单位时间内的效率如何？ 《Work the System: The Simple Mechanics of Making More and Working Less 》 《The 7 Habits of Highly Effective People》 《Essentialism: The Disciplined Pursuit of Less》 多做之过，少即是多：只有很少事情很重要，大部分情况只需要解决关键问题，其他问题也就自然而然的解决了。 《The Checklist Manifesto: How to Get Things Right》 高频事务配清单 《The Power of Full Engagement》 身体，精神，情感，意志四要素要补其短板，以便全身心投入工作 《Flow》 追求心流享受  文学  《红楼梦》 ☆☆☆☆，四星 2018  哲学  《道德经》 ☆☆☆☆☆，五星 2020  其他  《黑客与画家》 《浪潮之巅》  2022年  《Minimalist Entrepreneur》 《Zero to Sold》 《Rust for Rustaceans》 《Rust in Action》 《奔跑吧，程序员 - 从零开始打造产品、技术和团队》 《准备》 《亲密关系》 2022.11 《Noise A Flaw in Human Judgment》 《Information Theory and Coding by Example》 《事实》 《Academic Writing A Handbook for International Students》 《算法（第4版)》 《The Cold Start Problem: How to Start and Scale Network Effects》 《人类网络》 《数学通识讲义》 《Fundamentals of Software Architecture》 《穷查理宝典》 《The evolution of cooperation》 《计算之魂》 2022.10 《引爆点 如何引发流行》 《链接：商业、科学与生活的新思维》 2022.10 《Zero to Production in Rust》 《纳瓦尔宝典 (埃里克·乔根森)》 2022.11  2023  《100 Go Mistakes AND HOW TO AVOID THEM》 ☆☆☆☆☆ 2023.2 《The Mental Game of Trading: A System for Solving Problems with Greed, Fear, Anger, Confidence, and Discipline》 《The Sovereign Individual - 主权个人》 《Introduction to Algorithms, fourth edition》 《Do Dice Play God - The Mathematics of Uncertainty》 《Building a Second Brain》 《The Art of Game Design: A Book of Lenses》 《The Question Book - What Makes You Tick》 ☆☆☆☆ 2023.6 《How to Be a Person》 ☆☆☆☆ 2023.2 《The Second in Command: Unleash the Power of Your COO》 《显微镜下的大明》 《Complexity A Guided Tour》 《Richer, Wiser, Happier How the World’s Greatest Investors Win in Markets and Life》 《In Pursuit of the Unknown 17 Equations That Changed the World》 《The Joys of Compounding》 《肥尾效应》 《Hooked》 《Mastering the Trade, Third Edition: Proven Techniques for Profiting from Intraday and Swing Trading Setups》 《一人公司》 《A Hacker\u0026rsquo;s Mind: How the Powerful Bend Society\u0026rsquo;s Rules, and How to Bend Them Back》 《The Great Mental Models: General Thinking Concepts》 《Automate Your Busywork: Do Less, Achieve More, and Save Your Brain for the Big Stuff》 2023.5 《The Practitioner\u0026rsquo;s Guide to Graph Data: Applying Graph Thinking and Graph Technologies to Solve Complex Problems》 《How Not to Be Wrong: The Power of Mathematical Thinking》  后记 此篇每年更新(有一股力量让自己去行动总是好的)！\n纸上得来终觉浅 绝知此事要躬行！\n更新记录  2018年12月19日 更新 2021年1月16日 更新 2022年1月2日 添加2022年的书单  ", 
        "url": "http:\/\/myself659.github.io\/post\/read-post\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/share-post\/": {
        
        "title": "Share",
        "tags": [],
        "content": "科普  图解计算机科学 Why does time pass? | The Economist A MUST SEE!!! The Most Eye Opening 10 Minutes Of Your Life | Dr. Bruce Lipton Why Do Computers Use 1s and 0s? Binary and Transistors Explained. See How a CPU Works How do computers read code? 100 Amazing How-To Sites to Teach Yourself Anything  数学  The Map of Mathematics The Essence of Calculus, Chapter 1 Tips to be a better problem solver [Last lecture] | Lockdown math ep. 10  经济  经济机器是怎样运行的(文字版) 经济机器是怎样运行的 (时长30分钟) Ray Dalio  log  The Log: What every software engineer should know about real-time data\u0026rsquo;s unifying abstraction Logging Best Practices  工具 VS Code  VS Code Top-Ten Pro Tips VS Code: The Last Editor You\u0026rsquo;ll Ever Need  chrome  vimium Google Translate Plus   Programe  16 Programming Productivity Tools You Can Use Even if You’re Not a Programmer  latex  codecogs  搜索  15 Ways to Search Google 96% of People Don’t Know About  网站  10 Useful Websites You Wish You Knew Earlier! 2018  学习  How to Learn Anything\u0026hellip; Fast - Josh Kaufman The first 20 hours \u0026ndash; how to learn anything | Josh Kaufman | TEDxCSU  架构  亚马逊1万亿市值背后的架构经验：AWS十年沉淀下来的十条宝贵经验  导航  All cheat sheets TL;DR cheat for development linux-syscall-table egex Cheat Sheet GitSheet Awesome-Cheatsheets OverAPI.com HTML CheatSheet 10 JavaScript Cheat Sheets That Will Boost Your Productivity  生活  时区转换  人物 Jim Keller  Jim Keller (engineer) An AnandTech Exclusive: The Jim Keller Interview  Elon Musk  首飞成功！SpaceX “重型猎鹰\u0026quot;登顶世界运力最强运载火箭，马斯克卧薪七年终于再次改写历史 刚刚，马斯克改写人类航天史！SpaceX实现全球首次商业载人发射  公开信  网易CEO丁磊首封致股东信 黄峥发布2020年度致股东信：新的世界正在到来，新的物种必然出现 张一鸣卸任字节跳动CEO公开信  公关  美团外卖回应：宣布五项改进举措 给骑手留出8分钟弹性时间 饿了么将推出多等5分钟功能 外卖骑手，困在系统里  ", 
        "url": "http:\/\/myself659.github.io\/post\/share-post\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/slide-post\/": {
        
        "title": "Slide",
        "tags": [],
        "content": "2017  高性能服务器设计与优化(High performance server design and optimization)  2018  数字货币钱包产品定位与战略.pdf 下一代互联网基础：IPFS.pdf  ", 
        "url": "http:\/\/myself659.github.io\/post\/slide-post\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-09-21-ipfs-sec\/": {
        
        "title": "IPFS与下一代网络安全",
        "tags": ["IPFS",],
        "content": "IPFS 先简单说一下IPFS。 IPFS是点对点协议InterPlanetary File System的简称，它是一个面向全球的、点对点的分布式版本文件系统，试图将所有具有相同文件系统的计算设备连接在一起。它用基于内容的地址替代基于域名的地址，也就是用户寻找的不是某个地址而是储存在某个地方的内容，不需要验证发送者的身份，而只需要验证内容的哈希，通过这样可以让网页的速度更快、更安全、更健壮、更持久。IPFS目标是未来将替代HTTP。\nIPFS主要技术，用下面这张图说明：\nIPFS与安全 整个IPFS涉及很多方面的内容，这部分具体看一下IPFS对网络安全的影响。首先从DDOS防攻击展开，IPFS应对DDOS攻击主要如下：\n 道哥在弹性安全网络中表达过DDOS存在的原因就是现在互联网严重依赖存在三大问题的DNS系统,而在IPFS中通过内容寻址方式绕开了DNS IPFS底层网络是基于DHT，拥有大量节点的P2P网络，天生适合内容的分布式读写（PS：P2P网络安全需要另行考虑） 内容签名，通过加密加大攻击的难度与成本  上面的这些作法，很符合经济原理。DDOS存在主要经济学原因是DDOS获得的收益远大于DDOS的投资；IPFS的上述特点直接提高DDOS的成本。\n比较 上一篇分析了道哥的提出的弹性安全网络设想。那么，就在这里搞事情，对比一下两者。\n  道哥和Juan Benet都是杰出的技术人员及创业者，富有远见\n  作为安全出身的道哥的出发点解决网络安全问题主要是DDOS安全攻击问题，而IPFS目标如下：We believe the internet has become humanity's most important technology. We build protocols, systems, and tools to improve how it works. Today, we are focused on how we store, locate, and move information.\n  IPFS是一种去中心化技术，而弹性安全网络接入技术可以是一种大规模的云计算技术（中心化技术）。\n  IPFS没有网络访问控制功能，自由开放；弹性安全网络有网络访问控制能力，方便监管与控制\n  IPFS是从数据角度来解决问题（解决数据分布，版本，访问，权限控制等）,弹性安全网络从网络安全的角度来解决问题\n  IPFS开放源码，弹性安全网络没有开源，开源的IPFS体现了去中心化技术的态度\n  IPFS现网运行，弹性安全网络在游戏盾中得到应用与实践，两者都有很长的路需要走\n  IPFS目标是取代HTTP,同时兼容HTTP，弹性安全网络将应用场景定位在非域名类的IP网络\n  IPFS对现有应用冲击很大，因为去中心化应用及基础设施（如去中心数据库）还在起步阶段；弹性安全网络考虑基于现有云计算（大规模中心化技术）应用作为出发点一种网络安全的解决方案，能够兼容云计算应用。\n  IPFS支持端对端加解密，保证数据的隐私。弹性安全网络不涉及这方面内容。\n  IPFS是事前准备，弹性安全网络更多体现发现攻击一种事后处理角度出发。\n  IPFS用去中以化来应对攻击，弹性安全网络用技术（大数据，人工智能）来应对攻击。\n  最后说一下：IPFS就像以电为动力的特斯拉，道哥的弹性安全网络则像是不断改进的燃油车。就如同特斯拉给汽车带来的革命和冲击一样，IPFS对整个互联网带来变革与颠覆。\n（个人能力有限，不足与错误欢迎指正，欢迎交流！）\n参考  IPFS Amazon\u0026rsquo;s web servers are down and it\u0026rsquo;s causing trouble across the internet Why The Internet Needs IPFS Before It\u0026rsquo;s Too Late  ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-09-21-ipfs-sec\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-09-20-next-network\/": {
        
        "title": "关于弹性安全网络一点思考",
        "tags": ["ipfs",],
        "content": "作为网络研发出身的我，从事网络研发时间也最长，一直也关注道哥的微信公众号。\n下面就对道哥的提出弹性安全网络一些总结与思考。\n弹性安全网络 具体从以下几个方面解读弹性安全网络。\n来源 弹性安全网络这个设想来自阿里云游戏盾这个产品，而这个产品解决的问题就是如何解决DDOS问题。\n以前解决DDOS问题，很多厂商就是以暴制暴，准备大量带宽，抗住攻击流量，这种方式有以下问题：\n 流量成本高 万一没有抗住，服务会中断 业务局限于一个数据中心，目标明显，容易受攻击（将鸡蛋放到同一个篮子）  而在游戏盾产品采用另一种方式来解决问题，主要要点如下：\n 首先，业务访问支持多IP解析，分散流量（狡免三窟） 第二就是应对攻击，支持业务地址迁移，地址迁移难点就是如何快速通知到各个用户（你打我，我就闪）  定义  弹性安全网络是将DDoS防御前置到网络边缘处。但是，未来真正要做的事情是通过端到端的连接，通过风险控制技术，重新构建一个干净的、安全的互联网\n 目标  弹性安全网络真正想要去做的，是替换掉整个互联网最核心的心脏，替换掉DNS，从而让网络变得有弹性，能够快速调度资源，形成一个全新的网络架构。\n  弹性安全网络技术，不是为某一个客户设计的，它是为整个互联网设计的。\n DNS三个问题  DNS是互联网的心脏\n  第一个，是DNS完全解析的时间过长，这是整个DNS使用中遇到的一个非常大的痛点。\n  第二个问题是今天DNS Server软件中的解析数遇到了瓶颈，没有办法一个名字解析到几千个、甚至上万个，甚至未来十几万个不同地址。一个名字可能最多也就解析到十几个或几十个地址就不能再扩大了。这种瓶颈限制了我们的一些能力拓展。\n  第三个就是，原本可以基于DNS去实现的一些安全机制，比如风险控制，并没有建立起来。其实也比较好理解，在互联网1.0时代并没有如今天这般强大的数据能力和计算能力。\n 实现 文中并没有提及具体的实现，主要要点是：\n 基于大数据的足迹库 基于人工智能的快速识别能力 分布式的统一网络访问入口，取代DNS，具体细节未知  未来  主要机会就是在IoT和移动互联网，因为这两者实际上是没有DNS的需求的\n 总结 道哥的弹性安全网络，是一个伟大的构思。\n弹性安全网络出发点主要是解决DDOS问题。\n主要目标应用于IOT和移动互联网。\n弹性安全网络思考主要出发点是如何应对网络攻击，主要从两个角度出发：\n 如何快速应对攻击 如何利用技术（大数据，人工智能等）识别攻击  参考  弹性安全网络 \u0026ndash; 构建下一代安全的互联网 IPFS与下一代网络安全  ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-09-20-next-network\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-08-24-ethereum-start\/": {
        
        "title": "以太坊私链智能合约实践",
        "tags": ["blockchain",],
        "content": "环境说明  操作系统: macos.10.12.1 geth版本：1.5.9 solc版本：0.4.15  实践 1. 启动本地geth节点 1  Michaels-iMac:wallet eric$ geth --rpc --rpcaddr 127.0.0.1 --rpcport 8545 --dev --datadir myethchain   如上操作后，geth console输出如下：\n1 2 3 4 5 6  I0824 17:28:57.448455 p2p/server.go:340] Starting Server I0824 17:28:59.554115 p2p/discover/udp.go:227] Listening, enode://04697f62537244ee34aea28e613530a1f46a64de75d8174d963c9ca0c2e6b96d4aa756ef7a33e269de1b7c088163835b72dda8f4dea712cf39569db4e8d8e43a@[::]:54798 I0824 17:28:59.554264 p2p/server.go:608] Listening on [::]:58245 I0824 17:28:59.554324 whisper/whisperv2/whisper.go:176] Whisper started I0824 17:28:59.570668 node/node.go:341] IPC endpoint opened: /Users/eric/wallet/myethchain/geth.ipc I0824 17:28:59.581423 node/node.go:411] HTTP endpoint opened: http://127.0.0.1:8545   同时也创建在当前目录创建目录myethchain，其结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  Michaels-iMac:wallet eric$ tree myethchain/ myethchain/ ├── geth │ ├── LOCK │ ├── chaindata │ │ ├── 000002.log │ │ ├── CURRENT │ │ ├── LOCK │ │ ├── LOG │ │ └── MANIFEST-000003 │ ├── nodekey │ └── nodes │ ├── 000001.log │ ├── CURRENT │ ├── LOCK │ ├── LOG │ └── MANIFEST-000000 ├── geth.ipc └── keystore 4 directories, 13 files   2. 连接geth节点 在另外一个终端里连接geth节点。\n1 2 3 4 5 6 7  Michaels-iMac:wallet eric$ geth attach ipc://Users/eric/wallet/myethchain/geth.ipc Welcome to the Geth JavaScript console! instance: Geth/v1.5.9-stable-a07539fb/darwin/go1.8.3 modules: admin:1.0 debug:1.0 eth:1.0 miner:1.0 net:1.0 personal:1.0 rpc:1.0 shh:1.0 txpool:1.0 web3:1.0 \u0026gt;   3. 确保solidity编译器安装正确 1 2 3  \u0026gt; web3.eth.getCompilers() [\u0026#34;Solidity\u0026#34;] \u0026gt;   如果出错或者获取为空，请检查solc安装情况。\n4. 查看帐户列表 1 2 3  \u0026gt; personal.listAccounts null \u0026gt;   5. 创建帐户 1 2 3  \u0026gt; personal.newAccount(\u0026#39;pw1234\u0026#39;) \u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34; \u0026gt;   6. 查看帐户列表 1 2 3  \u0026gt; personal.listAccounts [\u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34;] \u0026gt;   7. 查看coibase地址 1 2  \u0026gt; web3.eth.coinbase \u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34;   与上面地址一致，默认取第一个创建帐户的地址，作为挖矿的收益打入该地址\n8. 准备智能合约 1 2 3  \u0026gt; source = \u0026#34;contract hello { function multen(uint a) returns(uint d){return a * 10;}}\u0026#34; \u0026#34;contract hello { function multen(uint a) returns(uint d){return a * 10;}}\u0026#34; \u0026gt;   9. 编译智能合约 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026gt; code = web3.eth.compile.solidity(source) { \u0026lt;stdin\u0026gt;:hello: { code: \u0026#34;0x60606040523415600e57600080fd5b5b60978061001d6000396000f300606060405263ffffffff7c0100000000000000000000000000000000000000000000000000000000600035041663e847973c8114603c575b600080fd5b3415604657600080fd5b604f6004356061565b60405190815260200160405180910390f35b600a81025b9190505600a165627a7a72305820395c2030cb020d0b4f79ac0803f1aa28b97082d962a13f37a914f7950e1de5ec0029\u0026#34;, info: { abiDefinition: [{...}], compilerOptions: \u0026#34;--combined-json bin,abi,userdoc,devdoc --add-std --optimize\u0026#34;, compilerVersion: \u0026#34;0.4.15\u0026#34;, developerDoc: { methods: {} }, language: \u0026#34;Solidity\u0026#34;, languageVersion: \u0026#34;0.4.15\u0026#34;, source: \u0026#34;contract hello { function multen(uint a) returns(uint d){return a * 10;}}\u0026#34;, userDoc: { methods: {} } } } }   10. 根据ABI创建合约对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  \u0026gt; MyContract = web3.eth.contract(code[\u0026#34;\u0026lt;stdin\u0026gt;:hello\u0026#34;].info.abiDefinition) { abi: [{ constant: false, inputs: [{...}], name: \u0026#34;multen\u0026#34;, outputs: [{...}], payable: false, type: \u0026#34;function\u0026#34; }], eth: { accounts: [\u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34;], blockNumber: 0, coinbase: \u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34;, compile: { lll: function(), serpent: function(), solidity: function() }, defaultAccount: undefined, defaultBlock: \u0026#34;latest\u0026#34;, gasPrice: 21782200000, hashrate: 0, mining: false, pendingTransactions: [], protocolVersion: \u0026#34;0x3f\u0026#34;, syncing: false, call: function(), contract: function(abi), estimateGas: function(), filter: function(fil, callback), getAccounts: function(callback), getBalance: function(), getBlock: function(), getBlockNumber: function(callback), getBlockTransactionCount: function(), getBlockUncleCount: function(), getCode: function(), getCoinbase: function(callback), getCompilers: function(), getGasPrice: function(callback), getHashrate: function(callback), getMining: function(callback), getPendingTransactions: function(callback), getProtocolVersion: function(callback), getRawTransaction: function(), getRawTransactionFromBlock: function(), getStorageAt: function(), getSyncing: function(callback), getTransaction: function(), getTransactionCount: function(), getTransactionFromBlock: function(), getTransactionReceipt: function(), getUncle: function(), getWork: function(), iban: function(iban), icapNamereg: function(), isSyncing: function(callback), namereg: function(), resend: function(), sendIBANTransaction: function(), sendRawTransaction: function(), sendTransaction: function(), sign: function(), signTransaction: function(), submitTransaction: function(), submitWork: function() }, at: function(address, callback), getData: function(), new: function() } \u0026gt;   11. 挖矿 第一步：获取帐户地址\n1 2 3  \u0026gt; account1 = web3.eth.coinbase \u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34; \u0026gt;   第二步：查看balance\n1 2 3  \u0026gt; web3.eth.getBalance(account1) 0 \u0026gt;   第三步：启动挖矿\n1 2  \u0026gt; miner.start() true   第四步：查看balance\n1 2  \u0026gt; web3.eth.getBalance(account1) 424531250000000000000   第五步: 停止挖矿\n钱差不多就够了。\n1 2 3  \u0026gt; miner.stop() true \u0026gt;   12. 解锁帐户 目的是为了发送交易\n1 2  \u0026gt; personal.unlockAccount(account1, \u0026#39;pw1234\u0026#39;) true   13. 初始化智能合约 1 2 3  \u0026gt; bytecode = code[\u0026#34;\u0026lt;stdin\u0026gt;:hello\u0026#34;].code \u0026#34;0x60606040523415600e57600080fd5b5b60978061001d6000396000f300606060405263ffffffff7c0100000000000000000000000000000000000000000000000000000000600035041663e847973c8114603c575b600080fd5b3415604657600080fd5b604f6004356061565b60405190815260200160405180910390f35b600a81025b9190505600a165627a7a72305820395c2030cb020d0b4f79ac0803f1aa28b97082d962a13f37a914f7950e1de5ec0029\u0026#34; \u0026gt;   获取部署合约的gas费用开销\n1 2 3  \u0026gt; web3.eth.estimateGas({data: bytecode}) 30886 \u0026gt;   14. 部署智能合约 1 2 3 4 5 6 7 8 9 10 11 12 13 14  contractInstance = MyContract.new({data: bytecode gas: 1000000, from: account1}, function(e, contract){if(!e){if(!contract.address){console.log(\u0026#34;Contract transaction send: Transaction Hash: \u0026#34;+contract.transactionHash+\u0026#34; waiting to be mined...\u0026#34;);}else{console.log(\u0026#34;Contract mined! Address: \u0026#34;+contract.address);console.log(contract);}}else{console.log(e)}}) Contract transaction send: Transaction Hash: 0xeeac0f028e559d469b94805b986b1d9a0bd0d30289e3285487310ca426dae034 waiting to be mined... { abi: [{ constant: false, inputs: [{...}], name: \u0026#34;multen\u0026#34;, outputs: [{...}], payable: false, type: \u0026#34;function\u0026#34; }], address: undefined, transactionHash: \u0026#34;0xeeac0f028e559d469b94805b986b1d9a0bd0d30289e3285487310ca426dae034\u0026#34; }   如果出现以下错误：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026gt; contractInstance = MyContract.new({data: bytecode gas: 1000000, from: account1}, function(e, contract){if(!e){if(!contract.address){console.log(\u0026#34;Contract transaction send: Transaction Hash: \u0026#34;+contract.transactionHash+\u0026#34; waiting to be mined...\u0026#34;);}else{console.log(\u0026#34;Contract mined! Address: \u0026#34;+contract.address);console.log(contract);}}else{console.log(e)}}) Error: authentication needed: password or unlock { abi: [{ constant: false, inputs: [{...}], name: \u0026#34;multen\u0026#34;, outputs: [{...}], payable: false, type: \u0026#34;function\u0026#34; }], address: undefined, transactionHash: null }   重新解锁用户即可\n14. 重新挖矿 1 2 3 4  \u0026gt; miner.start() true \u0026gt; Contract mined! Address: 0x58dba5bddccde639cef014c1766561abbc46c13f [object Object]   15. 切换 console 1 2 3 4  \u0026gt; Contract mined! Address: 0x58dba5bddccde639cef014c1766561abbc46c13f [object Object] ^C \u0026gt;   16. 检查合约安装是否成功 1 2 3  \u0026gt; eth.getCode(contractInstance.address) \u0026#34;0x606060405263ffffffff7c0100000000000000000000000000000000000000000000000000000000600035041663e847973c8114603c575b600080fd5b3415604657600080fd5b604f6004356061565b60405190815260200160405180910390f35b600a81025b9190505600a165627a7a72305820395c2030cb020d0b4f79ac0803f1aa28b97082d962a13f37a914f7950e1de5ec0029\u0026#34; \u0026gt;   17. 调用合约函数 1 2  \u0026gt; contractInstance.multen.call(9) 90   (end)\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-08-24-ethereum-start\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/dsa\/dfs-vs-bfs\/": {
        
        "title": "DFS与BFS适用场景",
        "tags": ["algorithm","graph",],
        "content": "背景 Depth-First-Search(DFS)深度优先搜索与Breadth-First Search(BFS)广度优先搜索是树与图中最常用的算法。\nDFS 适用于DFS场景：\n 在图中找到两个节点之间中最长路径 检测图中是否存在环 当一个树分支很多，使用BFS会导致内存不足或者占用太多，可以考虑使用DFS 需要在先访问子节点，再访问兄弟节点 通过DFS可以访问更多可能路径，可以用于解决迷宫与拼图问题  BFS 适用于BFS场景：\n 在图中找到两个节点之间的最短路径时 在断定目标节点在根节点或者起始节点附近（不需要深度搜索） 优先搜索靠近起始节点的节点 需要在先访问兄弟节点，再访问子节点  ", 
        "url": "http:\/\/myself659.github.io\/post\/dsa\/dfs-vs-bfs\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-08-22-ethereum-cannot-getsolidity\/": {
        
        "title": "以太坊开发环境问题记录",
        "tags": ["blockchain",],
        "content": "说明 主要记录以太坊开发环境过程出现的问题\ngetCompilers返回失败 问题描述 在搭建以太坊开发环境过程中，出现下面的错误信息：\n1 2 3 4 5 6 7 8 9 10 11  Welcome to the Geth JavaScript console! instance: Geth/v1.6.7-stable-ab5646c5/darwin-amd64/go1.8.3 modules: admin:1.0 debug:1.0 eth:1.0 miner:1.0 net:1.0 personal:1.0 rpc:1.0 shh:1.0 txpool:1.0 web3:1.0 \u0026gt; web3.eth.getCompilers() Error: The method eth_getCompilers does not exist/is not available at web3.js:3104:20 at web3.js:6191:15 at web3.js:5004:36 at \u0026lt;anonymous\u0026gt;:1:1   问题原因 geth版本编译不在gopath目录下编译\n解决方法 在gopath目录重新编译即可\n1 2 3 4 5 6 7 8 9  Michaels-iMac:wallet eric$ geth attach ipc://Users/eric/wallet/privchain/geth.ipc Welcome to the Geth JavaScript console! instance: Geth/v1.5.9-stable-a07539fb/darwin/go1.8.3 modules: admin:1.0 debug:1.0 eth:1.0 miner:1.0 net:1.0 personal:1.0 rpc:1.0 shh:1.0 txpool:1.0 web3:1.0 \u0026gt; web3.eth.getCompilers() [\u0026#34;Solidity\u0026#34;] \u0026gt;   parity启动失败 问题描述 搭建测试环境中出现以下问题：\n1 2 3 4  root@ia:~#parity --chain=kovan --jsonrpc-hosts=all parity: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `CXXABI_1.3.8\u0026#39; not found (required by parity) parity: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.20\u0026#39; not found (required by parity) parity: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21\u0026#39; not found (required by parity)   问题原因 gcc/g++版本是4.8版本\n解决方案 升级gcc/g++\n1 2 3 4  sudo add-apt-repository ppa:ubuntu-toolchain-r/test sudo apt-get update sudo apt-get install gcc-4.9 g++-4.9 sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.9 60 --slave /usr/bin/g++ g++ /usr/bin/g++-4.9   parity访问出现bad gateway问题 问题描述 1  curl -X POST http://localhost:8545 -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;eth_getBlockByNumber\u0026#34;,\u0026#34;params\u0026#34;:[\u0026#34;0x1b4\u0026#34;, true],\u0026#34;id\u0026#34;:1}\u0026#39;   本地访问ok\n1  curl -X POST http://47.96.45.67:8545 -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;eth_getBlockByNumber\u0026#34;,\u0026#34;params\u0026#34;:[\u0026#34;0x1b4\u0026#34;, true],\u0026#34;id\u0026#34;:1}\u0026#39;   远程访问返回失败\n问题原因 1  parity --chain=kovan --jsonrpc-hosts=all   上面命令限定侦听端口为本机接口\n解决方案 1  parity --chain=kovan --jsonrpc-interface=0.0.0.0 --jsonrpc-hosts=all   以上述命令启动parity打开侦听限制\n没有eth无法在kovan上部署智能合约 问题描述 没有eth无法部署成功部署智能合约\n问题原因 天下没有免费的午餐\n解决方法 参考Kovan Faucet,四种方式选择其中一个即可，Github Gist Faucet方式参考这里\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-08-22-ethereum-cannot-getsolidity\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-07-28-slice-trap\/": {
        
        "title": "slice复用的陷阱",
        "tags": ["golang",],
        "content": "前言 先下结论：slice复用得当心，引用不当深埋雷。如若复用请分叉，分叉之后再使用。\n问题 先看一下代码吧\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package main import ( \u0026#34;fmt\u0026#34; ) func a() { x := []int{} x = append(x, 0) x = append(x, 1) // commonTags := labelsToTags(app.Labels) \ty := append(x, 2) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tz := append(x, 3) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tfmt.Println(y, z) } func b() { x := []int{} x = append(x, 0) x = append(x, 1) x = append(x, 2) // commonTags := labelsToTags(app.Labels) \ty := append(x, 3) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tz := append(x, 4) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tfmt.Println(y, z) } func main() { a() b() }   上面的如此简单的代码，分析代码希望得到预期结果如下：\n1 2  [0 1 2] [0 1 3] [0 1 2 3] [0 1 2 4]   但是执行后，得到结果如下：\n1 2 3  Michaels-iMac:golab eric$ go run slice.go [0 1 2] [0 1 3] [0 1 2 4] [0 1 2 4]   原因分析 我们先不急着分析具体原因，我们对比一下下面这段代码，看看执行结果是怎么样\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  package main import ( \u0026#34;fmt\u0026#34; ) func a() { x := []int{} x = append(x, 0) x = append(x, 1) // commonTags := labelsToTags(app.Labels) \ty := append(x, 2) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tz := append(x, 3) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tfmt.Println(y, z) } func deepcopy(src []int) []int { dst := make([]int, len(src)) copy(dst, src) return dst } func b() { x := []int{} x = append(x, 0) x = append(x, 1) x = append(x, 2) // commonTags := labelsToTags(app.Labels) \ty := deepcopy(x) y = append(y, 3) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tz := append(x, 4) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tfmt.Println(y, z) } func main() { a() b() }   具体执行结果如下：\n1 2 3  Michaels-iMac:golab eric$ go run slice-2.go [0 1 2] [0 1 3] [0 1 2 3] [0 1 2 4]   对比错误的代码，会发现问题原因出现下面的代码：\n1 2  y := append(x, 3) // Tags: append(commonTags, labelsToTags(d.Labels)...) z := append(x, 4) // Tags: append(commonTags, labelsToTags(d.Labels)...)   从内存角度来思考，y与z对应是同一段内存，z的操作override的y的操作。（备注：y与z为什么会更对应同一段内存，请了解一下slice的实现及slice的巧妙的使用，也请阅读下面参考文章Golang slices gotcha）\n解决方法就是如果slice要进行复用的时候，进行深度copy再进行使用。\n总结 slice在golang编程属于超高频使用，如果出现上面的错误，前期没有发现，如果上线，并且系统复杂，出现了问题，定位成本是很大。\n虽然上面没有slice的内存分析，但是对于程序员来说学习一些内存知识还很帮助，理解上面的问题就是小case了。\n参考  Golang slices gotcha  ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-07-28-slice-trap\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/%E9%AB%98%E8%B4%A8%E9%87%8F%E6%80%9D%E8%80%83-thinking\/": {
        
        "title": "什么是高质量的思考",
        "tags": ["学习","thinking",],
        "content": "思考的质量 人一思考,上帝就开始发笑。所以人要学会思考，提高思考的质量。\n下面从四个角度来看看有哪些因素决定思考的质量？\n原则  怀疑一切，大胆假设，小心验证 实事求是 注重方法与策略  Input  好问题 问题描述 能量 专注  Process  广度 深度 清晰 适度 创造  Output  清晰 准确 全面 深度 逻辑 创造 可操作性 持续性  总结 高质量思考= 高质量的原则+高质量的Input+高质量的Process+高质量的Output。\n", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/%E9%AB%98%E8%B4%A8%E9%87%8F%E6%80%9D%E8%80%83-thinking\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/principle-to-set-goal-%E7%9B%AE%E6%A0%87\/": {
        
        "title": "设定目标的原则",
        "tags": ["life",],
        "content": "目标的意义  目标是指导前进的方向 目标帮助思考：我们真正想要的是什么？ 目标是动力的来源之一 目标有利于抗干扰，提高专注力  SMART原则 谈及目标原则，必会谈到SMART原则。\n关于SMART原则，可以根据五个字母拆解如下：\n　1. 目标必须是具体的（Specific） 2. 目标必须是可以衡量的（Measurable） 3. 目标必须是可以达到的（Attainable） 4. 目标必须和其他目标具有相关性（Relevant） 5. 目标必须具有明确的截止期限（Time-based）\nSMART原则存在以下问题：\n SMART原则是针对具体目标设置的原则 虽然SMART原则对于目标的完成作了具体的要求，但是缺少对于目标的标准没有明确的说明  针对这些问题，个人补充6个原则：\n 目标要少 目标要准 目标标准要高 目标要有阶段性 目标基于过程而是基于结果 目标与最强的动机结合  目标要少 在生活与工作我们在设定目标的时候最容易出现这种情况： 设定目标如山倒，完成目标如抽丝。出现这种情况的原因之一就是目标太多，导致缺少专注，同时要完成目标多，导致精力有限，目标之间切换成本增高。\n目标少的话，可以提高专注，进一步提高效率，在实际工作中就是遵守one-task的原则。\n目标要准 目标少可以有效提高目标的完成率，目标完成并不一定会有好的产出。这里举一个例子，有一些公司用代码行数来作为员工的考核指标，这种情况下往往只会导致公司的代码库越来越大，代码质量越来越差，整个系统的问题越来越多。这是一个典型目标设定不准确的体现，准确目标应该是提高公司产品稳定性，增加合理的功能，满足市场需求，提高公司的营收与市场竞争力。\n目标标准要高 目标要完成同时也要兼顾高标准，不能为了完成降低标准。特别是个人成长方面，只有高标准才能进一步激发自己的潜能，不断进步。\n典型例子：团队招聘的时候要求新加入的成员的水平要在团队平均水平之上，这样才能不断提高这个团队的水平。\n目标要有阶段性 最常见就是一个年度目标要有对应的季度目标，月度目标，星期目标，这样才能不断推进自己完成目标，而不是光有一个宏伟的目标。\n目标基于过程而是基于结果 基于结果的目标只关注你想要的结果，而不关注实现它所需的行动。如果你过于关注结果，而对实现结果所需的行动不够关注，你就不会取得任何进展。相反基于过程的目标可帮助您专注于实现特定结果所需采取的行动。例如如果要减肥，目标定为一周去四次健身房相比较于一个月减10斤更好。\n目标与最强的动机结合 制定目标要与最强的动机结合起来，动机越强，完成目标的可能性更高。\n怎么加强动机呢？目标要与自己最在意的人和事结合在一起。\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/life\/principle-to-set-goal-%E7%9B%AE%E6%A0%87\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-05-10-linux-process-diagnose\/": {
        
        "title": "Linux进程诊断小结",
        "tags": ["Linux",],
        "content": "日常工作中最常见问题是如何诊断一个进程运行过程中出现的问题，下面的总结从进程诊断的角度来展示，而是不从工具与命令角度来展示，进程诊断是工作的主体，工具与命令只是工具。\n进程信息 获得进程PID 方式一：\n1 2  root@iZ2ze9qnmldt4l3l82gtviZ:~# pidof tmsf-zc 2064   方式2：\n1 2 3 4  root@iZ2ze9qnmldt4l3l82gtviZ:~# ps -ef | grep tmsf-zc root 2064 1 0 Mar17 ? 02:24:25 ./tmsf-zc root 7596 7288 0 15:07 pts/4 00:00:00 grep --color=auto tmsf-zc root@iZ2ze9qnmldt4l3l82gtviZ:~#   查看进程线程个数 及对应PID 1 2 3 4 5 6 7 8  root@iZ2ze9qnmldt4l3l82gtviZ:~# ps -efL | grep tmsf-zc root 2064 1 2064 0 5 Mar17 ? 00:00:00 ./tmsf-zc root 2064 1 2066 0 5 Mar17 ? 01:04:46 ./tmsf-zc root 2064 1 2067 0 5 Mar17 ? 00:44:53 ./tmsf-zc root 2064 1 2068 0 5 Mar17 ? 00:34:39 ./tmsf-zc root 2064 1 2069 0 5 Mar17 ? 00:00:04 ./tmsf-zc root 7604 7288 7604 0 1 15:08 pts/4 00:00:00 grep --color=auto tmsf-zc root@iZ2ze9qnmldt4l3l82gtviZ:~#   查看进程CPU与内存使用情况 1 2 3 4 5 6 7 8 9 10 11 12 13 14  root@iZ2ze9qnmldt4l3l82gtviZ:~# top -H -p 2064 top - 15:10:57 up 14 days, 5:43, 3 users, load average: 0.00, 0.03, 0.05 Threads: 5 total, 0 running, 5 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.0 us, 0.0 sy, 0.0 ni, 99.7 id, 0.3 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem: 2049904 total, 1961580 used, 88324 free, 204396 buffers KiB Swap: 0 total, 0 used, 0 free. 1334832 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2064 root 20 0 55752 7180 2756 S 0.0 0.4 0:00.00 tmsf-zc 2066 root 20 0 55752 7180 2756 S 0.0 0.4 64:46.35 tmsf-zc 2067 root 20 0 55752 7180 2756 S 0.0 0.4 44:53.83 tmsf-zc 2068 root 20 0 55752 7180 2756 S 0.0 0.4 34:39.08 tmsf-zc 2069 root 20 0 55752 7180 2756 S 0.0 0.4 0:04.49 tmsf-zc   1 2 3 4 5 6 7 8 9 10  root@iZ2ze9qnmldt4l3l82gtviZ:~# top -p 2064 top - 15:11:05 up 14 days, 5:43, 3 users, load average: 0.00, 0.03, 0.05 Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.8 us, 1.2 sy, 0.0 ni, 98.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem: 2049904 total, 1961448 used, 88456 free, 204396 buffers KiB Swap: 0 total, 0 used, 0 free. 1334836 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2064 root 20 0 55752 7180 2756 S 0.0 0.4 144:25.09 tmsf-zc   查看进程对应的可执行文件 1 2 3  root@iZ2ze9qnmldt4l3l82gtviZ:~# ls -l /proc/2064/exe lrwxrwxrwx 1 root root 0 Mar 17 10:12 /proc/2064/exe -\u0026gt; /test/tmsf-zc root@iZ2ze9qnmldt4l3l82gtviZ:~#   查看进程占用fd个数 1 2  root@iZ2ze9qnmldt4l3l82gtviZ:~# ls -l /proc/2064/fdinfo | wc -l 18   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  root@iZ2ze9qnmldt4l3l82gtviZ:~# lsof -p 2064 | grep tmsf-zc tmsf-zc 2064 root cwd DIR 253,1 4096 1967431 /test tmsf-zc 2064 root rtd DIR 253,1 4096 2 /test tmsf-zc 2064 root txt REG 253,1 8660422 1049012 test/tmsf-zc tmsf-zc 2064 root mem REG 253,1 1840928 796801 /lib/x86_64-linux-gnu/libc-2.19.so tmsf-zc 2064 root mem REG 253,1 141574 796793 /lib/x86_64-linux-gnu/libpthread-2.19.so tmsf-zc 2064 root mem REG 253,1 149120 796794 /lib/x86_64-linux-gnu/ld-2.19.so tmsf-zc 2064 root 0r CHR 1,3 0t0 5304 /dev/null tmsf-zc 2064 root 1w REG 253,1 306118 1971776 test/nohup.out tmsf-zc 2064 root 2w REG 253,1 306118 1971776 test/nohup.out tmsf-zc 2064 root 3u sock 0,7 0t0 974790 can\u0026#39;t identify protocol tmsf-zc 2064 root 4u 0000 0,9 0 5259 anon_inode tmsf-zc 2064 root 5u IPv4 192212 0t0 TCP 172.17.11.187:47222-\u0026gt;60.191.13.153:http (ESTABLISHED) tmsf-zc 2064 root 6u IPv4 216011 0t0 TCP 172.17.11.187:47275-\u0026gt;60.191.13.153:http (ESTABLISHED) tmsf-zc 2064 root 7u IPv4 270741 0t0 TCP 172.17.11.187:40874-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 8u IPv4 357728 0t0 TCP 172.17.11.187:40966-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 9u IPv4 417481 0t0 TCP 172.17.11.187:47589-\u0026gt;60.191.13.153:http (ESTABLISHED) tmsf-zc 2064 root 10u IPv4 504612 0t0 TCP 172.17.11.187:41185-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 11u IPv4 555010 0t0 TCP 172.17.11.187:47795-\u0026gt;60.191.13.153:http (ESTABLISHED) tmsf-zc 2064 root 12u IPv4 665995 0t0 TCP 172.17.11.187:41409-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 13u IPv4 717507 0t0 TCP 172.17.11.187:42001-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 14u IPv4 755724 0t0 TCP 172.17.11.187:42108-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 15u IPv4 846915 0t0 TCP 172.17.11.187:48714-\u0026gt;60.191.13.153:http (ESTABLISHED) tmsf-zc 2064 root 16u IPv4 974784 0t0 TCP 172.17.11.187:49598-\u0026gt;60.191.13.153:http (ESTABLISHED)   从proc/pid/stat获取更多进程信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  root@iZ2ze9qnmldt4l3l82gtviZ:~# procstat 2064 pid: 2064 tcomm: (tmsf-zc) state: S ppid: 1 pgid: 2058 sid: 1911 tty_nr: 0 tty_pgrp: -1 flags: 1077960960 min_flt: 7652 cmin_flt: 0 maj_flt: 10 cmaj_flt: 0 utime: 2558.590000 stime: 6106.500000 cutime: 0.000000 cstime: 0.000000 priority: 20 nice: 0 num_threads: 5 it_real_value: 0.000000 start_time: 03.17 10:12 (971043.78s) vsize: 57090048 rss: 1795 rsslim: 9223372036854775807 start_code: 4194304 end_code: 7446752 start_stack: 140735025190528 esp: 140735025189968 eip: 4549907 pending: 0000000000000000 blocked: 0000000000000000 sigign: 0000000000000003 sigcatch: 000000007fc1fefc wchan: 0 zero1: 0 zero2: 0 exit_signal: 0000000000000011 cpu: 0 rt_priority: 0 policy: 0 root@iZ2ze9qnmldt4l3l82gtviZ:~#   查看进程父子关系 1 2 3 4 5 6  root@iZ2ze9qnmldt4l3l82gtviZ:~# pstree -g -p -s 2064 init(1,1)───tmsf-zc(2064,2058)─┬─{tmsf-zc}(2066,2058) ├─{tmsf-zc}(2067,2058) ├─{tmsf-zc}(2068,2058) └─{tmsf-zc}(2069,2058) root@iZ2ze9qnmldt4l3l82gtviZ:~#   查看进程内存map信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  root@iZ2ze9qnmldt4l3l82gtviZ:~# pmap -x -p 2064 2064: ./tmsf-zc Address Kbytes RSS Dirty Mode Mapping 0000000000400000 3180 1472 0 r-x-- /test/tmsf-zc 000000000071b000 2336 948 0 r---- /test/tmsf-zc 0000000000963000 204 104 72 rw--- /test/tmsf-zc 0000000000996000 140 60 60 rw--- [ anon ] 0000000000c6a000 132 4 4 rw--- [ anon ] 000000c000000000 8 8 8 rw--- [ anon ] 000000c41ffc0000 256 256 256 rw--- [ anon ] 000000c420000000 2048 1364 1364 rw--- [ anon ] 000000c420200000 2048 2048 2048 rw--- [ anon ] 000000c420400000 4096 672 672 rw--- [ anon ] 00007f27075d8000 1408 112 112 rw--- [ anon ] 00007f2707738000 4 0 0 ----- [ anon ] 00007f2707739000 8192 8 8 rw--- [ anon ] 00007f2707f39000 4 0 0 ----- [ anon ] 00007f2707f3a000 8192 8 8 rw--- [ anon ] 00007f270873a000 4 0 0 ----- [ anon ] 00007f270873b000 8192 8 8 rw--- [ anon ] 00007f2708f3b000 4 0 0 ----- [ anon ] 00007f2708f3c000 8192 8 8 rw--- [ anon ] 00007f270973c000 1768 232 0 r-x-- /lib/x86_64-linux-gnu/libc-2.19.so 00007f27098f6000 2048 0 0 ----- /lib/x86_64-linux-gnu/libc-2.19.so 00007f2709af6000 16 16 16 r---- /lib/x86_64-linux-gnu/libc-2.19.so 00007f2709afa000 8 8 8 rw--- /lib/x86_64-linux-gnu/libc-2.19.so 00007f2709afc000 20 16 16 rw--- [ anon ] 00007f2709b01000 100 68 0 r-x-- /lib/x86_64-linux-gnu/libpthread-2.19.so 00007f2709b1a000 2044 0 0 ----- /lib/x86_64-linux-gnu/libpthread-2.19.so 00007f2709d19000 4 4 4 r---- /lib/x86_64-linux-gnu/libpthread-2.19.so 00007f2709d1a000 4 4 4 rw--- /lib/x86_64-linux-gnu/libpthread-2.19.so 00007f2709d1b000 16 4 4 rw--- [ anon ] 00007f2709d1f000 140 116 0 r-x-- /lib/x86_64-linux-gnu/ld-2.19.so 00007f2709e6f000 780 376 376 rw--- [ anon ] 00007f2709f3f000 8 8 8 rw--- [ anon ] 00007f2709f41000 4 4 4 r---- /lib/x86_64-linux-gnu/ld-2.19.so 00007f2709f42000 4 4 4 rw--- /lib/x86_64-linux-gnu/ld-2.19.so 00007f2709f43000 4 4 4 rw--- [ anon ] 00007fff6d2d2000 132 16 16 rw--- [ stack ] 00007fff6d3e9000 8 4 0 r-x-- [ anon ] ffffffffff600000 4 0 0 r-x-- [ anon ] ---------------- ------- ------- ------- total kB 55752 7964 5092   从上面可以获取以下信息：\n 进程使用哪些共享库及其版本信息，以及这些共享库在内存中的起始位置 指令起始位置 0000000000400000 初始化全部 RSS  查看进程当前的调用栈 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153  [root@localhost db_proxy_server]# pstack 31002 Thread 22 (Thread 0x7f62dafae700 (LWP 31003)): #0 0x00000038332e1523 in select () from /lib64/libc.so.6 #1 0x00007f62db1e9125 in apr_sleep () from /usr/lib64/libapr-1.so.0 #2 0x00007f62db716096 in log4cxx::helpers::FileWatchdog::run (data=0x2497a70) at filewatchdog.cpp:76 #3 0x00007f62db7778ce in log4cxx::helpers::Thread::launcher (thread=0x2499c00, data=0x2499be8) at threadcxx.cpp:100 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 21 (Thread 0x7f62da5ad700 (LWP 31008)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c3f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c3e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c3e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 20 (Thread 0x7f62d9bac700 (LWP 31009)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c478) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c468) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c468) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 19 (Thread 0x7f62d91ab700 (LWP 31010)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c4f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c4e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c4e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 18 (Thread 0x7f62d87aa700 (LWP 31011)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c578) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c568) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c568) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 17 (Thread 0x7f62d7da9700 (LWP 31012)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c5f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c5e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c5e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 16 (Thread 0x7f62d73a8700 (LWP 31013)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c678) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c668) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c668) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 15 (Thread 0x7f62d69a7700 (LWP 31014)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c6f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c6e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c6e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 14 (Thread 0x7f62d5fa6700 (LWP 31015)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c778) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c768) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c768) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 13 (Thread 0x7f62d55a5700 (LWP 31016)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c7f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c7e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c7e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 12 (Thread 0x7f62d4ba4700 (LWP 31017)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c878) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c868) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c868) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 11 (Thread 0x7f62d41a3700 (LWP 31018)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c8f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c8e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c8e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 10 (Thread 0x7f62d37a2700 (LWP 31019)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c978) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c968) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c968) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 9 (Thread 0x7f62d2da1700 (LWP 31020)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c9f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c9e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c9e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 8 (Thread 0x7f62d23a0700 (LWP 31021)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251ca78) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251ca68) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251ca68) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 7 (Thread 0x7f62d199f700 (LWP 31022)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251caf8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251cae8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251cae8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 6 (Thread 0x7f62d0f9e700 (LWP 31023)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251cb78) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251cb68) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251cb68) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 5 (Thread 0x7f62d059d700 (LWP 31024)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251f518) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251f508) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251f508) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 4 (Thread 0x7f62cfb9c700 (LWP 31025)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251f598) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251f588) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251f588) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 3 (Thread 0x7f62cf19b700 (LWP 31026)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251f618) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251f608) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251f608) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 2 (Thread 0x7f62ce79a700 (LWP 31027)): #0 0x0000003833a0ba5e in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x000000000063f12c in CCondition::waitTime (this=0x251fec0, nWaitTime=5000) at /home/wubo/LeTalk/server/src/base/Condition.cpp:43 #2 0x00000000005d8fbb in CSyncCenter::doSyncGroupChat (arg=0x0) at /home/wubo/LeTalk/server/src/db_proxy_server/SyncCenter.cpp:299 #3 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #4 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 1 (Thread 0x7f62db1be820 (LWP 31002)): #0 0x00000038332e90a3 in epoll_wait () from /lib64/libc.so.6 #1 0x0000000000642f5d in CEventDispatch::StartDispatch (this=0x251f3f0, wait_timeout=10) at /home/wubo/LeTalk/server/src/base/EventDispatch.cpp:365 #2 0x000000000063f5fd in netlib_eventloop (wait_timeout=10) at /home/wubo/LeTalk/server/src/base/netlib.cpp:160 #3 0x00000000005e21ad in main (argc=1, argv=0x7ffd32681a78) at /home/wubo/LeTalk/server/src/db_proxy_server/db_proxy_server.cpp:216 [root@localhost db_proxy_server]#   进程故障信息 dmesg查找 1 2 3 4  [root@sqwx1 demo_server]# dmesg | grep demo_server demo_server[8425]: segfault at 22 ip 0000000000548b4c sp 00007ffff50281b0 error 4 in demo_server[400000+5c4000] demo_server[22891]: segfault at 50a09b ip 0000000000562723 sp 00007ffdde9276d0 error 7 in demo_server[400000+647000] demo_server[26185]: segfault at 52ecdb ip 0000000000562723 sp 00007fff09ca4120 error 7 in demo_server[400000+647000]   查看进程被谁杀死 1 2  root@iZ2ze9qnmldt4l3l82gtviZ:~# cat /var/log/audit/audit.log | grep 16135 type=OBJ_PID msg=audit(1491364584.465:11575): opid=16135 oauid=0 ouid=0 oses=35 ocomm=\u0026#34;tmsf-zc\u0026#34;   进程性能分析 主要有下面两种方式：\n perf工具 google perf  进程调试 主要针对linux上gdb调试，可以参考文章，这里不作描述\n未完，待续 ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-05-10-linux-process-diagnose\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-05-10-golang-present\/": {
        
        "title": "使用golang present工具制作presentation",
        "tags": ["golang",],
        "content": "依赖  依赖golang的开发环境  安装 present工具在golang.org/x/tools中，依赖golang.org/x/net包,安装过程如下：\n1 2 3  root@ia-VirtualBox:~# go get golang.org/x/net root@ia-VirtualBox:~# go get golang.org/x/tools root@ia-VirtualBox:~# go install golang.org/x/tools/cmd/present   安装结束后查看present位置\n1 2  root@ia-VirtualBox:~# which present /usr/local/go/bin/present   slide文件语法 具体参考准官方文档\n更新：Package present\n生成slide 1 2 3  root@ia-VirtualBox:/share/gocode/src/github.com/pcrawfor# present golanguk/talk.slide 2017/05/09 23:53:15 Open your web browser and visit http://127.0.0.1:3999 2017/05/09 23:57:19 accepting connection from: 127.0.0.1:50852   共享slide 通过http选项指定外部访问地址\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  root@ia-VirtualBox:/share/gocode/src/github.com/pcrawfor# present -http=\u0026#34;192.168.56.5:3999\u0026#34; golanguk/talk.slide 2017/05/10 00:02:47 WARNING! WARNING! WARNING! The present server appears to be listening on an address that is not localhost. Anyone with access to this address and port will have access to this machine as the user running present. To avoid this message, listen on localhost or run with -play=false. If you don\u0026#39;t understand this message, hit Control-C to terminate this process. WARNING! WARNING! WARNING! 2017/05/10 00:02:47 Open your web browser and visit http://192.168.56.5:3999   生成PDF 以chrome为例，步骤如下：\n  按ctrl + p进入打印界面   选择打印方式为adode pdf，点击打印，即可保存为pdf\n  (end)\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-05-10-golang-present\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/what-is-matter\/": {
        
        "title": "什么才是重要的",
        "tags": ["life",],
        "content": "什么才是重要的 什么才是重要的？对于这个问题有很多答案，每个人都有自己的回答。\n这里说一下我对这个问题的思考，从哪些角度来判断与评价重要性？\n 基础 稀缺 频率 紧急 第一性原理 与自己的相关性  ", 
        "url": "http:\/\/myself659.github.io\/post\/life\/what-is-matter\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-04-29-about-system-design\/": {
        
        "title": "对于系统设计的一些想法",
        "tags": ["Arch",],
        "content": "前言 学习了google，facebook等国际一流大厂的开源方案，也研究了国内BAT的一些设计案例，在平时工作自然也少不了一些系统设计的工作，想写一些自己的想法，同时也帮助自己梳理一下思路，实现自己的系统设计的套路。\n其实就是这一句话：立足需求与业务，利用工程与技术，得到最合适的tradeofff，追求更简单的设计与方案，以此不断推进系统的演化。\n下面对这句话展开说明（当然，下面是一堆费话，只是为了解决自己的不吐不快而已罢了）。\n立足需求与业务 套用一句话：一切脱离需求的设计都是耍流氓。这里不进行具体案例分析，主要从以下角度来细化需求，提供思考的方向。\n用户角度  performance（性能） availability（可用性） usability（易用性） security（安全性）  研发角度  maintainablity （可维护性性） protability（可移植性） reusability（可重用性） scalable(可扩展性) testability（可测试性）  商业与市场角度  time to market（及时发布推向市场） cost and benifits（成本和收益） projected life time （产品生命周期） targeted market（目标市场） integration with legacy system (系统集成) roll back schedule （回退时间表）  KISS(Keep It Simple, Stupid) 有太多的例子，说明追求简单与遵循简单的设计原则的重要性，最典型就是unix的设计哲学成就伟大的linux的操作系统。\n什么是简单的系统设计呢？ 这是需要不断思考的问题，举个例子说明吧；在GFS实现中，针对client向chunk server写文件失败的问题，GFS的作法是直接返回失败，由client决定是否重写，这种作法就是聪明的简单之举。\n简单并不是随手可得的。关于这个可以参考rob pike，golang发明人之一的这篇演进： Simplicity is Complicated\n下面借此说明以下几个问题？\n 什么是简单？  简单很难定义，还是举例说明吧 追求简单并不是单纯追求技术实现上的简单。简单追求是使用的简单，因为使用是高频，实现可能只有几次，例如上面演进谈到的GC,实现并不简单，想出这个GC算法就相当困难，实现那就更难了，但是有了GC，我们用golang编程的时候就不需要像C/C++那样关心内存的申请释放，再也不用担心踩内存的问题了，专心于设计与业务，给程序员带来了简单。（以我自己为例，学会了golang，我写代码都写得多，之前只会C/C++时候，业余时间主要是阅读代码，写代码都是工作驱动）\n另外还有一点，简单是先实现，再改进，例如golang的GC算法一开始并不好，GC导致应用 延迟大，到了1.5才有改进\n如何实现简单？  演进中const同c语言定义一个常量不一样，不需要关心类型，在生活中一般人说数字2017除了程序员谁关心它是整型数还是浮点数啊\n如何判断设计是否简单呢？  让普通人也能容易理解与使用。\n在生活中能够找到对应参考。\n能够简单描述问题。\n给人一种刚刚好感觉，不多不少。\n还有更多。。。\nEverything is tradeoff  理想很丰满，但是现实很骨感\n  硬币总是两面的\n 在系统设计过程中我们总会遇到下面的问题：\n 分布式场景下CAP只能三选二 Push vs Pull Latency vs Throughput 速度 vs 成本 vs 质量 SSD vs Disk SQL vs NoSQL Sharding vs Partitioning Scale Up vs Scale Out Performance vs Scalability 集中式 vs 分布式 同步 vs 异步 \u0026hellip;  如果系统设计过程不知道系统优缺点，那表示你无法掌握这个系统设计；相反如果深入理解每一个具体方案的优缺点，就可以SWOT原则作出判断与选择，而不是面对选择总是有那么多犹豫不决，而是一种感觉：在这种需求和条件，这样的选择是最合适的。\n工程与技术能力是基础 需要掌握技术，立足需求，协调不断变化需求与技术实现的矛盾。 技术方案实现的实现需要软件工程的指导，保证整个这个方案落地过程中保持顺畅与有序进行。\n对于一个工作多年的程序员来说，从技术上就是要构建自己的知识体系，这里引用一张图如下： 这张图从网络请求处理时序的角度概括系统设计过程中可能涉及的技术点。\n关于软件工程能力，在这里不多讲了，更多请参考微软邹欣老师的大作《构建之法》。\n后记 人生贵在行动，迟疑不决时，不妨先迈出小小一步，若是美好，叫做精彩；若是糟糕，叫做经历！\n写了一篇水货文章，方向大了，内容空洞，只能待以后将其拧干了。\n（to be continued）\n参考  Simplicity is Complicated system design primer 系统设计的典型分层和涉及的知识点  ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-04-29-about-system-design\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-04-08-ecs-basic-sec-check\/": {
        
        "title": "阿里云ECS基本安全检查小结",
        "tags": ["Secure",],
        "content": "背景 查看阿里云ECS服务器日志发现如下：\n1 2 3 4 5 6 7  type=USER_AUTH msg=audit(1491669519.156:15631): pid=22938 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=PAM:authentication acct=\u0026#34;deploy\u0026#34; exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=123.57.245.163 addr=123.57.245.163 terminal=ssh res=failed\u0026#39; type=USER_LOGIN msg=audit(1491669519.156:15632): pid=22938 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=login acct=28696E76616C6964207573657229 exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=? addr=123.57.245.163 terminal=sshd res=failed\u0026#39; type=USER_LOGIN msg=audit(1491669587.368:15634): pid=22940 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=login acct=28756E6B6E6F776E207573657229 exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=? addr=123.57.245.163 terminal=sshd res=failed\u0026#39; type=USER_LOGIN msg=audit(1491669587.368:15635): pid=22940 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=login acct=28696E76616C6964207573657229 exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=? addr=123.57.245.163 terminal=sshd res=failed\u0026#39; type=USER_AUTH msg=audit(1491669589.420:15636): pid=22940 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=PAM:authentication acct=\u0026#34;deploy\u0026#34; exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=123.57.245.163 addr=123.57.245.163 terminal=ssh res=failed\u0026#39; type=USER_LOGIN msg=audit(1491669589.420:15637): pid=22940 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=login acct=28696E76616C6964207573657229 exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=? addr=123.57.245.163 terminal=sshd res=failed\u0026#39; type=USER_LOGIN msg=audit(1491669658.624:15639): pid=22948 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=login acct=28756E6B6E6F776E207573657229 exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=? addr=123.57.245.163 terminal=sshd res=failed\u0026#39;   百度一下这个ip地址，如下图所示： ![记下这个IP,留下证据](/images/attck ip.png)\n这是有人在阿里云ECS写脚本要暴力破解云主机的密码。这个引起我的注意，赶紧检查一下自己的ECS是否被破解。\n说点题外话：记得去年帮人弄一个网站的时候，后面的她的云主机密码泄漏了，人家第一反应过来就是怀疑我，还得花心思给她解释有多种情况会导致密码泄漏与破解，伤不起啊。\n整个检查大体如下，分为以下几个部分：\n 检查有哪些用户？ 用户会干什么？ 用户干过什么？ 处于什么样的环境？  检查用户 查看当前在线用户 1  root@ecs-1:~# who   为了确定是否当前就有不明用户登录，如果有不明用户登录，那么得赶紧修改密码。\n查看当前ssh连接情况 1  root@ecs-1:~# ss -t sport = :22   查看用户的ssh连接情况，进行对比确认\n查看新增用户 1  root@ecs-1:~# awk -F\u0026#39;:\u0026#39; \u0026#39;{ print $1}\u0026#39; /etc/passwd   查看当前用户 1  root@ecs-1:~# awk -F\u0026#39;:\u0026#39; \u0026#39;{ print $1}\u0026#39; /etc/passwd   主要是确定是否存在可疑用户，是否有可疑用户加入\n检查是否存在特权用户 1 2  root@ecs-1:~# awk -F: \u0026#39;$3==0 {print $1}\u0026#39; /etc/passwd root   检查用户口令是否为空 1  root@ecs-1:~# awk -F: \u0026#39;length($2)==0 {print $1}\u0026#39; /etc/shadow   检查用户会干什么 top查看内存与内存使用情况 1  root@ecs-1:~# top   关注高cpu使用率与高内存占用程序，例如比特币的矿机一般会占用大量的cpu资源\n查看任务计划 1  root@ecs-1:~# crontab -l   查看网络连接情况 1  root@ecs-1:~# netstat -natp   检查隐藏进程 检查隐藏进程，三步走：\n第一步：\n1  root@ecs-1:~# ps -ef | awk \u0026#39;{print $2}\u0026#39; | sort -n | uniq \u0026gt; pid1   第二步：\n1  root@ecs-1:~# ls /proc | grep -E \u0026#39;[0-9]{1,}\u0026#39; | sort -n | uniq \u0026gt; pid2   第三步：\n1 2 3 4 5 6 7 8 9 10 11 12  root@ecs-1:~# diff pid1 pid2 1d0 \u0026lt; PID \u0026lt; 29592 \u0026lt; 29593 \u0026lt; 29594 \u0026lt; 29595 --- \u0026gt; 29588 \u0026gt; 29589 \u0026gt; 29590 \u0026gt; 29591   结果说明： 第一步有4个不同的进程表示这条命令对应的进程，第二步同样的，所以这里没有发现隐藏的进程\n检查rcx.d 1  root@ecs-1:~# ls /etc/rc3.d   检查用户干过什么 重点检查以下情况：\n 用户登录 机器重启情况 安全日志 历史操作 安全文件检查  用last -d 查看登录情况 1  root@ecs-1:~# last -d   用last -x 查看机器重启情况 1  root@ecs-1:~# last -x reboot   查看audit的log信息 1  root@ecs-1:~# cat /var/log/audit/audit.log   查看历史命令 1 2 3  root@ecs-1:~# history 271 iptables -L 272 package main   安全文件检查  检查授权的ssh key，查看是否有未知的ssh key添加  1  root@ecs-1:~# cat ~/.ssh/authorized_keys   检查bashrc  1  root@ecs-1:~# cat ~/.bashrc   检查密码最后修改时间  1  root@ecs-1:~# ls -l /etc/passwd   环境 网络隔离性 网络采用了VPC网络模式，检测结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  root@ecs-1# nmap -v -sT 172.17.11.0/28 --open Starting Nmap 6.40 ( http://nmap.org ) at 2017-03-14 10:23 CST Initiating ARP Ping Scan at 10:23 Scanning 16 hosts [1 port/host] Completed ARP Ping Scan at 10:23, 0.41s elapsed (16 total hosts) Initiating Parallel DNS resolution of 16 hosts. at 10:23 Completed Parallel DNS resolution of 16 hosts. at 10:24, 13.00s elapsed Initiating Connect Scan at 10:24 Scanning 16 hosts [1000 ports/host] Connect Scan Timing: About 2.42% done; ETC: 10:45 (0:20:49 remaining) Connect Scan Timing: About 11.94% done; ETC: 10:46 (0:19:40 remaining) Connect Scan Timing: About 16.72% done; ETC: 10:46 (0:18:31 remaining) Connect Scan Timing: About 21.57% done; ETC: 10:46 (0:17:20 remaining) Connect Scan Timing: About 26.57% done; ETC: 10:46 (0:16:13 remaining) Connect Scan Timing: About 31.72% done; ETC: 10:46 (0:15:06 remaining) Connect Scan Timing: About 37.01% done; ETC: 10:46 (0:13:59 remaining) Connect Scan Timing: About 41.86% done; ETC: 10:46 (0:12:52 remaining) Connect Scan Timing: About 47.34% done; ETC: 10:46 (0:11:45 remaining) Connect Scan Timing: About 52.56% done; ETC: 10:46 (0:10:37 remaining) Connect Scan Timing: About 57.65% done; ETC: 10:46 (0:09:27 remaining) Connect Scan Timing: About 62.67% done; ETC: 10:46 (0:08:19 remaining) Connect Scan Timing: About 67.69% done; ETC: 10:46 (0:07:11 remaining) Connect Scan Timing: About 72.92% done; ETC: 10:46 (0:06:01 remaining) Connect Scan Timing: About 78.18% done; ETC: 10:46 (0:04:51 remaining) Connect Scan Timing: About 83.26% done; ETC: 10:46 (0:03:43 remaining) Connect Scan Timing: About 88.35% done; ETC: 10:46 (0:02:35 remaining) Connect Scan Timing: About 93.58% done; ETC: 10:46 (0:01:25 remaining) Completed Connect Scan against 172.17.11.14 in 1276.55s (15 hosts left) Completed Connect Scan against 172.17.11.7 in 1279.69s (14 hosts left) Completed Connect Scan against 172.17.11.1 in 1280.09s (13 hosts left) Completed Connect Scan against 172.17.11.10 in 1291.35s (12 hosts left) Completed Connect Scan against 172.17.11.12 in 1291.68s (11 hosts left) Completed Connect Scan against 172.17.11.5 in 1322.08s (10 hosts left) Completed Connect Scan against 172.17.11.4 in 1322.13s (9 hosts left) Completed Connect Scan against 172.17.11.15 in 1325.48s (8 hosts left) Completed Connect Scan against 172.17.11.3 in 1328.10s (7 hosts left) Completed Connect Scan against 172.17.11.9 in 1329.43s (6 hosts left) Completed Connect Scan against 172.17.11.11 in 1331.76s (5 hosts left) Completed Connect Scan against 172.17.11.2 in 1335.78s (4 hosts left)) Completed Connect Scan against 172.17.11.0 in 1336.84s (3 hosts leftCompleted Connect Scan against 172.17.11.6 in 1337.46s (2 hosts left) Completed Connect Scan against 172.17.11.8 in 1338.91s (1 host left) Completed Connect Scan at 10:46, 1342.34s elapsed (16000 total ports) Read data files from: /usr/bin/../share/nmap Nmap done: 16 IP addresses (16 hosts up) scanned in 1355.80 seconds Raw packets sent: 16 (448B) | Rcvd: 16 (448B)   如果网络没有隔离，各个VM同一个局域网内，会发现同一个网段的开放的端口，检查结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  root@centos# nmap -v -sT 192.168.20.0/24 --open Discovered open port 80/tcp on 192.168.20.10 Discovered open port 3389/tcp on 192.168.20.63 Discovered open port 80/tcp on 192.168.20.38 Discovered open port 135/tcp on 192.168.20.49 Discovered open port 3389/tcp on 192.168.20.52 Discovered open port 80/tcp on 192.168.20.49 Discovered open port 80/tcp on 192.168.20.34 Discovered open port 445/tcp on 192.168.20.37 Discovered open port 445/tcp on 192.168.20.36 Discovered open port 135/tcp on 192.168.20.14 Discovered open port 3389/tcp on 192.168.20.38 Discovered open port 135/tcp on 192.168.20.50   通过对比可知，采用VPC隔离的ECS不能发现同一个网段开放的网络端口，这样安全性也大大增加，好在阿里云ECS已经支持上VPC,这样就不担心来自同一个网段的攻击了（堡垒更容易从内部攻破）\n总结  安全首先是一个意识问题，需要保证足够的敏锐 阿里云的ip基本是一个大段范围，这么多IP对应的ECS肯定有些用户是安全小白用户，这样攻击者的成本也不会很高，写一个脚本遍历这个大的ip池，就可以获取一些小白用户的ECS 密码一定不要用12345678之类或者那些常用的密码，另外注意定时更换密码 对阿里云一个建议：对于暴力破解ssh密码，增加功能实现同一个ip地址多次尝试ssh的限制 这篇主要写一些基本检查操作，有空的时候再写一篇加强基础安全防护的文章  不足与建议，欢迎指正与交流。\n（end）\n参考  Understanding Audit Log Files linux man Hiding Linux Processes For Fun And Profit Linux: Hide Processes From Other Users Understanding Red Hat Run Levels    ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-04-08-ecs-basic-sec-check\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-03-27-help-internet-available-more-people\/": {
        
        "title": "不要忘记那些正在追赶互联网潮流的用户",
        "tags": ["闲谈乱扯",],
        "content": "引子 在一家推拿店里，排队等叫号，遇到一个五十多数大叔，下面是我们之间的对话：\n大叔： 小伙子，帮我看一下怎么连接wifi？\n我： 好的。\n（他把手机给我，我弄好，把手机给他）\n我： 大叔，你连接wifi要看视频吗？\n大叔：不是的，我看直播\n我：（有点吃惊，直播一般不是年轻人看的吗？）那你用什么软件看直播？\n大叔将手机拿过来，对我说：我秀\n我：这是哪家直播？\n大叔：人人网旗下的，我还有来疯直播，youku下面的，还有快手\n我：想不到连你们都喜欢看直播，我一直以为只有年经人才爱看直播\n大叔： 下班后时间比较多，电视剧不好看，就看直播了\n想到前几天快手E轮融资3.5亿美元，就有下面的感想。\n互联网还有哪些没有覆盖到人群？ 上面引子的大叔虽然算是互联网用户，也只能是入门了，对于使用过程中一些wifi设置，app设置还是没有掌握。\n中国有14亿人口，网民有7亿，还有7亿不是网民，在这7亿中除了一些小孩子（高中生现在有相当一部分都有手机了）有相当一部分人，还是希望赶上互联网这躺车，他们不希望成为那些被抛弃的少数人，例如家里的一个伯母会主动让妈妈教她如何使用微信聊天。\n这里主要是想得出一个这样的人群：\n 50岁以上使用手机，却没有使用智能手机的人群，帮他们跨过手机进入智能手机应该不是很难的事情,毕竟会使用手机升级到使用智能手机也不是件很难的事情。（Ps：当这些用户转化互联网用户，视频是他们第一消费内容， 这个用户群体有多大呢？ 快手主动满足三四线城市的“低俗”用户，到现在收割大量用户，E轮3.5亿融资）  互联网产品如果要覆盖更多的人群要做些什么？ 简单表达如下：\n 追求产品更简单，打开app各个功能入口一目了然 生活化的内容，例如快手定位为生活分享平台 智能的推荐算法，例如今日头条在三四线及以下城市得到大量的使用，占据大量的用户时间 针对性优化，手机有老人机，app也可以针对性优化，视频只会wifi下载和播放，字体变大 剩下的，相信各位产品经理会有更深入的思考。  不要忘记那些正在追赶互联网潮流的用户，用技术与产品帮助他们上车吧！\n希望未来让更多人享受到互联网技术和产品带来的便利。\n参考  2017各省网民人数公布，总数7亿，看你们省多少人  （end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-03-27-help-internet-available-more-people\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/leetcode\/": {
        
        "title": "LeetCode",
        "tags": [],
        "content": "数据结构与算法实践\n", 
        "url": "http:\/\/myself659.github.io\/post\/leetcode\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-02-20-go-case-1-my-shadeofgo\/": {
        
        "title": "Go的50度灰补充--http response只能读一次",
        "tags": ["golang",],
        "content": "问题 还是从代码开始吧\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  func fetch(url string) { tlsConfig := \u0026amp;tls.Config{ InsecureSkipVerify: true, } transport := \u0026amp;http.Transport{ TLSClientConfig: tlsConfig, } client := http.Client{Transport: transport} resp, err := client.Get(url) if err != nil { fmt.Println(err) \u0026lt;-time.After(300 * time.Second) go fetch(url) return } buf, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(\u0026#34;fetchyh:\u0026#34;, err) return } save(buf) //保存html到文件 defer resp.Body.Close() // http to doc doc, err := goquery.NewDocumentFromResponse(resp) if err != nil { fmt.Println(err, \u0026#34;http resp to doc failed\u0026#34;) return } /* \u0026lt;div class=\u0026#34;datanowin\u0026#34; id=\u0026#34;myCont2\u0026#34;\u0026gt; */ datanowin := doc.Find(\u0026#34;div.datanowin\u0026#34;) fmt.Println(\u0026#34;datanowin:\u0026#34;, datanowin.Length()) tables := datanowin.Find(\u0026#34;table\u0026#34;) tablelen := tables.Length() fmt.Println(\u0026#34;tablelen:\u0026#34;, tablelen) for i := 0; i \u0026lt; tablelen; i++ { item := tables.Eq(i) tableDo(item) } fmt.Println(doc.Find(\u0026#34;.table\u0026#34;).Length()) }   调用上面的代码后，html网页上没有找到自己所需要的内容，上面的代码问题在哪里？ 假想一下，一般有以下原因选项：\n http请求失败 html网页没有对应内容 goquery使用错误导致未找到对应内容  自己排查一下，发现原因不是上面三个选项上，那又是什么原因呢？ 原因是对于http response实例只能读一次，只有第一次才是从0开始读，下一次是上一次读到位置开始的\n代码分析 层层调用与跳转就此略过，只看读取buf内容最终实现代码：\n1 2 3 4 5 6 7 8 9 10  // A Reader implements the io.Reader, io.ReaderAt, io.WriterTo, io.Seeker, // io.ByteScanner, and io.RuneScanner interfaces by reading from // a byte slice. // Unlike a Buffer, a Reader is read-only and supports seeking. type Reader struct { s []byte i int64 // current reading index prevRune int // index of previous rune; or \u0026lt; 0 }   1 2 3 4 5 6 7 8 9  func (r *Reader) Read(b []byte) (n int, err error) { if r.i \u0026gt;= int64(len(r.s)) { return 0, io.EOF } r.prevRune = -1 n = copy(b, r.s[r.i:]) r.i += int64(n) // 读index向后移动 return }   看到这些代码问题就很清楚了，第一次读取resp.Body时ioutil.ReadAll将所有内容都完了，第二次读调用goquery.NewDocumentFromResponse没有读到任何内容。\n其实问题不止上面这个：看了ioutil.ReadAll的流程后，又看了goquery.NewDocumentFromResponse的实现，发现还有一个问题:代码还存在一个问题，代码存在两次调用defer resp.Body.Close()，这是goquery.NewDocumentFromResponse接管了resp.Body,代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  func NewDocumentFromResponse(res *http.Response) (*Document, error) { if res == nil { return nil, errors.New(\u0026#34;Response is nil\u0026#34;) } defer res.Body.Close() // 接管了resp.Body if res.Request == nil { return nil, errors.New(\u0026#34;Response.Request is nil\u0026#34;) } // Parse the HTML into nodes root, e := html.Parse(res.Body) if e != nil { return nil, e } // Create and fill the document return newDocument(root, res.Request.URL), nil }   一种简单解决上述问题代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  func fetch(url string) { tlsConfig := \u0026amp;tls.Config{ InsecureSkipVerify: true, } transport := \u0026amp;http.Transport{ TLSClientConfig: tlsConfig, } client := http.Client{Transport: transport} resp, err := client.Get(url) if err != nil { fmt.Println(err) \u0026lt;-time.After(300 * time.Second) go fetch(url) return } /* buf, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(\u0026#34;fetchyh:\u0026#34;, err) return } save(buf) //保存html到文件 */ // defer resp.Body.Close() // http to doc doc, err := goquery.NewDocumentFromResponse(resp) if err != nil { fmt.Println(err, \u0026#34;http resp to doc failed\u0026#34;) return } /* \u0026lt;div class=\u0026#34;datanowin\u0026#34; id=\u0026#34;myCont2\u0026#34;\u0026gt; */ datanowin := doc.Find(\u0026#34;div.datanowin\u0026#34;) fmt.Println(\u0026#34;datanowin:\u0026#34;, datanowin.Length()) tables := datanowin.Find(\u0026#34;table\u0026#34;) tablelen := tables.Length() fmt.Println(\u0026#34;tablelen:\u0026#34;, tablelen) for i := 0; i \u0026lt; tablelen; i++ { item := tables.Eq(i) tableDo(item) } fmt.Println(doc.Find(\u0026#34;.table\u0026#34;).Length()) }   总结 第一次遇到这个问题，我就想到是先调用ioutil.ReadAll读取resp.Body的内容，后面调用goquery.NewDocumentFromResponse就没有读到东西。于是我把ioutil.ReadAll相关代码去掉，问题解决了。后面我就没有深入追究原因(还是给自己找个理由：忙)。\n本来我是抗拒写这篇文章的，想想自己在这个问题老是不长记性，还是读一下相关源码，简单记录下来，加深印象。\n读源码是最有收益的解决问题方式。\n最后推荐一下这篇文章：50 Shades of Go: Traps, Gotchas, and Common Mistakes for New Golang Devs\n(end)\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-02-20-go-case-1-my-shadeofgo\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-02-16-tcp-slow-down\/": {
        
        "title": "TCP连接下载文件失败，也许该看看这篇文章",
        "tags": ["Network",],
        "content": "体验一下标题党，现在自媒体横行，容我也放肆一回（多了我也不行，替自己码字能力捉急）！\n另起一行，到此为止，进入正题\n缘起 最近通过uc浏览器下载apk的时候，偶尔出现下载apk，下载了60%左右卡住，想到以前看到这篇文章：The curious case of slow downloads（PS：毕竟这个问题不是常出现，就算一次下载失败，反正可以重新下载，总能下载成功的）\n说明 由于本人英文水平有限，翻译水平更是不足，就不具体翻译上面的文章，仅作简单说明，更深的理解请阅读The curious case of slow downloads\n问题描述 Cloudflare是美国一家CDN厂商，他们的工程师发现下面的问题：\n 一些下载速度很慢的连接被突然关闭，导致用户下载失败\n  这些连接不是客户端主动关闭，而是服务端主动关闭的\n 问题原因 原文有具体解决这个问题详细过程，还是值得一看，这里不作描述。\n在满足如下条件情况下会出现下载失败：\n socket发送缓冲区可用空间低于缓冲区总大小的三分之一 用户下载速度不能达到在60秒内使该socket发送缓冲区可用空间超过缓冲区总大小的三分之一 nginx配置项send_timeout对应值为60秒  当满足上述条件，当60秒超时后，nginx会关闭该连接\n这里大家可能有一个问题，网速慢也会不断发送，怎么会超时出现关闭连接？\n这里有一个普遍的误解：认为send像recv那样，每发送成功一个都上报epoll事件（以linux为例）,而实际send上报epoll事件条件如下：\n send buffer有可用发送空间 进入发送队列的数据一定要低于LOWAT的设置值（注意：linux 内核2.6版本没有这个限制，linux 内核4.5版本以上有此条件，其他版本情况未知） 发送缓存区的可用空间一定要超过大于发送空间的已使用的空间的二分之一  其中第三个条件对应内核代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102  unsigned int tcp_poll(struct file *file, struct socket *sock, poll_table *wait) { unsigned int mask; struct sock *sk = sock-\u0026gt;sk; struct tcp_sock *tp = tcp_sk(sk); sock_poll_wait(file, sk-\u0026gt;sk_sleep, wait); if (sk-\u0026gt;sk_state == TCP_LISTEN) // 侦听状态，进入listen poll，即检查侦听socket的accpet队列是否为空 return inet_csk_listen_poll(sk); /* Socket is not locked. We are protected from async events * by poll logic and correct handling of state changes * made by other threads is impossible in any case. */ mask = 0; /* * POLLHUP is certainly not done right. But poll() doesn\u0026#39;t * have a notion of HUP in just one direction, and for a * socket the read side is more interesting. * * Some poll() documentation says that POLLHUP is incompatible * with the POLLOUT/POLLWR flags, so somebody should check this * all. But careful, it tends to be safer to return too many * bits than too few, and you can easily break real applications * if you don\u0026#39;t tell them that something has hung up! * * Check-me. * * Check number 1. POLLHUP is _UNMASKABLE_ event (see UNIX98 and * our fs/select.c). It means that after we received EOF, * poll always returns immediately, making impossible poll() on write() * in state CLOSE_WAIT. One solution is evident --- to set POLLHUP * if and only if shutdown has been made in both directions. * Actually, it is interesting to look how Solaris and DUX * solve this dilemma. I would prefer, if POLLHUP were maskable, * then we could set it on SND_SHUTDOWN. BTW examples given * in Stevens\u0026#39; books assume exactly this behaviour, it explains * why POLLHUP is incompatible with POLLOUT. --ANK * * NOTE. Check for TCP_CLOSE is added. The goal is to prevent * blocking on fresh not-connected or disconnected socket. --ANK */ /* socket 与tcp 状态转化 poll事件 */ if (sk-\u0026gt;sk_shutdown == SHUTDOWN_MASK || sk-\u0026gt;sk_state == TCP_CLOSE) mask |= POLLHUP; if (sk-\u0026gt;sk_shutdown \u0026amp; RCV_SHUTDOWN) mask |= POLLIN | POLLRDNORM | POLLRDHUP; /* Connected? */ if ((1 \u0026lt;\u0026lt; sk-\u0026gt;sk_state) \u0026amp; ~(TCPF_SYN_SENT | TCPF_SYN_RECV)) { int target = sock_rcvlowat(sk, 0, INT_MAX); if (tp-\u0026gt;urg_seq == tp-\u0026gt;copied_seq \u0026amp;\u0026amp; !sock_flag(sk, SOCK_URGINLINE) \u0026amp;\u0026amp; tp-\u0026gt;urg_data) target--; /* Potential race condition. If read of tp below will * escape above sk-\u0026gt;sk_state, we can be illegally awaken * in SYN_* states. */ /* 未处理接收报文字节数超过了最小阈值，满足可读条件 */ if (tp-\u0026gt;rcv_nxt - tp-\u0026gt;copied_seq \u0026gt;= target) mask |= POLLIN | POLLRDNORM; if (!(sk-\u0026gt;sk_shutdown \u0026amp; SEND_SHUTDOWN)) { /* sk-\u0026gt;sk_sndbuf - sk-\u0026gt;sk_wmem_queued \u0026gt;= sk-\u0026gt;sk_wmem_queued\u0026gt;\u0026gt;1 (简单理解为最大值 0.5* sk-\u0026gt;sk_wmem_queued) 如果未发送报文超过了66%，那么不会继续上报POLLOUT事件 */ if (sk_stream_wspace(sk) \u0026gt;= sk_stream_min_wspace(sk)) { mask |= POLLOUT | POLLWRNORM; } else { /* send SIGIO later */ /* 发送SIGIO */ set_bit(SOCK_ASYNC_NOSPACE, \u0026amp;sk-\u0026gt;sk_socket-\u0026gt;flags); set_bit(SOCK_NOSPACE, \u0026amp;sk-\u0026gt;sk_socket-\u0026gt;flags); /* Race breaker. If space is freed after * wspace test but before the flags are set, * IO signal will be lost. */ if (sk_stream_wspace(sk) \u0026gt;= sk_stream_min_wspace(sk)) mask |= POLLOUT | POLLWRNORM; } } else mask |= POLLOUT | POLLWRNORM; if (tp-\u0026gt;urg_data \u0026amp; TCP_URG_VALID) mask |= POLLPRI; } /* This barrier is coupled with smp_wmb() in tcp_reset() */ smp_rmb(); if (sk-\u0026gt;sk_err) mask |= POLLERR; return mask; }   解决方案 知道上面的原因对应可以选择方案如下：\n方案一：增加send_timeout时间，例如将时间调整为280秒，可以保证在5M发送缓冲区条件下，用户下载速度超过50Kbps不会出现超时导致连接被关闭\n方案二：通过设置/proc/sys/net/ipv4/tcp_wmem值减小socket发送缓冲区大小，发送缓冲区减小，那么在一定下载速率下在指定的时间需要完成下载的大小变小，就可以避免上述的问题出现的条件\n显而易见，这种两种方案都不能从根本上解决问题，只是降低问题出现的概率（这也是进步）\n方案三：改变超时处理，而不是直接关闭，可利用ioctl(TIOCOUTQ)来获取有多少数据仍停留在发送缓冲区，调整超时时间，具体实现可以参考The curious case of slow downloads中提到的方案：a Linux specific patch to NGINX\n相比较于方案一和方案二，方案三对网络速率变化与波动适应性强\n总结  The curious case of slow downloads值得一看（感谢cloudflare工程师没有放弃一些偶现的问题） nginx现有实现单一固化的处理导致不适应tcp传输的多变性 在复杂多变的网络环境下，保证传输高可靠性里面需要很多技术细节需要挖掘 网络是复杂的，主要由于以下原因：   网络协议复杂，例如tcp 网络本身不可靠 网络连接多样性 网络要求高：低延迟，少丢包，抖动小，高速率，自适应  参考  The curious case of slow downloads linux-2.26.32  ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-02-16-tcp-slow-down\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/internet\/2017-02-03-country-internet-user\/": {
        
        "title": "互联网在农村-用户",
        "tags": ["闲谈乱扯",],
        "content": "上一篇从电和物理网络两个方面说明自己所看到的农村互联网基础设施情况。这一篇就看看在农村的互联网用户的一些情况。 根据对app使用情况分为以下几种情况：\n 基本不使用智能手机 需要引导使用智能手机 自主使用智能手机一些应用 自主使用智能手机大多数应用  基本不使用智能手机 代表人物：大伯父，大伯母\n出生年代：50年代\n教育背景：小学未毕业\n相关经历：基本上很少去城市，只去县城\n需要引导使用智能手机 代表人物：爸爸，妈妈\n出生年代：60年代\n教育背景：爸爸初中未毕业，妈妈小学未毕业\n相关经历：爸爸曾经外出在浙江，江苏打工；妈妈由于晕车基本一直在老家，只有去年去一趟南京\n引导环境：三个孩子都上过大学，使用智能手机是妹妹教他们使用\n使用情况：爸爸把手机当成他的电视，使用手机大部分时间就用爱奇艺看电视剧（他看什么电视剧呢？这个等以后多了解其他用户再写），妈妈主要用微信聊天，聊天主要语音，不会打字聊天，反正我她用的很溜，经常用\n自主使用智能手机一些应用 代表人物：堂叔\n出生年代：1974年\n教育背景：初中未毕业\n相关经历：有一段时间浙江打工经历，近三年没有外出打工\n引导环境：无\n使用情况：自主使用微信，酷我音乐等app，但是还不会下载音乐MV,由于信息的原因未使用网易云音乐\n自主使用智能手机大多数应用 代表人物：堂兄\n出生年代：1979年\n教育背景：初中毕业\n相关经历：长年在苏州打工\n引导环境：无\n使用情况：主流app都有使用（微信，qq， 淘宝， 百度搜索，腾讯新闻，腾讯视频等等），但是有一点就是互联网金融应用不怎么使用，原因主要都是对钱不放心，一直都是把存到银行，对于把钱存在余额宝和微信从心理对安全有一些疑惑\n总结 这样用户基本有以下特征：\n 教育程度低（时代与历史的原因），其实他们都很勤劳善良，互联网产品的使用门槛确实对于他们来说有些高 互联网潮流的落后者或者抛弃者（望见谅：想不出更好的表达） 对互联网依赖性远低于年轻人（35岁以下），所以对于第二点反过来也可以说是他们抛弃了互联网 对于互联网应用以满足生活需求为主，只会使用少量的app，例如微信等聊天工具，爱奇艺等视频应用。。。 App推广成本高，但是这些用户一旦学会用使用则粘性大，不会轻易选用其他可以替换的app  （End）\n", 
        "url": "http:\/\/myself659.github.io\/post\/internet\/2017-02-03-country-internet-user\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/internet\/2017-02-02-country-internet-infra\/": {
        
        "title": "互联网在农村-基础设施",
        "tags": ["闲谈乱扯",],
        "content": "说明 老家在安徽省安庆市的一个小山村里，作为一名互联网从业人员，这次回家特地花了一点心思来观察家乡的互联网应用情况。\n这是第一篇，先看农村互联网基础设施情况，上网要有电，要有接入网络，所以下面内容分为两个方面：\n 电 物理网络  电 电这一部分是我要大力吐槽的，拿除夕晚上来说，来电，断电，来电，断电。。。这样的循环至少五次，原因大概有下面这些：\n 功率不足，除夕晚上电视，家家晚上都把自己家的灯点亮（家乡的风俗习惯） 电工技能水平有限 农村电力基础本身就差 农村有一些人家的线程本身就有问题，例如老化，漏电，甚至还有偷电的行为  除此之外，发现大多数人对于服务质量也没有意识，对于突然的停电也习以为常，毕竟大部分一直在生活在这里，不知道外面的供电服务是什么情况。\n物理网络 物理网络分为两个方面来写吧：\n 固定宽带 移动网络  固定宽带 固定宽带基本在10年到17年这七年的时间实现从无到有，从ADSL到光纤接入的发展。了解情况如下：\n 接入方式：光纤接入与ADSL并存，新接入方式以光纤为准 网络速度：光纤接入可以达到50M，个人在家使用与在杭州感觉不到什么差异，相反网络还更好一些，这主要可能是开通网络人数不多吧 接入高可用性：在家这十天左右的时间内基本没有出现连接不上的情况 接入费用： 我家的套餐是1500包两年电信套餐，与城市相差无异 网络开通率：了解到一个40户左右的村民小组只有4户开通宽带，开通率才10%左右  移动网络 07年放假回家，当时号称移动信号最好的移动手机回家基本上没有信号，要选好位置，作好姿势才能蹭到黄冈的移动网络，发短信，收短信变成一个十分美好的事情，现在回想起来还能感觉到那一刻自己的心情的美好：有信号真好。慢慢地几年内（具体时间已经记不清楚了）移动基站来了，电信基站来了，联通基站也来了\n15-16两年4G商用，想想也知道，这里还是3G，移动网络的速度正如段子所说：\n 2G看苍井空.txt，3G看苍井空.jpg，4G看苍井空.avi\n 这里速度当然不利于农村互联网喜欢的视频应用的使用。\n总结 虽然农村基础设施大大落后城市，但是进步迅速，想想在2010年村里才刚开始有ADSL接入，到现在支持50M光纤接入，在网速方面与城市基本上没有区别。希望今后能够网络连接可靠性方面有较大的进步，这样一年当中有一段时间在老家工作也是不错的，空气好，安静适合思考，而且还能吃到妈妈做的美食。\n最后再说明，这是自己的片面之词，写出来仅是记录一下自己见到的一些真实情况，为以后观察提供一个参考。\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/internet\/2017-02-02-country-internet-infra\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E4%B8%8D%E8%BF%BD%E6%B1%82%E5%AE%8C%E7%BE%8E\/": {
        
        "title": "不追求完美，追求进步",
        "tags": ["life",],
        "content": "完美 完美是一个理想的状态,但在现实生活中很难达成。不同的人对完美有不同的理解:\n  无错误。从客观角度,完美代表一种没有错误、瑕疵和Bug的状态。所有要素都处于最佳状况,没有任何改进的空间。但在复杂系统中要达成这种完美几乎是不可能的。\n  最优解。从目标角度,完美代表一种能达成目标或任务的最佳结果或最优解。所有资源和条件都被最理想地运用和调配。但现实生活中有太多变数,很难作出最优的选择。\n  主观满意。从个人角度,完美更多代表一种主观上的满足或达成感。当个人的愿望、期待和需求被满足时,会感到很完美。但不同人的需求不同,完美标准也随之不同。\n  最高境界。从哲学角度,完美代表一种最高的境界或理想状态。诸如“真、善、美”都可被视为完美,但这些理想很难在现实生活中充分实现。人类只能不断追求,但很难达到。\n  整体优化。从系统角度,完美代表一种全局最优的状态。各个系统要素高度协调,相互配合,整体效能最大化。但任何系统都有其复杂性,要优化到完美程度也属于理想。\n  综上,完美是一个人类永恒追求但很难达成的理想状态。从不同视角,完美可以理解为没有错误、最优解、主观满意、最高境界或整体优化等,但现实生活中的种种复杂性都使得完美变得遥不可及。人类只能不断逼近完美,但永远无法达到完全完美,这也给生活带来动力。完美永远是一种距离感和追求的过程。\n不追求完美   完美是很难具体清晰的定义。完美是一个主观概念,每个人对完美的理解都不同,很难给出一个客观清晰且被广泛接受的定义,这使得追求完美变得无序和模糊。\n  完美往往性价比差。追求完美需要投入大量资源,但收益并不成正比。根据帕累托法则,追求绝对完美的收益是递减的,而成本是递增的,这导致性价比下降。\n  完美是不必要的。大多数情况下,不完美也能满足需求。追求完美带来的边际效用并不高,所以从实用角度完美是不必要的。这符合功利主义观点。\n  完美导致拖延,影响行动。追求完美会不断改进与修正,难以达成结束点,这会产生拖延现象,延缓行动与实现。现实生活需要及时行动。\n  完成与拥有胜过完美。一个不完美的产品或结果,只要可以完成任务并带来实际效用,就已经胜过一件永远无法实现的完美设想。这符合实用主义思想。\n  完美可能是不存在的。就连宇宙这种高度复杂的系统,也难以达到绝对完美的状态。真实世界中,各种不确定因素的存在决定了完美可能永远也不可达成,它只存在于思维的理想境界中。完美就像数学里面无穷大与无穷小一样，你永远不知道它的值到底是多少？\n  追求进步   进步可以实现,完美不可及。进步是一个相对概念,可以通过持续努力逐步实现,而完美是一个绝对概念,现实生活中很难达成。所以进步是一个现实的目标,完美更像一种理想。\n  进步可以持续提高,完美无法衡量。进步度可以通过各种标准进行衡量和评价,并不断提高,而完美作为一种理想状态,很难给出客观衡量标准,无法判断是否真的达到完美。\n  进步可以满足需求,完美不实用。适度的进步可以满足大多数实际需求,实现比较理想的结果,而追求完美带来的收益是递减的,实用性较差。\n  进步促进行动,完美拖延行动。进步是一个渐进的过程,可以边行动边进步,而追求完美需要不断推翻重来,易产生拖延和行动滞后。\n  进步可以带来满足,完美只有距离感。实现一定进步可以带来成就感和满足,而完美作为一种永远无法达到的理想,只会带来无止境的距离感和不满足。\n  进步更科学合理。科学追求渐进改善,讲求实证与效果,而完美属于非理性和极端的思维方式。所以从科学角度来说,追求进步更加合理与适当。\n  综上,作为实用主义者,追求进步而非完美是更科学合理的选择。进步具有较强的实现性、可衡量性、实用性和结果导向性,能满足现实需求,不易拖延行动,更能带来成就感。而完美只是一个理想,科学和现实的思维方式不应追求不可达成的极端状态。所以,Done is better than perfect,但要不断进步,这才是积极实用的态度.\n", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E4%B8%8D%E8%BF%BD%E6%B1%82%E5%AE%8C%E7%BE%8E\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E4%BA%BA%E7%94%9F%E6%9C%89%E5%93%AA%E4%BA%9B%E5%A4%A7%E5%9D%91\/": {
        
        "title": "人生有哪些大坑",
        "tags": ["life",],
        "content": "背景 人生不如意十有八九。生活处处有坑，避免不踩坑不可能，但是还是要努力防止踩大坑。\n认知与心理  偏见、妄想等因素导致不能发现与尊重事实和规则 思维定势，错误地执念，拒绝改变，视野与格局打不开 盲目，盲从，懒惰，不能独立思考与验证 不知道什么是最重要的，没有明确的目标 不知道自己不知道，缺少敬畏 缺少长期心态与长远眼光，没有耐心，不能延迟满足  选择与环境  选择牺牲身体来赚钱 选错专业与行业 关键事件方面选错人来合作如结婚，创业等等 处于烂人的环境当中（如爱抱怨的工作同事，暗规则横行的工作氛围） 缺少对危险因素的洞察与风险控制(君子不立危墙之下)  行为与习惯  不思考，不学习，无进步 恶性循环（如赌博，混自己不喜欢的工作） 不自律，放纵自己 爱与别人比较 跟风与凑热闹 嫉妒 拖延并缺少执行力 只想不做，浅尝辄止，做事不到位 情绪不稳定，波动大，情绪冲动 重复犯相同的错误 拖延症  ", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E4%BA%BA%E7%94%9F%E6%9C%89%E5%93%AA%E4%BA%9B%E5%A4%A7%E5%9D%91\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E4%BA%94%E4%B8%AA%E9%97%AE%E9%A2%98%E6%89%BE%E5%88%B0%E7%9C%9F%E6%AD%A3%E8%A6%81%E6%83%B3%E7%9A%84\/": {
        
        "title": "五个问题帮你找到你真正的想要的",
        "tags": ["life",],
        "content": "问题 1. 你想要什么？ 2. 你有多想要它？ 3. 现在的你离你想要的有多远？ 4. 你能做什么来实现你想要的？ 5. 你开始行动吗？ ", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E4%BA%94%E4%B8%AA%E9%97%AE%E9%A2%98%E6%89%BE%E5%88%B0%E7%9C%9F%E6%AD%A3%E8%A6%81%E6%83%B3%E7%9A%84\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-09-10-from-cepoll-to-go-net\/": {
        
        "title": "从C语言epoll编程到go net实现分析",
        "tags": ["golang",],
        "content": "说明  go源码版本：1.7 go源码运行环境：Linux  epoll在c语言编程示例 先看一下大家比较熟悉的epoll在c语言中应用，代码取自rtmpserver_demo中的文件rtmpepollsrv.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179  int RtmpSessionHandle(int iFd, int iEvent, void *pContext) { int iRet; RTMP_SESSION *pSession = (RTMP_SESSION *)pContext; if(iEvent\u0026amp;EPOLLIN ) { if(0 == pSession-\u0026gt;handshake) { iRet = RtmpSessionHandshake(pSession); if(0 != iRet) { RtmpSessionHandleFin(pSession); } } else { iRet = RtmpPktHandle(pSession); } } if(iEvent \u0026amp; (EPOLLERR |EPOLLHUP) ) { RtmpSessionHandleFin(pSession); } return iRet; } int ListenHandle(int iFd, int iEvent, void *pContext) { int iNewFd; int iRet = 0; struct sockaddr tmpAddr; memset(\u0026amp;tmpAddr, 0, sizeof(tmpAddr)); int iSocketSize = sizeof(tmpAddr); EPOLL_CTX *pCtx; RTMP_SESSION *pServer; if(iEvent|EPOLLIN) { iNewFd = accept(iFd, \u0026amp;tmpAddr, (socklen_t *)\u0026amp;iSocketSize); if(RTMP_EPOLLSRV_INVALIDFD \u0026lt; iNewFd) { pServer = (RTMP_SESSION *)malloc(sizeof(RTMP_SESSION)); if(NULL == pServer) { return -1; } pServer-\u0026gt;handshake = 0; pCtx = (EPOLL_CTX *)malloc(sizeof(EPOLL_CTX)); if(NULL == pCtx) { free(pServer); return -1; } pServer-\u0026gt;socket = iNewFd; pCtx-\u0026gt;iFd = iNewFd; pCtx-\u0026gt;pContext = pServer; pCtx-\u0026gt;pfHandle = RtmpSessionHandle; /* 加入epoll */ iRet = epoll_op(g_iEpollFd, EPOLL_CTL_ADD, iNewFd, EPOLLIN|EPOLLERR|EPOLLHUP, pCtx); } else { printf(\u0026#34;accept errno:%s\u0026#34;,strerror(errno)); } } return iRet; } int epoll_op(int iEpollFd, int iOp, int iFd, int iEvent, EPOLL_CTX *pCtx) { int iRet; struct epoll_event ev; ev.events = iEvent; ev.data.ptr = pCtx; iRet = epoll_ctl(iEpollFd, iOp, iFd, \u0026amp;ev); return iRet; } int epoll_loop(int iEpollFd) { int iNum; struct epoll_event astEpEvent[RTMP_EPOLLSRV_MAXEPOLL]; int i; EpollCallBack_PF pfHandle; EPOLL_CTX *pCtx; for( ; ;) { iNum= epoll_wait(iEpollFd, \u0026amp;astEpEvent[0], RTMP_EPOLLSRV_MAXEPOLL, -1); if( 0 \u0026lt; iNum) { for(i = 0; i \u0026lt; iNum; i++) { pCtx = (EPOLL_CTX *)astEpEvent[i].data.ptr; pfHandle = pCtx-\u0026gt;pfHandle; (void)pfHandle(pCtx-\u0026gt;iFd, astEpEvent[i].events, pCtx-\u0026gt;pContext); } } else { printf(\u0026#34;epoll_wait failed\\r\\n\u0026#34;); } } return 0; } int main(void) { int iFd; struct sockaddr_in addr; printf(\u0026#34;in the main\\r\\n\u0026#34;); /* 初始化epoll */ g_iEpollFd = epoll_create(200); if(RTMP_EPOLLSRV_INVALIDFD \u0026gt;= g_iEpollFd) { printf(\u0026#34;create epoll failed\\r\\n\u0026#34;); return -1; } /* 创建侦听端口 */ iFd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); if(RTMP_EPOLLSRV_INVALIDFD \u0026gt;= iFd) { printf(\u0026#34;create listen socket failed\\r\\n\u0026#34;); return -1; } addr.sin_family = AF_INET; addr.sin_addr.s_addr = inet_addr(g_cRtmpSrvAddr); addr.sin_port = htons(g_usRtmpSrvPort); if( 0 != bind(iFd, (struct sockaddr *) \u0026amp;addr, sizeof(struct sockaddr_in))) { return -1; } if( 0 != listen(iFd, 200)) { return -1; } EPOLL_CTX *pEpollCtx = (EPOLL_CTX *)malloc(sizeof(EPOLL_CTX)); if(NULL == pEpollCtx) { return -1; } pEpollCtx-\u0026gt;iFd = iFd; pEpollCtx-\u0026gt;pfHandle = ListenHandle; pEpollCtx-\u0026gt;pContext = NULL; /* 加入epoll */ if(0 != epoll_op(g_iEpollFd, EPOLL_CTL_ADD, iFd, EPOLLIN|EPOLLERR|EPOLLHUP, pEpollCtx)) { return -1; } g_iListenFd = iFd; epoll_loop(g_iEpollFd); return 0; }   功能 上述代码代码主要通过epoll实现一个最基本的网络服务器（侦听一个端口，处理这个端口上连接）\n几个重要数据结构\n实现分析 简单说明如下：\n用下面的结构体EPOLL_CTX保存epoll的回调及异步处理的上下文\n1 2 3 4 5 6  typedef struct { int iFd; EpollCallBack_PF pfHandle; void *pContext; }EPOLL_CTX;   从面向过程编程角度简单梳理一下epoll相关的代码\n 创建epoll 加入epoll 进入epoll_loop,处理epoll事件  go 编程示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; ) const ( CONN_HOST = \u0026#34;localhost\u0026#34; CONN_PORT = \u0026#34;3333\u0026#34; CONN_TYPE = \u0026#34;tcp\u0026#34; ) func main() { // Listen for incoming connections.  l, err := net.Listen(CONN_TYPE, CONN_HOST+\u0026#34;:\u0026#34;+CONN_PORT) if err != nil { fmt.Println(\u0026#34;Error listening:\u0026#34;, err.Error()) os.Exit(1) } // Close the listener when the application closes.  defer l.Close() fmt.Println(\u0026#34;Listening on \u0026#34; + CONN_HOST + \u0026#34;:\u0026#34; + CONN_PORT) for { // Listen for an incoming connection.  conn, err := l.Accept() if err != nil { fmt.Println(\u0026#34;Error accepting: \u0026#34;, err.Error()) os.Exit(1) } // Handle connections in a new goroutine.  go handleRequest(conn) } } // Handles incoming requests. func handleRequest(conn net.Conn) { // Make a buffer to hold incoming data.  buf := make([]byte, 1024) // Read the incoming connection into the buffer.  reqLen, err := conn.Read(buf) if err != nil { fmt.Println(\u0026#34;Error reading:\u0026#34;, err.Error()) conn.Close() return } fmt.Printf(\u0026#34;recv:%s, len=%d\\n\u0026#34;, string(buf), reqLen) // Send a response back to person contacting us.  conn.Write([]byte(\u0026#34;Message received.\u0026#34;)) // Close the connection when you\u0026#39;re done with it.  conn.Close() }   对比  handleRequest代码对应c语言版本epoll回调，但是这个代码与业务逻辑很搭，读取报文，进行处理，返回结果这些操作可以同一个函数内（也就是同一个逻辑上面）实现，没有异步回调就是爽啊 go语言上编程上不需要看到epoll，也就没添加/删除epoll的操作 编程模型方面无论是原生的回调还是reactor模型，go语言更符合业务的逻辑，而不需要考虑epoll相关处理 够简洁明了，有着与c语言相当的性能，程序员们让我们一起go吧！  Go Net实现分析 通过以上对比，显而易见，go语言保证效率的情况，在易用性大大超过了c，那golang是如何实现的？下面具体分析golang的net库实现\ngoroutine调度时机 一般在以下四种情况下进行goroutine调度：\n channel收发 显示调用go函数 阻塞的系统调用，如read,write GC  epoll使用 先简单看一下各个epoll操作代码实现，先找到他们，再分析如何利用这些操作来完成简洁的网络编程\nepoll初始化 对应c语言版本的epoll_create，go语言版本在初始化在下面的代码中完成:\n1 2 3 4 5 6 7 8 9 10 11 12 13  func netpollinit() { epfd = epollcreate1(_EPOLL_CLOEXEC) if epfd \u0026gt;= 0 { return } epfd = epollcreate(1024) if epfd \u0026gt;= 0 { closeonexec(epfd) return } println(\u0026#34;netpollinit: failed to create epoll descriptor\u0026#34;, -epfd) throw(\u0026#34;netpollinit: failed to create descriptor\u0026#34;) }   将fd加入epoll 对应c语言版本的epoll_op，go语言版本在初始化在下面的代码中完成:\n1 2 3 4 5 6  func netpollopen(fd uintptr, pd *pollDesc) int32 { var ev epollevent ev.events = _EPOLLIN | _EPOLLOUT | _EPOLLRDHUP | _EPOLLET *(**pollDesc)(unsafe.Pointer(\u0026amp;ev.data)) = pd return -epollctl(epfd, _EPOLL_CTL_ADD, int32(fd), \u0026amp;ev) }   注意这里采用的边沿触发\n从epoll摘除fd 对应c语言版本的epoll_op，go语言版本在初始化在下面的代码中完成:\n1 2 3 4  func netpollclose(fd uintptr) int32 { var ev epollevent return -epollctl(epfd, _EPOLL_CTL_DEL, int32(fd), \u0026amp;ev) }   数据结构 pollDesc 结构体pollDesc用于关联fd与epoll，具体结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  // Network poller descriptor. // 每个添加到epoll中的fd都对应了一个PollDesc结构实例 type pollDesc struct { // 指向下一个pollDesc link *pollDesc // in pollcache, protected by pollcache.lock // The lock protects pollOpen, pollSetDeadline, pollUnblock and deadlineimpl operations. // This fully covers seq, rt and wt variables. fd is constant throughout the PollDesc lifetime. // pollReset, pollWait, pollWaitCanceled and runtime·netpollready (IO readiness notification) // proceed w/o taking the lock. So closing, rg, rd, wg and wd are manipulated // in a lock-free way by all operations. // NOTE(dvyukov): the following code uses uintptr to store *g (rg/wg), // that will blow up when GC starts moving objects. lock mutex // protects the following fields // 系统为socket分配的fd fd uintptr closing bool // 是否关闭 // 用于保护旧定时器和就绪的通知 seq uintptr // protects from stale timers and ready notifications // 网络io读状态，分为三种: 网络io就绪， 进入等待状态， 等待状态，此时rg保存等待goroutine实例的指针 rg uintptr // pdReady, pdWait, G waiting for read or nil rt timer // read deadline timer (set if rt.f != nil) // 读超时时间，单位为ns rd int64 // read deadline // 网络io写状态，分为三种: 网络io就绪， 进入等待状态， 等待状态，此时rg保存等待goroutine实例的指针 wg uintptr // pdReady, pdWait, G waiting for write or nil // 写超时时间，单位为ns wt timer // write deadline timer wd int64 // write deadline user uint32 // user settable cookie }   epoll操作封装 以初始化epoll及加入epoll为例，在下面的函数中完成的\n1 2 3 4 5 6 7 8 9 10 11 12  var serverInit sync.Once func (pd *pollDesc) init(fd *netFD) error { serverInit.Do(runtime_pollServerInit) ctx, errno := runtime_pollOpen(uintptr(fd.sysfd)) if errno != 0 { return syscall.Errno(errno) } pd.runtimeCtx = ctx return nil }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  func (fd *netFD) accept() (netfd *netFD, err error) { if err := fd.readLock(); err != nil { return nil, err } defer fd.readUnlock() var s int var rsa syscall.Sockaddr if err = fd.pd.prepareRead(); err != nil { return nil, err } for { s, rsa, err = accept(fd.sysfd) if err != nil { nerr, ok := err.(*os.SyscallError) if !ok { return nil, err } switch nerr.Err { case syscall.EAGAIN: if err = fd.pd.waitRead(); err == nil { continue } case syscall.ECONNABORTED: // This means that a socket on the // listen queue was closed before we // Accept()ed it; it\u0026#39;s a silly error, // so try again. continue } return nil, err } break } if netfd, err = newFD(s, fd.family, fd.sotype, fd.net); err != nil { closeFunc(s) return nil, err } // 调用上面函数加入epoll if err = netfd.init(); err != nil { fd.Close() return nil, err } lsa, _ := syscall.Getsockname(netfd.sysfd) netfd.setAddr(netfd.addrFunc()(lsa), netfd.addrFunc()(rsa)) return netfd, nil }   读处理 先从为Read代码开始\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  func (fd *netFD) Read(p []byte) (n int, err error) { if err := fd.readLock(); err != nil { return 0, err } defer fd.readUnlock() if len(p) == 0 { // If the caller wanted a zero byte read, return immediately // without trying. (But after acquiring the readLock.) Otherwise // syscall.Read returns 0, nil and eofError turns that into // io.EOF. // TODO(bradfitz): make it wait for readability? (Issue 15735) return 0, nil } if err := fd.pd.prepareRead(); err != nil { return 0, err } for { n, err = syscall.Read(fd.sysfd, p) if err != nil { n = 0 if err == syscall.EAGAIN { // 没有可读数据，进行读等待处理 if err = fd.pd.waitRead(); err == nil { continue } } } err = fd.eofError(n, err) break } if _, ok := err.(syscall.Errno); ok { err = os.NewSyscallError(\u0026#34;read\u0026#34;, err) } return }   具体分析读等待处理,跳过封装，直接分析处理代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  //go:linkname net_runtime_pollWait net.runtime_pollWait // 进入pollwait状态进行goroutine调度 func net_runtime_pollWait(pd *pollDesc, mode int) int { err := netpollcheckerr(pd, int32(mode)) if err != 0 { return err } // As for now only Solaris uses level-triggered IO. if GOOS == \u0026#34;solaris\u0026#34; { netpollarm(pd, mode) } // for !netpollblock(pd, int32(mode), false) { err = netpollcheckerr(pd, int32(mode)) if err != 0 { return err } // Can happen if timeout has fired and unblocked us, // but before we had a chance to run, timeout has been reset. // Pretend it has not happened and retry. } return 0 }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  // returns true if IO is ready, or false if timedout or closed // waitio - wait only for completed IO, ignore errors // 返回true表示IO就绪，返回false表示超时或者关闭 // waitio 表示是否等待IO,超时时该参数为false func netpollblock(pd *pollDesc, mode int32, waitio bool) bool { // 从pd.rg取指针 gpp := \u0026amp;pd.rg if mode == \u0026#39;w\u0026#39; { gpp = \u0026amp;pd.wg } // set the gpp semaphore to WAIT for { old := *gpp if old == pdReady { *gpp = 0 return true } if old != 0 { throw(\u0026#34;netpollblock: double wait\u0026#34;) } // cas 设置读状态为pdWait状态 if atomic.Casuintptr(gpp, 0, pdWait) { break } } // need to recheck error states after setting gpp to WAIT // this is necessary because runtime_pollUnblock/runtime_pollSetDeadline/deadlineimpl // do the opposite: store to closing/rd/wd, membarrier, load of rg/wg // 因为runtime_pollUnblock runtime_pollSetDeadline/deadlineimpl 将rg/wg状态修改为closing if waitio || netpollcheckerr(pd, mode) == 0 { gopark(netpollblockcommit, unsafe.Pointer(gpp), \u0026#34;IO wait\u0026#34;, traceEvGoBlockNet, 5) } // be careful to not lose concurrent READY notification old := atomic.Xchguintptr(gpp, 0) if old \u0026gt; pdWait { throw(\u0026#34;netpollblock: corrupted state\u0026#34;) } return old == pdReady }   总结  net网络库的设计的精华,良好的封装与接口,提高简单可靠的接口 充分利用goroutine机制 同步编程，异步执行，这一点其实在内核也能找到，只是调度机制不一样 多学习源码，这里面有精妙的设计，科学的框架 很多问题深入一下就到底层了 异步编程能够带来高性能，但是也是高要求，如果系统复杂，出现问题不好定位，同时代码的可读性也差 代码在满足正确性的基础上，应先追求可读性，规范性，高性能往后排  参考  How Goroutines Work  ", 
        "url": "http:\/\/myself659.github.io\/post\/2016-09-10-from-cepoll-to-go-net\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-08-20-go-channel-program-demo\/": {
        
        "title": "Go channel 编程篇",
        "tags": ["golang",],
        "content": "本篇以ChanBroker版本迭代过程，总结常见Channel编程问题\n简介 ChanBroker设计主要参考Kafka模型，主要提供进程内goroutine之间通信，实现以下功能：\n 支持多个Publisher发布内容 支持Subscriber注册与去注册订阅 发布内容可以是任何形式 ChanBroker根据订阅情况完成内容推送  版本1 具体代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68  package ChanBroker type Content interface{} type Subscriber chan Content type ChanBroker struct { RegSub chan Subscriber UnRegSub chan Subscriber Contents chan Content Stop chan bool Subscribers map[Subscriber]bool } func NewChanBroker() *ChanBroker { ChanBroker := new(ChanBroker) ChanBroker.RegSub = make(chan Subscriber) ChanBroker.UnRegSub = make(chan Subscriber) ChanBroker.Contents = make(chan Content) ChanBroker.Stop = make(chan bool) ChanBroker.Subscribers = make(map[Subscriber]bool) ChanBroker.run() return ChanBroker } func (self *ChanBroker) run() { go func() { // Broker goroutine  for { select { case content := \u0026lt;-self.Contents: for sub := range self.Subscribers { sub \u0026lt;- content } case sub := \u0026lt;-self.RegSub: self.Subscribers[sub] = true case sub := \u0026lt;-self.UnRegSub: delete(self.Subscribers, sub) close(sub) case \u0026lt;-self.Stop: for sub := range self.Subscribers { delete(self.Subscribers, sub) close(sub) } return } } }() } func (self *ChanBroker) RegSubscriber() Subscriber { sub := make(Subscriber) self.RegSub \u0026lt;- sub return sub } func (self *ChanBroker) UnRegSubscriber(sub Subscriber) { self.UnRegSub \u0026lt;- sub } func (self *ChanBroker) StopPublish() { self.Stop \u0026lt;- true } func (self *ChanBroker) PubContent(c Content) { self.Contents \u0026lt;- c }   存在以下问题，具体如下：\n问题1：不支持扩展 问题描述：\n在一个Broker goroutine内完成注册与去注册以及内容发布推送给Subscriber，无法控制Subscriber数量，且不支持扩展\n解决思路：\n主要修改如下：\n 增加Pusher goroutine，Pusher goroutine支持动态创建，由Pusher goroutine完成具体内容的推送  问题2： 推送内容到Subscriber存在Deadlock风险 问题描述：\n例如一个Subscriber不能正确从通道接收订阅内容，那么Broker会阻塞在上述代码的34行，与此同时其他Subscriber都会阻塞，极有可能引起级联阻塞，影响恶劣\n解决思路：\n主要修改如下：\n 支持Subscriber可以定制订阅通道的大小，利用队列缓存内容 增加Pusher goroutine，避免由于某个内容的推送导致整个内容推送的阻塞 增加超时机制，避免在具体内容推送过程由于某一个Subscriber不正常工作影响其他的Subscriber  问题3： Broker goroutine退出后调用RegSubscriber，UnRegSubscriber，StopPublish，PubContent函数存在Deadlock风险 问题描述：\n如题\n解决思路：\n主要修改如下：\n ChanBroker增加退出状态描述，避免Broker goroutine退出之后上述函数向Broker goroutine 的channel发送信息  版本2 具体代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109  package ChanBroker import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) type Content interface{} type Subscriber chan Content type ChanBroker struct { RegSub chan Subscriber UnRegSub chan Subscriber Contents chan Content Stop chan bool exit bool Subscribers map[Subscriber]bool lock sync.RWMutex timeout time.Duration } func NewChanBroker(timeout time.Duration) *ChanBroker { ChanBroker := new(ChanBroker) ChanBroker.RegSub = make(chan Subscriber) ChanBroker.UnRegSub = make(chan Subscriber) ChanBroker.Contents = make(chan Content) ChanBroker.Stop = make(chan bool) ChanBroker.exit = false ChanBroker.Subscribers = make(map[Subscriber]bool) ChanBroker.timeout = timeout ChanBroker.run() return ChanBroker } func (self *ChanBroker) run() { go func() { // Broker goroutine  for { select { case content := \u0026lt;-self.Contents: go func() { // Pusher goroutine  self.lock.RLock() for sub := range self.Subscribers { select { case sub \u0026lt;- content: case \u0026lt;-time.After(self.timeout): fmt.Println(sub, \u0026#34;time out \u0026#34;) } } self.lock.RUnlock() }() case sub := \u0026lt;-self.RegSub: self.lock.Lock() self.Subscribers[sub] = true self.lock.Unlock() case sub := \u0026lt;-self.UnRegSub: self.lock.Lock() delete(self.Subscribers, sub) self.lock.Unlock() close(sub) // may be close of closed channel  case \u0026lt;-self.Stop: if self.exit == false { self.exit = true close(self.Stop) self.lock.Lock() for sub := range self.Subscribers { delete(self.Subscribers, sub) // 必须先删除再close  close(sub) } self.lock.Unlock() return // exit goroutine  } } } }() } func (self *ChanBroker) RegSubscriber(size uint) Subscriber { if self.exit == true { return nil } sub := make(Subscriber, size) self.RegSub \u0026lt;- sub // maybe block  return sub } func (self *ChanBroker) UnRegSubscriber(sub Subscriber) { if self.exit == true { return } self.UnRegSub \u0026lt;- sub // maybe block } func (self *ChanBroker) StopPublish() { if self.exit == true { return } self.Stop \u0026lt;- true // maybe panic } func (self *ChanBroker) PubContent(c Content) { self.Contents \u0026lt;- c // maybe block }   存在以下问题，具体如下：\n问题1：存在 panic:close of closed channel的风险 问题描述：\n如果Subscriber goroutine两次调用UnRegSubscriber，就会发生close of closed channel，导致panic\n相应代码如下：\n1 2 3 4 5  case sub := \u0026lt;-self.UnRegSub: self.lock.Lock() delete(self.Subscribers, sub) self.lock.Unlock() close(sub) // may be close of closed channel   解决思路：\n很简单，关闭前检查Subscriber对应channel是否订阅map当中，代码如下：\n1 2 3 4 5 6 7 8  case sub := \u0026lt;-self.UnRegSub: self.lock.Lock() _, ok := self.Subscribers[sub] if ok { delete(self.Subscribers, sub) close(sub) } self.lock.Unlock()   问题2：不靠谱的exit标记 问题描述：\nexit标记不能同步goroutines对Stop通道的写操作与关闭操作，具体分析如下：\n写操作代码如下：\n1 2 3 4 5 6 7 8  func (self *ChanBroker) RegSubscriber(size uint) Subscriber { if self.exit == true { return nil } sub := make(Subscriber, size) self.RegSub \u0026lt;- sub // maybe block return sub }   关闭操作代码段如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  case \u0026lt;-self.Stop: if self.exit == false { self.exit = true close(self.Stop) self.lock.Lock() for sub := range self.Subscribers { delete(self.Subscribers, sub) // 必须先删除再close close(sub) } self.lock.Unlock() return // exit goroutine }   在多核多个goroutine并发情况，极小概率会发生如下情况：\n 某同一个时刻，CPU0 运行RegSubscriber goroutine检查exit标记为false，CPU0继续运行，CPU1运行到关闭操作代码段第1行，继续运行 CPU0 继续运行RegSubscriber goroutine，直到阻塞在第6行, 切换运行其他goroutine，CPU 1 关闭Stop Channel,并退出broken goroutine CPU0 继续运行其他goroutine，RegSubscriber goroutine一直阻塞在第6行,等待 broken goroutine 读Stop channel CPU0 继续执行其他goroutine，RegSubscriber goroutine一直阻塞在第6行，,等待 broken goroutine 读Stop channel CPU0 继续执行其他goroutine，RegSubscriber goroutine一直阻塞在第6行，,等待 broken goroutine 读Stop channel \u0026hellip;  解决思路：\n不用exit标记了，将状态关联到Stop Channel状态上（这又掉到另一个坑里）\n问题3：不能保证Subscribers有序的接收消息 问题描述：\n版本2中每接收一个Content都会启动一个Push goroutine,这些Push goroutine执行是无序执行的，有序的内容推送需求遇上了无序的goroutine，自然有问题了\n解决思路：\n方案1：无序推送，由Content自身加上序号，同时由各个Subscriber处理逻辑根据序号保证有序处理Content\n方案2：每一个Subcriber有一个Content队列，保证有序推送，简化各个Subscriber处理逻辑，具体实现见版本5\n版本3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159  package ChanBroker import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) type Content interface{} type Subscriber chan Content type ChanBroker struct { RegSub chan Subscriber UnRegSub chan Subscriber Contents chan Content Stop chan bool exit bool Subscribers map[Subscriber]bool lock sync.RWMutex timeout time.Duration } var errBrokerExit error = errors.New(\u0026#34;Broker exit\u0026#34;) var errTimeOut error = errors.New(\u0026#34;Time out\u0026#34;) func NewChanBroker(timeout time.Duration) *ChanBroker { ChanBroker := new(ChanBroker) ChanBroker.RegSub = make(chan Subscriber) ChanBroker.UnRegSub = make(chan Subscriber) ChanBroker.Contents = make(chan Content) ChanBroker.Stop = make(chan bool) ChanBroker.exit = false ChanBroker.Subscribers = make(map[Subscriber]bool) ChanBroker.timeout = timeout ChanBroker.run() return ChanBroker } func (self *ChanBroker) run() { go func() { for { select { case content := \u0026lt;-self.Contents: go func() { self.lock.RLock() for sub := range self.Subscribers { select { case sub \u0026lt;- content: case \u0026lt;-time.After(self.timeout): fmt.Println(sub, \u0026#34;time out \u0026#34;) } } self.lock.RUnlock() }() case sub := \u0026lt;-self.RegSub: self.lock.Lock() self.Subscribers[sub] = true self.lock.Unlock() case sub := \u0026lt;-self.UnRegSub: self.lock.Lock() _, ok := self.Subscribers[sub] if ok { delete(self.Subscribers, sub) close(sub) } self.lock.Unlock() case \u0026lt;-self.Stop: close(self.Stop) self.lock.Lock() for sub := range self.Subscribers { delete(self.Subscribers, sub) close(sub) } self.lock.Unlock() return // exit goroutine  } } }() } func (self *ChanBroker) RegSubscriber(size uint) (Subscriber, error) { select { case _, ok := \u0026lt;-self.Stop: if ok == false { return nil, errBrokerExit } else { sub := make(Subscriber, size) self.RegSub \u0026lt;- sub return sub, nil } case \u0026lt;-time.After(self.timeout): return nil, errTimeOut default: sub := make(Subscriber, size) self.RegSub \u0026lt;- sub return sub, nil } } func (self *ChanBroker) UnRegSubscriber(sub Subscriber) { select { case _, ok := \u0026lt;-self.Stop: if ok == false { return } else { self.UnRegSub \u0026lt;- sub return } case \u0026lt;-time.After(self.timeout): return default: self.UnRegSub \u0026lt;- sub return } } func (self *ChanBroker) StopPublish() { select { case _, ok := \u0026lt;-self.Stop: if ok == false { return } else { self.Stop \u0026lt;- true return } default: self.Stop \u0026lt;- true return } } func (self *ChanBroker) PubContent(c Content) error { select { case _, ok := \u0026lt;-self.Stop: if ok == false { return errBrokerExit } else { self.Contents \u0026lt;- c return nil } case \u0026lt;-time.After(self.timeout): return errTimeOut default: self.Contents \u0026lt;- c return nil } }   存在以下问题，具体如下：\n问题1： 读channel出现错误的竞争 问题描述：\n版本3的一个错误的方案选择，导致Stop Channel出现读竞争，导致不能停止发布，出现goroutine leak，分析如下：\n Stop Channel 只会写一次 Stop Channel 却有多个读goroutine 基于上面有情况，并不能保证Broker goroutine 能收到停止发布的信息，如果被其他goroutine收到，导致Broker goroutine收不到结束消息，进而不能关闭所有Subscriber，导致所有Subscriber goroutine泄露  解决思路：\n版本3引入关闭状态是一个错误的设计，引入状态，也就引入对依赖状态的对象，增加了代码的复杂性，状态的维护容易导致bug，在设计与代码应当追求无状态设计（好处多多）, 这里采用超时来解决，如果超时用由调用者确定处理策略\n版本4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128  package ChanBroker import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) type Content interface{} type Subscriber chan Content type ChanBroker struct { RegSub chan Subscriber UnRegSub chan Subscriber Contents chan Content Stop chan bool exit bool Subscribers map[Subscriber]bool lock sync.RWMutex timeout time.Duration } var errBrokerExit error = errors.New(\u0026#34;ChanBroker exit\u0026#34;) var errTimeOut error = errors.New(\u0026#34;ChanBroker Time out\u0026#34;) func NewChanBroker(timeout time.Duration) *ChanBroker { ChanBroker := new(ChanBroker) ChanBroker.RegSub = make(chan Subscriber) ChanBroker.UnRegSub = make(chan Subscriber) ChanBroker.Contents = make(chan Content) ChanBroker.Stop = make(chan bool) ChanBroker.exit = false ChanBroker.Subscribers = make(map[Subscriber]bool) ChanBroker.timeout = timeout ChanBroker.run() return ChanBroker } func (self *ChanBroker) run() { go func() { for { select { case content := \u0026lt;-self.Contents: go func() { self.lock.RLock() for sub := range self.Subscribers { select { case sub \u0026lt;- content: case \u0026lt;-time.After(self.timeout): fmt.Println(sub, \u0026#34;time out \u0026#34;) } } self.lock.RUnlock() }() case sub := \u0026lt;-self.RegSub: self.lock.Lock() self.Subscribers[sub] = true self.lock.Unlock() case sub := \u0026lt;-self.UnRegSub: self.lock.Lock() _, ok := self.Subscribers[sub] if ok { delete(self.Subscribers, sub) close(sub) } self.lock.Unlock() case \u0026lt;-self.Stop: // close(self.Stop)  self.lock.Lock() for sub := range self.Subscribers { delete(self.Subscribers, sub) close(sub) } self.lock.Unlock() return // exit goroutine  } } }() } func (self *ChanBroker) RegSubscriber(size uint) (Subscriber, error) { sub := make(Subscriber, size) select { case \u0026lt;-time.After(self.timeout): return nil, errTimeOut case self.RegSub \u0026lt;- sub: return sub, nil } } func (self *ChanBroker) UnRegSubscriber(sub Subscriber) { select { case \u0026lt;-time.After(self.timeout): return case self.UnRegSub \u0026lt;- sub: return } } func (self *ChanBroker) StopPublish() error { select { case self.Stop \u0026lt;- true: return nil case \u0026lt;-time.After(self.timeout): return errTimeOut } } func (self *ChanBroker) PubContent(c Content) error { select { case \u0026lt;-time.After(self.timeout): return errTimeOut case self.Contents \u0026lt;- c: return nil } }   存在以下问题，具体如下：\n问题1：timeout问题 问题描述：\n timeout 导致长时间持有读锁 timeout 导致消息丢失，并没有推送成功 上一个Subscriber超时影响后面Subscriber内容的实时性  解决方案：\n 采用select实现channel非阻塞写 对于非阻塞写失败，加入Subscriber对应的链表 非阻塞写保证避免Subscribers之间相互影响  问题2：锁问题 问题描述：\n 每个Pusher goroutine持有读锁，一定情况下会成为性能的瓶颈  解决方案：\n 在上面避免阻塞的基础上，只有一个goroutine来推送内容  版本5 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194  package ChanBroker import ( \u0026#34;container/list\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;time\u0026#34; ) type Content interface{} type Subscriber chan Content type ChanBroker struct { regSub chan Subscriber unRegSub chan Subscriber contents chan Content stop chan bool subscribers map[Subscriber]*list.List timeout time.Duration cachenum uint timerChan \u0026lt;-chan time.Time } var ErrBrokerExit error = errors.New(\u0026#34;ChanBroker exit\u0026#34;) var ErrPublishTimeOut error = errors.New(\u0026#34;ChanBroker Pulish Time out\u0026#34;) var ErrRegTimeOut error = errors.New(\u0026#34;ChanBroker Reg Time out\u0026#34;) var ErrStopPublishTimeOut error = errors.New(\u0026#34;ChanBroker Stop Publish Time out\u0026#34;) func NewChanBroker(timeout time.Duration) *ChanBroker { Broker := new(ChanBroker) Broker.regSub = make(chan Subscriber) Broker.unRegSub = make(chan Subscriber) Broker.contents = make(chan Content) Broker.stop = make(chan bool, 1) Broker.subscribers = make(map[Subscriber]*list.List) Broker.timeout = timeout Broker.cachenum = 0 Broker.timerChan = nil Broker.run() return Broker } func (self *ChanBroker) onContentPush(content Content) { for sub, clist := range self.subscribers { loop := true for next := clist.Front(); next != nil \u0026amp;\u0026amp; loop == true; { cur := next next = cur.Next() select { case sub \u0026lt;- cur.Value: if self.cachenum \u0026gt; 0 { self.cachenum-- } clist.Remove(cur) default: loop = false } } len := clist.Len() if len == 0 { select { case sub \u0026lt;- content: default: clist.PushBack(content) self.cachenum++ } } else { clist.PushBack(content) self.cachenum++ } } if self.cachenum \u0026gt; 0 \u0026amp;\u0026amp; self.timerChan == nil { timer := time.NewTimer(self.timeout) self.timerChan = timer.C } } func (self *ChanBroker) onTimerPush() { for sub, clist := range self.subscribers { loop := true for next := clist.Front(); next != nil \u0026amp;\u0026amp; loop == true; { cur := next next = cur.Next() select { case sub \u0026lt;- cur.Value: if self.cachenum \u0026gt; 0 { self.cachenum-- } clist.Remove(cur) default: loop = false } } } if self.cachenum \u0026gt; 0 { timer := time.NewTimer(self.timeout) self.timerChan = timer.C } else { self.timerChan = nil } } func (self *ChanBroker) run() { go func() { // Broker Goroutine  for { select { case content := \u0026lt;-self.contents: self.onContentPush(content) case \u0026lt;-self.timerChan: self.onTimerPush() case sub := \u0026lt;-self.regSub: clist := list.New() self.subscribers[sub] = clist case sub := \u0026lt;-self.unRegSub: _, ok := self.subscribers[sub] if ok { delete(self.subscribers, sub) close(sub) } case _, ok := \u0026lt;-self.stop: if ok == true { close(self.stop) } else { if self.cachenum == 0 { return } } self.onTimerPush() for sub, clist := range self.subscribers { if clist.Len() == 0 { delete(self.subscribers, sub) close(sub) } } } } }() } func (self *ChanBroker) RegSubscriber(size uint) (Subscriber, error) { sub := make(Subscriber, size) select { case \u0026lt;-time.After(self.timeout): return nil, ErrRegTimeOut case self.regSub \u0026lt;- sub: return sub, nil } } func (self *ChanBroker) UnRegSubscriber(sub Subscriber) { select { case \u0026lt;-time.After(self.timeout): return case self.unRegSub \u0026lt;- sub: return } } func (self *ChanBroker) StopPublish() error { select { case self.stop \u0026lt;- true: return nil case \u0026lt;-time.After(self.timeout): return ErrStopPublishTimeOut } } func (self *ChanBroker) PubContent(c Content) error { select { case \u0026lt;-time.After(self.timeout): return ErrPublishTimeOut case self.contents \u0026lt;- c: return nil } }   存在以下问题，具体如下：\n问题1：不支持扩展 问题描述：\n在一个Broker goroutine内完成注册与去注册以及内容发布推送给Subscriber，无法控制Subscriber数量，且不支持扩展\n解决思路：\n 业务场景：chanbroker是进程内goroutines之间pub-sub通信方式一种实现方案，一个goroutine占用一个核来处理能满足绝太多数需求 即使不能满足极个别需求，也可以选择创建多个ChanBroker来实现扩展  channel编程总结  避免Panic，参考Go channel 特点篇 最大程度保证非阻塞 若非业务需要，避免channel之间读写竞争 channel使用很灵活，也容易出错，建议多在设计上下功夫，分解问题采用简单的模型来解决问题 避免多余的channel状态引入,例如关闭channel 要有并发意识，由代码想到goroutine的运行 禁止通道复用，避免复用带来的复杂性 初期测试很重要，而且应作到充分测试 Don\u0026rsquo;t communicate by sharing memory, share memory by communicating  由于个人水平有限，有什么不足与错误，敬请指正！\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-08-20-go-channel-program-demo\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-08-05-im-user-state\/": {
        
        "title": "IM后端系统设计总结(2)",
        "tags": ["Arch",],
        "content": "这篇具体写一下用户在线状态系统的具体设计。\n后端架构 这个后端系统设计如下图：\n很大众，国内基本都这么干，不多说\n用户状态系统设计 初期设计 单IDC部署，设计如下:\n相关说明  AG：接入网关，负责用户的连接 ConnRouter：连接路由服务器，主要提供以下功能：   所有用户状态的维护 用户状态查询 用户状态推送 用户状态同步 异步消息路由与转发  状态通知流: 用户登录成功或者下线状态通知 状态同步流：ConnRouter服务器之间用户状态的同步，不需要推送给订阅者 用户消息流: 异步发送给用户的消息在服务器内部的传输  设计要点  参考Kafka的模型，将用户状态改变作为事件，将事件描述为消息，将消息队列化成消息队列 AG对应Kafka中的Producer角色，主要原因是用户状态是用户连接的影子，AG能真实快速感知用户状态 ConnRouter对应Kafka中的Broker UserStat（用户统计与分析）与StateNotify（用户状态通知）对应Kafka中的Consumer 减少耦合，以异步发送消息到用户为例，整个流程三步走：   第一步：生成发送消息，发送到ConnRouter 第二步：根据目的用户ID，查找到出口AG，将消息转发到出口AG 第三步：出口AG查找用户连接，通过连接发送到目的用户  ConnRouter设计 用户状态数据存储设计 用户状态数据存储设计，如下图所示：\n 内存消耗 主要内存消耗来自用户状态数组（与ConnRouter连接都是长连接，可以忽略不计） 每种客户端类型下每个用户占用一个1Byte，那么1G内存可以存1073741824个用户的状态，超过了10亿，支持亿级用户内存不是瓶颈 查找用户所在AG与状态O(1)  高可用性  服务器级Master-Master模式 根据用户ID选择ConnRouter Master实现用户级Master-Standby模式  高性能  epoll事件驱动 无锁数据访问 流程无阻塞 O(1)查找 多核并发 支持批量处理  支持Failover，方便升级  当ConnRouter宕机或者主动升级重启时，各AG重新建立连接时，将自身的用户状态同步到ConnRouter，完成用户状态数据恢复  无状态与单点自治  ConnRouter用户状态数据是各个AG的同步，真正用户状态保存在AG网关 单点可以独立工作  数据冲突处理 主要是一个数据优先级的原则（根据数据源，从高到低）：\n 状态数据来自AG 状态数据来自ConnRouter-Master 状态数据来自ConnRouter-Standby 状态数据来自RouterProxy  支持多IDC 保证更高可用性，需要支持多机房部署，实现两城三中心甚至更多节点异地多活，具体设计如下图：\n这里主要是引入了RouterProxy，将跨IDC ConnRouter连接起来，其中RouterProxy主要功能如下：\n 作为Producer同步状态通知到其他IDC RouterProxy 作为Comsumer接收同步状态发布到本IDC的ConnRouter 作为IDC间消息转发的网关  ConnRouter扩展 随着用户量增长，ConnRouter转发消息量，状态通知量，消息转发量都会不断增长，当然可以简单采用更好机器来scale up;下面是考虑进行业务拆分方式进行scale out，具体设计如下图： 从上图可知主要方案：\n 将异步消息转发业务拆分出来由Forward服务器来完成 将RouterProxy跨IDC消息转发业务拆分出来，由ForwardProxy服务器来完成  不足与应对  需要优化跨IDC间消息同步与转发流量 在大量用户且系统中存在多个状态维护服务器，这样会有大量的状态同步通信，服务器的网络与CPU易成为瓶颈 这时候就考虑将用户状态进行拆分，不将用户状态放到同一个服务器上维护，采用以下方式进行用户状态数据划分：   哈希方式 用户ID范围 按用户量划分 一致性hash  后记 方案可以有很多种，觉得引入直接引入Kafka是一个很好的选择，以后再研究。\n由于个人水平有限，有什么不足与错误，敬请指正！\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-08-05-im-user-state\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-07-29-im-message\/": {
        
        "title": "IM后端系统设计总结(1)",
        "tags": ["Arch",],
        "content": "定义IM 为用户提供即时消息服务，这里面有三个关键词：用户，消息，服务；下面根据三个关键词来展开总结，先从消息开始。\n消息 消息分类 对消息分类，很简单但是重要，方便后面业务的拆分。\n 注册 登录 用户信息 聊天消息 群组 好友 文件 版本 内部服务器之间消息 客户端诊断 其他业务消息  信息语义描述 在互联网和移动互联网时代常见有以下几种方式：\n XML 文本 MQTT 自定义二进制（这里一般默认为google protobuf）  这四种类型比较如下表所示：\n   比较项 XML 文本 MQTT 自定义二进制     可读性 好 好 差 差   通用性 标准协议，易通用 支持通用http协议，也可自定义 通用标准协议 私有协议，无法通用   扩展性 易扩展，支持第三方 易扩展 可扩展 仅协议可扩展，不支持第三方   流量消耗 极大 大 小 小   处理效率 低 一般 高 高   网络适应性 差 一般 较好 较好   业内应用 新浪微博/GTalk MSN facebook messenger QQ/weixin    再补充说一点，采用二进制协议，在网络带宽及消息存储方面可以节约成本，特别用户量达到千万级以上\n参考业内应用和移动互联网需求，二进制协议应该是不二选择。这里强烈推荐google protobuf，理由如下：\n 亲爹是google 支持多种编程语言(C++, JAVA, PYTHON, GO，PHP,C#)，支持多种平台 自定义且灵活 支持数据压缩 完整的技术生态，以及多年的应用实践  消息可扩展性 自定义二进制消息（google protobuf）可扩展性方面的一些经验：\n 采用T(ype)L(ength)V(alue) 数据结构中的成员不要使用变长数据类型，例如long，在32位系统中占4Bytes，在64位系统占用8Bytes 不删除消息体的数据成员 消息类型递增，不删除消息类型，即使不再使用也保留 消息头带上版本号，客户端无需要关心版本变化，由服务器完成不同版本的兼容适配处理 消息头与消息体的设计统一管理，不允许任何人私自修改 除非确定，protobuf消息字段尽量使用optional，由代码逻辑确定是否需要相应字段 考虑业务需求与变化，为未来留有应对变化的空间，同时保证消息的简洁  消息存储  初期简单点，采用mysql，同时利用mysql主备部署解决单点故障问题，分布式存储后面再说了，针对大量的消息存储后面考虑 对用户之间的聊天消息分表 对群信息等利用redis缓存 对于热点数据可以直接加载到内存  消息转发  消息从用户到用户（单播） 消息从用户到服务器 （单播） 消息从用户到群组 （组播） 消息从服务器到用户（单播） 消息从服务器到群组（组播）  消息传输 相对于PC互联网情况下，移动互联网情况下，丢包概率高，传输延迟大，问题自然就比较多，这方面优化请参考手机QQ的移动网络实践之路\n消息安全  防修改 消息检查或校验 防窃听 消息加密 防泄漏 系统防入侵，系统加固 防丢失 消息请求与回应机制，消息重传与幂等性 防损坏 多副本，分布式存储 防伪装 身份验证，签名  消息描述 消息由消息头和消息体组成，消息头参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12  #pragma pack(1) typedef struct { uint16_t type; // msg type uint16_t length; // the whole pdu length uint32_t version; // pdu version number uint32_t magic; // magic number uint32_t reserve; //后面为消息体 } UserPduHeader_t; #pragma pack()   后记 由于个人水平有限，有什么不足与错误，敬请指正！\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-07-29-im-message\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-07-26-go-channel-feature\/": {
        
        "title": "Go channel 特点篇",
        "tags": ["golang",],
        "content": "channel模式 根据同步方式不同，channel有两种模式：\n1、同步模式,形式如下：\n1  ch := make(chan int)   2、队列模式，形式如下：\n1  ch := make(chan int, 10)   根据数据方向流不同，channel类型可以有以下三种模式：\n 写操作模式（只发送） 读操作模式（只接收） 读写操作模式（不限发送与接收）  channel操作 channel有以下操作：\n 创建 关闭 写(发送)操作 读(接收)操作  这些操作都是原子操作\nchannel状态 根据模式与操作，channel有以下状态：\n 同步写阻塞 同步读阻塞 关闭状态 队列写阻塞 队列读阻塞 队列可读写 nil状态  channel状态与操作之间关系    状态/操作 写操作 读操作 关闭 创建     nil状态 写阻塞 写阻塞 产生panic(close of nil channel) -   同步写阻塞 写阻塞 成功读取数据 进入关闭状态，产生panic -   同步读阻塞 成功写入数据 读阻塞 进入关闭状态 -   关闭状态 产生panic 立即返回(nil，false) 产生panic -   队列写阻塞 写阻塞 成功读取队列中数据 进入关闭状态，成功写入队列的数据可读 -   队列读阻塞 成功写入数据 读阻塞 进入关闭状态 -   队列可读写 成功写入数据 成功读取数据 进入关闭状态，成功写入队列的数据可读 -    由于个人水平有限，有什么不足与错误，敬请指正！\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-07-26-go-channel-feature\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/how-to-start-%E5%BC%80%E5%A7%8B\/": {
        
        "title": "如何开始行动",
        "tags": ["学习","成长",],
        "content": "背景 人们常说：\n  万事开头难。\n  好的开始是成功的一半。\n   “The secret of getting ahead is getting started. The secret of getting started is breaking your complex overwhelming tasks into small manageable tasks, and starting on the first one.” — Mark Twain\n 从上可知开始很难，但是开始却很重要。\n为什么是开始行动 行动是实践。\n行动是执行力的体现。\n行动是真正的学习（纸上得来终觉浅，绝知此事要躬行）。\n行动是知行合一的关键（我们懂了很多道理，却依然过不好这一生）。\n所以开始行动是启动实践第一步。\n所以开始行动是打造执行力。\n所以开始行动是开始学习。\n所以开始行动是追求知行合一。\n如何开始行动 思考先行 行动之前先思考：\n what 做什么行动？ why 为什么要行动？ who 与谁一起行动？ when 什么时候行动？ where 在哪行动？ how 怎么行动？  准备 不打没有准备的仗，行动之前一定要做好准备，但是也不存在100%准备好。如果做什么事情都需要100%准备好，那么你将不会开始做任何事情，因为你会一直在准备。\n准备是不可少，但不过度准备。\n开始Tips   尽量早开始\n  从容易的开始，从小的开始，从最基础的开始，从能完成的开始\n  为开始建立触发器Trigger\n  降低开始的难度\n  为开始建立shortcut\n  利用习惯开始\n  为开始建立势头Momentum，利用势头开始\n  自动化开始\n  为开始设置deadline\n  有意识地主动开始\n  挑战5分钟的不舒服\n  开始行动吧 凡事只有开始行动,才有可能。\n凡事只有开始行动,才有收获。\n凡事只有开始行动,才有进步。\n开始行动吧,让过去不再成为遗憾,让将来不再成为憧憬，让现在不再迷茫，让自己享受当下。\n", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/how-to-start-%E5%BC%80%E5%A7%8B\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/arch\/2016-06-02-10-lessons-from-10-years-of-amazon-web-services\/": {
        
        "title": "10 Lessons from 10 Years of Amazon Web Services（译文）",
        "tags": ["Arch",],
        "content": "前言  亚马逊在2006年3月14日发布AWS，到现在差不多10年了。回首过去的10年里，我们在构建 安全，高可用性，可扩展性，低成本的服务方面积累了几百条经验与教训。 由于AWS是建设并在全球运营这些服务的先驱，这些教训对我们的业务至关重要。正如我们以前多次说，“没有压缩经验的算法”，每月有超过百万的活跃客户，这些客户服务几个亿的用户，在这个过程我们不乏机会积累经验并持续优化从而为客户提供更好的服务。\n  我选择了下面这些经验教训，与大家分享，希望它们对你们有用。\n 1. 构建不断进化的系统  几乎从第一天开始,我们知道自己开发的软件在一年后将不会继续运行。我们需要重新审视和改进架构，以确保我们可以解决订单规模增长一到二个数量级所带来的问题。但是我们不能采取停电检修这种旧方法升级系统，这是因为遍布世界各地的海量业务需要我们的平台提供7*24小时高可用性服务。我们需要建立这样架构：能够在不停止服务的情况下引入新的组件。Marvin Theimer,亚马逊杰出工程师，曾开玩笑地说，亚马逊S3的演变可以被描述为从当初的单引擎飞机，随着时间的推移飞机不断升级，先是升级到737，然后是一组747，现在成了3805的空中舰队。在此期间，我们在飞行过程中完成加油，而客户甚至没有觉察到这一点。\n 感悟： 唯有变化才是确定，系统应该保证灵活性与扩展性。云计算系统是需要不断进化，开发人员也需要不断进化\n2. 总有想不到的  异常总是会发生的，随着时间的推移，一切都会出现异常：从路由器到硬盘，从操作系统到内存单元，从瞬态错误到永久性故障。无论你使用的是最高品质的硬件或最低成本的硬件，这些总是会发生的。在大规模系统中更是如此，例如，在S3中处理和存储的万亿交易，任何异常，即使是最小的可能性也将成为现实。部分这样的异常可以事先预见的，但更多的异常却在设计和开发过程中未能被发现。\n  我们需要开发一个视异常为常态的系统，即使我们不知道会有什么样的异常。即使“房子着火了”，系统也需要保持运行。重要的是在整个系统在不宕机的情况下能够处理这些异常。我们掌握隔离异常与控制异常的影响范围的方法从而使整个系统能够正常运行。\n 感悟：异常是常态，如何处理异常是系统设计阶段必须考虑到的问题。\n3. 提供基元而不是框架  我们很快意识到，客户的需求是不断变化的。当客户摆脱传统的IT硬件和数据中心的限制，他们开始使用感兴趣却没有应用过的模式搭建系统。因此，我们努力做到超级敏捷以确保满足客户的需求。\n  其中一个最重要的策略是向客户提供的基元和工具，让客户从中选择最合适他们的集合，而不是只提供一个框架中，迫使他们不得不使用。这种做法使我们的客户取得了成功，其后的AWS服务也同样利用这些客户已经熟悉的基础服务。\n  同样重要的是我们不知道客户下一个关心问题是什么，直到他们开始使用我们的服务。这就是为什么我们经常用最少的功能集提供新的服务，让我们的客户能够帮助推动产品路线图规划与新功能的开发。\n 感悟： 客户的需求是下一个产品。立足基础，理解客户的需求，才能满足客户。\n4. 自动化是关键  提供云计算服务不同于开发并交付软件，管理大规模系统需要不同的思维方式，以确保满足用户的高可用性，高性能和可扩展性的需求。\n  这其中关键的一点是尽可能地实现自动化管理以避免容易出错的手动操作。要做到这一点，我们需要实现管理API从而管理我们的业务的关键功能。AWS可以帮助客户做到这一点。通过为应用程序的每一个分解组件提供管理API，从而应用自动化的规则来保证可靠性和预期的性能。\n  如果你需要SSH到一个服务器或一个实例，那么你仍然需要更多的自动化，这是一个衡量自动化水平的好方法。\n 感悟： 用人管理代码，用代码管理机器\n5. APIs are forever（API是不会变的）  这是我们从亚马逊零售业务经验中吸取的教训，它的重要性甚至超过了AWS中那些以API为中心的业务。\n  一旦客户开始使用我们的API构建他们的应用程序和系统，改变这些API变得不可能，因我们修改这些API,会影响客户的业务运营。我们只有一次机会定义API,所以设计API是一个非常重要的工作。\n 感悟： 接口优先，实现其次，实现可以调整，而接口一旦上线就没有什么回旋的余地。\n6. 监控资源应用  当构建一个服务，一定要有服务及其运营成本的数据以确定相应的计费方式，尤其是对于运行高营业额-低利润率的业务。AWS理所应当关注服务的成本，这样我们在为客户的提供服务的同时能够明确在哪些地方可以提高运营效率，以进一步削减成本，以更低的价格回馈客户。\n  在创业初期，我们不知道S3服务应该采用哪种计费方式：我们曾认为应该对存储和带宽资源计费;经过一段时间，我们认识到请求的数量也应当计费。如果客户有许多微小的文件，即使他们上百万次数请求服务，消耗的存储和带宽都不会很高。我们不得不针对资源使用各个维度调整计费方式使AWS成为是一个可持续发展的业务。\n 感悟： 无监控不系统，无度量不优化。 作任何商业服务不仅要有成本意识，而且应该作到度量成本。\n7. 从一开始集成安全  保护你的客户应该永远是你的首选，对于AWS来说亦是如此。不管运营的角度，还是策略方面，这将永远是我们的头号投资领域。\n  我们很快地发现只有在一开始就把安全考虑进去才能提供安全的服务。安全团队的工作不是服务开发完成之后进行验证，他们必须在服务设计的第一天确认安全已经落实，且稳如泰山。总之对于安全，没有任何妥协。\n 感悟： 安全是基本功能。\n8. 加密是一等公民  加密是为确保客户能控制谁有权访问他们的数据一个关键机制。十年前，加密工具和服务很难使用，直到几年前我们学会更好地将加密集成到我们的服务当中。最早的加密是从S3服务端开始的。如果您想检查我们的数据中心的任何磁盘，任何数据都不可访问的。但随着亚马逊推出CloudHSM（硬件安全模块）和Amazon Key Management Service（密钥管理服务），客户可以加密自己的密钥，从而不再需要AWS来管理钥匙。一段时间以来，每个新服务均支持加密。例如，Amazon Redshift的每个数据块默认以随机密钥加密，随后这些随机密钥被私钥再加密。私钥由客户提供，确保他们是唯一可以解密和访问他们的关键业务数据或个人身份信息。\n  加密仍然是我们业务的重点。我们将继续为我们的客户提供更加便捷的加密方式，使他们能够更好地保护自己及其客户的数据。\n 感悟：一定不要让核心数据裸奔。\n9. 网络相当重要的  AWS已经支持许多不同类型业务：大规模的事务处理，大规模网站流量，视频转码，高性能并行计算。其中每个业务具有独特的要求，但都涉及到网络。\n  利用AWS特有的数据中心技术，我们实现了弹性网络以满足客户的各种不同网络负载。随着时间的推移，我们确信自己开发的硬件解决方案能够帮助客户实现他们的目标。这使我们能够满足非常具体的要求，比如实现不同AWS用户在网络方面达到最高级别的安全（也就是实现不同租户之间的网络隔离）。\n  AWS设计的网络硬件和软件是如何进一步提高我们的客户性能的另一个成功的例子是解决虚拟机的虚拟网络访问的问题。由于网络接入是不同客户共享的，导致客户的网络访问时常有明显的抖动。开发一个支持SRIOV网卡让每个虚拟机拥有自身的虚拟网卡，从而使延迟时间降低2倍以上，并在延迟网络环境的改善超过10倍。\n 感悟： 网络是服务的交付与实现的交通运输线，重要性不言而喻。传统网络难以满足云计算的需求，所以以SDN与NFV为基础的新网络技术会得到广泛的应用，但是这些技术很有可能是由云计算厂商自己开发利用，而不是由思科等传统网络设备商决定的，因为云计算厂商更需要这样的技术也更理解云计算对网络的需求。云计算厂商也有决心来作这件事：既然网络需求会不断变化，那应该将变化掌握在自己手中，另一方面，云计算作为未来长期存在的互联网基础设施，从长远来看网络产品的自研也可以节省一大笔成本。\n10. 保持开放  随着时间的推移，AWS团队通过提供多种服务和功能已经为客户创造了非常广泛而深入的平台。AWS上现有服务数量远远超过我们开发的服务数量：通过我们的合作伙伴，该平台不断扩展新的方向，已经成为一个丰富的生态系统。\n  例如，我们合作伙伴Stripe在AWS上为Twilio提供支付服务。还有许多客户基于AWS构建自己的平台服务于特定垂直需求：飞利浦正在建设自己的Healthsuite数字平台来管理医疗数据，Ohpen已经建立了AWS零售银行业务的平台，Eagle Genomics已经建立了一个基因处理平台，还有很多。最重要的是，目前在AWS平台上没有条条框框告诉我们的合作伙伴，他们可以做什么和不能做什么。 没有条条框框的限制解放了创新，并诞生了许多意想不到的发明，这是一定要遵循的。\n 感悟： 云计算提供开放平台，让百花齐放！ 云计算是互联网的基础的设施！\n后记 这是亚马逊CTO Werner Vogels在AWS发布十年之际写的一篇文章，亚马逊是云计算的先驱和全球的领导者，作为亚马逊CTO还常写一些技术性文章，必定是真知灼见，这些经验教训为今后的系统设计提供了很好的参考，有助于权衡决策。\n第一次翻译一篇完整的文章，表达与措词方面有很多不足，把它发出来了，主要想看看以后能取得多大的进步。\n最后，虽然翻译水平一般，但是还是建议：有时间结合工作认真地读一遍原文\n参考  10 Lessons from 10 Years of Amazon Web Services AWS Key Management Service Amazon Redshift AWS CloudHSM  ", 
        "url": "http:\/\/myself659.github.io\/post\/arch\/2016-06-02-10-lessons-from-10-years-of-amazon-web-services\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/arch\/2016-05-27-facebook-live-detail\/": {
        
        "title": "Facebook live一些技术细节",
        "tags": ["Arch",],
        "content": "协议选择 最初选择HLS,后面切换为RTMP，切换为RTMP主要为了降低延迟，提供更好直播用户体验。\n解决并发问题  分发架构\n采用Live stream server， origin server， edge server 三层架构；如下图如示： ![分发架构图](/images/facebook live arch.png)  一句话就是：通过遍布各地的CDN节点（edge server）实现海量用户的播放请求。\n 请求合并应对高并发 采用的CDN方案，应对一般数量级的播放是没有问题，但是facebook上有很多名人与网红，他们每个人都有几百万个粉丝，这就要求facebook live 直播系统能够处理超过一亿人同时播放的能力。假如一个名人的直播有100万粉丝同时观看，edge server缓存命中率为98%，那么未命中用户为2万，这2万用户回源到origin server甚至回源到Live stream server，服务器压力可想而知，这不是2W个连接而已，而是2W个视频播放，带宽，cpu都是一个很大的考验。用数字说话，以带宽为例； 假设一个HLS切片为3S，高清视频码率为1800K bps，那么一秒带宽需求为：  1  20K /3 *1800K b/s * 1s = 20*600 Mb = 12 Gb   每秒的带宽超过10Gb，服务器网卡高配也才10Gb。\n业务驱动方案，其具体解决方案如下： 在edge server 对同一个视频切片的多人cache miss请求进行合并，只发送一个到 origin server，待origin server 返回该视频切片，同时发送给该视频切片的所有请求。这样就可以大量减少回源的请求数量。origin server亦是如此。\n想到下面的问题：\n 最近520，林心如与霍建华在微博宣布恋爱关系，微博是怎么搞定推送信息众粉丝的呢？ 一个直播有100W在线观看，如何实现海量消息的转发？\n 既然想到了，以微博为例写一下自己的方案：\n 微博消息是一种pub-sub模型，简单的在问题的场景下林心如这样明星是pub，粉丝是sub，粉丝数量是7000W 微博发布了，如何发送到7000W粉丝？不可能直接将立即将消息推送到各个粉丝，不可能是一个推模型，瞬间大并发写与大量存储都会有问题，可能是拉模型吗？拉模型好处只写一条微博，新上线的用户会主动拉取订阅（关注）用户的发布的微博；僵尸用户，活不过来用户，睡眠用户是可以忽略的，怎么触发在线用户主动获取关注的人的动态保证消息的实时性呢？ 在用户线用户定时获取更新，例如60秒定时获取订阅用户是否有更新，这是一个很大的开销，假如微博有2000W同时在线，那么一秒有30多W个拉取更新的请求，每个请求都会查询订阅用户的微博，虽然可以承受的，但是代价还是很大的，同时这种定时拉取会消耗用户的流量，长期下来用户是无法忍受的，所以在线用户拉取是不可行的 对于在线用户采用推消息，7000W粉丝假设有5%用户在线，那在线粉丝为350W，如果在60S内完成，那一秒要完成60W个推送（发送60W个包，更新60W个用户订阅微博信息），如果整个系统只处理这一件事，是可以的，但是微博大V多，假如1分钟有10个类似的情况，同时也还有其他在线千万级用户（数据是乱猜的）; 系统容量是有限的，总会出现抗不住的情况的，墨菲定律告诉我们：这种情况总会发生的，只是我们不知道什么时候会发生。 抗住是目的，这时候需要作好监控，限流，扩容，降级服务保证核心功能 针对粉丝数量超过1000W以上的大V进行特殊处理  实现RTMP 选择基于nginx rtmp改造，并开发rtmp proxy，采用nginx rtmp有如下好处：\n nginx拥有一个良好的技术生态 nginx的多进程模型能够充分分挥多核cpu的能力 nginx rtmp已经有大量的应用，基本功能可靠 nginx rtmp是基于c语言实现，有良好的性能，当有大量的节点部署的情况下，可以省一大批服务器，能够节省一大笔成本  个人水平有限，若有不妥与错误，欢迎指正，谢谢！\n参考  Under the hood: Broadcasting live video to millions  ", 
        "url": "http:\/\/myself659.github.io\/post\/arch\/2016-05-27-facebook-live-detail\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-05-21-git-cmd\/": {
        
        "title": "git常用命令总结",
        "tags": ["Linux",],
        "content": "配置  config user  1 2  git config --global user.email \u0026#34;you@example.com\u0026#34; git config --global user.name \u0026#34;Your Name\u0026#34;   Ignore Git permission changes  1  git config core.fileMode false   Fix .gitignore  1  git rm -r --cached .   git仓库  初始化一个版本仓库  1  git init   clone远程版本库  1  git clone git@github.com:myself659/FFmpeg.git   添加远程版本库origin  1  git remote add origin git@github.com:myself659/rtmpserver_demo.git   查看远程仓库信息  1  git remote -v   删除远程仓库  1  git remote rm \u0026lt;repository\u0026gt;   git修改  添加当前修改的文件到暂存区  1  git add .   提交修改到本地  1  git commit -m \u0026#34;fix bug 0001\u0026#34;   提交修改到远程  1  git push -u origin master   查看修改状态  1  git status   重命名文件  1  git mv README readme   从版本库中删除文件  1  git rm readme   取消对文件修改  1  git checkout -- readme   修改最新一次修改注释  1  git commit amend   显示所有提交  1  git show   1  git show \u0026lt;commit\u0026gt; --stat   1  git show \u0026lt;commit\u0026gt; -- \u0026lt;filepath\u0026gt;   恢复最后一次提交的状态  1  git revert HEAD   恢复某次提交的状态  1  git revert \u0026lt;$id\u0026gt;   Remove untracked files \u0026amp; directories  1 2 3 4  # To remove untracked files git clean -f # TO remove untracked directories git clean -fd   git log  查看修改log  1  git log   查看指定文件每次提交记录  1  git log \u0026lt;filename\u0026gt;   查看最近两次详细修改内容的diff  1  git log -p -2   查看提交统计信息  1  git log --stat   Move a commit from one branch to another  1  git cherry-pick COMMIT-HASH   查看项目各个成员提交代码统计  1  git log --format=\u0026#39;%aN\u0026#39; | sort -u | while read name; do echo -en \u0026#34;$name\\t\u0026#34;; git log --author=\u0026#34;$name\u0026#34; --pretty=tformat: --numstat | awk \u0026#39;{ add += $1; subs += $2; loc += $1 - $2 } END { printf \u0026#34;added lines: %s, removed lines: %s, total lines: %s\\n\u0026#34;, add, subs, loc }\u0026#39; -; done   git log graph  1  git log --graph --format=format:\u0026#39;%C(bold blue)%h%C(reset) - %C(bold green)(%ar)%C(reset) %C(white)%an%C(reset)%C(bold yellow)%d%C(reset) %C(dim white)- %s%C(reset)\u0026#39; --all   git分支  查看远程分支  1  git branch -r   创建新分支  1  git branch \u0026lt;new_branch\u0026gt;   1  git checkout -b NEW-BRANCH-NAME   查看各分支创建最后提交信息  1  git branch -v   删除指定分支  1  git branch -d \u0026lt;branch_name\u0026gt;   强制删除指定分支  1  git branch -D \u0026lt;branch_name\u0026gt;   查看已经被合并到当前分支的分支  1  git branch --merged   查看尚未被合并到当前分支的分支  1  git branch --no-merged   合并分支  1  git merge \u0026lt;merge_branch\u0026gt;   切换分支  1  git checkout \u0026lt;branch_name\u0026gt; -f   抓取远程仓库所有分支更新并合并到本地  1  git pull   抓取远程仓库所有分支更新并合并到本地，不要快进合并  1  git pull --no-ff   抓取远程仓库更新  1  git fetch origin   push所有分支  1  git push   将本地主分支推到远程主分支  1  git push origin master   将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库)  1  git push -u origin master   创建远程分支  1  git push origin \u0026lt;local_branch\u0026gt;:\u0026lt;remote_branch\u0026gt;   查看所有分支名称  1  git branch --all   check branch status  1  git status   rename local branch  1  git branch -m OLD-BRANCH-NAME NEW-BRANCH-NAME   rename remote branch  1  git push origin :OLD-BRANCH-NAME NEW-BRANCH-NAME   Delete a branch on a remote repository  1  git push REMOTE-NAME --delete BRANCH-NAME   clean git branches exclude main and master  1  git branch | grep -v \u0026#34;master\u0026#34; | grep -v \u0026#34;main\u0026#34; | grep -v ^\\* | xargs git branch -D;   git diff  比较当前文件和暂存区文件差异  1  git diff \u0026lt;file\u0026gt;   比较两次提交之间的差异  1  git diff \u0026lt;$id1\u0026gt; \u0026lt;$id2\u0026gt;   比较两个分支  1  git diff \u0026lt;branch1\u0026gt; \u0026lt;branch2\u0026gt;   比较统计信息  1  git diff --stat   提交git diff  How to Include Diff into Git Commit Message\n1 2 3 4 5 6 7 8 9 10 11 12 13  #!/bin/bash  COMMIT_MSG_FILE=$1 COMMIT_SOURCE=$2 SHA1=$3 RESULT=\u0026#34;# Differences to be committed:\u0026#34; while IFS= read -r line do RESULT+=\u0026#34;$IFS# $line\u0026#34; done \u0026lt;\u0026lt;\u0026lt; $(git diff --staged) echo \u0026#34;$RESULT\u0026#34; \u0026gt;\u0026gt; $COMMIT_MSG_FILE   misc  提交文件超过100M  1  git filter-branch -f --index-filter \u0026#34;git rm -rf --cached --ignore-unmatch slides/tt.sql\u0026#34; -- --all   提交代码到新分支  创建新分支  1  git checkout -b feature-43   添加修改  1  git add .   提交修改到本地  1  git commit -m \u0026#34;f43\u0026#34;   将本地修改推送到指定分支  1  git push origin feature-43   丢弃本地修改 1  git reset --hard \u0026lt;the sha1 hash\u0026gt;   Reset to the last commit 1  git reset -hard origin/BRANCH-NAME   拉取所有分支 1  git pull --all   1 2 3 4  #!/bin/bash for branch in $(git branch --all | grep \u0026#39;^\\s*remotes\u0026#39; | egrep --invert-match \u0026#39;(:?HEAD|master)$\u0026#39;); do git branch --track \u0026#34;${branch##*/}\u0026#34; \u0026#34;$branch\u0026#34; done   1 2 3 4 5 6 7 8 9  #!/bin/sh # Usage: fetchall.sh branch ... set -x git fetch --all for branch in \u0026#34;$@\u0026#34;; do git checkout \u0026#34;$branch\u0026#34; || exit 1 git rebase \u0026#34;origin/$branch\u0026#34; || exit 1 done   查看远程git地址 1  git config --get remote.origin.url   merge 1 2  git checkout feature git merge master   将当前分支合并到原来master分支。\nrebase 1 2  git checkout feature git rebase master   将master后面的修改合并到当前分支，将当前分支作为个人开发master分支。\n跳转到根目录 1 2 3  gitroot(){ cd $(git rev-parse --show-toplevel 2\u0026gt; /dev/null) }   gitstart 1 2  mkdir your-project gitstart go   ", 
        "url": "http:\/\/myself659.github.io\/post\/2016-05-21-git-cmd\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-04-17-linux-kernel-crashs\/": {
        
        "title": "Linux内核常见crash原因",
        "tags": ["Linux",],
        "content": "前言 与前同事交流，发现以前的技术经历与解决的问题，现在接触不多，但是想想还是很有意思，虽然很多细节现在已经不能表达出来或展示出来，但是还得写出来。下面写的得主要个人经历的linux内核crash原因。\n内存类 这一类同用户态类似，主要有以下几种情况，\n 访问NULL 访问释放后的内存 非法访问内存 内存被踩 内存耗尽 野指针操作  堆栈类  内核调用栈溢出 写坏调用栈  锁  死锁 rcu使用错误 锁内存被写坏 长期获取不到锁，导致看门狗饿死，狗叫重启  调度  线程陷入死循环或者长时间占用cpu，在非抢占模式下其他线程得不到调度  中断上下文  在中断上下文调用错误的函数，例如在中断上下文使用信号量，更多参考那些可进入睡眠状态的Linux内核函数  硬件故障 在系统运行过程出现硬件故障也会导致内核crash。接触较少，不作说明。\n后记 能力有限，条件有限，写的很虚，也不全面，以后有机会再来点实际的，这个目的主要是回忆总结自己的知识体系。\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-04-17-linux-kernel-crashs\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-03-09-x86-64-call-stack\/": {
        
        "title": "Linux x86-64 函数调用栈实例分析",
        "tags": ["Linux",],
        "content": "前言 动手实践并写文章花5倍的时间一次性把事情做到90分，好过读别人文章只能做到60分，后面还需要花时间继续深入学习(做事情一定要做到有效的阈值)。本文目的希望通过分析一个简单的函数调用加深对x86-64寄存器及栈帧的结构的认识，以便在定位问题需要的时候能够熟练运用。\n环境 1.操作系统和内核\n1 2  [root@localhost ~]# cat /proc/version Linux version 3.10.0-229.4.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) ) #1 SMP Wed May 13 10:06:09 UTC 2015   2.GCC版本\n1 2 3 4 5 6 7 8  [root@localhost ~]# gcc -v Using built-in specs. COLLECT_GCC=gcc COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/4.8.3/lto-wrapper Target: x86_64-redhat-linux Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-linker-hash-style=gnu --enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto --enable-plugin --enable-initfini-array --disable-libgcj --with-isl=/builddir/build/BUILD/gcc-4.8.3-20140911/obj-x86_64-redhat-linux/isl-install --with-cloog=/builddir/build/BUILD/gcc-4.8.3-20140911/obj-x86_64-redhat-linux/cloog-install --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux Thread model: posix gcc version 4.8.3 20140911 (Red Hat 4.8.3-9) (GCC)   3.GDB版本\n1 2 3 4 5 6 7 8 9 10  [root@localhost ~]# gdb --version GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-64.el7 Copyright (C) 2013 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \u0026#34;show copying\u0026#34; and \u0026#34;show warranty\u0026#34; for details. This GDB was configured as \u0026#34;x86_64-redhat-linux-gnu\u0026#34;. For bug reporting instructions, please see: \u0026lt;http://www.gnu.org/software/gdb/bugs/\u0026gt;.   GDB 分析调用栈 1. 准备代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  #include \u0026lt;stdio.h\u0026gt; int sum(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, int a9) { int s = 0xaaaa; s = a1+a2+a3+a4+a5+a6+a7+a8+a9; return s; } void caller(void) { int iRet = 0x0; iRet = sum(0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99); printf(\u0026#34;sum: %x\\r\\n\u0026#34;, iRet); } int main(void) { caller(); return 0; }   2. 生成可执行文件 1 2 3  [root@localhost cpp]# gcc -g stackexample.c -o stackexample [root@localhost cpp]# ./stackexample sum: 2FD   3. 分析调用栈 主要通过gdb分析调用栈变化情况\n3.1 初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  Breakpoint 1, main () at stackexample.c:22 warning: Source file is more recent than executable. 22 caller(); Missing separate debuginfos, use: debuginfo-install glibc-2.17-78.el7.x86_64 (gdb) info registers rax 0x4005e6 4195814 rbx 0x0 0 rcx 0x400600 4195840 rdx 0x7fffffffe518 140737488348440 rsi 0x7fffffffe508 140737488348424 rdi 0x1 1 rbp 0x7fffffffe420 0x7fffffffe420 rsp 0x7fffffffe420 0x7fffffffe420 r8 0x7ffff7dd5e80 140737351868032 r9 0x0 0 r10 0x7fffffffe270 140737488347760 r11 0x7ffff7a3ba00 140737348090368 r12 0x400440 4195392 r13 0x7fffffffe500 140737488348416 r14 0x0 0 r15 0x0 0 rip 0x4005ea 0x4005ea \u0026lt;main+4\u0026gt; eflags 0x246 [ PF ZF IF ] cs 0x33 51 ss 0x2b 43 ds 0x0 0 es 0x0 0 fs 0x0 0 ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- gs 0x0 0 (gdb)   栈内存（堆栈向下生长）:\n1 2 3 4 5 6 7 8 9 10 11 12  rbp 0x7fffffffe420 0x7fffffffe420 rsp 0x7fffffffe420 0x7fffffffe420 0x7fffffffe428 +------------------+ | | rbp-\u0026gt;0x7fffffffe420 +------------------+ \u0026lt;-rsp | | 0x7fffffffe218 +------------------+ | | 0x7fffffffe210 +------------------+ | | 0x7fffffffe208 +------------------+   3.2 调用caller 寄存器信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  (gdb) s caller () at stackexample.c:14 14 int iRet = 0x0; (gdb) info registers rax 0x4005e6 4195814 rbx 0x0 0 rcx 0x400600 4195840 rdx 0x7fffffffe518 140737488348440 rsi 0x7fffffffe508 140737488348424 rdi 0x1 1 rbp 0x7fffffffe410 0x7fffffffe410 rsp 0x7fffffffe3e0 0x7fffffffe3e0 r8 0x7ffff7dd5e80 140737351868032 r9 0x0 0 r10 0x7fffffffe270 140737488347760 r11 0x7ffff7a3ba00 140737348090368 r12 0x400440 4195392 r13 0x7fffffffe500 140737488348416 r14 0x0 0 r15 0x0 0 rip 0x40058a 0x40058a \u0026lt;caller+8\u0026gt; eflags 0x202 [ IF ] cs 0x33 51 ss 0x2b 43 ds 0x0 0 es 0x0 0 fs 0x0 0 ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- gs 0x0 0 (gdb) x /6gx 0x7fffffffe3e0 0x7fffffffe3e0: 0x0000000000000001 0x000000000040064d 0x7fffffffe3f0: 0x0000000000000000 0x0000000000000000 0x7fffffffe400: 0x0000000000400600 0x0000000000400440 (gdb) (gdb) x /12gx 0x7fffffffe3e0 0x7fffffffe3e0: 0x0000000000000001 0x000000000040064d 0x7fffffffe3f0: 0x0000000000000000 0x0000000000000000 0x7fffffffe400: 0x0000000000400600 0x0000000000400440 #小端系统，前8位存储iRet的值 0x7fffffffe410: 0x00007fffffffe420 0x00000000004005ef 0x7fffffffe420: 0x0000000000000000 0x00007ffff7a3baf5 0x7fffffffe430: 0x0000002000000000 0x00007fffffffe508 (gdb) (gdb) p iRet $3 = 0 (gdb) p \u0026amp;iRet $4 = (int *) 0x7fffffffe40c #局部变量在堆栈的位置   栈内存（堆栈向下生长）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  rbp 0x7fffffffe410 0x7fffffffe410 rsp 0x7fffffffe3e0 0x7fffffffe3e0 0x7fffffffe428 +------------------+ | | 0x7fffffffe420 +------------------+ |0x00000000004005ef| #保存返回main的指令地址,参考汇编代码 0x7fffffffe418 +------------------+ |0x00007fffffffe420| #保存main函数对应rbp rbp --\u0026gt;0x7fffffffe410 +------------------+ | | 0x7fffffffe408 +------------------+ | | 0x7fffffffe400 +------------------+ | | 0x7fffffffe3f8 +------------------+ | | 0x7fffffffe3f0 +------------------+ | | 0x7fffffffe3e8 +------------------+ | | rsp --\u0026gt;0x7fffffffe3e0 +------------------+   main函数的汇编代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  (gdb) disassemble /m main Dump of assembler code for function main: 21 { 0x00000000004005e6 \u0026lt;+0\u0026gt;: push %rbp 0x00000000004005e7 \u0026lt;+1\u0026gt;: mov %rsp,%rbp 22 caller(); 0x00000000004005ea \u0026lt;+4\u0026gt;: callq 0x400582 \u0026lt;caller\u0026gt; 23 24 return 0; 0x00000000004005ef \u0026lt;+9\u0026gt;: mov $0x0,%eax #调用caller返回后执行的指令地址 25 } 0x00000000004005f4 \u0026lt;+14\u0026gt;: pop %rbp 0x00000000004005f5 \u0026lt;+15\u0026gt;: retq End of assembler dump. (gdb)   3.3调用sum 寄存器信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  Breakpoint 2, sum (a1=17, a2=34, a3=51, a4=68, a5=85, a6=102, a7=119, a8=136, a9=153) at stackexample.c:6 6 int s = 0x0; (gdb) info registers rax 0x4005e6 4195814 rbx 0x0 0 rcx 0x44 68 #第四个参数 rdx 0x33 51 #第三个参数 rsi 0x22 34 #第二个参数 rdi 0x11 17 #第一个参数 rbp 0x7fffffffe3d0 0x7fffffffe3d0 rsp 0x7fffffffe3d0 0x7fffffffe3d0 r8 0x55 85 #第五个参数 r9 0x66 102 #第六个参数 r10 0x7fffffffe270 140737488347760 r11 0x7ffff7a3ba00 140737348090368 r12 0x400440 4195392 r13 0x7fffffffe500 140737488348416 r14 0x0 0 r15 0x0 0 rip 0x400548 0x400548 \u0026lt;sum+24\u0026gt; eflags 0x202 [ IF ] cs 0x33 51 ss 0x2b 43 ds 0x0 0 es 0x0 0 fs 0x0 0 ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- gs 0x0 0 (gdb)   caller对应汇编代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  (gdb) disassemble /m caller Dump of assembler code for function caller: 13 { 0x0000000000400582 \u0026lt;+0\u0026gt;: push %rbp #保存调用函数main的rbp 0x0000000000400583 \u0026lt;+1\u0026gt;: mov %rsp,%rbp #将上一个栈顶指针作为本函数的栈底（设置当前函数的栈基址） 0x0000000000400586 \u0026lt;+4\u0026gt;: sub $0x30,%rsp #分配栈空间 14 int iRet = 0x0; 0x000000000040058a \u0026lt;+8\u0026gt;: movl $0x0,-0x4(%rbp) 15 16 iRet = sum(0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99); 0x0000000000400591 \u0026lt;+15\u0026gt;: movl $0x99,0x10(%rsp) #第9个参数 0x0000000000400599 \u0026lt;+23\u0026gt;: movl $0x88,0x8(%rsp) #第8个参考 0x00000000004005a1 \u0026lt;+31\u0026gt;: movl $0x77,(%rsp) #第7个参数 0x00000000004005a8 \u0026lt;+38\u0026gt;: mov $0x66,%r9d #第6个参数 0x00000000004005ae \u0026lt;+44\u0026gt;: mov $0x55,%r8d #第5个参数 0x00000000004005b4 \u0026lt;+50\u0026gt;: mov $0x44,%ecx #第4个参数 0x00000000004005b9 \u0026lt;+55\u0026gt;: mov $0x33,%edx #第3个参数 0x00000000004005be \u0026lt;+60\u0026gt;: mov $0x22,%esi #第2个参数 0x00000000004005c3 \u0026lt;+65\u0026gt;: mov $0x11,%edi #第1个参数 0x00000000004005c8 \u0026lt;+70\u0026gt;: callq 0x400530 \u0026lt;sum\u0026gt; #调用函数sum 0x00000000004005cd \u0026lt;+75\u0026gt;: mov %eax,-0x4(%rbp) #取返回值 ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- 17 printf(\u0026#34;sum: %X\\r\\n\u0026#34;, iRet); 0x00000000004005d0 \u0026lt;+78\u0026gt;: mov -0x4(%rbp),%eax 0x00000000004005d3 \u0026lt;+81\u0026gt;: mov %eax,%esi 0x00000000004005d5 \u0026lt;+83\u0026gt;: mov $0x400690,%edi 0x00000000004005da \u0026lt;+88\u0026gt;: mov $0x0,%eax 0x00000000004005df \u0026lt;+93\u0026gt;: callq 0x400410 \u0026lt;printf@plt\u0026gt; 18 } 0x00000000004005e4 \u0026lt;+98\u0026gt;: leaveq #出栈处理 0x00000000004005e5 \u0026lt;+99\u0026gt;: retq End of assembler dump. (gdb)   通过上面汇编与寄存器信息，可以了解到函数调用的参数一般先通过寄存器传递。但是可用于传递函数的参数有限，超出的参数怎么传递呢？入调用函数的栈空间，具体如下：\n1 2 3 4 5 6 7 8 9  (gdb) x /12gx $rsp 0x7fffffffe3d0: 0x00007fffffffe410 0x00000000004005cd #main函数栈底，返回指令 0x7fffffffe3e0: 0x0000000000000077 0x0000000000000088 #第七个参数 第八个参数 0x7fffffffe3f0: 0x0000000000000099 0x0000000000000000 #第九个参数 0x7fffffffe400: 0x0000000000400600 0x0000000000400440 #这两个内容是什么 0x7fffffffe410: 0x00007fffffffe420 0x00000000004005ef 0x7fffffffe420: 0x0000000000000000 0x00007ffff7a3baf5 (gdb)   栈内存（栈向下生长）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  rbp 0x7fffffffe3d0 0x7fffffffe3d0 rsp 0x7fffffffe3d0 0x7fffffffe3d0 0x7fffffffe428 +------------------+ | | 0x7fffffffe420 +------------------+ |0x00000000004005ef| #保存返回main的地址 0x7fffffffe418 +------------------+ |0x00007fffffffe420| #保存main函数对应rbp 0x7fffffffe410 +------------------+ | | 0x7fffffffe408 +------------------+ | | 0x7fffffffe400 +------------------+ | | 0x7fffffffe3f8 +------------------+ | 0x99 | 0x7fffffffe3f0 +------------------+ | 0x88 | 0x7fffffffe3e8 +------------------+ | 0x77 | 0x7fffffffe3e0 +------------------+ |0x00000000004005cd| #保存调用caller返回的指令地址 0x7fffffffe3e0 +------------------+ |0x00007fffffffe410| #保存caller函数对应的rbp rsp --\u0026gt;0x7fffffffe3e0 +------------------+   3.4 sum获取参数 1 2 3 4 5 6 7 8 9  (gdb) x /16gx $rsp-0x28 0x7fffffffe3a8: 0x0000005500000066 0x0000003300000044 0x7fffffffe3b8: 0x0000001100000022 0x0000000000000006 0x7fffffffe3c8: 0x00000000f7ab9646 0x00007fffffffe410 0x7fffffffe3d8: 0x00000000004005cd 0x0000000000000077 0x7fffffffe3e8: 0x0000000000000088 0x0000000000000099 0x7fffffffe3f8: 0x0000000000000000 0x0000000000400600 0x7fffffffe408: 0x0000000000400440 0x00007fffffffe420 0x7fffffffe418: 0x00000000004005ef 0x0000000000000000   栈内存（栈向下生长）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  rbp 0x7fffffffe3e0 0x7fffffffe3e0 rsp 0x7fffffffe3e0 0x7fffffffe3e0 0x7fffffffe428 +------------------+ | | 0x7fffffffe420 +------------------+ |0x00000000004005ef| #保存返回main的地址 0x7fffffffe418 +------------------+ |0x00007fffffffe420| #保存main函数对应rbp 0x7fffffffe410 +------------------+ | | 0x7fffffffe408 +------------------+ | | 0x7fffffffe400 +------------------+ | | 0x7fffffffe3f8 +------------------+ | 0x99 | 0x7fffffffe3f0 +------------------+ | 0x88 | 0x7fffffffe3e8 +------------------+ | 0x77 | 0x7fffffffe3e0 +------------------+ |0x00000000004005cd| #保存返回caller的指令地址 0x7fffffffe3e0 +------------------+ |0x00007fffffffe410| #保存caller函数对应的rbp rsp --\u0026gt;0x7fffffffe3e0 +------------------+ | | 0x7fffffffe3d8 +------------------+ | | 0x7fffffffe3d0 +------------------+ | | 0x7fffffffe3e8 +------------------+ | | 0x7fffffffe3e0 +------------------+ | | 0x7fffffffe3c8 +------------------+ | | 0x7fffffffe3c0 +------------------+ |0x0000001100000022| 0x7fffffffe3b8 +------------------+ |0x0000005500000066| 0x7fffffffe3b0 +------------------+ |0x0000003300000044| 0x7fffffffe3a8 +------------------+ | | 0x7fffffffe3a0 +------------------+   sum函数对应汇编如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  (gdb) disassemble /m sum Dump of assembler code for function sum: 5 { 0x0000000000400530 \u0026lt;+0\u0026gt;: push %rbp 0x0000000000400531 \u0026lt;+1\u0026gt;: mov %rsp,%rbp 0x0000000000400534 \u0026lt;+4\u0026gt;: mov %edi,-0x14(%rbp) #获取函数参数，顺序为从左到右 0x0000000000400537 \u0026lt;+7\u0026gt;: mov %esi,-0x18(%rbp) 0x000000000040053a \u0026lt;+10\u0026gt;: mov %edx,-0x1c(%rbp) 0x000000000040053d \u0026lt;+13\u0026gt;: mov %ecx,-0x20(%rbp) 0x0000000000400540 \u0026lt;+16\u0026gt;: mov %r8d,-0x24(%rbp) 0x0000000000400544 \u0026lt;+20\u0026gt;: mov %r9d,-0x28(%rbp) 6 int s = 0x0; 0x0000000000400548 \u0026lt;+24\u0026gt;: movl $0x0,-0x4(%rbp) 7 s = a1+a2+a3+a4+a5+a6+a7+a8+a9; =\u0026gt; 0x000000000040054f \u0026lt;+31\u0026gt;: mov -0x18(%rbp),%eax 0x0000000000400552 \u0026lt;+34\u0026gt;: mov -0x14(%rbp),%edx 0x0000000000400555 \u0026lt;+37\u0026gt;: add %eax,%edx 0x0000000000400557 \u0026lt;+39\u0026gt;: mov -0x1c(%rbp),%eax 0x000000000040055a \u0026lt;+42\u0026gt;: add %eax,%edx 0x000000000040055c \u0026lt;+44\u0026gt;: mov -0x20(%rbp),%eax 0x000000000040055f \u0026lt;+47\u0026gt;: add %eax,%edx 0x0000000000400561 \u0026lt;+49\u0026gt;: mov -0x24(%rbp),%eax ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- 0x0000000000400564 \u0026lt;+52\u0026gt;: add %eax,%edx 0x0000000000400566 \u0026lt;+54\u0026gt;: mov -0x28(%rbp),%eax 0x0000000000400569 \u0026lt;+57\u0026gt;: add %eax,%edx 0x000000000040056b \u0026lt;+59\u0026gt;: mov 0x10(%rbp),%eax #取参数a7 = 0x77 0x000000000040056e \u0026lt;+62\u0026gt;: add %eax,%edx 0x0000000000400570 \u0026lt;+64\u0026gt;: mov 0x18(%rbp),%eax #取参数a8 = 0x88 0x0000000000400573 \u0026lt;+67\u0026gt;: add %eax,%edx 0x0000000000400575 \u0026lt;+69\u0026gt;: mov 0x20(%rbp),%eax #取参数a9 = 0x99 0x0000000000400578 \u0026lt;+72\u0026gt;: add %edx,%eax 0x000000000040057a \u0026lt;+74\u0026gt;: mov %eax,-0x4(%rbp) 8 9 return s; 0x000000000040057d \u0026lt;+77\u0026gt;: mov -0x4(%rbp),%eax #计算结果通过eax寄存器返回 10 } 0x0000000000400580 \u0026lt;+80\u0026gt;: pop %rbp 0x0000000000400581 \u0026lt;+81\u0026gt;: retq End of assembler dump. (gdb)   注意的是调用sum的时候并没有分配栈空间？主要原因是sum函数内没有调用其他函数，sum就只能被别的函数调用，sum的局部变量直接由rsp向下生长，调用结束后，直接恢复调用者的栈，这样的好处有两个：\n 少一个指令，提高执行效率 编译的时候并不需要计算需要开辟多少栈空间  为什么需要将值从寄存器取出？直接利用寄存器取值不可以吗？ 传递参数的寄存器在函数执行指令的时候有其他用处，调用函数需要将参数从寄存器取出到栈内存中（在一定的情况下即调用函数的指令不需要占用传递参数的寄存器，如果加大编译的优化级别，是否不会从参数寄存器取出参数到函数的栈内存中而是直接使用寄存器？）另外可以从这里看出，从代码层面优化性能可以考虑减少函数调用以及优化一些不必要的参数传递，尽管只能尽一丝绵薄之力。\n3.5 sum返回值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  (gdb) n caller () at stackexample.c:17 17 printf(\u0026#34;sum: %X\\r\\n\u0026#34;, iRet); (gdb) info registers rax 0x2fd 765 #返回值 rbx 0x0 0 rcx 0x44 68 rdx 0x264 612 rsi 0x22 34 rdi 0x11 17 rbp 0x7fffffffe410 0x7fffffffe410 rsp 0x7fffffffe3e0 0x7fffffffe3e0 r8 0x55 85 r9 0x66 102 r10 0x7fffffffe270 140737488347760 r11 0x7ffff7a3ba00 140737348090368 r12 0x400440 4195392 r13 0x7fffffffe500 140737488348416 r14 0x0 0 r15 0x0 0 rip 0x4005d0 0x4005d0 \u0026lt;caller+78\u0026gt; eflags 0x202 [ IF ] cs 0x33 51 ss 0x2b 43 ds 0x0 0 es 0x0 0 fs 0x0 0 ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- gs 0x0 0 (gdb) (gdb) x /16gx 0x7fffffffe3c0 0x7fffffffe3c0: 0x0000000000000006 0x000002fdf7ab9646 #返回值0x2fd 0x7fffffffe3d0: 0x00007fffffffe410 0x00000000004005cd 0x7fffffffe3e0: 0x0000000000000077 0x0000000000000088 0x7fffffffe3f0: 0x0000000000000099 0x0000000000000000 0x7fffffffe400: 0x0000000000400600 0x000002fd00400440 0x7fffffffe410: 0x00007fffffffe420 0x00000000004005ef 0x7fffffffe420: 0x0000000000000000 0x00007ffff7a3baf5 0x7fffffffe430: 0x0000002000000000 0x00007fffffffe508 (gdb)   x86-64寄存器说明  rsp：对应32位esp寄存器，保存当前堆栈栈顶指针的寄存器 rbp：对应32位ebp寄存器，保存了当前堆栈基地址指针的寄存器 rax: 临时寄存器，当我们调用系统调用的时候，rax保外系统调用号 rdx：传递第3个参数到函数 rdi：传递第1个参数到函数 rsi：传递第2个参数到函数 rip: 下一个执行指令地址  参考  Calling_convention GDB and Reverse Debugging Assembly x86_64 programming for Linux  ", 
        "url": "http:\/\/myself659.github.io\/post\/2016-03-09-x86-64-call-stack\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-03-05-do-more-than-coding\/": {
        
        "title": "代码是核心，但不仅仅是代码",
        "tags": ["闲谈乱扯",],
        "content": "其实以前也有类似的想法，但是决定写这篇文章是由下面一件事情引起的。\n引子 同事自已造轮子要实现一个rtmp协议，在调试过程由于有一个问题有没有解决，影响团队的联调，对于他造主动造轮子，我是不支持的。重复实现一个完整的rtmp协议，会走很多坑的，需要花费较多的时间，而开源的librtmp已经实现完整的rtmp协议功能，我决定将librtmp协议移植到现在系统。\n接着就自己开始干，了解librtmp实现，动手写一个利用librtmp支持epoll的rtmpserver。 在调试过程出现rtmp握手失败的问题，初看定位无果的情况下，我修改了makefile，生成调试的符号表，同时打开调试开关。这些弄好之后，试了一下，没有我期待的符号表与调试信息。\n于是我怀疑自己对makefile是否正确。重新学习makefile与编译的一些知识还是无果，觉得makefile修改是正确的。这时候灵光一现，看看进程加载的是哪些lib\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  (gdb) info sharedlibrary From To Syms Read Shared Object Library 0x0000003a74600b00 0x0000003a746198db Yes (*) /lib64/ld-linux-x86-64.so.2 0x00007ffff7dd57e0 0x00007ffff7de4358 Yes (*) /usr/local/lib/librtmp.so.1 #加载的librtmp库 0x0000003c39a18340 0x0000003c39a53558 Yes (*) /usr/lib64/libssl.so.10 0x0000003c39669cc0 0x0000003c3975dbe8 Yes (*) /usr/lib64/libcrypto.so.10 0x0000003a76602120 0x0000003a7660d3a8 Yes (*) /lib64/libz.so.1 0x0000003a74a1ea20 0x0000003a74b3f76c Yes (*) /lib64/libc.so.6 0x0000003a8260ac30 0x0000003a82638728 Yes (*) /lib64/libgssapi_krb5.so.2 0x0000003a8161b430 0x0000003a81694a78 Yes (*) /lib64/libkrb5.so.3 0x0000003a806013f0 0x0000003a80601fc8 Yes (*) /lib64/libcom_err.so.2 0x0000003a812043d0 0x0000003a8121d5a8 Yes (*) /lib64/libk5crypto.so.3 0x0000003a74e00de0 0x0000003a74e01998 Yes (*) /lib64/libdl.so.2 0x0000003a80a02a40 0x0000003a80a080c8 Yes (*) /lib64/libkrb5support.so.0 0x0000003a80e00bf0 0x0000003a80e011d8 Yes (*) /lib64/libkeyutils.so.1 0x0000003a76a03930 0x0000003a76a12938 Yes (*) /lib64/libresolv.so.2 0x0000003a75205660 0x0000003a75210eb8 Yes (*) /lib64/libpthread.so.0 0x0000003a76205850 0x0000003a76215cc8 Yes (*) /lib64/libselinux.so.1 (*): Shared library is missing debugging information. (gdb)   看到上面的一幕，犯了这样的错误：改对了代码，却没有更新lib\n反思 在现实的开发过程中常常碰到下面的情行：\n场景1： “我修改了代码，代码也改好，怎么还是这样的？”\n场景2： “在我的环境下，测试ok，怎么在你的环境就不行了呢？”\n场景3： “前几天运行都ok的，怎么现在不对了？”\n场景4： “以前上线都没事，这次同样的操作却没有成功”\n场景5： \u0026ldquo;原来从业务角度出发，可以设计，确实不要那么麻烦\u0026rdquo;\n以上这些问题，很大一部分因素我们只考虑到代码本身而已，还没有考虑代码的深层次问题，也没有考虑代码与业务的关联，在实际系统中很多问题一部分原因也是因为深层上没有了解代码的本质或者没有吃透业务对代码的要求。\n代码是核心，但不仅仅是代码，还有下面几个方面需要考虑：\n 代码的本质 测试验证 系统设计 业务需求 部署需求 监控需求 升级问题 团队合作 安全问题  对此，个人大胆划分四个层次：\n  码农，以码为主，停留在代码上，关注代码与算法（如果有足够的天赋研究像人工智能这样的顶级算法，请继续深入研究）\n  工程师，以解决具体业务为主，代码作为业务的实现，关注的业务与需求，能够实现技术持续性满足小范围内的业务需求\n  架构师，考虑上述各个方面，从需求，设计，实现，部署，演进等各个阶段满足具体一个产品的技术需求，除此之外，主动思考技术对业务的发展的支撑\n  技术总监，CXO，创始人，这一层次就不YY了\n  后记 需要强调的一点：作为程序员写好代码是第一要务，本文强调写好代码的基础上，要从深度与广度角度思考代码与审视代码，这样让自己不停留在代码层面，让自己不仅能技术上取得进步，更能让技术上的进步转化为业务上的价值\n自己接下来的重点，除了继续提高自已技术能力，另一个重点加强对业务的学习与研究，用技术更快，更好地满足业务需求\n(PS：起了标题，希望后面能够有更深的感悟，写得更具体一些)\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-03-05-do-more-than-coding\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s\/2016-01-28-docker-cmd-pratice\/": {
        
        "title": "docker image命令实践",
        "tags": ["Linux",],
        "content": "搭建了docker环境，就来体验一下Docker，常用docker image命令如下：\n1. 搜索docker image 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  root@localhost ~]# docker search ubuntu NAME DESCRIPTION STARS OFFICIAL AUTOMATED ubuntu Ubuntu is a Debian-based Linux operating s... 2954 [OK] ubuntu-upstart Upstart is an event-based replacement for ... 58 [OK] dorowu/ubuntu-desktop-lxde-vnc Ubuntu with openssh-server and NoVNC on po... 32 [OK] torusware/speedus-ubuntu Always updated official Ubuntu docker imag... 25 [OK] ubuntu-debootstrap debootstrap --variant=minbase --components... 22 [OK] tleyden5iwx/ubuntu-cuda Ubuntu 14.04 with CUDA drivers pre-installed 18 [OK] rastasheep/ubuntu-sshd Dockerized SSH service, built on top of of... 16 [OK] consol/ubuntu-xfce-vnc Ubuntu container with \u0026#34;headless\u0026#34; VNC sessi... 8 [OK] ioft/armhf-ubuntu [ABR] Ubuntu Docker images for the ARMv7(a... 7 [OK] n3ziniuka5/ubuntu-oracle-jdk Ubuntu with Oracle JDK. Check tags for ver... 7 [OK] nuagebec/ubuntu Simple always updated Ubuntu docker images... 4 [OK] nickistre/ubuntu-lamp-wordpress LAMP on Ubuntu with wp-cli installed 3 [OK] nimmis/ubuntu This is a docker images different LTS vers... 3 [OK] maxexcloo/ubuntu Docker base image built on Ubuntu with Sup... 2 [OK] sylvainlasnier/ubuntu Ubuntu 15.10 root docker images with commo... 1 [OK] isuper/base-ubuntu This is just a small and clean base Ubuntu... 1 [OK] densuke/ubuntu-jp-remix Ubuntu Linuxの日本語remix風味です 1 [OK] seetheprogress/ubuntu Ubuntu image provided by seetheprogress us... 1 [OK] nickistre/ubuntu-lamp LAMP server on Ubuntu 1 [OK] teamrock/ubuntu TeamRock\u0026#39;s Ubuntu image configured with AW... 0 [OK] konstruktoid/ubuntu Ubuntu base image 0 [OK] birkof/ubuntu Ubuntu 14.04 LTS (Trusty Tahr) 0 [OK] zoni/ubuntu 0 [OK] esycat/ubuntu Ubuntu LTS 0 [OK] rallias/ubuntu Ubuntu with the needful 0   2. 下载image 1  docker pull   3. 查看image 1 2 3 4 5 6  [root@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu latest d55e68e6cc9c 4 weeks ago 187.9 MB ubuntu 14.04 d55e68e6cc9c 4 weeks ago 187.9 MB training/sinatra latest f0f4ab557f95 19 months ago 447 MB   4. 删除image 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  [root@localhost ~]# docker rm training/sinatra Error response from daemon: no such id: training/sinatra Error: failed to remove containers: [training/sinatra] [root@localhost ~]# docker rm f0f4ab557f95 Error response from daemon: no such id: f0f4ab557f95 Error: failed to remove containers: [f0f4ab557f95] [root@localhost ~]# docker rmi f0f4ab557f95 Untagged: training/sinatra:latest Deleted: f0f4ab557f954f3e04177663a3af90e88641bcdcce1f02ac900dbd9768ef4945 Deleted: 79e6bf39f99322cc062a79bec4a09de0dd19cb7f5f735b4b6b7832c04b13bb45 Deleted: ce80548340bb03726d391bb8fa4d134f8418c2fff90be9a7323560debdea9bd2 Deleted: e809f156dc985e07105fdc86ec05eb03eb7aac8636dc210e8595d31b55787f4a Deleted: bfab314f3b766eddf9778f8dce089f44e84ea028f4a44ce68740dce81a844ec8 Deleted: be88c4c27e80023b6aea82f0f2e15fb21c6f4193fe814e5b58010d356dd7846b Deleted: 3e76c0a80540a0d36493ae7110796fc92f559a191454e3ac19c1d4c650bdd9e0 Deleted: 511136ea3c5a64f264b78b5433614aec563103b4d4702f3ba7d4d2698e22c158 You have new mail in /var/spool/mail/root [root@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu latest af88597ec24b 6 days ago 187.9 MB ubuntu 14.04 d55e68e6cc9c 4 weeks ago 187.9 MB   5. 运行image 1  [root@localhost ~]# docker run -i -t apache2   6. kill运行的docker image 1 2 3 4 5 6 7 8 9 10  [root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 68333b272b52 ubuntu \u0026#34;/bin/bash\u0026#34; 18 minutes ago Up 18 minutes clever_babbage 0ca2aff5b94b ubuntu \u0026#34;bash\u0026#34; 48 minutes ago Up 48 minutes focused_hypatia You have new mail in /var/spool/mail/root [root@localhost ~]# docker kill 68333b272b52 68333b272b52 [root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0ca2aff5b94b ubuntu \u0026#34;bash\u0026#34; 54 minutes ago Up 54 minutes focused_hypatia   7. 制作image 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  [root@localhost tmp]# more Dockerfile FROM apache2 RUN apt-get install -y wget [root@localhost tmp]# docker build -t wget . Sending build context to Docker daemon 2.609 MB Sending build context to Docker daemon Step 0 : FROM apache2 ---\u0026gt; f5cf247f22af Step 1 : RUN apt-get install -y wget ---\u0026gt; Running in ab3cd326c53c [root@localhost tmp]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE wget latest be8bf51f39d5 29 seconds ago 229.1 MB apache2 latest f5cf247f22af 5 hours ago 223.8 MB ubuntu latest af88597ec24b 6 days ago 187.9 MB ubuntu 14.04 d55e68e6cc9c 4 weeks ago 187.9 MB   8. docker volume clean 1  docker system prune --all --volumes --force   ", 
        "url": "http:\/\/myself659.github.io\/post\/k8s\/2016-01-28-docker-cmd-pratice\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s\/2015-12-13-docker-way-1-build-docker-env\/": {
        
        "title": "升级Linux内核，搭建docker环境",
        "tags": ["Linux",],
        "content": "docker可以说是去年最热的技术，也是业界大谈特谈的技术，到了今年有很多公司已经将docker应用于自己的生产环境。Docker已经从一个工具转化成平台，小生态圈。作为一名程序员应该与时俱进，学习新技术，不断地提高自己。\n升级内核 docker要求linux内核版本3.12以上，作为常用linux2.26.32版本，虽然也可以安装docker，但是有一些特性不支持，所以第一步就是升级内核。个人选择最新的长期维护版本升级linux4.13,内核升级最关键的一件事情就是配置内核，关于内核支持docker的内核配置文件，如果不想自己动手配置内核，可以参考Linux-4.13-configfordocker;\n在未正确配置linux内核会出现以下一些错误：\n docker启动过程中iptables命令执行失败，原因是 iptables模块没有配置  1 2 3 4 5 6 7 8  [root@localhost ~]# docker -d INFO[0000] Listening for HTTP on unix (/var/run/docker.sock) INFO[0000] [graphdriver] using prior storage driver \u0026#34;devicemapper\u0026#34; FATA[0000] Error starting daemon: Error initializing network controller: Error creating default \u0026#34;bridge\u0026#34; network: Failed to Setup IP tables: Unable to enable NAT rule: iptables failed: iptables -t nat -I POSTROUTING -s 172.17.42.1/16 ! -o docker0 -j MASQUERADE: iptables v1.4.7: can\u0026#39;t initialize iptables table `nat\u0026#39;: Table does not exist (do you need to insmod?) Perhaps iptables or your kernel needs to be upgraded. (exit status 3) You have new mail in /var/spool/mail/root [root@localhost ~]#   cgroup创建失败，具体参考stackoverflow  1 2 3 4  [root@localhost ~]# service docker start Starting cgconfig service: Error: cannot mount memory to /cgroup/memory: No such file or directory /sbin/cgconfigparser; error loading /etc/cgconfig.conf: Cgroup mounting failed Failed to parse /etc/cgconfig.conf or /etc/cgconfig.d[FAILED]   具体内核升级过程参考如下：\n1 2 3 4 5 6 7  [root@localhost linux-4.1.13]# cp /share/github/docker-way/env/linux-4.1.3-configfordocker .config [root@localhost linux-4.1.13]# sh -c \u0026#39;yes \u0026#34;\u0026#34; | make oldconfig\u0026#39; [root@localhost linux-4.1.13]# make -j2 bzImage [root@localhost linux-4.1.13]# make -j2 modules [root@localhost linux-4.1.13]# make -j2 modules_install [root@localhost linux-4.1.13]# make install   检查grub配置，修改并将linux-4.13作为默认启动项，重启系统，系统启动成功后，查看内核版本：\n1 2  [root@localhost ~]# uname -a Linux localhost.localdomain 4.1.13 #1 SMP Sat Dec 5 11:17:50 CST 2015 x86_64 x86_64 x86_64 GNU/Linux   安装device-mapper 1 2  [root@localhost ~]#yum install -y device-mapper   安装docker 1  [root@localhost ~]# yum -y install docker-io   安装完成后，检查docker是否能够正确启动\n1 2 3 4 5 6 7 8 9  [root@localhost ~]# docker -d INFO[0000] [graphdriver] using prior storage driver \u0026#34;devicemapper\u0026#34; INFO[0000] Listening for HTTP on unix (/var/run/docker.sock) WARN[0000] Your kernel does not support swap memory limit. INFO[0000] Loading containers: start. INFO[0000] Loading containers: done. INFO[0000] Daemon has completed initialization INFO[0000] Docker daemon commit=786b29d execdriver=native-0.2 graphdriver=devicemapper version=1.7.1   没有错误，接下来可以开启一段docker学习之旅了!\n(更新)\nUninstall old versions 1  sudo apt-get remove docker docker-engine docker.io containerd runc   install How To Install and Use Docker on Ubuntu 18.04\n", 
        "url": "http:\/\/myself659.github.io\/post\/k8s\/2015-12-13-docker-way-1-build-docker-env\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2015-08-28-gdb-command-example\/": {
        
        "title": "gdb自定义断点操作",
        "tags": ["Linux",],
        "content": "gdb是c/c++上调试利器，有很多技巧能让调试程序与解决问题更加方便与高效，下面关于command 命令的使用一个实例，具体如下：\n1. 设置断点 1 2 3  (gdb) b GenVedioSeekPoint Breakpoint 1 at 0x402e58: file GenIndex.cpp, line 140. (gdb)   2. 利用commad自定义断点操作 1 2 3 4 5 6 7  (gdb) command 1 Type commands for breakpoint(s) 1, one per line. End with a line saying just \u0026#34;end\u0026#34;. \u0026gt;p *pstPktHead \u0026gt;continue \u0026gt;end (gdb)   3. 设置gdb log信息输出到指定文件 1 2 3 4 5  (gdb) set logging file genindex.txt (gdb) set logging on Copying output to genindex.txt. (gdb) set pagination off (gdb)   4. 开始或继续执行程序 1  (gdb) run   有输出信息如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  ... Breakpoint 1, GenVedioSeekPoint (pstPktHead=0x7fffffdfdcff, offset=71678) at GenIndex.cpp:140 140 uiTimeStamp = pstPktHead-\u0026gt;stBlockHead.iTimeStamp; $253 = {cFlag = 170 \u0026#39;\\252\u0026#39;, uiPktLen = 236, uiPktSeq = 3418810467, sCheckNum = 1, cBlockCount = 27 \u0026#39;\\033\u0026#39;, stBlockHead = {cBlogTag = 90 \u0026#39;Z\u0026#39;, iTimeStamp = 14811476, iDatalen = 0}} Breakpoint 1, GenVedioSeekPoint (pstPktHead=0x7fffffdfddeb, offset=71914) at GenIndex.cpp:140 140 uiTimeStamp = pstPktHead-\u0026gt;stBlockHead.iTimeStamp; $254 = {cFlag = 170 \u0026#39;\\252\u0026#39;, uiPktLen = 155, uiPktSeq = 3962300516, sCheckNum = 1, cBlockCount = 59 \u0026#39;;\u0026#39;, stBlockHead = {cBlogTag = 90 \u0026#39;Z\u0026#39;, iTimeStamp = 9503060, iDatalen = 0}} Breakpoint 1, GenVedioSeekPoint (pstPktHead=0x7fffffdfde86, offset=72069) at GenIndex.cpp:140 140 uiTimeStamp = pstPktHead-\u0026gt;stBlockHead.iTimeStamp; $255 = {cFlag = 170 \u0026#39;\\252\u0026#39;, uiPktLen = 1959, uiPktSeq = 3774212197, sCheckNum = 257, cBlockCount = 125 \u0026#39;}\u0026#39;, stBlockHead = {cBlogTag = 90 \u0026#39;Z\u0026#39;, iTimeStamp = 127730004, iDatalen = 0}} ...   同时在gdb的运行程序的目录下生成genindex.txt文件，这样可以通过分析genindex.txt找问题的原因；同时整个执行的过程中不需要个人操作，在断点不断命中的情况下极大提高效率，如果是生产的环境，避免长时间占用进程，进而影响业务，\n5. 分析log文件 这一步你可以用shell，awk， sed，python等来分析genindex.txt文件内容\n", 
        "url": "http:\/\/myself659.github.io\/post\/2015-08-28-gdb-command-example\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2015-08-08-nginx-pratice-1-add-hello-module\/": {
        
        "title": "nginx实践-添加自定义模块hello",
        "tags": ["nginx",],
        "content": "nginx是一个值得学习与研究的开源代码，写这篇文章主要目的是让自己能够能够从最简单的任务开始，通过写作促进自己一步一步地深入学习与分析nginx。本文是这个系列的第一篇，主要是记录自己实现一个自定义的模块hello的过程。\n1. 下载源码 下载nginx 1.8.0 源代码\n1 2  root@localhost github]# wget http://nginx.org/download/nginx-1.8.0.tar.gz root@localhost github]# tar zxf   2. 准备文件与代码 在nginx解压目录下，添加如下文件：\n1 2 3 4 5 6 7 8 9 10  [root@localhost nginx-1.8.0]# tree | more . |-- **addon** | `-- **hello** | |-- **config** | `-- **ngx_http_hello_module.c** |-- auto | |-- cc | | |-- acc | | |-- bcc   新增文件分析参考nginx-hello\n1 2 3 4 5 6 7 8  [root@localhost nginx-1.8.0]# grep -r ngx_addon_name /share/github/nginx-1.8.0 /share/github/nginx-1.8.0/auto/modules: echo \u0026#34; + $ngx_addon_name was configured\u0026#34; /share/github/nginx-1.8.0/addon/hello/config:ngx_addon_name=ngx_http_hello_module [root@localhost nginx-1.8.0]# [root@localhost nginx-1.8.0]# grep -r add-module /share/github/nginx-1.8.0 /share/github/nginx-1.8.0/auto/options: --add-module=*) NGX_ADDONS=\u0026#34;$NGX_ADDONS $value\u0026#34; ;; /share/github/nginx-1.8.0/auto/options: --add-module=PATH enable an external module   3. 编译与安装 编译三步走\n1 2 3 4 5  1. ./configure --add-module=/share/github/nginx-1.8.0/addon/hello 2. make 3. make install   4.测试 在/usr/local/nginx/conf/nginx.conf文件的http配置项下，添加如下内容：\n1 2 3  location =/hello{ hello; }   过程如下：\n1 2 3 4 5 6 7  [root@localhost ~]# nginx -t nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful [root@localhost ~]# service nginx restart Restarting nginx (via systemctl): [ OK ] [root@localhost nginx-1.8.0]# curl http://localhost/hello/ hello nginx!   另外也可以通过浏览器访问：http://serverip/hello\n如果出现不能打开，检查一下iptable 设置，在/etc/sysconfig/iptables增加下面一条配置，允许80端口通过：\n1  -A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT   然后输入命令service iptables restart重启iptables服务，使新增配置生效\n5. 实例代码 本文代码请参考：nginx-hello\n本人水平有限，若有疏漏与错误，欢迎交流与指正。\n", 
        "url": "http:\/\/myself659.github.io\/post\/2015-08-08-nginx-pratice-1-add-hello-module\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2015-07-28-linux-netstat\/": {
        
        "title": "Linux netstat 应用示例",
        "tags": ["Linux",],
        "content": "关于netstat netstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态 (Interface Statistics)，masquerade 连接，多播成员 (Multicast Memberships) 等等。\n常用参数 -a (all)显示所有选项，默认不显示LISTEN相关\n-t (tcp)仅显示tcp相关选项\n-u (udp)仅显示udp相关选项\n-n 拒绝显示别名，能显示数字的全部转化成数字\n-l 仅列出有在 Listen (监听) 的服務状态\n-p 显示建立相关链接的程序名\n-r 显示路由信息，路由表\n-e 显示扩展信息，例如uid等\n-s 按各个协议进行统计\n-c 每隔一个固定时间，执行该netstat命令\n注意：LISTEN和LISTENING的状态只有用-a或者-l才能看到\n应用实例 1. 选项组合应用 命令：\n1  netstat -tlnp   说明：显示处于listen状态的tcp连接，并显示对应进程pid\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  [root@localhost default]# netstat -tlnp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:21 0.0.0.0:* LISTEN 1284/pure-ftpd tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1022/sshd tcp 0 0 0.0.0.0:445 0.0.0.0:* LISTEN 1309/smbd tcp 0 0 0.0.0.0:139 0.0.0.0:* LISTEN 1309/smbd tcp 0 0 0.0.0.0:6379 0.0.0.0:* LISTEN 1298/redis-server tcp 0 0 0.0.0.0:11211 0.0.0.0:* LISTEN 1002/memcached tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 31604/nginx tcp 0 0 :::21 :::* LISTEN 1284/pure-ftpd tcp 0 0 :::22 :::* LISTEN 1022/sshd   2. 显示网关地址 命令：\n1  netstat -rn | grep UG | tr -s \u0026#34; \u0026#34; | cut -d \u0026#34; \u0026#34; -f2   说明：先显示路由信息，找出网关所对应表项，删除多余的空格并显示第二个表项field\n示例：\n1 2 3  [root@localhost default]# netstat -rn | grep UG | tr -s \u0026#34; \u0026#34; | cut -d \u0026#34; \u0026#34; -f2 192.168.20.1   3.统计tcp各种连接状态的个数 命令：\n1  netstat -n | awk \u0026#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}   说明：显示连接信息，通过awk统计各tcp状态连接个数\n示例：\n1 2 3 4  [root@localhost default]#netstat -n | awk \u0026#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]} ESTABLISHED 516 TIME_WAIT 14   4.显示所有tcp监听端口 命令：\n1  netstat -lnt | awk \u0026#39;{print $4}\u0026#39; | cut -f2 -d: | grep -o \u0026#39;[0-9]*\u0026#39;   说明：\n示例：显示处于listen状态的tcp连接，打印每行第4个域元素，并以:作为该域的内部分隔符，同时显示其中第二个域元素，对结果进行过滤，只显示数字部分\n1 2 3 4 5 6 7 8 9  [root@localhost default]# netstat -lnt | awk \u0026#39;{print $4}\u0026#39; | cut -f2 -d: | grep -o \u0026#39;[0-9]*\u0026#39; 21 22 445 139 6379 11211 80   5.统计每个IP连接数 命令：\n1  netstat -anp |grep \u0026#39;tcp\\|udp\u0026#39; | awk \u0026#39;{print $5}\u0026#39; | sed s/::ffff:// | cut -d: -f1 | sort | uniq -c | sort -n   说明：显示所有网络连接并从中过滤出tcp与udp连接，打印这些连接表项的第5个域元素，删除包含/::ffff:的表项，以：为分隔符显示剩下的内容的第一个域元素，再进行排序并统计个数，最后以数值排列显示结果\n示例：\n1 2 3 4 5  [root@localhost default]# netstat -anp |grep \u0026#39;tcp\\|udp\u0026#39; | awk \u0026#39;{print $5}\u0026#39; | sed s/::ffff:// | cut -d: -f1 | sort | uniq -c | sort -n 3 192.168.70.36 8 0.0.0.0   6.查看80端口的连接，并排序 命令：\n1  netstat -ant | grep “:80″ | grep ESTABLISHED | awk ‘{printf “%s %s\\n”,$5,$6}’ | sort   说明： 不解释了，你懂的\n示例：\n未完，待续\n", 
        "url": "http:\/\/myself659.github.io\/post\/2015-07-28-linux-netstat\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2015-07-03-thought-about-zero-to-one\/": {
        
        "title": "读书笔记：《从0到1---开启商业与未来的秘密》",
        "tags": ["闲谈乱扯",],
        "content": "启发思考  在什么重要问题上你与其他有不同的看法？   除了书中讲到参考模式:太多数人相信X，但是事实却是X的对立面；世界是多样的，我们应当追求正确的差异化\n  企业失败的共同的原因   企业失败的原因却是相同：它们都无法逃脱竞争\n  应对趋势潮流   最反主流的行动不是抵制潮流，而是在潮流中不丢弃自己的独立思考\n 从0到1vs从1到N   从0到1是创新，创造；从1到N是创新成果应用及商业化\n ###关于团队\n 现金奖励不是王道，股票报酬才能让员工全力以赴 那些决定命运的基础元素：合伙人，早期团队成员 所有权，经营权，控制权 招聘要求：有才华+真正喜欢与团队合作及一起成长的意愿 特立独行的创始人  ###关于销售 这一部分内容作者回答一系列问题：\n 销售是什么？   产品离不开销售，销售是产品设计的一部分；销售是隐形的，销售人员第一要务是说服而不是真诚\n 谁是销售对象？   品牌无界限，销售对象除了产品与服务的潜在用户，还要社会，媒体销售公司，建立品牌\n 谁是销售员？   不论是员工，创始人，还是投资者，都应该是销售，无人不销售，无时不销售\n 怎么进行销售？   常用销售方法：复杂销售，人员销售，市场营销和广告，病毒式营销，粉丝营销；\n  销售的法则？   选择一个最有效的销售方法或者销售渠道\n 绿色能源与特斯拉 绿色能源与特斯拉是《从0到1》这本书倒数是第二章，这一章是对前面章节讲到竞争，团队，未来，销售等观点在具体行业与具体公司的具体应用的一个展示，有意创业，投资或者像我有时仅好分析一个企业的人，可以细细口味。\n这一章节提到的七个必须回答的问题，可以作为分析一家企业的checklist问题，具体如下：\n 工程问题：   你的技术具有突破性，而不是仅仅是稍有改进吗？\n 时机问题：   现在开创事业，时机合适吗？\n 垄断问题：   开创之初，是在一个小市场抢占大份额吗？\n 人员问题：   你有合适的团队吗？\n 销售问题：   除了创造产品，你有没有办法销售产品？\n 持久问题:   未来10年或者20年，你能保住自己的市场地位吗？\n 秘密问题：   你有没有找到一个其他人没有发现的独特机会？\n 总之，Peter_Thiel作为一个成功的创业家和投资家，《从0到1 开启商业与未来的秘密》为我们讲了很多干货，作者分享了很多真知灼见，值得阅读与学习。\n相关参考  Peter_Thiel palantir  ", 
        "url": "http:\/\/myself659.github.io\/post\/2015-07-03-thought-about-zero-to-one\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2015-06-14-number-divide\/": {
        
        "title": "实现无符号整型数的分解",
        "tags": ["编程",],
        "content": "题目 将一个无符号数N拆分为不多于M个数，使拆分的数之和等于N,条件：\n N \u0026gt;= M； N与M都是无符号整型数  求：一共有多少中拆分方法？\n分析 参考代码\n代码 代码实现计算拆分方法及打印拆分组合信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149  #include \u0026lt;iostream\u0026gt; #include \u0026lt;stdint.h\u0026gt; using namespace std; class CSolution { private: uint32_t uiM; uint32_t uiN; uint32_t uiCount; uint32_t *puiRecord; public: CSolution(); CSolution(uint32_t uiM, uint32_t uiN); ~CSolution(); uint32_t GetCount() {return uiCount;} void PrintCombinations(); uint32_t CountNum(uint32_t uiM, uint32_t uiN);\tvoid GetCombination(uint32_t uiMin, uint32_t uiLeft, uint32_t uiGetNum, uint32_t uiTargetNum, uint32_t *puiRecord); }; CSolution::CSolution(uint32_t uiM,uint32_t uiN){ this-\u0026gt;uiM = uiM; this-\u0026gt;uiN = uiN; this-\u0026gt;puiRecord = new unsigned int [uiM]; this-\u0026gt;uiCount = CountNum(uiM, uiN); return ; } CSolution::CSolution() { uiM = 1; uiN = 1; puiRecord = new unsigned int [uiM]; uiCount = CountNum(uiM, uiN); return ; } CSolution::~CSolution() { delete [] puiRecord; return ; } uint32_t CSolution::CountNum(uint32_t uiM, uint32_t uiN) { if((0 == uiM) || (0 == uiN) || ( 1 == uiM) || ( 1 == uiN)) { return 1; } if(uiN \u0026lt; uiM) { return CountNum(uiN,uiN); } return CountNum(uiM - 1, uiN) + CountNum(uiM, uiN - uiM); }\t/* UINT uiMin 最小值 UINT uiLeft 剩下值 UINT uiGetNum 已拆分元素个数 UINT uiTargetNum\t需要拆分的个数 UINT *puiCombination 拆分组合首地址 */ void CSolution::GetCombination(uint32_t uiMin, uint32_t uiLeft, uint32_t uiGetNum, uint32_t uiTargetNum, uint32_t *puiRecord) { uint32_t i; uint32_t j; /*递归结束条件 */ if(1 == uiTargetNum) { cout \u0026lt;\u0026lt; uiLeft\u0026lt;\u0026lt;endl; return ; } /* 将剩下值拆分为多个数,除了最后一个拆分值，其他的拆分数都应小于等于uiLeft/2 */ for(i = uiMin; i \u0026lt;= uiLeft / 2; i++) { puiRecord[uiGetNum] = i; uiGetNum++; if(uiGetNum + 1 == uiTargetNum) { puiRecord[uiGetNum] = uiLeft - i; for(j = 0; j \u0026lt; uiTargetNum; j++) { cout \u0026lt;\u0026lt;puiRecord[j]\u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } else { GetCombination(i, uiLeft - i, uiGetNum, uiTargetNum, puiRecord); } uiGetNum--; } return ;\t} void CSolution::PrintCombinations() { uint32_t i; cout\u0026lt;\u0026lt;\u0026#34;print combinations as follow:\u0026#34;\u0026lt;\u0026lt;endl; for(i = 1; i \u0026lt;= uiM; i++) { GetCombination(1, uiN, 0, i, puiRecord);\t} cout\u0026lt;\u0026lt;\u0026#34;The Total num is \u0026#34;\u0026lt;\u0026lt; GetCount()\u0026lt;\u0026lt;endl; return ; } int main(void) { CSolution test(7, 11); test.PrintCombinations(); return 0; }   运行结果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  [root@localhost cpp]# ./numdecom print combinations as follow: 11 1 10 2 9 3 8 4 7 5 6 1 1 9 1 2 8 1 3 7 1 4 6 1 5 5 2 2 7 2 3 6 2 4 5 3 3 5 3 4 4 1 1 1 8 1 1 2 7 1 1 3 6 1 1 4 5 1 2 2 6 1 2 3 5 1 2 4 4 1 3 3 4 2 2 2 5 2 2 3 4 2 3 3 3 1 1 1 1 7 1 1 1 2 6 1 1 1 3 5 1 1 1 4 4 1 1 2 2 5 1 1 2 3 4 1 1 3 3 3 1 2 2 2 4 1 2 2 3 3 2 2 2 2 3 1 1 1 1 1 6 1 1 1 1 2 5 1 1 1 1 3 4 1 1 1 2 2 4 1 1 1 2 3 3 1 1 2 2 2 3 1 2 2 2 2 2 1 1 1 1 1 1 5 1 1 1 1 1 2 4 1 1 1 1 1 3 3 1 1 1 1 2 2 3 1 1 1 2 2 2 2 The Total num is 49   ", 
        "url": "http:\/\/myself659.github.io\/post\/2015-06-14-number-divide\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/2015-05-27-ping-error\/": {
        
        "title": "ping不通常见原因总结",
        "tags": ["Network",],
        "content": "ping不通从ping的流程分为两大类：\n 请求报文没有到达对端 应答报文未收到  请求报文没有到达对端的可能原因：\n 发送端发送流程出错 源端,转发设备没有目的地址的路由 ttl 小于转发跳数 分片丢包 MTU限制 转发丢包 报文错误 防火墙规则不允许该类型报文通过 中间进行nat转换等处理出错 目的地址不存在 接收端收包流程出错  应答报文未收到的可能原因：\n 发送端发送流程出错 MTU限制 目的端禁止应答 接收报文错误 防火墙规则不允许该类型报文通过 接收到了报文，但是超出等待时间 接收报文错误，ping 应答检查失败 转发丢包  ", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/2015-05-27-ping-error\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/2015-06-01-linux-may-sleep-function\/": {
        
        "title": "那些可进入睡眠状态的Linux内核函数",
        "tags": ["Linux",],
        "content": "在linux内核开发中断处理函数不能调用可能导致睡眠的函数，下面总结linux内核可能引起睡眠的函数如下：\nschedule函数    schedule_timeout schedule_timeout_uninterruptible schedule_timeout_interruptible cond_resched might_resched    sleep函数    msleep msleep_interruputible ssleep osal_usleep might_sleep    取信号量函数    down down_timeout down_read down_write down_interruptible wait_for_completion wait_for_completion_interruptible wait_for_completion_timeout wait_for_completion_interruptible_timeout    kmalloc相关函数含有标志GFP_KERNEL    kmalloc kzalloc krealloc kmem_cache_create kmem_cache_alloc kmem_cache_zalloc    取睡眠锁函数    mutex_lock mutex_lock_timeout mutex_lock_nested mutex_lock_interruptible mutex_lock_interruptible_nested    在中断处理函数不能使用睡眠函数原因 主要原因如下：\n 中断是一种紧急事务，中断处理函数要求快 linux是以进程为调度单位的，调度器只看到进程内核栈，而看不到中断栈，在独立中断栈的模式下，如果linux内核在中断处理函数内发生了调度或者睡眠，导致无法找到回家的路，未执行的中断处理代码再也无法获得执行机会（贪睡开小差是有代价哦）  ", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/2015-06-01-linux-may-sleep-function\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/c-codereivew\/": {
        
        "title": "C语言代码 review的总结",
        "tags": ["编程",],
        "content": "代码review是保证代码质量在项目开发及代码修改中一项重要的环节，下面就代码reiew的一些总结，总结一些代码的review的关注点，提高代码review的效率与效果，提前发现问题，降低后期的测试成本，以及避免软件上线或交付出问题导致的经济损失和恶劣影响（ps:对每一行代码保持敬畏之心）。\n代码中的资源  以内存为例，C语言内存操作都是由程序员来定义与控制，内存的一些错误总是不断地出现，例如内存泄漏，踩内存，写越界等，如果这种问题在线上系统中出现，定位与修复的成本都是很高的。\n    动态内存 信号量 文件描述符 锁 句柄 中断 资源的引用 资源的引用计数  代码的错误高发特征    冗余实现 异常处理 结构复杂 层次嵌套多 不合理实现 字符串处理 代码临界区 移植代码  代码的追求    正确性 可靠性 可读性 可维护性 可测试性 可扩展性 可移植性 可伸缩性 易用性 可用性 可重用性 互操作性 可管理性 一致性 安全性 性能 稳定性 精确性 可差异化性 魯棒性  ", 
        "url": "http:\/\/myself659.github.io\/post\/c-codereivew\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-thought\/": {
        
        "title": "Linux性能优化杂谈",
        "tags": ["Linux",],
        "content": "性能不仅仅是一串串数字，性能体现更大的吞吐量及更低的延迟；如果网络延迟增加0.1秒，google每秒损失100W,不是人民币是美元；网页响应慢0.1秒，运营成本每天增加100万美金。亚马逊的数据也显示，网页延迟1秒可能导致全年损失16亿美金；移动页面加载时间时长超过5秒，74%的用户会选择离开，高性能主要体现下面三个方面：\n 少资源 高吞吐 低延迟  在具体网络转发性能优化过程中对性能优化有以下几点体会与总结：\n软硬结合 软件灵活，硬件高效，软硬结合就像双剑合壁，威力巨大；具体在网络设备中交换机就是一个很好的例子：通常由CPU完成协议的处理，下发转发表项到芯片，由芯片完成报文的转发，在这种思路下才会cisco，H3C，Huawei的大容量的交换机；如果完全交给CPU来处理成本很高，而且在现有技术下很难完成那么大的交换容量（1T以上）。在这种情况对于软件上来说基本不需要优化，本文后面的优化是针对软转的优化；\n分离与分解 控制与转发分离 由控制平面维护转发表项，转发平面根据表项完成转发\n针对性优化 性能优化一定要指定优化场景，例如对于收包优化针对不同的接入方式，不同报文类型；\n快慢结合，先慢后快 对于交换机与路由机这种网络转发设备，通过首包建流，后续报文匹配流实现快慢结合提高报文转发效率；\n缓存 缓存大法好，在现在各种系统与应用中缓存无处不在，硬件上看，有硬盘缓存，RAID卡缓存，存储缓存，主存，NUMA特性，CPU cache；软件架构上看，有全局数据缓存，私有数据缓存，连接池，应用服务器缓存，WEB服务器缓存，CDN缓存，客户端文件缓存，客户端内存缓存等等。\ndo more with less 性能优化大体就是开源与节流，do more with less需要考虑如何提高cpu，存储，网络的利用效率\n预处理 兵马未动粮草先行 例如在报文发送针对不同流准备相应的链路层头，避免发送报文再逐字段填充，作到一次性完成报文贴头处理；其实很多应用系统的线程池，内存池，连接池等也是类似思想\n二八原则 主要体现如下:\n 对于优化的代码，集中精力优化是关键20%的代码 在具体的系统性能优化过程刚开始投入20%可以使取得整个优化成果的80%，而最后的20%需要花费80%的时间来完成，而且涉及的挑战会更多，更有难度，所以优化过程越到后面越难，需要良好的心态与意志  无profile，不优化 If you can\u0026rsquo;t measure it, you can\u0026rsquo;t improve it。若无度量，则无提高。优化一定要有一套profile方法，profile以下几个方面的作用：\n profile建立一个性能基线，有利于优化过程中比较与参考 profile查找系统的瓶颈，在一个大型的系统查找到性能瓶颈是一件很有挑战的事情,通过profile有利于快速定位瓶颈 profile评估优化结果，对每一个优化点有一个数字化清晰的记录 profile指导优化的方向  避免过度优化 在性能优化过程中切忌一味追求性能，忽略了业务，没有关注优化对系统带来的哪些不好影响，例如：\n 优化使系统变得更复杂，不利于维护 优化影响了其他业务 优化忽略了业务功能（功能正确性，功能可扩展性等等） 优化只是特定环境下数据提升并不适用具体应用  减少状态的改变 在报文处理与协议处理过程中设计更精简的状态机，避免过多的状态变化处理的开销。\n避免代码的黑盒 避免代码的黑盒，主要有下面几点：\n1.优化过程忽略部分代码，导致这一部分代码未能出现优化对象中\n2.虽然考虑了所有该关注的代码，但是没有理解代码，特别这一部分代码涉及跨团队，个人经验：这一部分代码需要重点关注，往往有意想不到的收获\n总之，性能优化需要充分理解业务，根据数据，实现硬件，系统，业务三者最佳协同。\n", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-thought\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-droppacket\/": {
        
        "title": "一个linux网络丢包问题分析",
        "tags": ["编程",],
        "content": "丢包问题是十分常见一类问题，下面总结的一个网络丢包问题的分析过程。\n问题描述 组网：\nTC-PORT1\u0026mdash;\u0026mdash;-VSR-eth1\nTC-PORT2\u0026mdash;\u0026mdash;-VSR-eth2\n打流：\n报文从TC-Port1打入VSR-eth1，再从VSR-eth2出，到TC-Port2，打流的时候变换了源ip与源端口\n问题：\n测试同学在根据RFC2544打流测试转发性能中，发现报文有效转发性能总是小于40W pps，总是会出现丢包，而实际cpu利用率才20%左右\n问题分析 丢包的原因很多，需要根据现场进行具体问题分析，下面就一个一个排查怀疑点，没有怀疑点再分析的过程：\n 昨天测试都ok的，检查一下测试打流报文，报文正确 查看报文处理过程中丢包计数，以确认丢包阶段，不幸地发现处理过程中无丢包统计 与打多条流有关？实测打一流问题同样存在，与多条流无关 再次回头检查报文是否有多种code path，导致第2步遗漏检查到丢包点，确认报文走一条code path 上面又被否认，继续分析怀疑点，没有分析出怀疑点，自已动手打流，观察TC收发包统计发现丢包有周斯性，大概周期是30s，这是一个重要信息 又回过头去确认一下丢包统计是否有漏统计，很欣慰又很失望的结果：丢包，错包统计没有遗漏统计 这时候收包处理过程丢包可能性已经排除 从上到下的报文流排查，报文丢在网卡上送cpu过程中？ 内核采用epoll收包存在问题？ 进程如果得到调度就没有问题 top 查看进程调度，这时候有重大发现了： 看tc丢包统计与top的里面的进程natlog运行就同步了，但是看到natlog的线程状态为D状态，同时检查配置，开启nat log功能   natlog进程设置为D状态，导致不响应异步信号，在natlog释放cpu前，在转发线程与natlog运行在同一个cpu的情况下，转发线程得不到调度，导致报文接收缓冲区溢出，导致部分报文丢弃；\n  与natlog线程开发同学交流，natlog早期是基于多核开发，natlog根据运营商需求，每30s定时运行，natlog线程运行在控制核，转发线程运行在数据核，导致问题没有暴露出来\n 问题总结  定位问题，特别是未知的问题是一步步有依据推断与确认的过程 获取现场的全方位消息，同时要对信息进行去噪，避免关键信息遗漏与无关干扰  ", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-droppacket\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-tips-nobranchmiss\/": {
        
        "title": "在没有分支miss条件下，实现取最小值",
        "tags": ["Linux",],
        "content": "在实际性能优化过程，加了一个if判断整个系统转发性能就有大约5%的下降，下面简单分享一种在没有分支miss条件下，实现取最小值的方法。\n一般实现 取两个数最小值，一般代码常见两种写法如下：\n 写法一：  1  if(a \u0026lt; b ) { min = a } else { min = b}   写法二：  1  min = a \u0026lt; b ? a:b;   这两种写法只是代码写法不一致，实际都是通过一个if的语句的比较，存在if语句就代码运行过程就存在分支miss，而一个分支的miss的开销范围40到60 cycles；在追求高性能代码，且没有太多的优化点的过程中这是极其宝贵，且这两个分支出现概率都相当，也就不能简单通过likely与unlikely来实现分支预测\n无分支miss实现 无分支实现代码如下：\n1  min = b ^ ((a ^ b) \u0026amp;-(a\u0026lt;b));   分两种情况分析如下：\n当a\u0026lt;b时,-(a\u0026lt;b)为True，表达式等价于min= b ^(a ^ b) = a;\n当a\u0026gt;=b时，-（a \u0026lt; b）为False，表达式等价于min= b ^ 0 = b\n故可以宏定义如下：\n1  #define min(a,b) = (b) ^ ( ((a) ^ (b)) \u0026amp; (-((a)\u0026lt;(b))) )   ", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-tips-nobranchmiss\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-05-09-web-server-perf-and-design\/": {
        
        "title": "",
        "tags": [],
        "content": "+++ banner = \u0026quot;\u0026quot; categories = [\u0026ldquo;Arch\u0026rdquo;] date = \u0026ldquo;2017-05-09T11:58:06+02:00\u0026rdquo; description = \u0026quot;\u0026quot; images = [] menu = \u0026quot;\u0026quot; tags = [\u0026ldquo;Arch\u0026rdquo;] title = \u0026ldquo;高性能服务器设计与优化\u0026rdquo; draft = false +++\n为了构建自己的知识体系，对高性能服务器设计与优化一点想法，其中不足与错误，欢迎指正。\n高性能服务器设计与优化\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-05-09-web-server-perf-and-design\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/gpt-code-errors\/": {
        
        "title": "",
        "tags": [],
        "content": "", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/gpt-code-errors\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/internet\/2017-02-04-country-internet-music\/": {
        
        "title": "",
        "tags": [],
        "content": "+++ banner = \u0026quot;\u0026quot; categories = [\u0026ldquo;闲谈乱扯\u0026rdquo;] date = \u0026ldquo;2017-02-04T11:58:06+02:00\u0026rdquo; description = \u0026quot;\u0026quot; images = [] menu = \u0026quot;\u0026quot; tags = [\u0026ldquo;闲谈乱扯\u0026rdquo;] title = \u0026ldquo;互联网在农村-音乐\u0026rdquo; draft = false +++\n手机上网就是通过app获取服务，在农村里人们上网喜欢干些什么呢？先从喜欢听什么歌开始？ 在家里时间有限，这次就写这么多，待以后回家再观察其他方面。这里仅仅是开一个小引子：农村互联网用户喜欢什么样内容？\n通过小样本获取不负责农村流行歌单如下：\n 小苹果 青藏高原 送情郎 江南 十三不亲 辣妹子 刘三姐 路边的野花不要采 美酒加咖啡 南泥湾 伤不起 妈妈的吻 茉莉花 火苗 月亮之上  再次申明，样本数量有限，不要太当真，随手记记而已\n从上面的歌单可以看出神曲，流行歌曲在哪里都流行，另外就是90年代左右的经典歌曲。\n（End）\n", 
        "url": "http:\/\/myself659.github.io\/post\/internet\/2017-02-04-country-internet-music\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/invest\/invest-l0\/": {
        
        "title": "",
        "tags": [],
        "content": "banner = \u0026quot;\u0026quot; categories = [\u0026ldquo;Invest\u0026rdquo;] date = \u0026ldquo;2021-01-08T11:58:06+02:00\u0026rdquo; description = \u0026quot;\u0026quot; images = [] menu = \u0026quot;\u0026quot; tags = [\u0026ldquo;Invest\u0026rdquo;] title = \u0026quot;\u0026quot; draft = true +++\n交易 https://bridge.harmony.one/erc20/operations/06cb73c6-cb6a3860-78e416ed-b41f39e2\nhttps://explorer.harmony.one/tx/0x23d7957bbb268c3e92a0711fe0ec8959cdac5b9b515ee779ecd1b06ea21f673c\nhttps://layerzeroscan.com/116/address/0xf4d83e35874bee7cb363d37d45ca2adf8c6c26d7/message/102/address/0x1edb8bded80e1b87ed19ee7d97ee80b4fdb615c1/nonce/6\n使用layerzero获利空投。\n两次使用。\n桥是连接的机会。\n跨链6000个one到bsc上面，将来可以当作bsc链上的手续费\nhttps://bridge.harmony.one/one/operations/3733aa6d-5e7d808e-e26819bf-fd25952b\nhttps://explorer.harmony.one/tx/0xc76821b7c62a36568a4d784b62414e201c6a2586400faac8a4575e76ad15cbb9\nhttps://bscscan.com/tx/0xae2deccb48e438125c7bccf434d2f2a96d47bd33c6bee47889182f96a230a332\n希望有空投的机会的。\n原理 Circumventing Layer Zero: Why Isolated Security is No Security\n", 
        "url": "http:\/\/myself659.github.io\/post\/invest\/invest-l0\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s-githubaction\/": {
        
        "title": "",
        "tags": [],
        "content": "banner = \u0026quot;\u0026quot; categories = [\u0026ldquo;Kubernetes\u0026rdquo;] date = \u0026ldquo;2020-10-17T11:58:06+02:00\u0026rdquo; description = \u0026quot;\u0026quot; images = [] menu = \u0026quot;\u0026quot; tags = [\u0026ldquo;Docker\u0026rdquo;, \u0026ldquo;Kubernetes\u0026rdquo;] title = \u0026ldquo;利用github action部署到k8s集群\u0026rdquo; draft = true +++\n目标 个人开发项目软件工程实践。\n概念 先从静态开始\n列表  Cluster pods labels Replication Controllers services Nodes  vs gitlab https://docs.github.com/en/enterprise-server@2.22/actions/learn-github-actions/migrating-from-gitlab-cicd-to-github-actions\n参考  file:///E:/Docker/Using%20GitHub%20Actions%20to%20deploy%20to%20Kubernetes%20-%20Project%20A%20Insights.mht Using GitHub Actions to deploy to Kubernetes https://dotblogs.com.tw/explooosion/2020/10/09/143330 https://gianarb.it/blog/kubernetes-github-action  ", 
        "url": "http:\/\/myself659.github.io\/post\/k8s-githubaction\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/substrate-runtime\/": {
        
        "title": "",
        "tags": [],
        "content": "banner = \u0026quot;\u0026quot; categories = [\u0026ldquo;Substrate\u0026rdquo;] date = \u0026ldquo;2019-09-19T11:58:06+02:00\u0026rdquo; description = \u0026quot;\u0026quot; images = [] menu = \u0026quot;\u0026quot; tags = [\u0026ldquo;Substrate\u0026rdquo;, \u0026ldquo;BlockChain\u0026rdquo;] title = \u0026ldquo;Substrate Runtime实践\u0026rdquo; draft = true +++\ninstall substrate 安装substrate有以下两种方式：\n 快速安装 完全安装  快速安装 1  curl https://getsubstrate.io -sSf | bash -s -- --fast   完全安装 1  curl https://getsubstrate.io -sSf | bash   更新环境变量 1  source ~/.cargo/env   检查版本 1 2 3 4  root@IA:~/rust/install-substrate# substrate --version substrate 2.0.0-37bc8c545-x86_64-linux-gnu root@IA:~/rust/install-substrate# subkey --version subkey 2.0.0   同时安装的还有以下文件：\n substrate-module-new substrate-node-new substrate-ui-new  更新substrate 1 2 3 4  f=`mktemp -d` git clone https://github.com/paritytech/substrate-up $f cp -a $f/substrate-* ~/.cargo/bin cp -a $f/polkadot-* ~/.cargo/bin   substrate \u0026ndash;help 这一步虽然简单，但是很有必要，了解常用的substrate命令。方便以后出现问题快速解决或者找到线索。\n这相当于官方文档。必须要做的一步。短时间的投入，有益的作用。\nRuntime SRML SRML全称Substrate Runtime Module Library。\n实践 准备作一个基于substrate的hello world的实例。\n创建节点 1  root@IA:~/rust/runtime-demo# substrate-node-new hello-node chenfeng   这个过程可以持续10分钟左右。\n启动节点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  root@IA:~/rust/runtime-demo/hello-node# ./target/release/hello-node --dev 2019-09-20 16:04:28 Substrate Node 2019-09-20 16:04:28 version 1.0.0-7f6843a-x86_64-linux-gnu 2019-09-20 16:04:28 by chenfeng, 2017, 2018 2019-09-20 16:04:28 Chain specification: Development 2019-09-20 16:04:28 Node name: exotic-drain-0405 2019-09-20 16:04:28 Roles: AUTHORITY 2019-09-20 16:04:28 Initializing Genesis block/state (state: 0xc727…2701, header-hash: 0x4e61…bccd) 2019-09-20 16:04:28 Loaded block-time = 10 seconds from genesis on first-launch 2019-09-20 16:04:28 Best block: #0 2019-09-20 16:04:28 Using default protocol ID \u0026#34;sup\u0026#34; because none is configured in the chain specs 2019-09-20 16:04:28 Local node identity is: QmXzUZcAxzmAWL8htpX6upw1W9tvecUXLx5h8dP18j3ouL 2019-09-20 16:04:28 Libp2p =\u0026gt; Random Kademlia query has yielded empty results 2019-09-20 16:04:28 Listening for new connections on 127.0.0.1:9944. 2019-09-20 16:04:28 Using authority key 5FA9nQDVg267DEd8m1ZypXLBnvN7SFxYwV7ndqSYGiN9TTpu 2019-09-20 16:04:30 Starting consensus session on top of parent 0x4e61ac8af8f7b3e822d04c678e85c954eb1ec09256253a61c59a3e38d719bccd 2019-09-20 16:04:30 Prepared block for proposing at 1 [hash: 0x0004fc217c56f2970fd3e9d4b80b8263d258424edd13454d34cabda98ff8c110; parent_hash: 0x4e61…bccd; extrinsics: [0x44d0…6310]] 2019-09-20 16:04:30 Pre-sealed block for proposal at 1. Hash now 0x17574e947b8024789cc1af6048fdc69e00ec92fbec46a57c8844989e909fb058, previously 0x0004fc217c56f2970fd3e9d4b80b8263d258424edd13454d34cabda98ff8c110. 2019-09-20 16:04:30 Imported #1 (0x1757…b058) 2019-09-20 16:04:30 Accepted a new tcp connection from 127.0.0.1:20003. 2019-09-20 16:04:31 Libp2p =\u0026gt; Random Kademlia query has yielded empty results 2019-09-20 16:04:33 Idle (0 peers), best: #1 (0x1757…b058), finalized #0 (0x4e61…bccd), ⬇ 0 ⬆ 0 2019-09-20 16:04:35 Libp2p =\u0026gt; Random Kademlia query has yielded empty results 2019-09-20 16:04:38 Idle (0 peers), best: #1 (0x1757…b058), finalized #0 (0x4e61…bccd), ⬇ 0 ⬆ 0 2019-09-20 16:04:40 Starting consensus session on top of parent 0x17574e947b8024789cc1af6048fdc69e00ec92fbec46a57c8844989e909fb058 2019-09-20 16:04:40 Prepared block for proposing at 2 [hash: 0x773e99df58009dd0331262b6468131c3d4ce9de609db8a79ef0e5e1f673de5ae; parent_hash: 0x1757…b058; extrinsics: [0x0bf0…c888]] 2019-09-20 16:04:40 Pre-sealed block for proposal at 2. Hash now 0x6e5b0fb72f9476d03b7b510f21935a8238eaa3f85d8ff7355a66a466b8637204, previously 0x773e99df58009dd0331262b6468131c3d4ce9de609db8a79ef0e5e1f673de5ae. 2019-09-20 16:04:40 Imported #2 (0x6e5b…7204)   连接远端节点 前面的文章提到，在中国现在的网络环境下，选择远端节点开发是一个十分明智的选择。 根据前面的文章，连接远端节点即可以。\n这个我们省得自己搭节点，直接用官方的UI: polkadot.js.org/apps。\n具体步骤如下：\n 进入 https://polkadot.js.org/apps/#/setting 页面 打开custom endpoint选项，设置对应wss网址即可  添加模块 进入runtime目录 1  root@IA:~/rust/runtime-demo/hello-node/runtime/src#   新建mod 1 2 3 4 5 6 7 8 9  root@IA:~/rust/runtime-demo/hello-node/runtime/src# substrate-module-new hello Substrate Module Setup Creating module in .... Customising module... SRML module created as ./hello.rs and added to git. Ensure that you include in your ./lib.rs the line: mod hello;   修改lib.rs 引入hello mod 1  mod hello;   为hello实现Runtime trait 1 2 3  impl hello::Trait for Runtime { type Event = Event; }   添加mod到construct_runtime!宏 1 2 3 4 5 6 7 8 9 10 11 12  construct_runtime!( pub enum Runtime with Log(InternalLog: DigestItem\u0026lt;Hash, AuthorityId, AuthoritySignature\u0026gt;) where Block = Block, NodeBlock = opaque::Block, UncheckedExtrinsic = UncheckedExtrinsic { // add hello mod //Hello: hello::{Module, Call, Storage}, Hello: hello::{Module, Call, Storage, Event\u0026lt;T\u0026gt;}, } );   重新编译与启动 1 2 3 4 5 6 7 8 9 10 11 12  # 编译runtime的wasm版本 ./scripts/build.sh # 编译runtime的本地二进制版本，并构建可执行的客户端 cargo build --release # 删除链上的历史数据 ./target/release/hello-node purge-chain --dev # 启动本地测试网络 ./target/release/hello-node --dev   自定义业务 自动生成mod代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128  ///Aruntimemoduletemplatewithnecessaryimports///Feelfreetoremoveoreditthisfileasneeded.///Ifyouchangethenameofthisfile,makesuretoupdateitsreferencesinruntime/src/lib.rs///Ifyouremovethisfile,youcanremovethosereferences///FormoreguidanceonSubstratemodules,seetheexamplemodule///https://github.com/paritytech/substrate/blob/master/srml/example/src/lib.rsusesupport::{decl_event,decl_module,decl_storage,dispatch::Result,StorageValue};usesystem::ensure_signed;///Themodule\u0026#39;s configuration trait. pub trait Trait: system::Trait { // TODO: Add other types and constants required configure this module. /// The overarching event type. type Event: From\u0026lt;Event\u0026lt;Self\u0026gt;\u0026gt; + Into\u0026lt;\u0026lt;Self as system::Trait\u0026gt;::Event\u0026gt;; } /// This module\u0026#39;sstorageitems.decl_storage!{traitStoreforModule\u0026lt;T:Trait\u0026gt;ashello{//Justadummystorageitem.//HerewearedeclaringaStorageValue,`Something`asaOption\u0026lt;u32\u0026gt;//`get(something)`isthedefaultgetterwhichreturnseitherthestored`u32`or`None`ifnothingstoredSomethingget(something):Option\u0026lt;u32\u0026gt;;}}decl_module!{///Themoduledeclaration.pubstructModule\u0026lt;T:Trait\u0026gt;forenumCallwhereorigin:T::Origin{//Initializingevents//thisisneededonlyifyouareusingeventsinyourmodulefndeposit_event\u0026lt;T\u0026gt;()=default;//Justadummyentrypoint.//functionthatcanbecalledbytheexternalworldasanextrinsicscall//takesaparameterofthetype`AccountId`,storesitandemitsaneventpubfndo_something(origin,something:u32)-\u0026gt;Result{//TODO:Youonlyneedthisifyouwanttocheckitwassigned.letwho=ensure_signed(origin)?;//TODO:Codetoexecutewhensomethingcallsthis.//Forexample:thefollowinglinestoresthepassedinu32inthestorage\u0026lt;Something\u0026lt;T\u0026gt;\u0026gt;::put(something);//hereweareraisingtheSomethingeventSelf::deposit_event(RawEvent::SomethingStored(something,who));Ok(())}}}decl_event!(pubenumEvent\u0026lt;T\u0026gt;whereAccountId=\u0026lt;Tassystem::Trait\u0026gt;::AccountId,{//Justadummyevent.//Event`Something`isdeclaredwithaparameterofthetype`u32`and`AccountId`//Toemitthisevent,wecallthedepositfuntion,fromourruntimefuntionsSomethingStored(u32,AccountId),});///testsforthismodule#[cfg(test)] modtests{usesuper::*;useprimitives::{Blake2Hasher,H256};useruntime_io::with_externalities;useruntime_primitives::{testing::{Digest,DigestItem,Header},traits::{BlakeTwo256,IdentityLookup},BuildStorage,};usesupport::{assert_ok,impl_outer_origin};impl_outer_origin!{pubenumOriginforTest{}}//Fortestingthemodule,weconstructmostofamockruntime.Thismeans//firstconstructingaconfigurationtype(`Test`)which`impl`seachofthe//configurationtraitsofmoduleswewanttouse.#[derive(Clone, Eq, PartialEq)] pubstructTest;implsystem::TraitforTest{typeOrigin=Origin;typeIndex=u64;typeBlockNumber=u64;typeHash=H256;typeHashing=BlakeTwo256;typeDigest=Digest;typeAccountId=u64;typeLookup=IdentityLookup\u0026lt;Self::AccountId\u0026gt;;typeHeader=Header;typeEvent=();typeLog=DigestItem;}implTraitforTest{typeEvent=();}typehello=Module\u0026lt;Test\u0026gt;;//Thisfunctionbasicallyjustbuildsagenesisstoragekey/valuestoreaccordingto//ourdesiredmockup.fnnew_test_ext()-\u0026gt;runtime_io::TestExternalities\u0026lt;Blake2Hasher\u0026gt;{system::GenesisConfig::\u0026lt;Test\u0026gt;::default().build_storage().unwrap().0.into()}#[test] fnit_works_for_default_value(){with_externalities(\u0026amp;mutnew_test_ext(),||{//Justadummytestforthedummyfuntion`do_something`//callingthe`do_something`functionwithavalue42assert_ok!(hello::do_something(Origin::signed(1),42));//assertingthatthestoredvalueisequaltowhatwestoredassert_eq!(hello::something(),Some(42));});}}  修改代码如下 1    参考  Getting Started on Substrate Substrate Collectables Using the Substrate Scripts Codec types  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/substrate-runtime\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/stupid-foolish-is-enemy\/": {
        
        "title": "愚蠢：危险的敌人",
        "tags": ["Thinking",],
        "content": "背景 今天是愚人节。愚人是今天大部分人的例行活动。这里不列举各种愚人的活动，只谈一下这些愚人活动的意义。 在我看来，这些愚人活动有以下作用：\n 大部分愚人活动提供了一些幽默 提供教育价值，让大部分了解一些骗人的方法与形式 测试一下哪些人容易被骗  愚蠢的人与社会 愚蠢的人 对于愚蠢的人caoz总结下面的六大定律：\n第一定律，从来没觉得自己傻逼过的，往往是不可救药的大傻逼\n第二定律，觉得别人都是傻逼的，往往自己才是最傻逼的一个\n第三定律，收割傻逼的会被傻逼们封神，试图唤醒傻逼的是傻逼眼中的傻逼\n第四定律，热衷于证明傻逼是傻逼的，自己也是傻逼\n第五定律，永远不要认为事实会教育傻逼，因为他们对事实的解读方式和你不一样\n第六定律，过度强调团体荣誉的往往也是极度自卑的体现，要用团体的强大幻象掩盖自己的虚弱本质\n愚蠢的社会  低估社会上愚蠢的数量 每个人都会愚蠢的时候 损人不利已是愚蠢的共性 重复别人的愚蠢 大部分会低估愚蠢的破坏力 蠢货，是最危险的一类人  愚蠢来源  自己 他人 环境与系统  应对愚蠢 自己  保持敬畏之心 保持怀疑，大胆猜想，小心求证 不断学习，不断反思 提高自己的圈子水平或者加入高一档水平的圈子 敢于接受错误与事实  他人  不要试图改变他人 远离这些愚蠢的人 对这些愚蠢的人的行为建立防火墙 发现自己与愚蠢的人有一些合作，要学会主动止损  环境与系统  危邦不入,乱邦不居,天下有道则入,无道则隐 如果一个系统出了问题，不要心存侥幸，逃离系统是最好的选择 如果制度出了问题，不要对未来抱有侥幸，时间会给出最坏的结果  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/stupid-foolish-is-enemy\/"
    },
    
}
</script>

<script src="/js/lunr.min.js"></script>
<script src="/js/search.js"></script>
    </footer>
  </article>
        </div>
        

  

  
    <script src="https://utteranc.es/client.js"
            repo="myself659/ipds-public"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/utterance">comments powered by utterances.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.3.1/mermaid.min.js"></script>
<div class="social-links">
      <a href="mailto:myself659@163.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/myself659" class="iconfont icon-github" title="github"></a>
      <a href="https://weibo.com/6484347913" class="iconfont icon-weibo" title="weibo"></a>
      <a href="https://www.zhihu.com/people/lejoys" class="iconfont icon-zhihu" title="zhihu"></a>
  <a href="http://myself659.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/myself659/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2023
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">沉风网事</span>
  </span>
</div>

<script>
window.store = {
    
    
    
    
    "http:\/\/myself659.github.io\/post\/": {
        
        "title": "Posts",
        "tags": [],
        "content": "", 
        "url": "http:\/\/myself659.github.io\/post\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/what-is-writing\/": {
        
        "title": "写作是什么",
        "tags": ["writing",],
        "content": "背景 写作这项技能被低估了。\n写作被低估了，是因为我们没有好好定义什么是写作？或者说我们没有理解写作是什么？\n当我们不去作的事情，我们一定认为这件事是不重要的。当我们深入理解了写作的重要性，才能动力去写作，至少会开始记录（写作的最低水平）。\n写作即记录 写作首先完成记录。\n如果把一条记录看作一条数据，那么写作就是不断扩大与完善自己的（知识与信息）数据库。这个数据库是你记忆的外部缓存，这个数据库是进行知识构建的原材料。\n写作即沟通 写作的过程就是一个与自己沟通的过程，一个基于输出的沟通过程，可以分以下几个基本流程：\n 写作输出内容 基于输出内容给出反馈 基于反馈再修改与优化  写作即思考 写作是知识整理，知识提炼，知识整合的过程。\n写作是知识表达与输出的过程。\n写作是知识学习自我检查的过程。\n写作有利于专注思考。\n清晰的输出离不开清晰，深度，广度的思考。\n写作即学习 学习一个新的知识与技能，通过写作输出教程就是一种不错的学习方法。\n在写作的过程需要解决学习过程遇到的各种问题，只有解决这些问题，才能完成写作。这种也可以叫做写作驱动学习（Writing drive Learning）。\n读书使人充实，写作使人精确。通过写作驱动学习可以精确地掌握知识与技能。\n写作即输出 写作不仅是记录，写作的文章与内容只给自己看那是对自己的输出，如果公开出来那就是公开的输出。 这些内容的输出在当今互联网时代，就是自己这个节点对外连接的连接点（endpoint）之一。\n输出即证明。写作的输出的水平可以一个人的水平。\n写作即分享 写作的内容通过互联网传播就是分享，优质的分享可以带来影响力。\n写作即复利 写作可以让一个人的思想、知识和技能在不断的实践和积累中不断提高，就像财务投资中的复利可以让初始投资随着时间的推移不断增长。\n坚持写作，会不断地提高自己的能力，不断地提高自己输出的质量，不断地提高自己的影响力。。。\n小结 写作是什么？写作是记录，是沟通，是思考，是学习，是输出，是分享，是复利。\n开始写作吧，打开一个新的动力引擎，开启一个新的成长之路。\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/what-is-writing\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/sport\/%E7%A7%91%E6%99%AE%E6%9C%80%E5%A4%A7%E6%91%84%E6%B0%A7%E9%87%8F\/": {
        
        "title": "科普最大摄氧量",
        "tags": ["sport",],
        "content": "定义 最大摄氧量（maximal oxygen uptake，或写为 VO2 max），指一个人在海平面上，从事最激烈的运动时，组织细胞所能消耗或利用的氧之最高值。最大摄氧量可用来评价个人有氧作业能量及心肺耐力，并可藉以设定运动员的耐力运动训练强度。\n最大摄氧量是衡量心肺系统在给定的身体条件和氧气供应水平下将氧气从空气输送到组织的能力极限的有效指标。\n数值 一般说来，最大摄氧量是越大越好。这个给出一个参考值：一个精英级的马拉松运动员其最大摄氧量是80左右，单位是毫升每千克体重每分钟(ml/kg/min)。这是很多人都难以达到的数值。所以普通人的低线要将最大摄氧量保持在40以上，然后尽量往上提高。\n测量 除了平板运动测试，个人推荐使用苹果的iwatch，在跑步的时候进行测试，这种很方便，而且可以持续的测试与跟踪。\n影响因素  肺的通气能力 心脏输出量 血液运氧能力 肌肉的有氧代谢能力 运动能力  重要性 提高最大摄氧量对个人的健康与健身具有重要的意义。\n 改善心血管健康 预测运动表现 确定运动强度 监控培训进度 识别和监测健康风险  如何提高最大摄氧量   定期的心血管运动如慢跑、骑自行车、网球或游泳，以改善心血管健康和耐力\n  高强度间歇训练和冲刺\n  力量运动\n  有氧和无氧交叉训练\n  保持合理的体重\n  运动后充分的恢复和恢复\n  适当的营养与水分补充\n  总结 最大摄氧量不仅是体能的重要指标，也是心血管健康重要指标。\n", 
        "url": "http:\/\/myself659.github.io\/post\/sport\/%E7%A7%91%E6%99%AE%E6%9C%80%E5%A4%A7%E6%91%84%E6%B0%A7%E9%87%8F\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/%E8%AF%B4%E8%AF%B4%E6%A8%A1%E5%9E%8Bmodel\/": {
        
        "title": "说说模型",
        "tags": ["AI","GPT",],
        "content": "定义 先看wiki的定义：\n A model is an informative representation of an object, person or system. The term originally denoted the plans of a building in late 16th-century English, and derived via French and Italian ultimately from Latin modulus, a measure\n 模型是对世界的简化，抽象和概括。\n一切知识都是模型。\npattern vs model pattern是现象,model是机制;\npattern是描述,model是解释;\npattern是观察,model是理解。\npattern偏向应用，model偏向框架。\npattern偏向具体，model偏向抽象。\npattern与model在应用的时候都有一定的限制与局限性。\n模型无处不在，模型无时不在 一切知识都是模型。模型无处不在。\n无论主观上心智模型而是客观世界的规律，模型无时不在默默地影响整个世界。\n下面举几个例子说明：\n  科学模型：在科学研究中，科学家们通过建立数学模型、物理模型和计算模型等，来描述和预测现象。例如，牛顿运动定律可以看作是描述物体运动的模型；基因的遗传模型帮助我们理解遗传特征是如何传递的。\n  心理模型：在心理学中，心理模型是指人们用来解释自己和他人行为的一种内在认知结构。心理模型可以帮助我们理解和预测别人的行为。例如，我们可能有一个关于朋友性格特点的心理模型，这个模型可以帮助我们预测朋友在特定情境下的行为反应。\n  概念模型：我们在学习新知识时，通常会建立一些概念模型，以便更好地理解这些知识。例如，我们在学习计算机科学时，可能会建立一个关于计算机系统结构的概念模型，这个模型可以帮助我们理解计算机是如何工作的。\n  数据模型：在数据处理领域，数据模型是用来描述现实世界中的实体和它们之间关系的一种形式化表示。例如，关系型数据库中的表结构就是一种数据模型，它可以帮助我们组织和操作数据。\n  应用模型 善用模型 学会利用模型来理解世界，理解自己。\n利用模型可以减少认知的成本。\n善用模型要点如下：\n 用好模型 用好模型 超越模型  不迷信模型 不要迷信模型的原因如下：\n  模型的质量参差不齐\n  即使最好的模型也只是对事实的近似描述与表达。模型只是事实的简化，它并不能代表事实\n  模型的应用范围一定是有限制，模型可能不适用于现实\n  模型存在偏见\n  模型是压缩的，很可能存在压缩损失\n  所以在应用模型不要迷信模型，要敢于怀疑一切，大胆假设，小心求证。\n提高自己的心智模型 上面提到不能迷信的模型，所以要努力提高自己的心智模型。\n我们是什么样的人取决于我们如何思考。 我们如何思考取决于我们的心智模型。\n提高自己的心智模型，有利于我们能够适应新的挑战，复杂性的问题，不断变化的世界。\n总结   模型是对世界的简化，抽象和概括。一切知识都是模型，模型无时不在，无处不在\n  用好模型\n  超越模型\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/%E8%AF%B4%E8%AF%B4%E6%A8%A1%E5%9E%8Bmodel\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/autogpt-101\/": {
        
        "title": "说说autoGPT",
        "tags": ["AI","GPT",],
        "content": "背景 chatGPT开启的AIGC领域，最近几个月的发展可以说日新月异，众多LLM如雨后春笋，最近autoGPT的出现，更是吸引大家的关注。\nautoGPT   autoGPT是什么？作者对其定义是：An experimental open-source attempt to make GPT-4 fully autonomous.\n  如果说GPT-4是当前最先进的知识计算引擎，那么autoGPT改变我们使用GPT-4的方式：由写prompt手动操作到由autoGPT根据目标自动写prompt.打一个比方就是汽车由手动档换成自动档。\n  所以说autoGPT改变了我们与GPT-4的交互方式\n  与GPT-4交互方式的发展方向：低门槛，语音化，自动化，智能化\n  autoGPT给GPT-4提供一种使用方式：根据目标自动生成一系列的prompt， 相信GPT-4极大可能将这种使用方式融入自身当中\n  如果GPT-4属于引擎层，那么autoGPT属于接口层或者称为代理层， 接口层的作用是将GPT-4以更多的方式接入到更多的应用场景当中\n  autoGPT是如何工作呢？这里面最核心的问题是如何根据任务分解任务，生成prompt？\n  以autoGPT为代表的接口层未来是否可以实现多LLM协同完成任务？\n  以autoGPT为代表的代理层成为个人在数字世界（元宇宙）的代理？\n  autoGPT当前存在的问题：使用成本与门槛过高，太费token同时也要求使用者自己会搭建应用环境\n  总之，autoGPT开启一个如何使用AGI这一新的研究课题\n  参考 Auto-GPT\nAgentGPT\ncognosys\n", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/autogpt-101\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/chatmind-book-mindmap\/": {
        
        "title": "利用chatmind生成mindmap实现快速阅读",
        "tags": ["Think",],
        "content": "chatGPT是知识计算引擎 chatGPT是知识计算引擎。\nchatmind团队在chatGPT的基础之上，开发一款产品：提供prompt模块，快速生成各种总结与思维导图。\n下面先看一个具体的例子。\n示例 模板 1  Please help me generate a study notes mind map about [A Hacker\u0026#39;s Mind]   输出 ![思维导图](/images/ai/A Hacker\u0026rsquo;s Mind.svg)\n优化与调整 ![增加细节](/images/ai/A Hacker\u0026rsquo;s Mind-1.svg)\n![增加维度](/images/ai/A Hacker\u0026rsquo;s Mind-2.svg)\n评价  速度快 内容重点突出 支持优化与调整：rewrite, ex Branch, ex Level, Ex Detail, Ex Idea 使用简单  总结  chatmind充分利用GPT的api chatmind专注于一个小应用场景：总结与思维导图 chatmind对prompt进行封装 chatmind优化用户体验，降低门槛  ", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/chatmind-book-mindmap\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E5%81%87%E5%A6%82%E7%A4%BE%E4%BC%9A%E6%8A%9B%E5%BC%83%E4%BA%86%E4%BD%A0\/": {
        
        "title": "假如社会抛弃你",
        "tags": ["life",],
        "content": "背景 天门山跳崖：四个决绝赴死的农村青年\n天门山跳崖：四个决绝赴死的农村青年\n看到这个新闻，深受震撼，十分痛心与惋惜。\n决绝赴死的原因极大可能是在长期苦难之下，看不到希望，感到绝望。\n社会的声音 对于这个事件社会有很多声音：\n 没有刀人，撞人和砸人……而是选择默默地离开，或许他们对这个世界曾经爱过吧…\n  活着如果只是没完没了吃苦，真的会丧失活下去的意志\n  我只不过是投胎投的好点罢了，没有一点资格评价他们\n  都是被苦难击倒的可怜人，下辈子过得好点吧\n  可能到了最后，只能感觉到只有死才是自己能做主的[单身狗]，安息吧朋友们，愿那边没有压力\n  这里容不下疲累，不承认贫穷，不允许错误。根基稍弱一点，运气稍差一点，一不留神就会被远远抛下。愿他们在那边世界得以解脱，\n  让年青人绝望的社会是没有希望的社会\n 假如社会抛弃了你 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  假如社会抛弃了你，不要颓废，不要气馁！ 孤独的日子里须要坚强：相信吧，友爱的人们终将相逢！ 心儿永远追求着真理；现在却常是彷徨。 一切都是过程，一切都将会改变；而那改变了的，就会成为坚定的信念。 假如社会抛弃了你，不要忧虑，不要恐惧！ 挫折的日子里须要勇敢：相信吧，成功的喜悦必将降临！ 心儿永远展望着前方；现在却常是迷茫。 一切都是成长，一切都将会消逝；而那消逝了的，就会成为宝贵的经验。 假如社会抛弃了你，不要沮丧，不要退缩！ 黑暗的日子里须要希望：相信吧，光明的未来正等待着你！ 心儿永远燃烧着激情；现在却常是疲惫。 一切都是奋斗，一切都将会起航；而那起航了的，就会成为美好的回忆。   对自己好一点   不断学习，熟悉社会，学会保护自己，防止上当受骗\n  坦然面对现实，接受自己的普通与平凡，善待自己\n  看长远一些，时间也许会冲淡一切\n  学会断舍离\n  尽力就好，躺平无过\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E5%81%87%E5%A6%82%E7%A4%BE%E4%BC%9A%E6%8A%9B%E5%BC%83%E4%BA%86%E4%BD%A0\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/how-to-ai-help-growth\/": {
        
        "title": "如何利用GPT类AI提升自己",
        "tags": ["AI","GPT",],
        "content": "背景 chatGPT的横空出世，宣告真正的人工智能时代已经开启。\n未来会是怎么样，没有人知道，我只知道这两点：\n 会用AI的人淘汰不会用AI 谁更会用AI，谁更有竞争力  下面我们就看一下GPT们是怎么教我们用好他们的。\nhow use GPTs to level up my knowledge, insight, wisdom, and skills. chatGPT 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  Certainly! Here are 20 different ways you can use me to level up your knowledge, insight, wisdom, and skills: 1. Ask me questions about topics you\u0026#39;re interested in. I can provide you with information and explanations that can help you deepen your understanding of those topics. 2. Use me to practice your writing skills by asking me to generate writing prompts for you. 3. Ask me to suggest books, articles, or other resources on a topic you want to learn more about. 4. Use me to practice your public speaking skills by asking me to generate speech topics for you. 5. Ask me to provide you with feedback on your writing or speaking. I can help you identify areas for improvement. 6. Use me to practice your critical thinking skills by asking me to generate thought-provoking questions for you to answer. 7. Ask me for advice on a problem you\u0026#39;re facing. I can help you brainstorm solutions and weigh the pros and cons of different options. 8. Use me to practice your research skills by asking me to find information on a specific topic. 9. Ask me to provide you with a daily dose of inspiration or motivation by generating inspiring quotes or messages. 10. Use me to learn a new language by asking me to generate vocabulary words or phrases in that language. 11. Ask me to generate trivia questions for you to answer. This can help you expand your general knowledge. 12. Use me to practice your creativity by asking me to generate writing prompts or art prompts for you. 13. Ask me to suggest podcasts or documentaries on a topic you\u0026#39;re interested in. This can help you gain a deeper understanding of that topic. 14. Use me to practice your time management skills by asking me to generate a schedule or to-do list for you. 15. Ask me to provide you with tips or strategies for learning a new skill or subject. 16. Use me to practice your communication skills by asking me to generate conversation starters or icebreakers for you. 17. Ask me to suggest online courses or tutorials on a topic you want to learn more about. 18. Use me to practice your problem-solving skills by asking me to generate hypothetical problems for you to solve. 19. Ask me to provide you with feedback on your creative work, such as writing, art, or music. 20. Use me to practice your decision-making skills by asking me to generate hypothetical scenarios for you to make decisions about.   GPT4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  1. **Research assistance**: Use me to gather information on any subject, from history to technology, to deepen your understanding. 2. **Book summaries**: Request summaries of books or articles to quickly expand your knowledge on various topics. 3. **Language learning**: Practice your language skills by engaging in conversations with me in your target language. 4. **Writing tips**: Improve your writing skills by asking for tips, techniques, and feedback on your work. 5. **Problem-solving**: Pose complex problems or scenarios for me to help you brainstorm creative solutions. 6. **Critical thinking**: Engage in debates or discussions to challenge your perspective and enhance your critical thinking abilities. 7. **Skill development**: Ask me for resources or exercises to develop specific skills such as programming, graphic design, or public speaking. 8. **Career advice**: Seek guidance on your career path, job applications, and interview techniques. 9. **Time management**: Request tips and strategies to improve your time management and productivity. 10. **Memory techniques**: Learn memory-enhancing techniques such as the Method of Loci, mnemonics, or the Major System. 11. **Study strategies**: Ask for study techniques and methods like the Pomodoro Technique, spaced repetition, or the Feynman Technique. 12. **Philosophy and ethics**: Discuss philosophical ideas and ethical dilemmas to expand your moral and intellectual horizons. 13. **Personal finance**: Request advice on budgeting, investing, and financial planning. 14. **Health and wellness**: Discuss nutrition, exercise, and mental health strategies to improve your overall well-being. 15. **Cooking and recipes**: Learn new recipes and cooking techniques to expand your culinary skills. 16. **Art and culture**: Delve into the world of art, music, and culture to broaden your appreciation and understanding. 17. **Travel and geography**: Discover new destinations, cultures, and languages to enrich your global perspective. 18. **Science and technology**: Stay updated on the latest scientific discoveries and technological advancements. 19. **History and current events**: Discuss historical events and their impact on the present, as well as stay informed on current news. 20. **Personal growth**: Reflect on your strengths, weaknesses, and goals, and ask for guidance on self-improvement and personal development.   Claude 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  Here are 20 ways I can help level up your knowledge, insight, wisdom and skills: 1. Ask me to explain complex ideas in simple terms. This strengthens your understanding. 2. Ask me for summaries of topics you\u0026#39;re interested in. This provides a high-level overview before diving into details. 3. Ask me for book or resource recommendations on subjects you want to learn. I can suggest materials at different skill levels. 4. Ask me to outline key steps to achieve a goal or master a skill. This breaks down the path into manageable chunks. 5. Ask me to provide examples that illustrate concepts or ideas. Examples enhance learning. 6. Ask me for key insights, main takeaways or lessons learned on various topics. This distills information into concise, memorable points. 7. Ask me for video, online course or tutorial recommendations to supplement your learning. I can recommend high-quality resources. 8. Brainstorm ideas with me on any topic or project. We can have an open exchange of ideas to gain new insights. 9. Ask me to find opportunities for hands-on practice. For example, tools to learn, ways to mentor others, meetups to join, side projects, etc. 10.Ask me thought-provoking questions about various issues. This sparks engaging discussion where you defend your position and challenge assumptions. 11. Ask me to provide facts, statistics, quotes or data on topics you\u0026#39;re exploring. I can supply credible information from reputable sources. 12. Ask me to review and provide feedback on work you\u0026#39;ve done like papers, projects, blog posts, code, designs, etc. My input can strengthen your thinking and outputs. 13. Ask me open-ended hypothetical questions like \u0026#34;What if?\u0026#34; or \u0026#34;Why not?\u0026#34;. We can explore possibilities and push boundaries. 14. Ask me to find contradictory or alternative perspectives on issues. This enhances critical thinking to navigate paradoxes and complex problems. 15. Ask me to share latest advances, discoveries or trends that could impact the future of a field. Staying current keeps you adaptable to change. 16.Ask me to compile information from multiple sources on subjects you\u0026#39;re interested in. I can synthesize material from across books, articles, studies, and expert opinions. 17. Quiz me on concepts or topics you want to learn. Explaining information back strengthens your own understanding and memory. 18. Ask me to generate ideas, options or solutions around problems you\u0026#39;re trying to solve. Fresh perspectives can lead to new insights. 19. Ask me open-ended questions about my knowledge, abilities or limitations. Understanding an AI system\u0026#39;s capabilities and constraints is important. 20. Experiment by giving me new types of questions or complex problems to see how I respond. Pushing an AI\u0026#39;s limits helps identify weaknesses and areas for improvement. (edited)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  这里有50种方法可以帮助提高您的知识、洞察力、智慧和技能: 1. 让我用简单的词语解释复杂的思想。这有助于加深您的理解。 2. 让我概括您感兴趣的主题。这在深入细节之前提供了高级概述。 3. 询问我关于您想学习的主题的书籍或资源推荐。我可以推荐不同技能水平的材料。 4. 让我概述实现目标或掌握一项技能的关键步骤。这能将路径分解为可管理的部分。 5. 让我提供例子来说明概念或思想。例子可以增强学习。 6. 让我提供各个主题的关键见解、要点或经验教训。这可以将信息简洁明了地表达出来,令人难忘。 7. 询问我的视频、在线课程或教程推荐以补充您的学习。我可以推荐高质量的资源。 8. 与我一起对任何主题或项目进行头脑风暴。我们可以开放意见交流,获得新的见解。 9. 让我找到实践的机会。例如,学习工具、辅导他人的方式、参加聚会、边项目等。 10.问我关于各种问题的发人深省的问题。这可以引发令人兴奋的讨论,在讨论中您要为自己的立场辩护并质疑假设。 11. 让我提供您探索的主题的事实、统计数据、引语或数据。我可以从可靠来源提供可信的信息。 12. 让我审阅并对您完成的工作(如论文、项目、博客文章、代码、设计等)提供反馈。我的意见可以加强您的思考与输出。 13. 问我开放式的假设性问题,如\u0026#34;如果呢?\u0026#34;或\u0026#34;为什么不呢?\u0026#34;。我们可以探索可能性,推动界限。 14. 让我找到问题的相反或另类观点。这可以增强您的批判性思维,帮助应对悖论与复杂问题。 15. 让我分享可能影响某个领域未来发展的最新进展、发现或趋势。密切关注可以使您适应变化。 16.让我从多个来源汇编您感兴趣的主题的信息。我可以综合书籍、文章、研究和专家意见中的材料。 17. 对我提问您想学习的概念或主题。解释信息可以加强您自己的理解与记忆。 18. 让我针对您要解决的问题生成想法、选择或解决方案。新视角可以导致新的见解。 19. 向我提出开放性的有关我的知识、能力或限制的问题。了解人工智能系统的功能与限制很重要。 20. 通过给我新的问题类型或复杂问题来试验,看我的反应。推动人工智能的极限可以发现弱点与改进空间。 21. 让我对您想学习的主题创建大纲或思维导图。可视化组织信息可以产生新的联系和见解。 22.与我讨论伦理问题和思想实验。探讨道德、价值观和\u0026#34;如果\u0026#34;可以增强批判性思维。 23. 让我在您关心的问题上担任魔鬼的代言人。辩护相反的观点可以质疑假设,拓宽视角。 24. 让我解释我的推理过程或\u0026#34;展示我的工作\u0026#34;的方式来提供信息。对人工智能过程的透明度可以建立信任并发现缺陷。 25. 与我提出假设场景或角色扮演情况。在各种情境中实践可以主动学习和解决问题。 26. 问我任何主题的开放领域问题。一个可以处理多样化、非限定性问题的人工智能需要强大的知识与会话能力。 27. 要求我以不同的方式重新解释或重新表达事物。以多种形式呈现信息可以加强学习。 28. 问我与可能性、创造力或想象力有关的推测性问题。讨论开放性的\u0026#34;如果\u0026#34;可以拓展思维。 29. 询问我的知识限制或我作为人工智能系统的工作方式。理解一项技术的功能与当前能力的限制是重要的环境因素。 30.通过给我故意模糊或含混不清的问题进行试验,看我的反应。处理不清晰、非结构化的输入需要高级会话能力。 31. 与我讨论观点或立场问题的论点与反论点。探讨一个讨论的双方可以拓宽视角。 32. 问我暗喻或诗意的问题,看我是否能创造性地回应。以多元、抽象的方式与语言和思想互动可以培养理解能力。 33. 询问我的知识与能力如何可以根据新数据和研究随着时间的推移而增强或扩展。 理解人工智能可能如何发展提供有用的背景环境。 34. 要求我总结信息或概括某个领域的最新进展。概括与总结信息对学习很有帮助。 35. 要我复述和总结您提供的信息和论点。重新表达信息有助于记忆与理解。 36. 询问与技术、科学或人工智能前沿发展领域相关的问题。了解最新进展有助于适应变化。 37. 让我分享各个主题的工具、技术或资源的比较与对比。对不同选项的权衡有助于做出更明智的选择。 38. 让我解释复杂系统、技术过程或科学主题。简明扼要地阐述这些概念有助于加深理解。 39. 让我建议解决某个问题或实现某个目标的步骤性方法。将任务分解为清晰易行的步骤十分实用。 40. 让我为某个概念、主题或技能筛选学习资源。我可以考虑不同的学习方式与技能水平进行推荐。 41. 让我溯源某个概念、主题或产品以完整描述其起源与演变过程。理解历史背景与发展轨迹有助于加深理解与判断。 42. 与我探讨有争议的主题或无法达成共识的问题。 43. 让我从不同学科、文化或观点解释某个概念或事件。多角度分析可以提供全面而平衡的理解。 44. 向我提出需要创新、思考外盒或与常识相悖的问题。这可以推动我发展更强大、更具创造力的推理与解决问题的能力。 45. 让我总结并重新表述您表达的某个观点或论据。这有助于澄清理解,发现以往未考虑的角度。 46. 询问我未来几年内某个技术、领域或社会问题可能产生的影响与结果。考虑不同的可能性与后果可以为应对变化做好准备。 47. 让我找出某个观点或论据中的逻辑漏洞、偏差或矛盾之处。理性和批判性分析对建立符合逻辑的观点很重要。 48. 询问我对某个决定或问题的建议,包括各种选择的优点、缺点与权衡考量。提供决策支持需要综合分析不同的因素。 49. 让我指出信息、数据、研究或推论中的瑕疵、限制与不确定性。理解信息的局限性对作出明智判断很重要。 50. 与我玩文字游戏或解谜来推动创造性思维。运用语言和模式识别的能力可以以新的方式关联概念与见解。 通过上述方法,我们可以进行深入和广泛的交流与探讨,不断推动并丰富我的知识与能力。我由衷地希望这些建议能对您有所帮助!如果您有任何其他的意见或建议,我也十分欢迎。   总结  GPT们知识储备远远超过个人 GPT们知识计算速度比我们人类 GPT们的总结，发散能力远超人类 GPT们没有自我意识，不会主动，被动接受prompt，人类要充分分挥自己的主动性与积极性，用好AI GPT们遵守这一规则：GIGO。所以要写好prompt HI+AI结合才是正道  ", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/how-to-ai-help-growth\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/logic-gpt4-chatgpt\/": {
        
        "title": "从三道逻辑分析题看GPT4",
        "tags": ["AI",],
        "content": "背景 GPT-4最近已经推出，那么GPT-4表现如何？相对于chatGPT使用的gpt3.5模型有哪些提高与进步？\n下面就通过三道逻辑题展开测试与对比。\n第一题 问题描述 1 2 3 4 5 6  三个逻辑学家下班后想在一起喝一杯，就来到一家酒吧。服务员问：给你们所有人都来杯酒？ 第一个说，我不知道。 第二个说，我也不知道。 第三个说：是的。 为什么第三人说“是的”。   chatGPT的回答 1  第三个逻辑学家的回答是“是的”，是因为如果服务员给所有人都倒一杯酒，那么第三个逻辑学家也会被包括在内。这里是一种间接的否定方式，他的意思是“不会有任何一个人不能喝酒，所以给所有人都来一杯酒”。   GPT4的回答 1 2 3 4 5 6 7 8 9  这个问题涉及到了逻辑推理。在这个场景中，三个逻辑学家下班后想喝酒。当服务员询问他们是否所有人都需要酒时，他们的回答反映了他们的观察和思考。我们可以分析每个逻辑学家的回答： 1. 第一个逻辑学家说：“我不知道。” 这表明他自己想喝酒，但不知道其他两人是否想喝。如果他自己不想喝，他会直接回答“不是”。 2. 第二个逻辑学家听到了第一个的回答，所以知道第一个逻辑学家想喝酒。然后他说：“我也不知道。” 这表示他自己也想喝酒，但仍然不知道第三个人是否想喝。如果第二个逻辑学家不想喝酒，他会知道答案是“不是”。 3. 第三个逻辑学家听到了前两个人的回答，所以知道第一个和第二个逻辑学家都想喝酒。然后他说：“是的。” 这表明他也想喝酒。因为前两个人都想喝酒，他可以确信所有人都想喝酒，所以回答“是的”。 通过逻辑学家们的回答，他们能够推理出彼此是否想喝酒，最终得出所有人都想喝酒的结论。   第二题 问题描述 1  下面是一个戴帽子的游戏，现在有2 顶黑帽子，3 顶白帽子，主持人用黑布蒙上A、B、C三人的眼睛，并在每个人头上戴一顶帽子，剩下的两顶藏起来，然后解开B、C的蒙眼布，让他们三个人分别说出自己头上戴的帽子颜色，B、C看着别人头上的帽子却都回答不上来。这个时候A却说他知道了 ，她戴的是白色。主持人说对，请问 A是怎么推理的   chatGPT的回答 1  A可以推断出自己戴的是白色帽子，因为如果B或C看到自己和另一个人都戴黑帽子，那么他们就可以推断自己戴白帽子，但是他们都无法回答，说明两者中至少有一个人戴白帽子，那么A就知道自己戴白帽子了。   GPT4的回答 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  A 知道有 2 顶黑帽子和 3 顶白帽子。当 B 和 C 的蒙眼布被解开时，A 仍无法看到其他人头上的帽子颜色，但可以听到 B 和 C 的回答。 首先，B 看到了 C 的帽子，有以下两种可能： 1. 如果 C 戴着黑帽子，那么 B 知道还有 1 顶黑帽子和 3 顶白帽子。此时，B 知道自己戴的帽子颜色可能是黑色（剩下的一顶黑帽子）或白色（3 顶白帽子中的一顶）。 2. 如果 C 戴着白帽子，那么 B 知道有 2 顶黑帽子和 2 顶白帽子。此时，B 知道自己戴的帽子颜色可能是黑色（2 顶黑帽子中的一顶）或白色（2 顶白帽子中的一顶）。 由于 B 无法确定自己戴的帽子颜色，接下来轮到 C 推理。此时，C 已知 B 看到了 C 戴的帽子颜色，但无法确定 B 戴的帽子颜色。因此，C 可以推测如下： 1. 如果 B 看到了 C 戴的是黑帽子，那么 C 知道 B 有可能看到剩下的一顶黑帽子和 3 顶白帽子。此时，C 会认为自己戴的帽子颜色可能是黑色或白色。 2. 如果 B 看到了 C 戴的是白帽子，那么 C 知道 B 看到有 2 顶黑帽子和 2 顶白帽子。此时，C 怀疑自己戴的帽子颜色可能是黑色（2 顶黑帽子中的一顶）或白色（2 顶白帽子中的一顶）。 因为 C 也无法确定自己戴的帽子颜色，A 可以从 B 和 C 的回答中得出一些信息。A 可以推理如下： 1. 如果 B 和 C 都看到了对方戴的是黑帽子，那么他们应该能够确定自己戴的是白帽子（因为只有 2 顶黑帽子）。 2. 但实际上，B 和 C 都无法判断自己戴的帽子颜色。这意味着他们看到的是对方戴的白帽子，因为如果他们看到的是黑帽子，他们会知道自己戴的是白帽子。 所以，A 可以推理出自己戴的是白帽子，因为 B 和 C 都无法确定自己戴的帽子颜色。   第三题 问题描述 1  国王让三智者站成一个纵队，闭上眼睛，给他们每人戴一顶帽子。然后睁眼，中间可以看到前面的帽子，最后面的可以看到前两个。他们都知道共有2顶白帽子和3顶红帽子。国王问这三人：“谁知道自己戴的帽子颜色？” 问了两遍无人回答。第三遍时是否有人能回答？如果有，他是哪一位？戴什么颜色帽？   chatGPT的回答 1 2 3 4 5 6 7 8  第三遍时，有一个智者能回答。他是最后面的智者，戴的是白色帽子。 这是推理过程： 如果前面两顶帽子都是红色，那么最后面的智者就知道自己戴的帽子颜色是白色，因为只有两顶白帽子。但是，在第一次和第二次问答时，前面两位智者都没有回答，这表明前面两顶帽子至少有一顶是白色。 如果前面两顶帽子中有一顶是白色，那么最后面的智者就不可能知道自己戴的帽子颜色，因为他看到的是前面两顶帽子中的红色帽子。但是，在第三次问答时，最后面的智者回答了，说明前面两顶帽子都是红色的，最后面的智者知道自己戴的是白色帽子。   GPT4的回答 1 2 3 4 5 6 7 8 9  首先，我们来分析一下这个问题。三智者站成一个纵队，我们称他们为A、B和C，其中A站在前面，B站在中间，C站在最后。共有2顶白帽子和3顶红帽子。 1. 当国王第一次询问时，C看到了A和B的帽子。如果C看到了两顶白帽子，那么他就可以确定自己戴的一定是红帽子（因为只有2顶白帽子）。但C没有回答，说明C看到的帽子中至少有一顶红帽子。 2. 当国王第二次询问时，B知道C看到的帽子中至少有一顶红帽子。如果B看到A戴的是白帽子，那么B就可以确定自己戴的是红帽子（因为C没有看到两顶白帽子）。但B也没有回答，说明A戴的帽子也是红帽子。 3. 当国王第三次询问时，A已经了解到C看到的帽子中至少有一顶红帽子，B也看到了红帽子。所以，A可以推断出自己戴的帽子是红帽子（因为C和B都没有回答）。 综上所述，第三遍时A能够回答，他戴的是红帽子。   总结 从上面的三道逻辑题的例子可以看出GPT-4模型的厉害之处：\n 理解能力更强了 表达能力更强了 逻辑推理能力可以说有新的突破  ", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/logic-gpt4-chatgpt\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/human\/%E4%BD%93%E5%88%B6%E5%86%85%E4%BA%BA%E5%91%98%E5%86%85%E5%8D%B7%E8%B5%B7%E6%9D%A5\/": {
        
        "title": "体制内会越来越内卷",
        "tags": ["human",],
        "content": "国际与国内大环境 先来看看中国及其外部环境：\n 疫情三年，大部分民众经济状态恶化（收入下降，开支增加） 政府税收增速远跟不上政府开支的需求 一部分企业家躺平（goblin mode） 疫情冲击（中国阳后出现肺炎人群约为8%）民众健康，影响劳动力市场，增加医保开销 投资，消费，出口的带动作用均下降 全球化下全球分工与协作受到影响 俄乌等局部战争 中美关系的修复关键在中方 2023年房地产卖地收入只会比2022年进一步下降(2022年城投当托，帮拿了不少地)  体制内环境 看了大环境，再看一下体制内环境：\n 国考录用比约70:1，这会招进一批卷王 国家自然科学基金委通报8人学术不端，这是多年不见的事情 各地公务员降薪 内部反腐力度加大 一点常识：体制内不创造财富，大部分国有企业能创造财富，但是效率低下 体制内一直是比较封闭，且近年来有加强的趋势  分析与结论 内卷原因 个人对于内卷的原因通用分析如下：\n 封闭或者开放不足导致空间不足 控制过多 集中度过高 目标趋同 路径趋同  体制内环境与运行方式十足地满足上面的原因。\n越来越卷原因  封闭越来越强，开放越来越不足 控制越来越多（如各种规定如考核） 集中度越来越高（如国考录用比约70:1） 体制内目标趋同（大部分人求安稳，领一份生活的工资） 路径趋同（大部分人讲内部潜规则与暗规则） 财政收入跟不上开支，导致体制内各部门竞争加大 更多的卷王加入体制内，增加相互卷的动力（只要这种工作处于社会的顶端，一定会卷起来，互联网大厂就是最好的证明）  由上可知：内卷的条件越来越符合，内卷的动力越来越强，所以会越来越内卷。\n结论 如果经济不能很好的恢复（当然经济恢复到原来的增长是不可能的），财政压力没有缓解，体制内只会越来越卷。\n希望 最后希望卷的目标是合法的收入与职位，卷的路径是实实在在为人民服务，努力避免那种无意义无效果的内卷。\n", 
        "url": "http:\/\/myself659.github.io\/post\/human\/%E4%BD%93%E5%88%B6%E5%86%85%E4%BA%BA%E5%91%98%E5%86%85%E5%8D%B7%E8%B5%B7%E6%9D%A5\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E5%9B%A2%E9%98%9F%E7%8A%B6%E6%80%81%E8%AF%8A%E6%96%AD\/": {
        
        "title": "如何判断团队是否处于下行状态",
        "tags": ["Thinking",],
        "content": "团队如果有以下状态，团队可能处于下行状态：\n 团队成员流失严重，且处于加速状态 团队一部分成员内卷严重 团队一部分成员普遍躺平 团队会议没有人主动发声 团队成员总是同意领导的决定 团队成员害怕失败，怕承担责任 团队效率与产出下降 团队的决定需要逐级上报 团队内有大量的微管理 团队成员即使状态挣扎，也不主动求助 团队不能正视问题，拖延或甩锅 团队内团伙多，存在内讧，缺少凝聚力 团队目标与路径不统一  团队领导如何解决这些问题?说一句正确的废话：尊重事实，直面问题，对症下药，制定正确的策略，领导要以身作则，以实际行动来改变团队的现状，至少要让团队在变坏的路上先停下来。\nPs：只适用于小型组织，特别不适用于像国家这样大型组织。\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E5%9B%A2%E9%98%9F%E7%8A%B6%E6%80%81%E8%AF%8A%E6%96%AD\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/how-to-ask-gpt\/": {
        
        "title": "如何更好地向ChatGPT提问",
        "tags": ["AI",],
        "content": "说明 下面的所有的问题均由chatGPT回答。\n如何描述问题才能让chatGPT更好的回答？ 以下是描述问题的一些技巧，可以帮助 ChatGPT 更好地理解和回答你的问题：\n简明扼要地描述你的问题：尽可能简单清晰地表达你的问题，避免使用复杂或模糊的术语或语言。\n提供相关背景信息：提供与问题相关的背景信息，例如任何先前的经验或事件、相关的环境或条件、你的目标等。\n采用具体的语言：使用具体的词汇和语言，以确保问题的清晰度和准确度。\n避免主观判断：尽量避免使用主观性的描述或判断，以免对问题的理解和回答造成误导。\n确定你想要的答案类型：明确你希望 ChatGPT 回答的是什么类型的问题，例如一个事实、一个意见、一个建议或者一个说明等。\n提供示例：如果可能的话，提供示例或场景，以便 ChatGPT 更好地理解你的问题。\n相关问题的链接：如果你的问题与某个领域的其他问题有关，可以提供相关的链接或参考资料，以便 ChatGPT 提供更全面的答案。\n通过以上技巧，你可以帮助 ChatGPT 更好地理解你的问题，提供更准确、详细和有用的回答。\n请提供一些具体的例子 当你在描述问题时，以下是一些具体的例子可以帮助 ChatGPT 更好地理解你的问题：\n问题描述：如何在网上购物？\n不够好的问题描述：告诉我网上购物的所有事情。\n更好的问题描述：我想在亚马逊上购买一些物品。你可以告诉我如何浏览商品、下订单、支付和退货吗？\n问题描述：如何在大学申请研究生项目？\n不够好的问题描述：我需要研究生项目的所有信息。\n更好的问题描述：我想申请某所大学的计算机科学研究生项目。你可以告诉我申请过程、文书材料、要求、截止日期和其他相关信息吗？\n问题描述：如何学习编程？\n不够好的问题描述：告诉我学习编程的所有东西。\n更好的问题描述：我想学习 Python 编程语言。你可以建议一些学习资源、练习项目和实践技巧吗？\n问题描述：如何烤比萨饼？\n不够好的问题描述：告诉我如何烤一张比萨饼。\n更好的问题描述：我想在家里烤一张美味的比萨饼。你可以分享一些比萨饼面团的配方、烤箱设置和烹饪时间吗？\n问题描述：如何降低血压？\n不够好的问题描述：告诉我如何降低血压。\n更好的问题描述：我被诊断为高血压，你可以给我一些改善生活方式、饮食、锻炼和药物治疗的建议吗？\n以上例子中，更好的问题描述提供了更具体、清晰、明确和可操作的信息，让 ChatGPT 更好地理解问题并提供更有针对性的答案。\n请从所有你回答的问题中选择十个你觉得问最好的问题 以下是我从我回答的问题中选择的十个我认为最好的问题：\n什么是人工智能，它的优点和缺点是什么？\n如何在工作和家庭生活之间取得平衡？\n什么是气候变化，它是如何发生的，我们可以做些什么来减缓它的影响？\n什么是心理健康，我们可以做些什么来保持它？\n为什么有些人会拥有更强的意志力？我们如何训练我们的意志力？\n什么是全职教育，我们可以从中获得什么收益？\n如何成为一个好的领导者？哪些特质和技能是必要的？\n什么是区块链技术，它是如何工作的，有什么应用场景？\n如何学会自我管理和组织，以提高效率和效益？\n什么是数据隐私，为什么它很重要？我们可以做些什么来保护我们的数据隐私？\n以上这些问题都是现代生活中普遍而重要的问题，能够引起人们的关注和探究，涉及科技、生活、工作、社会等多个方面，希望我的回答可以帮助人们更好地了解和处理这些问题。\n请从所有你回答的问题中选择十个最有趣的问题 以下是我从我回答的问题中选择的十个我认为最有趣的问题：\n如果你可以回到过去，在什么时候，你会选择去哪里？为什么？\n如果你可以选择一个超能力，你会选择什么？为什么？\n什么是灵魂，它是否存在？如果存在，我们如何定义它？\n如果你被允许以另一个种族的身份生活一天，你会选择哪一个？为什么？\n在人类历史上，你认为最具影响力的发明是什么？为什么？\n你认为最重要的美德是什么？为什么？\n如果你可以选择任何职业，你会选择做什么？为什么？\n你认为幸福是什么？我们可以通过什么途径获得幸福？\n如果你可以改变世界上的一个事情，你会选择什么？为什么？\n你认为人工智能是否有可能具有情感和意识？为什么？\n以上这些问题都是有趣和具有思想性的问题，涉及到哲学、心理学、历史等多个领域，希望我的回答可以激发人们的好奇心，启发人们思考，并帮助人们更好地了解自己和周围的世界。\n请从所有你回答的问题中选择十个最有深度的问题 以下是我从我回答的问题中选择的十个我认为最有深度的问题：\n什么是意识，它如何产生？有没有可能制造出拥有意识的机器？\n什么是真正的自由？我们如何实现真正的自由？\n什么是生命，它从哪里来，我们如何定义它？\n为什么有些人更容易受到诱惑和短视的行为，我们如何控制自己的欲望和冲动？\n什么是社会公正，我们如何实现社会公正？\n什么是爱，我们如何定义爱，它是否可以被量化？\n什么是幸存者偏差，它是如何影响我们的决策和思维？\n什么是文化，它对我们的思维和行为有何影响？\n什么是自我，我们如何定义自我，它是否可以被消除？\n什么是意义，我们如何寻找生命的意义？\n以上这些问题都是深刻和复杂的问题，它们涉及哲学、心理学、人类学等多个领域，是我们探索和思考生命和世界的基本问题。我的回答可能无法回答所有的问题，但是希望它们能够为读者提供启示和帮助，激发人们对这些问题的好奇心，并引导他们更深入地思考。\n请从所有你回答的问题中选择十个最复杂的问题 以下是我从我回答的问题中选择的十个我认为最复杂的问题：\n什么是宇宙，它的起源是什么？它的未来是什么？\n为什么我们需要睡觉？睡眠对我们的身体和心理有什么影响？\n为什么有些人会成为创造性的天才？创造性思维是如何产生的？\n什么是意识流，它对我们的思维和创造力有什么影响？\n为什么时间感觉会随着年龄的增长而变得更快？我们如何感知时间？\n为什么我们会有梦境？梦境对我们的心理和情感有什么影响？\n什么是人格，它是如何形成的？我们如何改变或塑造自己的人格？\n为什么有些人比其他人更容易上瘾？成瘾的机制是什么？如何预防和治疗成瘾？\n什么是记忆，它是如何存储和检索的？我们如何增强和改变自己的记忆？\n什么是语言，它是如何产生和发展的？语言对我们的思维和行为有何影响？\n这些问题都非常复杂，涉及多个学科和领域的研究。它们需要深入的思考、仔细的研究和对相关领域的广泛知识。这些问题的答案也没有定论，因为它们可能因为新的研究和发现而不断发生变化。\n请列出人们常问的50个问题。 以下是人们常问的50个问题，它们按主题分类：\n健康和医疗问题：\n如何保持健康？\n如何治疗感冒？\n如何预防癌症？\n如何减轻头痛？\n如何治疗焦虑和抑郁症？\n人际关系问题：\n如何与家人和朋友建立良好的关系？\n如何处理婚姻问题？\n如何与同事相处？\n如何处理分手？\n如何避免孤独感？\n个人成长和发展问题：\n如何成为更好的人？\n如何掌控自己的情绪？\n如何克服拖延症？\n如何提高自我意识？\n如何建立自信？\n职业和就业问题：\n如何寻找工作？\n如何准备面试？\n如何谈判薪资？\n如何升职？\n如何转行？\n金融和理财问题：\n如何储蓄和投资？\n如何制定预算？\n如何消除债务？\n如何降低开支？\n如何理解股票和基金？\n教育和学习问题：\n如何学习？\n如何提高记忆力？\n如何制定学习计划？\n如何提高成绩？\n如何选择专业？\n生活方式问题：\n如何放松和减轻压力？\n如何保持健康的饮食习惯？\n如何克服不良习惯？\n如何保持身材？\n如何提高睡眠质量？\n科技和媒体问题：\n如何使用智能手机？\n如何保护个人隐私？\n如何保持安全的网络习惯？\n如何利用社交媒体？\n如何使用计算机软件？\n这只是一份简单的列表，人们提出的问题种类和数量随着时间和地点的变化而变化。\n参考  Best practices for prompt engineering with OpenAI API  ", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/how-to-ask-gpt\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rust\/rust-lifetime\/": {
        
        "title": "Rust lifetime 101",
        "tags": ["Rust",],
        "content": "定义 在 Rust 中，生命周期（lifetime）是用来描述引用（reference）有效期的一种概念。每个引用都有一个生命周期，表示该引用指向的数据在内存中的存活时间。生命周期用于在编译时检查引用是否有效，并避免出现空指针、野指针等内存安全问题。\n生命周期通过单引号字符（'）来表示，通常采用小写字母 a、b、c 等表示。生命周期参数一般写在函数、结构体、枚举等数据类型定义的左尖括号后面，并用尖括号括起来。例如：\n1 2 3  fn foo\u0026lt;\u0026#39;a, \u0026#39;b\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;b str) -\u0026gt; \u0026amp;\u0026#39;a str { // function body here }   这个例子中，foo 函数有两个生命周期参数，\u0026lsquo;a 和 \u0026lsquo;b，它们用于描述 x 和 y 引用的有效期。\u0026lsquo;a 表示 x 引用的生命周期，\u0026lsquo;b 表示 y 引用的生命周期。\n在 Rust 中，生命周期的主要作用是帮助编译器进行引用的内存管理和安全检查，避免出现悬垂指针、空指针、野指针等内存安全问题。生命周期检查是 Rust 语言的静态检查机制之一，编译器会在编译时检查引用是否有效，以避免程序在运行时出现内存错误。\n使用lifetime的场景 在 Rust 中，必须写明生命周期的情况主要包括以下几种情况：\n函数的输入参数或返回值是引用类型，且该引用类型可能有多个实例，这些引用实例之间可能存在生命周期的依赖关系。\n在结构体中储存引用类型时，结构体和其中的引用之间可能存在生命周期的依赖关系。\n在实现 trait 时，trait 中定义的方法参数或返回值是引用类型，且该引用类型可能有多个实例，这些引用实例之间可能存在生命周期的依赖关系。\n在上述情况中，编译器需要知道引用的生命周期，以便确定引用是否有效，以及引用是否存在悬垂指针等安全问题。如果没有指定生命周期，编译器将无法检查这些安全问题并发出编译错误。\n例如，以下是需要指定生命周期的示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  fn longest\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str { if x.len() \u0026gt; y.len() { x } else { y } } struct Foo\u0026lt;\u0026#39;a\u0026gt; { x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;a str, } impl\u0026lt;\u0026#39;a\u0026gt; Trait for Foo\u0026lt;\u0026#39;a\u0026gt; { fn bar(\u0026amp;self, x: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str { // method body here } }   在这些例子中，我们需要指定生命周期参数来确保编译器可以正确地检查引用的有效性。\n应用原则 Rust中lifetime（生命周期）是一个非常重要的概念，它与所有权（ownership）和借用（borrowing）密切相关。下面是rust lifetime的几大原则：\n  每个变量都有其生命周期 每个变量都有其生命周期，生命周期描述了变量存在的时间范围，即在哪里被创建，在哪里被销毁。如果一个变量超出了其生命周期，它将被认为是无效的，访问它将导致编译时错误。\n  生命周期的注解是可选的，但有时必需 Rust编译器可以根据变量的使用情况推断出生命周期，因此不必在每个变量或函数上都手动注明生命周期。然而，在某些情况下，注明生命周期是必需的，例如，当函数参数和返回值都是引用时，需要注明它们的生命周期以确保编译器能够验证引用的有效性。\n  生命周期遵循引用的作用域 引用的生命周期不能超过其所引用的变量的生命周期。在rust中，引用的作用域是定义该引用的语句块。因此，在同一作用域中创建的引用具有相同的生命周期。\n  生命周期参数具有\u0026rsquo;static生命周期的最长寿命 \u0026lsquo;static生命周期表示整个程序的生命周期，即从程序启动到程序结束。具有\u0026rsquo; static生命周期参数的引用可以跨越整个程序运行时间，它们是最长寿命的引用。\n  生命周期参数是泛型类型的一部分 与其他泛型类型一样，生命周期参数可以用于泛型函数和结构体。这样可以为函数和结构体中的引用类型指定生命周期参数，以确保它们的有效性。\n  总的来说，lifetime是rust中非常重要的概念，它使得编译器能够静态验证程序中的引用有效性，并防止出现运行时错误。\nrust lifetime常见错误 引用的lifetime超期 具体分为以下几种情况：\n引用的lifetime超过了它所引用的变量的lifetime 1 2 3 4 5 6 7 8 9  fn main() { let r; { let x = 5; r = \u0026amp;x; // \u0026#39;x\u0026#39; does not live long enough } println!(\u0026#34;r: {}\u0026#34;, r); }   代码运行结果\n函数返回引用的lifetime超过了函数参数的引用lifetime 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  fn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let result; { let s2 = String::from(\u0026#34;world\u0026#34;); result = get_longest_string(\u0026amp;s1, \u0026amp;s2); // expected lifetime parameters do not have the same lifetime bounds } println!(\u0026#34;The longest string is {}\u0026#34;, result); } fn get_longest_string\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str { if x.len() \u0026gt; y.len() { x } else { y } }   代码运行结果\n结构体的lifetime超过其结构成员的引用的lifetime 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  struct Car\u0026lt;\u0026#39;a\u0026gt; { engine: \u0026amp;\u0026#39;a str, color: String, } fn main() { let color = String::from(\u0026#34;red\u0026#34;); let engine; { let v8 = String::from(\u0026#34;v8\u0026#34;); let my_car = Car { engine: \u0026amp;v8, // \u0026#39;v8\u0026#39; does not live long enough color: color, }; engine = my_car.engine; } println!(\u0026#34;The engine is {}\u0026#34;, engine); }   代码运行结果\n在函数中返回一个指向局部变量的引用 返回函数定义的局部变量的引用 1 2 3 4 5 6 7 8 9 10  fnmain(){letresult=get_reference();println!(\u0026#34;The value is {}\u0026#34;,result);}fnget_reference\u0026lt;\u0026#39;a\u0026gt;() -\u0026gt; \u0026amp;\u0026#39;ai32{letn=42;\u0026amp;n//`n`doesnotlivelongenough}  代码运行结果\n返回函数参数变量的引用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  fn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = String::from(\u0026#34;world\u0026#34;); let result = get_longest_string(\u0026amp;s1, s2); println!(\u0026#34;The longest string is {}\u0026#34;, result); } fn get_longest_string\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: String) -\u0026gt; \u0026amp;\u0026#39;a str { if x.len() \u0026gt; y.len() { x } else { \u0026amp;y // borrowed value does not live long enough } }   代码运行结果\n缺少lifetime 函数缺少lifetime 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  fn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = String::from(\u0026#34;world\u0026#34;); let result = get_longest_string(\u0026amp;s1, \u0026amp;s2); println!(\u0026#34;The longest string is {}\u0026#34;, result); println!(\u0026#34;{} {}\u0026#34;, s1, s2); } fn get_longest_string(x: \u0026amp;str, y: \u0026amp;str) -\u0026gt; \u0026amp;str { if x.len() \u0026gt; y.len() { x } else { y } }   代码运行结果\n结构体缺少lifetime 1 2 3 4 5 6 7 8 9 10  struct Foo { x: \u0026amp;str, // 缺少生命周期参数，编译错误 } fn main() { let s = \u0026#34;hello\u0026#34;; let f = Foo { x: s }; println!(\u0026#34;{}\u0026#34;, f.x); }   代码运行结果\n正确代码如下：\n1 2 3 4 5 6 7 8 9  struct Foo\u0026lt;\u0026#39;a\u0026gt; { x: \u0026amp;\u0026#39;a str, // 指定生命周期参数 } fn main() { let s = \u0026#34;hello\u0026#34;; let f = Foo { x: s }; println!(\u0026#34;{}\u0026#34;, f.x); }   ", 
        "url": "http:\/\/myself659.github.io\/post\/rust\/rust-lifetime\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E6%88%90%E5%8A%9F%E7%9A%84%E8%B7%AF%E5%BE%84%E4%B8%8E%E6%A6%82%E7%8E%87\/": {
        
        "title": "成功的路径和概率",
        "tags": ["life",],
        "content": "成功的路径 别人的成功你很难复制,所以要想成功你必须走自己的路。\n自己动手实践的路径是唯一有可能属于自己走向成功的路径。\n成功的概率 走自己的路必不一定能成功。成功与失败是概率的游戏。那么如何提高自己成功的概率呢？\n每个人情况不一样，毕竟每个人都要走自己的路，这里只是很宽泛讲一下：\n  发现事实，立足事实\n  学习科技，应用科技\n  掌握规则，应用规则\n  洞察市场，满足市场\n  总结一下提高成功的概率的原则：\n越靠近事实，越靠近科学，越靠近明规则，越靠近市场，则越靠近成功。\n", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E6%88%90%E5%8A%9F%E7%9A%84%E8%B7%AF%E5%BE%84%E4%B8%8E%E6%A6%82%E7%8E%87\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E8%A7%82%E9%9F%B3%E6%98%AF%E5%A6%82%E4%BD%95%E6%9D%83%E5%8A%9B%E5%8F%98%E7%8E%B0\/": {
        
        "title": "观音菩萨是如何实现权力变现的",
        "tags": ["Thinking",],
        "content": "背景 《西游记》小时候只知道看那只猴子，实际上无论是电视剧还是小说里面都隐含大量的知识点。\n下面就以观音菩萨是如何实现权力变现的展开说明。\n权力来源与意图 西游记第八回：\n 如来又取出三个箍儿，递与菩萨道：“此宝唤做‘紧箍儿’，虽是一样三个，但只是用各不同。我有‘金、紧、禁’的咒语三篇。假若路上撞见神通广大的妖魔，你须是劝他学好，跟那取经人做个徒弟。他若不伏使唤，可将此箍儿与他戴在头上，自然见肉生根。各依所用的咒语念一念，眼胀头痛，脑门皆裂，管教他入我门来。”\n 从原文可知，如来佛祖作为观音菩萨上级给其三个紧箍儿，显而易见权力的来源是如来佛祖，其意图是让这三个紧箍儿来帮助取经人（唐僧）管教约束三个徒儿。\n权力应用与效率最大化 西游记第十四回：\n 老母道：“东边不远，就是我家，想必往我家去了。我那里还有一篇咒儿，唤做《定心真言》；又名做《紧箍儿咒》。你可暗暗的念熟，牢记心头，再莫泄漏一人知道。我去赶上他，教他还来跟你，你却将此衣帽与他穿戴。他若不服你使唤，你就默念此咒，他再不敢行凶。也再不敢去了。”三藏闻言，低头拜谢。那老母化一道金光，回东而去。三藏情知是观音菩萨授此真言，急忙撮土焚香，望东恳恳礼拜。拜罢，收了衣帽，藏在包袱中间。却坐于路旁，诵习那《定心真言》。来回念了几遍，念得烂熟，牢记心胸不题.\n 由于孙悟空不受管教，同时已经安排的猪悟能与沙悟净能耐都不如孙悟空，且不像孙悟空那样心猿不定，所以一定要把紧箍儿（权力）给孙悟空戴上，方便唐僧管教，为取经团队的稳定打下基础，保证完成取经任务。\n另外紧箍儿咒，原来叫做定心真言，也是恰当好处，让孙悟空专注一件事：保唐僧取真经。\n权力变现1：收服黑熊怪作为自己的守山大神 西游记第十七回：\n 菩萨现相，问妖取了佛衣。行者早已从鼻孔中出去。菩萨又怕那妖无礼，却把一个箍儿，丢在那妖头上。那妖起来，提枪要刺，行者、菩萨早已起在空中，菩萨将真言念起。那怪依旧头疼，丢了枪，满地乱滚。半空里笑倒个美猴王，平地下滚坏个黑熊怪。\n 变现点评：\n 等待变现时机，等孙悟空主动请自己去帮忙降妖，才开始变现，隐藏变现的主动动机 变现要有合理的理由：用箍制服黑熊怪 合理的变现的对象：黑熊怪，小说中黑熊怪无背景，好学上进，一心向佛，有本领，无劣迹 变现要为自己服务：让黑熊怪作为自己的守山大神 变现后不要给自己惹麻烦：黑熊怪无背景，不属于任何大佬 变现要快：用第一个箍约束孙悟空（西游记第十四回），再到第二个箍收服黑熊怪（西游记第十七回），这中间只间隔三回  权力变现2：收服红孩儿作童子 西游记第四十二回：\n “这宝贝原是我佛如来赐我往东土寻取经人的‘金、紧、禁’三个箍儿。紧箍儿，先与你戴了；禁箍儿，收了守山大神；这个金箍儿，未曾舍得与人，今观此怪无礼，与他罢。\n 变现点评：\n 等待变现时机，等孙悟空主动请自己去帮忙降妖，才开始变现，隐藏变现的主动动机 变现要有合理的理由：用箍制服红孩儿 合理的变现的对象：红孩儿，小说中红孩儿是牛魔王的儿子，不属于任何门派，同时潜力大 变现要为自己服务：用箍控制了红孩儿，可以将牛魔王纳入自己的势力，或者将其作为人质要挟牛魔王 变现后不要给自己惹麻烦：将红孩儿收为童子（以教化的名义变现这样名正言顺）  总结 通过上面分析，可知观音菩萨是厉害主啊，其权力变现有以下特点：\n 善于发现变现机会，用一箍收了孙悟空，发现另外两个箍不需要用来收猪八戒与沙悟净，同时也避免得罪这两人 合理选择变现对象与路径 把握好变现时机 最大化变现收益  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E8%A7%82%E9%9F%B3%E6%98%AF%E5%A6%82%E4%BD%95%E6%9D%83%E5%8A%9B%E5%8F%98%E7%8E%B0\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/chances-from-what-problem\/": {
        
        "title": "什么样的问题背后有大机会呢？",
        "tags": ["Thinking",],
        "content": "前言 人们常说：\n 问题的背后常常隐藏了机会。\n 那么什么样的问题背后有大机会呢？或者隐藏大机会的问题有哪些特征？\n下面个人谈一个自己对这个问题一些思考与看法。\n问题特征 隐藏大机会的问题个人认为往往有以下特征：\n 高频的问题 重要的问题 紧急的问题 未能得到解决的问题 范式变化带来的问题 解决之后会带来正反馈的问题  典型的例子，就是互联网技术发展与应用，这一范式变化带来的问题，如搜索，电商，及时通信的问题。\n机会 满足上面特征的问题不少，但是这些问题并不都是你的机会。是不是你的机会取决于你能否解决问题，并且在解决问题所有方案里面具有竞争力？\n解决问题就是把握机会。\n为市场解决的问题越大，机会越大。\n解决问题一定要与自己能力，资源相结合，这样才能把握机会。\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/chances-from-what-problem\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/linux-btop\/": {
        
        "title": "linux btop 101",
        "tags": ["Linux",],
        "content": "背景 最近发现一个很好用的系统监控命令：btop。 btop一站式实时显示cpu，memory，disk，network，processes的统计信息。\ninstall 具体参考Installation\npanels btop默认有5个显示面板（panels）。每个面板都有一个对应控制命令：\n1： 打开或关闭cpu面板\n2： 打开或关闭memory面板\n3： 打开或关闭disk面板\n4： 打开或关闭network面板\n5： 打开或关闭processes面板\n具体如下图所示： 命令 打开btop，输入h会提出示相关命令的提示。\n个性化 从github下载主题放到$HOME/.config/btop/themes。\n(end)\n", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/linux-btop\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rust\/tips-learn-rust\/": {
        
        "title": "tips for learning rust",
        "tags": ["Rust",],
        "content": "资料  The Rust Programming Language Rust Language Cheat Sheet Zero to Production in Rust This Week in Rust awesome-rust awesome-cli-rust  tools and libaries  cargo-asm A cargo subcommand that displays the generated assembly of Rust source code. cargo-fuzz A cargo subcommand for fuzzing with libFuzzer hyperfine A command-line benchmarking tool flamegraph sqlx yarte opentelemetry thiserror rust-clippy  心法  保持耐心，不要心急，毕竟rust学习曲线陡峭 编译器是最好的老师，同时记住编译器永远是正确的 克服传统语言的思维定势，建立新思维模型如资源与变量分离，同时尝试整合范型编程，类型编程，函数式编程，异步编程，meta-programming 从简单开始，从基础开始 深入从rust内存管理原理开始，扩展到多线程与异步环境 学以致用，可以用rust做一些个人的项目  ", 
        "url": "http:\/\/myself659.github.io\/post\/rust\/tips-learn-rust\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/uniswap-impermanent-loss-formula\/": {
        
        "title": "uniswap的非永久性损失公式的推导",
        "tags": ["BlockChain","DEX",],
        "content": "说明 公式推导基于uniswap v2，不适用于uniswap v3。\n非永久性损失 用户为流动性池提供流动性时，由于交易对价格变化使池内的交易对的代币数量发生变化，相比较于不参加提供流动性的情况下，这种变化会导致用户资产有一定的损失，而这种损失被称为非永久性损失（国内很多人将其称为无常损失）。\nCFMM的原则 uniswap v2是典型的Const Product Market Maker。其遵守以下三条原则：\n 交易对（x,y）流动性池内的两种资产价值永远视为相等，v(x) = v(y) 改变流动性池的k值，保证价格不变, p(x) = y/x 交易的时候k值不变,k = x*y  推导 0. 说明  在公式推导过程中，以y对应的token为币本位，或者说以y对应的token作为计价单位。 不考虑交易费用收入与流动性挖矿收入等任何收入  1. 引入原则 上面CFMM的原则是进行无常公式推导的基础。具体公式如下：\n2. 推导x与y 用p(x)与k来表示x与y，方便后面的替换。 3. 定义非永久性损失 首先确定因变量r，然后确定holder及流通性提供者的价值计算公式，最后根据定义得到非永久性损失的定义公式。\n4. 推导非永久性损失与价格变化倍数之间的关系 前面提到以y对应的token作为计价单位，那么就假设y对应的token在任何时间价格都不变，永远为1.\n具体过程如下： 5. 可视化 利用mania对公式进行可视化，具体如下： ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/uniswap-impermanent-loss-formula\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/defi-tools\/": {
        
        "title": "常用Defi工具与网站",
        "tags": ["Defi",],
        "content": "DeBank DeBank 是一款DeFi资产跟踪和投资组合管理工具。\n优点：\n 支持多链 不仅支持链上帐户资产也支持TVL资产 支持多种协议 支持帐号approve风险提示  缺点：\n 新协议支持速度慢  vFat Tools vFat Tools为defi农民提供挖矿分析，收益计算，数据面板等服务。\n优点：\n 免费 界面简洁 提供了收益与池子详细信息 基本支持主流兼容evm的公链及其对应的yield farming项目 实时数据  缺点：\n 不支持过滤无关的池子 不支持对池子的分析 不支持图表展示  Defi Pulse Defi Pulse 提供了以太坊上各种defi项目TLV数据。\n优点：\n 提供项目TVL的排名 提供了以太坊总体TVL的变化情况  缺点：\n 数据更新速度慢 不支持跨链TVL  DeFi Llama DeFi Llama\n优点：\n 支持多链 支持分类别查看如DEX, lending, yield, insurance, option等 数据丰富，如支持1h，7天的TLV变动数据  缺点：\n 缺少对外api服务  Dune Analytics Dune Analytics支持对链上原始数据进行SQL级别的分析与展示。\n优点：\n 支持个性化的查询链上数据并图表化 支持SQL 支持模板 内置可视化功能  缺点：\n 用户技能要求较高如理解原始数据与SQL，不适合新手  Revert Finance Revert Finance面向DEX流动性提供者的分析工具。\n优点：\n 流动性挖矿数据详细（gas费用，收益） 支持历史流动性数据分析 无常损失分析  缺点：\n 只支持uniswap与sushi  APY Vision APY Vision 是一款流动性挖矿分析与图表工具。\n优点：\n 无常损失与持有对比分析  缺点：\n 收费，免费功能单一 不支持历史数据分析  Token Terminal Token Terminal是去中心化版本的Bloomberg Terminal。\n优点：\n 丰富的数据指标 每4个小时更新数据 提供API服务  缺点：\n API收费且不便宜  dappradar dappradar提供dapp的用户数（DAU,MAU等）等一系列反应dapp基本面的数据。\nLunarCrush LunarCrush可以跟踪加密货币在社交网络的活跃度。\ndexscreener dexscreener支持多链的dex dashboard。\ndextools dextools是集数据，dashboard，交易的于一体的且支持多链的工具。\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/defi-tools\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/crypto-519-fall\/": {
        
        "title": "说说519事件",
        "tags": ["BlockChain",],
        "content": "背景 加密货币历史上几次大跌：\n 2017年94事件 2020年312事件 2021年423事件 2021年519事件  每次大跌都验证一句话：币圈一天，人间一年。\n作为这些事件的经历者，说一下自己对519事件一点看法。\n下跌原因 个人认为大跌原因如下：\n 美国5月12号公布了美国通胀达到4.2%，超出市场的预期，这是促使美联储不得不提前收紧货币 5月12号Elon Musk宣布由于考虑比特币挖矿对环境的影响，暂停通过bitcoin购买Telsa电动车 5月18号中国禁止金融机构和支付公司为加密货币提供服务 加上从2021年以来加密货币快速上涨，风险也积累比较多，高位离场的资金比较多 上面4点导致下跌成为趋势，下跌过程中由于整个币圈杠杆很高，导致相互踩踏，从而出现一两个小时就狂跌50%的情况  快速恢复原因 这次下跌恢复很快，基本到20号比特币就恢复到40k的关口。\n个人认为有以下原因：\n 下跌只是货币收紧信号一个反应，实际上货币供应并没有受到影响，恐慌得到释放 机会都是跌出来，按照历史经验，加密货币每一次大跌都是机会 加密货币在这一年中得到大量的宣传，越来越多的认识到加密货币是资产配置的一个重要选项  影响 牛市就此结束吗？ 个人认为疯牛结束，慢牛开启。这次下跌是对最近一段时间过于疯狂的市场打一针退烧针，清理高杠杆了，减少投机成分，让人们理性认识到市场的残酷，让市场回归到技术与应用。\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/crypto-519-fall\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/pos-increase-decentralization\/": {
        
        "title": "PoS更有利于去中心化",
        "tags": ["BlockChain","cryptocurrency",],
        "content": "背景 PoW和PoS作为现在最常用的两大共识算法，PoW与PoS之争已经有多年了。\n下面从去中心化角度来对比两条公链：\n 采用PoW的以太坊 采用EPoS的Harmony  以太坊 随着以太坊矿池兴起加上PoW天生容易导致算力集中，以太坊独立挖矿的节点越来越少，出块节点也越来越少，越来越集中，下图就是一个很好的说明。\n从图可知，以太坊前三大矿池的总算力已经超过了51%，这说明只要前三大矿池联合，可以对以太坊发起51%攻击，是威胁以太坊安全的一个不可忽略的隐患。\n注：数据来自Top 25 Miners by Blocks\nharmony 我们来看一下采用了EPoS的Harmony。\n首先还是了解一下Harmony：\n Harmony is the first Proof-of-Stake \u0026amp; sharding mainnet. 2-second finality, trustless cross-chain liquidity.\n Harmony是第一个上线PoS并实现分片的公链，其代币是ONE。\n使用了PoS的Harmony去中心化验证节点数量是多少呢？\n从上图可知，参与验证节点数是193，其中114个被选举成为验证节点参与验证与出块。\n注：数据来自harmony validators\n关于harmony的EPoS，更多请参考Harmony公开抵押的官方指南。\n结论 越降低参与门槛，越多节点。 越多节点，越去中心化。 越去中心化，越安全。\n转到pos的eth2.0值得期待，实现分片的eth2.0将会是多链时代的最核心的一条链。\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/pos-increase-decentralization\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/eth-overtake-btc\/": {
        
        "title": "以太坊未来会超过比特币吗？",
        "tags": ["BlockChain",],
        "content": "背景 最近以太坊单日交易量与矿工收入均创历史新高。据THEBLOCK数据显示，4月23日以太坊网络上的每日交易量达150万，再创历史新高，在日交易量创新高的带动下，以太坊矿工单日收入达到$66.3million，其中交易费用手续费为$34.92million。\n将时间拉长看，近7日比特币跌幅接近20%，而ETH仅为6%。近30日比特币跌幅为10%，以太坊涨幅为33%。而且在几次下跌过程中以太坊恢复速度都比比特币快。\n最近一短时间，以太坊与比特币总市值差距也越来越小。\n那么，很多都会这么一个想法：以太坊未来是否会超过比特币呢？\n个人认为，以太坊未来会超过比特币。\n理由 个人看好以太坊未来会超过比特币，主要基于以下理由：\n 尽管以太坊上的交易成本很高，以太坊仍然是最活跃，使用最广泛的区块链平台 以太坊现在价格与市值相比较于比特币都低很多，以太坊是一个更好投资选项 尽管以太坊有很多竞争者，但是以太坊先发优势，网络优势与生态优势均是良好的护城河 以太坊有更多的开发者，是最大区块链的社区 以太坊有V神，V神会为以太坊赢得极大的信任 以太坊上各种L2会不断增强以太坊 以太坊背后有大量的Dapp，这些Dapp中不断有创新涌现，繁荣以太坊生态 以太坊EIP-1599正在路上 以太坊2.0正在稳步推进 以太坊支持智能合约，可以做更多的事情，在满足未来的需求的同时也进一步壮大生态 以太坊上的wbtc会越来越多  时间点 以太坊什么时候会超过比特币？\n时间很难预测，比特币市值现在不到以太坊市值的4倍，如果是出现此消彼涨的情况，这次牛市有希望看到以太坊超过比特币成为新的加密货币的一哥。\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/eth-overtake-btc\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/nft-naval\/": {
        
        "title": "Demystifying NFTs by Naval ",
        "tags": ["NFT",],
        "content": "NFT is blooming. Naval\u0026rsquo;s insightful viewpoints about NFTs as follow:\n An NFT is a unique, on-chain token representing ownership of an off-chain asset. The token is backed by a social contract from its creator and a surrounding community. By assigning a unique token to a thing, its ownership (not the thing itself!) becomes programmable, verifiable, divisible, durable, universally addressable, composable, digitally secured, and easy to transfer. Bitcoin and other completely on-chain assets are provably scarce - scarcity is enforced by code and distributed consensus. Off-chain assets represented by NFTs are not provably scarce. The promise of scarcity is a slender thread, only as strong as the social contract with the creator and interwoven with the backing of the community. An NFT’s creator may break their promise, or be unable to enforce it, or may have picked the wrong underlying platform and community - rendering the NFT worthless. For NFTs representing digital art and collectibles, the creator cannot enforce scarcity - it’s up to a surrounding community to imbue the authorized NFT with scarcity and prestige within the context of that community. Just as HODLers imbue Bitcoin with value, and developers infuse Ethereum with value, collectors, admirers, and users imbue NFTs with value. NFTs gain value when displayed, used, and promoted within vibrant and growing communities. If the community around an NFT is dying, the NFT is likely bleeding value. If the community is surging, the NFT is likely gaining value. NFTs are monetized memes.* “Actual-value NFTs” can draw upon legal and code-based contracts - a song token can provide a royalty stream, a ticket token can provide access, a metaverse token can grant land titles, an item token can have in-game powers, an ISA token can provide a cut of creator earnings. Even “actual-value NFTs” require a social contract with the creator and community to transfer the value from the off-chain contracts onto the chain where the NFT is registered. Just as there are those who won’t accept that mere consensus can create digital gold, and those who won’t accept that mere smart contracts can create a decentralized Wall Street, there are those that won’t accept that digitized social contracts will create valuable tokens. As with most art and most tokens, most NFTs will have very little value. But a select few NFTs will become focal points for communities who gather to celebrate art, build collections, and explore virtual worlds. With NFTs, blockchains make the jump from finance into creative applications. Regulators would do well to recognize that blockchains are the next generation of the Internet, and applying financial regulations to NFTs is a category error. NFTs tokenize all the things. We are going from a world where every protocol has a token, to where every (decentralized) application has a token, to where every valuable digital representation of an object or person has a token. Public blockchains will be the title registries for everything of value. Ultimately, NFTs will authenticate the world.**    ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/nft-naval\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/economy\/the-essence-of-arbitrage\/": {
        
        "title": "套利的本质",
        "tags": ["economy",],
        "content": "套利大行其道，那么套利是什么？\n下面这张图是一个活生生的套利案例。\n套利的本质是什么？\n 套利的本质是利用非对称获利 套利的竞争是发现非对称机会以及利用机会的速度竞争 任何套利模式都是公开即失效  ", 
        "url": "http:\/\/myself659.github.io\/post\/economy\/the-essence-of-arbitrage\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/bitcoin-telsa\/": {
        
        "title": "Telsa买入bitcoin意味着什么",
        "tags": ["BlockChain",],
        "content": "background 最近Telsa投入15亿美元买入了bitcoin，消息一出，bitcoin应声大涨，这事激起广泛的关注。\ntelsa买入bitcoin的原因 为什么telsa买入比特币？个人认为有以下原因：\n 在全球继续放水的预期下，telsa公司资产配置的需要 telsa买入bitcoin，可以赢得加密货币富豪的支持，这些人有很强的消费能力 传统金融政策难以持续，买入bitcoin可以试水新的货币机制，也可以赢得先机 bitcoin时隔3年重回2万美元，并继续突破了3万美元，4万美元等历史新高，对于比特币来说，它的反脆弱性得到证明 bitcoin得到paypal与square等公司支付业务的支持  为什么只买入bitcoin而没有买入其他的加密货币如ethereum呢？个人认为有以下原因：\n bitcoin市值最高，占比超过了整个加密货币的60% bitcoin相比较于其他加密货币风险更小 bitcoin共识长达10多年，共识稳固 bitcoin具有抗通胀的属性，而ethereum现在每年都有一定的通胀 总之，bitcoin是加密货币的始姐，也是最强的头部  意义与影响 telsa买入比特币意义与影响有哪些？\n bitcoin得到世界顶级精英与公司的认可，也意味加密货币得到认可，为整个加密货币市场注入活力，吸引了用户，资产及人才。 意味牛市继续，很有可能是长牛 为其他机构与公司提供了入场的参考，telsa进场了，apple，amazon，google，microsoft下一步也会来吗？ Elon Musk及其telsa的影响力有利于加密货币与区块链技术的普及  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/bitcoin-telsa\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/internet\/about-clubhouse\/": {
        
        "title": "谈谈clubhouse",
        "tags": ["internet",],
        "content": "背景 最近clubhouse的邀请一码难求，自己有幸被邀请。体验一下，说一下自己对clubhouse一些想法。（Ps：由于区块链与加密货币的火爆，只写一些要点，不展开说明）\n感受与评价 个人对clubhouse一些主观感受与评价如下：\n 通讯录验证，避免僵尸用户 扩展式邀请，带来扩展式社交 精准推荐 领袖主导 价值分享 语音聊天，便捷自然 实时分享与交流，无回放与录音 用户时间黑洞 开放打破界限 高质量的人群  问题  如何商业化？ 微信会跟进吗以及如何跟进？ clubhouse产品内核是什么？ 用户推荐算法机制？ Elon Musk这样超级KOL进入，服务不可用的原因是什么？ clubhouse热度会持续吗？ clubhouse什么时候会被墙？ 给clubhouse取一个什么样的中文名字呢？  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/internet\/about-clubhouse\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/economy\/china-trust-crisis\/": {
        
        "title": "爆雷，接盘侠与社会信用",
        "tags": ["Economy",],
        "content": "背景 首先，先看看这个新闻： 湖南益阳62岁老人投江后续：当地多家养老机构爆雷，有老人获悉后心梗去世。\n由这个新闻想到中国从2018年开始了一系列爆雷：\n P2P爆雷断断续续到现在还没有结束 民营企业债爆雷 国有企业债爆雷，如永煤，华晨，北大方正，清华紫光 房地产全线爆雷，如北京院子，北京山水等等，还有很多烂尾楼 养老机构爆雷，如益阳市纳诺老年公寓 教育机构爆雷，如学霸君 共享单车爆雷，如OFO 黄金爆雷，如武汉金黄 信托爆雷，如四川信托 股票爆雷，如獐子岛 银行爆雷，如包商银行  爆雷背后是什么？ 爆雷其实是骗局的破灭。破灭是由于业务与模式的不可持续，不可持续由于缺少接盘侠。 上面列举几种爆雷，其实都是缺少接盘侠（中国居民负债率在2019年就超过了50%）。典型的例子是泰和北京院子与恒大地产。 恒大地产有了接盘侠，撑过来了，而泰和没有接盘侠，北京院子就烂尾了。\n接盘侠 人人皆韭菜。\n人人都是接盘侠。\n爆雷深深伤害了接盘侠，加上前两句话：爆雷伤害全社会，特别是社会信用。\n社会信用 爆雷导致社会信用的减弱，这样全增加全社会的运行成本，成本上升，会导致社会协作的效率下降，从而影响整个社会的财富的创造与流通。\n希望中国政府要重视爆雷的严重影响，并找到其中的根本原因，加强制度与法制建设，为社会信用提供坚定的基石。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/economy\/china-trust-crisis\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/invest\/invest-balajis-directions\/": {
        
        "title": "错过了2010年的比特币，不要错过这些新领域的机会",
        "tags": ["Invest",],
        "content": "今天哪些新领域会像2010年比特币一样的成长 twitter一个用户提出一个问题：Is there a thing today like being into Bitcoin in 2010？\n下面是Balaji S. Srinivasan的回答\n Bitcoin itself (still early relative to 99%)比特币，且比特币仍然是早期 Ethereum, crypto in general 以太坊以及其他的加密货币 Startup cities 创业型城市如迈阿密，新加坡和迪拜 Reversing aging 抗衰老及长寿技术 Brain-machine-interface 脑机接口 Transhumanism 超人类主义（人类增强） Robotics 机器人技术 Digital nomadism, in green zones at least 数字游牧 India, rest-of-world tech in general 印度 AI-assisted content creation 人工智能辅助内容创作 VR as office replacement VR替代办公室 AR for productivity (eg Google Glass Enterprise)AR提高生产力 Self-hosting makes a comeback (see http://cloudron.io)自主托管 Telemedicine, personal genomics, health tracking v2 远程医疗，个人基因，健康跟踪 3D printing of metals 金属的3D打印 Pseudonymity, aided by crypto and AI voices \u0026amp; faces 仿真，借助加密和AI仿真声音和人脸  对于上面的回答的，个人补充一些：\n NFT Defi Hyperautomation  twitter原文\n关于Balaji S. Srinivasan 关于Balaji S. Srinivasan介绍如下：\n Balaji S. Srinivasan is an angel investor and entrepreneur. Formerly the CTO of Coinbase and General Partner at Andreessen Horowitz, he was also the cofounder of Earn.com (acquired by Coinbase), Counsyl (acquired by Myriad), Teleport (acquired by Topia), and Coin Center.\n  He was named to the MIT TR35, won a Wall Street Journal Innovation Award and holds a BS/MS/PhD in Electrical Engineering and an MS in Chemical Engineering, all from Stanford University. Dr. Srinivasan also teaches the occasional class at Stanford, including an online MOOC in 2013 which reached 250,000+ students worldwide.\n 从上面可知Balaji S. Srinivasan是一个真大佬，没有一点水分：\n 除了拥有斯坦福大学电子工程的学士，硕士，博士学位，还拥有化学工程的硕士学位 MIT TR35 企业家：四次创业，三次被收购 Coinbase前任CTO 投资人 多面手并且在多个领域做到世界顶级水平  ", 
        "url": "http:\/\/myself659.github.io\/post\/invest\/invest-balajis-directions\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/openness-importance\/": {
        
        "title": "谈谈开放的重要性",
        "tags": ["闲谈乱扯",],
        "content": "说明 本文从软件，互联网，区块链，安全的视角谈谈开放的重要性。\n软件 软件方面看几个例子吧。\n首先看一下chrome浏览器，chrome浏览器首先建立应用市场，对开发者开发浏览器api，各种浏览器插件丰富了chrome的功能，对不同场景有针对性的插件来满足用户的需求。\n再看苹果ios对外开放应用商店，有大量的app，为各种不同的用户和不同场景提供针对性app。\n最后是微软的vs code。vs code作为一个编辑器不如vim，emacs，但是由于vs code有针对性不同开发者和开发场景的插件，让开发者的需求得到充分满足。\n对了，不能忘记开源的操作系统Linux。Linux是开源软件的巅峰。Linux开启的开源软件浪潮，基本支撑了整个互联网的运行。\n互联网 微信小程序对外开放微信的接口与用户，相对于独立开发app，降低用户成本与开发成本。小程序带来的GMV超过了1万亿。\n区块链 如果讲区块链精神的内核，那么开放我觉得开放一定要会占有一个位置。在区块链的世界：\n 代码是开源的 账本数据是开放的 进入门槛是开放的  这种开放带来了透明，分享，效率及信任，促进了区块链的发展与快速迭代。在这样的环境涌现不少快速增长的例子。\n 以太坊2015年上线到2017年市值最高超过了1000亿美元，而这仅仅用于2年多的时间。 uniswap去中心化交易所，上线2年的uniswap就在月交易额超过了成立超过了8年的coinbase，UNI代币市值达到15亿美元以上，而整个团队不到20人。  安全 TK教主说过：\n 怎么评价一个东西有多安全呢？唯一金标准是：公开接受挑战、接受公开挑战、接受挑战公开。 典型代表就是密码学领域。AES 也好，RSA 也好，椭圆曲线也好，算法公开，你有能耐就去破解，破解了发论文，还给你颁奖。 胸脯拍得响，但又怕别人公开研究、研究公开的，都属于魑魅魍魉，四小鬼各自肚肠。\n 这里提一个概念：Proof of security.那么如果证明安全呢？\n首先要开放，然后要通过挑战与检查来证明安全。\n这方面最典型的例子就是比特币与以太坊。区块链浏览器上地址公开资产情况，但是现在还没有能力破解ecdsa算法。\n小结 开放建立连接。\n连接组成网络。\n网络产生交易。\n交易产生机会与双赢。\n", 
        "url": "http:\/\/myself659.github.io\/post\/openness-importance\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/eth-2021\/": {
        
        "title": "展望2021年的Ethereum",
        "tags": ["cryptocurrency","blockchain",],
        "content": "前言 Ethereum作为第一个支持图灵完备的智能合约平台，同时也是最大的智能合约平台。从现在区块链应用角度来看是最重要的公链。个人认为公链的市场规模在万亿美元以上。\n上涨原因 最近一个月以太坊从600美元左右上涨到1200美元左右。具体如下图：\n以太坊最近一个月大涨的原因如下：\n 比特币上涨太多，上涨无力 以太坊2.0成功启动，质押以太坊会不断增长 Defi继续发展，TLV继续增长 通胀预期加大 随着比特币从1万到4万，吸引更多人关注到以太坊 以太坊的利益同盟不断壮大 上涨预期中网络效应与正反馈效应  2021展望 对于以太坊2021个人展望如下：\n 以太坊价格保守估计将会达到2000美元，市值超过了2000亿美金，乐观估计参考2020的telsa 以太坊2.0第1阶段会在2021年内完成 以太坊受到竞争者的挑战：harmony，near，Solana会比以太坊市值增长更快 NFT在以太坊不会有太大的进展 Defi的TLV增长10倍以上 L2百花齐放，这些L2增加了以太坊的护城河 以太坊EIP1599将会在2021年上线  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/eth-2021\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/history-read-list\/": {
        
        "title": "那些值得多读的历史书",
        "tags": ["History",],
        "content": "前言 历史是一面镜子。\n历史是一个任人打扮的小姑娘。\n历史告诉我们过去发生什么，启示我们现在做什么，预示着未来发什么。\n做为多年历史爱好者，这里列出我觉得值得阅读的历史书单。\n书单 大历史 以大历史的视角来审视历史信息，从中洞察真正的启示。\n历史的教训 在完成了十卷文明史之后，Will和Ariel Durant将他们最重要的课程汇编成了一百多页。每页的智慧比几乎任何其他书籍都多，《历史教训》一次又一次地展示了我们文化中出现的模式。它并不总是最乐观的，但它通常是深思熟虑的。历史的教训以一种宏面大视野教我们如何读历史。\n春秋左传 《春秋左传》记载了从鲁隐公元年（前722）到鲁哀公二十七年（前468）共254年的历史，是我国现存极早的编年体史书。《左传》在《春秋》大事纲要的记史方法基础上，代之以系统灵活的史书编纂方式，既记春秋史实，又包含了大量古代典章史料，是了解我国先秦文化的重要典籍。其中“一字所嘉，有同华袞之赠；一言所黜，无异萧斧之诛”的“一字之褒贬”的春秋笔法，使《春秋左传》蕴含着史学和文学上的无限魅力。\n史记 《史记》，二十四之首，是西汉史学家司马迁撰写的纪传体史书，是中国历史上第一部纪传体通史，记载了上至上古传说中的黄帝时代，下至汉武帝太初四年间共3000多年的历史。《史记》被鲁迅先生誉为“史家之绝唱，无韵之离骚”。\n资治通鉴 《资治通鉴》以时间为纲，事件为目，从周威烈王二十三年（公元前403年）写起，到五代后周世宗显德六年（公元959年）结束，涵盖十六朝1362年的历史。\n万年十五年 全球视野下万历十五年。\n南明史 探究南明是如何大溃败的。\n南明史\nSapiens 人类简史 这是过去几年写的最重要的书之一。作者带我们历史回答一个问题：智人是如何成为地球上的优势物种的？他涵盖了人类学，科学和经济学等主题，描绘了一幅相当全面的图景。它可能会改变你对人类的看法。\n全球科技通史 熟知人类科技文明史，真正洞察世界变化的趋势。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/history-read-list\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/tips-for-crypto-invest\/": {
        
        "title": "加密货币新手应该注意哪些问题",
        "tags": ["Invest",],
        "content": "背景 随着eth 2.0信标链启动以及defi的快速发展，加密货币会迎来一个新的牛市。在牛市开启之后，一定有很多新人进场。\n作为一名老韭菜，简单说说自己一些想法（不会展开说明）。\n安全 首先是安全，安全分为以下几种：\n 出入金通道安全 交易平台安全 帐号安全 加密货币钱包安全 政策与法律安全  学习 区块链与加密货币还处于早期，新人入场一定要学习基本知识。具体建议：\n 先学习一点基本密码学，弄懂公私钥（这是必须的） 从比特币开始学习 深入比特币交易原理与细节 学习交易基本知识及其应用 学习如何分析加密货币项目 学习以太坊 学习Defi  投资  不要投资超过你能承担的损失 不要加杠杆，也不要All-in 避免单一化投资，投资组合要多样化 识别空气币 避免FUD心理（Fear，Uncertainty，Doubt） 保持独立性，Do your own search 不懂的不要参与 尊重市场与事实，而不是执着于个人意愿与偏见 制定退出策略 区分投资与投机 不要追高，学会与趋势作朋友  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/tips-for-crypto-invest\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/dsa\/dp-knapsack\/": {
        
        "title": "学会背包问题，再也不怕动态规划 0-1背包",
        "tags": ["DP",],
        "content": "问题描述  Given weights and values of n items, put these items in a knapsack of capacity W to get the maximum total value in the knapsack. In other words, given two integer arrays val[0..n-1] and wt[0..n-1] which represent values and weights associated with n items respectively. Also given an integer W which represents knapsack capacity, find out the maximum value subset of val[] such that sum of the weights of this subset is smaller than or equal to W. You cannot break an item, either pick the complete item, or don’t pick it (0-1 property).\n 给定n个物品的重量和价值，从中选择物品放在容量为W的背包中(表示选择物品重量不超过W)，同时每个物品最多到允许选择1个，使得背包中物品价值之和最高。\n背包问题是一个非常典型的考察动态规划应用的题目，对其加上不同的限制和条件，可以衍生出诸多变种，若要全面理解动态规划，就必须对背包问题了如指掌。学习背包问题有利于举一反三，融会贯通，再也不怕动态规划。\n问题建模 用程序语言重新定义一下问题。\n先看输入：\n int Values[n]，表示物品的价值 int Weights[n]，表示物品的重要 int LimitWeight，表示背包容量的限制  再看输出：\n int MaxValue，表示背包里的物品最大价值  转化为函数（以C++为例）：\n1 2 3 4 5 6  int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; return MaxValue; }   问题分析 是否可以应用DP 应用DP应以满足以下三个条件：\n 最优子结构 边界条件 满足重叠要求的状态转移方程  最优子结构  如果一个问题的最优解包含其子问题的最优解，我们就称此问题具有最优子结构。  编程中常见最大与最小的问题，一般都是满足最优子结构的这一条件。\n本题要求是求背包里物品的最大价值。故初步判断满足条件。\n边界条件 连界条件包括开始条件与结束条件。\n这个条件可以从下面三个问题来解答：\n 用什么来作边界条件？ 边界条件是起点是什么，终点是什么？ 边界是如何从起点到终点？  针对上面问题，结合本题的信息，可以回答如下：\n 用背包里的物品重量作为边界 重量限制起点是1，终点是不超过LimitWeight；物品在数组的位置起点从0开始，终点不超过数组的长度 从起点开始，逐个加1直到终点  状态转移方程 状态转移方程也就是我们常说的DP公式。这是解决DP问题的关键。\n满足重叠要求是指后面的状态可以重复使用前面的生成的状态。\n如果不是很简单的直接可以看出来，建议在解题步骤中一步一步分析出来。本题我们会在后面分析给出对应的状态转移方程。\n解题步骤 确定采用DP来解决问题，那我们正式进行DP解题的步骤。\n1. 定义状态 前面问题分析中提到状态转移方程，状态应当在状态转移方程之下定义。完成状态定义，才能开始定义状态转移方程。\n本题的状态是S(w,i,v),其中w表示不能超过最大重量，i表示遍历到第i个物品，v表示对应的最大的价值。\n那么如何用数据结构保存状态呢？\n使用一个二维数组state[LimitWeight+1][n+1]来表示。\n2. 确定递归关系 这里我们采用top-down思考方式。\n先看代码，具体如下：\n1 2 3 4 5 6 7 8  int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; int itemLen = Weights.size(); // 处理入口 MaxValue = knapsackDo(Values, Weights, LimitWeight,itemLen); return MaxValue; }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  int knapsackDo(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight, int posIndex) { int localMaxValue = 0; int posWeight = Weights[posIndex-1]; int posValue = Values[posIndex-1]; if(LimitWeight \u0026gt;=posWeight){ // 选择当前位置的物品 int selectValue = posValue + knapsackDo(Values, Weights, LimitWeight- posWeight, i -1); // 跳过当前位置的物品 int skipValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); localMaxValue = MAX(selectValue, skipValue); }else { // 超过重量限制，跳过 localMaxValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); } return localMaxValue; }   3. 根据递归关系，得出并检查状态转移方程 当限制重量大于等于当前物品重量时，状态转移方程如下：\n1 2 3  knapsackDo(Values, Weights, LimitWeight,posIndex) = MAX(knapsackDo(Values,Weights, LimitWeight - Weights[posIndex],posIndex -1), knapsackDo(Values,Weights, LimitWeight,posIndex -1))   当限制重量小于当前物品重量时，状态转移方程如下：\n1 2  knapsackDo(Values, Weights, LimitWeight,posIndex) = knapsackDo(Values,Weights, LimitWeight,posIndex -1)   4. 确定递归结束条件 本题中递归结束条件有两个，分别如下：\n 限制重量小于等于0（即0 \u0026gt;= LimitWeight ） 数组index小于0 （即0 \u0026gt; posIndex）  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  int knapsackDo(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight, int posIndex) { if( 0 \u0026gt;= LimitWeight || 0 \u0026gt; posIndex ){ return 0; } int localMaxValue = 0; int posWeight = Weights[posIndex-1]; int posValue = Values[posIndex-1]; if(LimitWeight \u0026gt;=posWeight){ // 选择当前位置的物品 int selectValue = posValue + knapsackDo(Values, Weights, LimitWeight- posWeight, posIndex -1); // 跳过当前位置的物品 int skipValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); localMaxValue = MAX(selectValue, skipValue); }else { // 超过重量限制，跳过 localMaxValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); } return localMaxValue; }   5. 完成递归的实现 将代码结合起来如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; int itemLen = Weights.size(); // 处理入口 MaxValue = knapsackDo(Values, Weights, LimitWeight,itemLen-1); return MaxValue; } int knapsackDo(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight, int posIndex) { if( 0 \u0026gt;= LimitWeight || 0 \u0026gt; posIndex ){ return 0; } int localMaxValue = 0; int posWeight = Weights[posIndex]; int posValue = Values[posIndex]; if(LimitWeight \u0026gt;=posWeight){ // 选择当前位置的物品 int selectValue = posValue + knapsackDo(Values, Weights, LimitWeight- posWeight, posIndex -1); // 跳过当前位置的物品 int skipValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); localMaxValue = MAX(selectValue, skipValue); }else { // 超过重量限制，跳过 localMaxValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); } return localMaxValue; }   6. 添加缓存保存子问题结果优化递归方案 缓存对象是什么？状态。根据状态定义，添加如下代码：\n1 2 3 4 5 6 7 8 9 10  int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; int itemLen = Weights.size(); // 定义与实始化状态 static vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; stateDP(LimitWeight+1, vector\u0026lt;init\u0026gt;(itemLen+1)); // 处理入口 MaxValue = knapsackDo(Values, Weights, LimitWeight, itemLen - 1); return MaxValue; }   什么时候添加缓存与什么时候使用缓存呢？\n具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  int knapsackDo(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight, int posIndex) { if( 0 \u0026gt;= LimitWeight || 0 \u0026gt; posIndex ){ return 0; } int localMaxValue = 0; int posWeight = Weights[posIndex]; int posValue = Values[posIndex]; if(LimitWeight \u0026gt;=posWeight){ // 选择当前位置的物品 if(0 != stateDP[LimitWeight][posIndex+1]){ // 使用缓存 int selectValue = stateDP[LimitWeight][posIndex+1]; }else { int selectValue = posValue + knapsackDo(Values, Weights, LimitWeight- posWeight, i -1); // 添加缓存 stateDP[LimitWeight][posIndex+1] = selectValue； } // 跳过当前位置的物品 int skipValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); localMaxValue = MAX(selectValue, skipValue); }else { // 超过重量限制，不能选择 localMaxValue = knapsackDo(Values, Weights, LimitWeight, posIndex -1); } return localMaxValue; }   注意：根据代码执行顺序，只需要添加上面一处添加缓存处理代码即可。\n7. 将递归转化为迭代 上面一直采用的是top-down来解决DP问题。这一步我们要尝试将递归转化为迭代。\n递归的情况下状态转移方程是函数的方程。在迭代的情况，状态转移方程是状态变量的方程，具体如下：\n当限制重量大于等于当前物品重量时，状态转移方程如下：\n1 2 3  stateDP[LimitWeight][posIndex] = MAX(stateDP[LimitWeight - Weights[posIndex-1]][posIndex -1]+Values[posIndex-1], stateDP[LimitWeight],[posIndex -1])   当限制重量小于当前物品重量时，状态转移方程如下：\n1  stateDP[LimitWeight][posIndex] = stateDP[LimitWeight][posIndex -1]   代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; int itemLen = Weights.size(); // 定义与实始化DP状态 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; stateDP(LimitWeight+1, vector\u0026lt;int\u0026gt;(itemLen+1)); // 限定重量从1开始 for(int w = 1; w \u0026lt;= LimitWeight; w++){ // 在限定重量为w的情况下，遍历数组获取最大值 for(int posIndex = 1; posIndex \u0026lt;= itemLen; posIndex++){ int selectValue = 0; int skipValue = stateDP[w][posIndex -1]; int posWeight = Weights[posIndex -1]; int posValue = Values[posIndex -1]; if (w \u0026gt;= posWeight) { selectValue = posValue + stateDP[w - posWeight][posIndex -1]; } stateDP[w][posIndex] = max(skipValue, selectValue); } } // 从状态中取出最大值 MaxValue = stateDP[LimitWeight][itemLen]; return MaxValue; }   为了方便理解上面的代码，我们进行一个实例分析：\n假定有4个物品，其价值分别为10, 40, 30, 50，对应重量分别为5, 4, 6, 3，限定总重量不超过10。 下面我们观察stateDP的变化过程。\n首先看初始化的stateDP状态：\n根据初始化的stateDP状态和状态转移方程，整个stateDP状态构建一列一列进行即可，过程与结果如下：\n8. 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; // std::max #include \u0026lt;iomanip\u0026gt; using namespace std; int knapsack(vector\u0026lt;int\u0026gt; Values, vector\u0026lt;int\u0026gt; Weights, int LimitWeight) { int MaxValue = 0; int itemLen = Weights.size(); // 定义与实始化DP状态 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; stateDP(LimitWeight+1, vector\u0026lt;int\u0026gt;(itemLen+1)); // 限定重量从1开始 for(int w = 1; w \u0026lt;= LimitWeight; w++){ // 在限定重量为w的情况下，遍历数组获取最大值 // 完全DP问题，在遍历数组的情况下需要考虑同一个选项多次选择的问题 int posIndex ; for(posIndex = 1; posIndex \u0026lt;= itemLen; posIndex++){ int selectValue = 0; int tmepSelectValue = 0; int skipValue = stateDP[w][posIndex -1]; int posWeight = Weights[posIndex -1]; int posValue = Values[posIndex -1]; int selectCnt = w / posWeight; for (int i = selectCnt; i \u0026gt;= 1; i--){ tmepSelectValue = i * posValue + stateDP[w - i*posWeight][posIndex -1]; selectValue = max(tmepSelectValue,selectValue); } stateDP[w][posIndex] = max(skipValue, selectValue); } } // 从状态中取出最大值 MaxValue = stateDP[LimitWeight][itemLen]; // 打印状态表 cout\u0026lt;\u0026lt;\u0026#34;print stateDP:\u0026#34;\u0026lt;\u0026lt;endl; for(int i = 0; i \u0026lt;= itemLen; i++){ for(int j = 0; j \u0026lt;= LimitWeight; j++){ cout\u0026lt;\u0026lt;setw(3)\u0026lt;\u0026lt;stateDP[j][i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt;endl; } return MaxValue; } int main(){ vector\u0026lt;int\u0026gt; Values{10, 40, 30, 50}; vector\u0026lt;int\u0026gt; Weights{5, 4, 6, 3}; int LimitWeight = 10; int maxValues = knapsack(Values, Weights, LimitWeight); cout\u0026lt;\u0026lt;\u0026#34;maxValues:\u0026#34;\u0026lt;\u0026lt;maxValues; }   运行结果如下：\n1 2 3 4 5 6 7 8  print stateDP: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 10 10 10 10 10 20 0 0 0 0 40 40 40 40 80 80 80 0 0 0 0 40 40 40 40 80 80 80 0 0 0 50 50 50 100 100 100 150 150 maxValues:150   推荐是在leetcode测试，由于leetcode上没有这道题，所以就简单测试一下。\n测试代码参考链接。\n总结 掌握使用DP解决问题三个条件：\n 最优子结构 边界条件 满足重叠要求的状态转移方程  使用DP解决问题采用以下步骤：\n 定义状态 确定递归关系 根据递归关系，得出并检查状态转移方程 确定递归结束条件 完成递归的实现 添加缓存保存子问题结果优化递归方案 将递归转化为迭代  对上面的步骤总结如下：\n根据问题的目标采用Top-down方式弄清问题的本质（状态转移方程），然后采用Bottom-up方式实现代码。\nPs：关于DP还有很多内容可以写（如背包问题的扩展及类似leetcode题目），以后有机会再补充一些。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/dsa\/dp-knapsack\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/gpt3-thought\/": {
        
        "title": "谈谈GPT3",
        "tags": ["编程",],
        "content": "GPT-3 GPT-3全称是\u0026quot;General Pre-trained Transformer-3\u0026quot;，对应中文翻译为：第三代通用预训练转换器。\n其wiki定义如下：\n Generative Pre-trained Transformer 3 (GPT-3) is an autoregressive language model that uses deep learning to produce human-like text.\n GPT-3是一种自回归语言模型，这种模型利用深度学习产生类似于人类语言的文本。\n从本质上看，GPT-3是计算机程序。\n现阶段GPT-3能干什么呢？\n 直接能够理解英文理解并将转化为需求 英文翻译 自动创作如小说 人机对话  具体请看下面的一个视频： 看完这个视频作为程序员的我感觉一阵阵凉意，AI会下围棋也就算了，AI现在可以直接根据需求写代码，这是解放程序员还是解决程序员呢？\n值得注意的是，GPT-3背后的OpenAI公司的投资人有两位硅谷大佬：当代钢铁侠埃隆·马斯克（Elon Musk）和《从0到1》作者彼得·蒂尔（Peter Thiel）。\nGPT-3意味着什么？ 无码编程时代 从上面的视频中我们可以清楚看到需求定义即代码。从中进一步思考可以得出一个结论：编程的未来发展一个方向是无代码化（no code ）或者少代码化（less code）。这也意味着编程的门槛进一步下降。\n超级大脑外挂 随着GPT不断进步与发展，GPT-X将来会成人类大脑超级外挂。拥有GPT-X在知识方面远远会超越普通人。以程序开发为例，在未来开发人员只需要定义需求，而AI将帮助开发人员完成编程，测试，部署等功能，这也意味着当你定义好需求之后，几分钟之后需求就得了实现，测试，部署，上线等流程，整个开发周期大大缩短。\n新一代脑力资源 现在脑力资源主要来自人类，未来类似于GPT-3这样的AI会成为新一代脑力资源。其实现阶段计算机程序已经实现部分这样的功能，如象棋对奕软件，Alphago，这些计算机程序已经在象棋与围棋领域超越了人类，已经成为人类最强大的陪练。除此之外在机器翻译，语言识别，自然语言处理等技术已经得到广泛应用。\n面对新一代的脑力资源：AI, 人类应该如何应对呢？\n如同人类要避免同计算机比计算能力，未来的人类也要避免在AI擅长的领域与之竞争。 如同人类利用计算机来创造一个互联网世界，未来人类也会应用AI技术创造一个智能的世界。\n感想 下面谈一下我个人一些感想：\n 只会写CRUD肯定是不行了，不说未来怎么样，现在这个阶段，只会CRUD的程序员已经在危险的地带，现在这个阶段，只要定义好SQL语句，就可以生成CRUD的代码了，未来就更不说了 GPT-3并不会取代那些高级程序员 成为SQL工程师也比成为一个CRUD工程师更好，因为SQL离需求更近，离数据更近 在数学和算法方面精进，做到Write code to create 未来程序员只需要四类工程师：业务类，基础设施类，算法类，架构类 AI的进步与发展，会带来新的变化，主动拥抱AI的变化，才能适应未来世界 不可替代永远是现在还不存在的东西，所以培养创新意识与创造能力变得相当重要了  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/gpt3-thought\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/linux-wget-retry\/": {
        
        "title": "利用WSL和wget从github下载文件",
        "tags": ["Linux",],
        "content": "背景 由于GFW的干扰，即使科学上网方式从github下载文件，下载连接经常会被中断。由于chrome重新连接的次数有限，据说chrome重新建立连接重试次数最大为5次。所以遇到一个大的下载文件，通常是不会下载成功，费时费力费心。\n针对这种情况提供一个解决方案。\n解决方案 在windows上科学上网基础之上，解决方案主要工作如下：\n 在windows上安装wsl 在wsl上安装与配置polipo  应用 应用就很简单,通过wget指定重连接的次数，参考如下：\n1  wget --tries=1000 https://github.com/downloadurl   （end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/linux-wget-retry\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/think-outof-box\/": {
        
        "title": "谈谈跳出框架思考",
        "tags": ["成长",],
        "content": "引子 先看一下这道数学题：\n画直线经过下图中九个点，并且做到不重复经过任何一个点。\n这里不是出题给大家做，只是引出话题。\n下面是这个问题的答案：\n这个答案并没有局限在题目中要求9个点，扩大到面的范围，由9个点范围扩大到16个点范围。如果一直在考虑9个点的范围这个题目你是不会找到正确的答案。解题的关键是：think outside of the box。在上面这道题主要打破只有9个点的限制，也就是跳出只有9个点的框框。\n至此，关键话题来了： think outside of the box，这里我将其翻译为跳出框架思考。\n定义 跳出框架思考是要尽可能地消除约束，从更多的视角或层次思考，发现更多的选项和方案。\n我们还是具体看几个例子吧。\n作为一名多年的码农，先从技术研发开始吧。跳出框架思考是指研发不要局限于技术，要多关注业务。具体看几个例子：\n实例1：以前看一个科技电影，大概是两个黑客比赛，谁先攻破系统，则对应灯亮作为获胜；其中黑客A紧急投入攻破系统，而黑客B却在电影需要下，轻淡幽闲地装B，带上主角光环的他其实心里早有准备，采用直接攻击灯控系统，降低攻击难度，同时利用规则的漏洞。这里黑客B看到规则里另一种含义：谁的灯先亮，谁就获胜，跳出一般人理解先攻破系统，再亮灯的习惯性思维。\n实例2：早期的阿里云CDN系统需要定位ip地址的地理位置，阿里云的工程师想到根据淘宝用户的收货地址来定位地理位置。\n实例3：互联网安全方面：如果微信账号被盗，可以通过社交关系找回；淘宝帐号找回，需要通过最近购物的测试；这些都是从多个维度确认帐号对应是用户是原来的用户，而不是仅仅通过密码和手机还确认用户。\n在工作方面，跳出框架思考要点之一就是员工要跳出员工的视角，学会站在老板或者上级的角度来思考问题。这里分享一个职场的技巧：\n 在任何领域，众所周知，要让老板支持你的想法，最容易的方法就是让他认为这个想法是他的。 ​​​​\n 在交易领域，对冲基金的操作手法也体现了跳出框架思考，如跨市场交易，跨地区交易。\n下面这个例子让我是佩服不已。 从上面例子可知，tk教主的朋友跳出员工与公司的二元框架，在二元框架下一般只有三种选项：\n 不作处理，等其主动离职（水货一般都是没有水平，要想让他主动离开时间长，概率小） 逼他主动离职（需要耍手段，双方关系可能弄僵） 通过赔偿主动解雇（需要花钱）  tk教主的朋友从员工，公司，人才市场的三元框架下思考，通过上面的方法，达到不止双赢，而是三赢：\n 公司摆脱了水货，并且将水货送到竞争对手的公司，去祸害竞争对手，算是打击了竞争对手 水货员工得到加薪 猎头成交一笔大单，获得丰厚的报酬  在自然语言处理领域，科学家跳出了语法与主义的框架，改用统计分析的方法，大大促进的自然语言处理技术的进步，也才有现在推荐与搜索技术的广泛应用。\n跳出框架思考是如此充满威力，那如何培养自己的跳出框架思考的能力呢？\n如何培养跳出框架思考的能力 记录灵感，避免刻意思考 平时记录自己一些想法与灵感，这种有充足的信息与思路储备的情况下，思考的灵活性就不会打折扣，相反由于信息与思路够多，这些信息与思路的形成新的结合，会有更多的想法出现。\n摆脱限制 跳出框架思考最重要的一步是摆脱限制，在思考方面不要给自己设限。\n广泛阅读与学习，并且多尝试与实践 平时要广泛阅读与学习，扩大信息源，广泛涉猎各个领域的知识，以技术领域为例，比特币技术综合了P2P技术，PoW共识，密码学，区块链等多种技术，同时结合经济学的知识，将数字货币与计算机技术紧密地结合在一起。\n5W1H替换法 从原因（何因Why）、对象（何事What）、地点（何地Where）、时间（何时When）、人员（何人Who）、方法（何法How）等六个方面提出问题进行思考，在此基础上对这6个要素进行替换，并尝试找到更多的替换选项。\n培养同理心 同理心能够让我们站在他人的角度来思考，有利于提供更多的视角。很多时候，我们不能跳出框架，是因为我们缺少视角。\n避免以目标为中心 避免以目标为中心的思维方式，目标更应该是一个导向的作用。目标很重要，但是目标并不代表全部，目标并不是系统。眼睛全是目标，就看不到系统，也就不能从从系统中发现更多的其他可能性。\n后记 ”不识庐山真面目，只缘身在此山中“。 ”当局者迷，旁观者清“。 学会跳出框架思考，会给我们带来更多的视角，看见不同的世界，提高我们的视野与格局。 ", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/think-outof-box\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/cryptocurrency_antifrangible\/": {
        
        "title": "谈谈数字货币的反脆弱性",
        "tags": ["BlockChain",],
        "content": "定义 首先我们来看一下反脆弱性的定义。这里直接借用：\n 有些事情能从冲击中受益，当暴露在波动性、随机性、混乱和压力、风险和不确定性下时，它们反而能茁壮成长和壮大。不过，尽管这一现象无处不在，我们还没有一个词来形容脆弱性的对立面。所以，不妨叫它反脆弱性（antifragile）吧。\n 接下来我们来探究一下数字货币反脆弱性体现在哪些方面？需要说明一下这里的数字货币是指比特币和以太坊。\n具体如下：\n 构建在坚实的科学基础之上 强大的抗打击能力 去中心化组织 保持开放性 开拓独特性并保持领先 超越主权资产配置  构建在坚实的科学基础之上 比特币与以太坊都是构建在数学、密码学、计算机科学等基础之上。以比特币为例，比特币的技术由密码学、分布式帐本、PoW共识、P2P等组成。这些技术都得到无数次实践证明或者简单可靠。正是因为有这些科学基础，整个比特币系统一直可靠运行，没有出现一笔交易错误。\n强大的抗打击能力 以比特币为例，比特币具有很强的抗打击能力。比特币曾被媒体宣布死亡近400次，被部分政府定义为非法，打击比特币交易，自身生态也遭受到交易所被盗、比特币分叉之争等重大事故，但是到了现在，比特币的链上交易依然活跃，始终稳居加密货币王座，同时也是每个月开发更新最多最频繁的加密货币。\n去中心化组织 比特币节点网络是一个去中心化组织，类似于海星，具有极强的生命力：\n 海星这种生物是没有头的，它的智能控制分布在肢体的各个部分，砍掉海星的一条手臂，这个手臂可以演化成另一个海星。海星就是一个去中心化的组织系统。\n 比特币网络由千千万万的节点（矿工）组成，这些节点维护网络安全和共识账本，即使一部分节点掉线甚至退出，也不影响比特币整个网络的运行，整个网络具有极强的高可用性。同时这种多个节点运行的模式，也有利于对抗攻击。\n保持开放性 无论是比特币还是以太坊都有很好的开放性，其开放性体现如下：\n 节点自由加入与退出 代码开源 社区开放，支持各种BIP与EIP，促进比特币与以太坊不断进化  开拓独特性并保持领先 独特性意味着不可替代性，并且会拥有独特性带来的先发优势。\n比特币是数字加密货币的鼻祖，同时也是第一个抗通胀的数字资产，是当之无愧的数字黄金，从诞生开始一直保持市值第一，在整个熊市过程中比特币的所占的市值份额是增长趋势。\n以太坊首先实现智能合约，并一直保持最大智能合约平台。\n超越主权资产配置 现在国际形势变化多端，中美关系降温明显，世界经济这些年的发展离不了经济全球化。在政治上全球化协作倒退的今天，已经全球化的数字货币正好可以抢占这一倒退空出的空间。毕竟长期来看，经济全球化是不可逆的趋势。数字货币可以在全球范围内实现了货币自由（从另一个角度数字货币提供一种新的自由方式：货币自由）。\n资产配置的需要 现在由于大数据的发展与应用，富人的钱基本处于透明状态。这时候数字货币的匿名性与抗监管满足这些人的需求。\n后记 说明一下，虽然数字货币价格波动范围较大，但是从一个货币的角度来看数字货币具有很强的反脆弱性。个人投资由于价格波动大而出局，体现了数字货币系统的遍历性。\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/cryptocurrency_antifrangible\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/covid-19-symptom\/": {
        
        "title": "分享：一图了解新型冠状病毒的症状有哪些",
        "tags": ["Life",],
        "content": "新型冠状病毒（Covid-19）在全球的传播与感染速度有一定的控制，但是并没有结束。全世界累计确诊已经超过了500万，累计死亡人数超过了30万。新型冠状病毒是数十年来最危险，最棘手的新型病毒性之一。它可以攻击体内几乎所有器官，并可能造成毁灭性的伤害。\n下面我们看一下美国发布的新型冠状病毒的症状有哪些？\n上面这张图并没有包括中国前一段时间发布新型冠状病毒可能攻击男性的生殖系统的内容。\n这些导致这些器官的症状的原因并没有完全的科学解释，医疗界还在研究中。新型冠状病毒是一个新型的病毒，人体是一个复杂的系统，在短短几个月弄清楚其中的原理也是不太现实。\n关于美国发布的这个新型冠状病毒的症状，个人认为还是具有很大的参考价值：\n 美国的感染人数超过了160万，全球第一，有大量的数据和案例提供研究，大量的样本保证其可靠性 这个新型冠状病毒的症状出自美国顶级大学与科研机构之手（当然也是世界顶级，要承认事实） 美国开放性的言论与研究环境  另外全球疫情在全球经济落后，医疗不发达的国家和地区更是难以应对，这会是全球的防控疫情最大的不确定，典型的例子就是巴西，巴西确诊数已经仅次于美国，居于世界第二。\n参考  Coronavirus May Be a Blood Vessel Disease, Which Explains Everything 金银潭出院新冠患者追踪：超 7 成半年后仍有症状  ", 
        "url": "http:\/\/myself659.github.io\/post\/covid-19-symptom\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/book-skin-in-the-game-how\/": {
        
        "title": "读书笔记:《非对称风险》",
        "tags": ["Read",],
        "content": "首先了解一下作者：纳西姆·塔勒布，研究不确定性的专家，华尔街明星交易员。他先后出版“不确定性”四部曲：《随机漫步的傻瓜》、《黑天鹅》、《反脆弱》和《非对称风险》。读完《非对称风险》这本书，你发现作者是一个直言不讳的真性情中的人，在书中直接点面道姓的怼名人（包括巴菲特）。\n书中精句不少，例如这句：\n 你永远无法说服一个人他错了，只有现实才能教育他。\n 什么是非对称风险？ 市场参与者所承担的风险和收益是不对称的。塔勒布把由此引发的风险叫做“非对称风险”。典型如2008年美国的金融危机的华尔街精英们，他们玩的是自己赚钱，民众买单的勾当。在生活中一些银行的业务员只管放长期贷款，等货款到期的时候，他早就离职不干了，后面出现了什么债务风险，他一点责任都不用担，只管放货拿提成。\n有哪些非对称风险？ 书中提到非对称风险分为以下几类：\n 信息不对称 权力和责任不对称 少数派主导 理论与实践不对称(书中未明确提出，个人总结)  信息不对称 信息是生活的基础元素，如同空气。信息不对称随处可见。中国大部分人的信息不对称都受到防火墙的影响。\n在经济活动中最常见就是交易双方一方比别一方掌握的信息更多，具体例子如书中提到的罗得岛粮食的价格。\n权力和责任不对称 最典型例子就是书中提到西方干涉主义。现实中的例子就是伊拉克、叙利亚与利比亚等受到西方的干涉行动，最终给当地人民带来了巨大苦难。但是这些西方国家动用强权对别国进行干涉，却根本不需要为自己的错误买单，不用承担任何责任，甚至标榜自己了“成功赶跑了独裁者”。\n少数派主导 只要人群中有3%~4%的顽固少数派，那么，最终整个群体的人都会服从少数派的偏好和选择。生活中最典型的例子：一桌子人聚会吃饭，都用本地方言聊天。这时候来了一个远道而来的客人，他不会说本地话，只会说普通话。为了能让他听懂，结果一桌子人全部改用普通话聊天。\n理论与实践不对称 现实是不确定性，现实是一个复杂系统，理论或是出自实验，或来自逻辑，理论视角有限，但是现实是时间的产物，是无数动力相互作用的结果，同时结构复杂。而所有的实践都是基于现实，可以说现实是实践的环境。现实比理论的环境复杂多了。没有注意到理论与实践不对称在军事上最典型的例子就是赵括纸上谈兵，导致40万赵军被坑杀，成就了白起成为战国战神的神话。\n如何应对非对称风险？ 风险会一直存在，非对称风险也会一直存在。那么我们如何应对非对称风险？这也是我们读这本书最终目标。\n避免思考三大坑 识别风险需要思考，思考要注意避免以下三大坑：\n  只考虑静止的状态，而不考虑动态的机制 思考是低维度而非高维度的 只想到了采取什么行动，而没有想到行动本身会有反作用   避免思考三大坑，才能减少识别风险的错误。\n识别非对称风险 首先看一张书中总结一张图：\n识别风险还要注意以下几点：\n 区分波动和风险，防止成为非对称风险的教条主义者 重点关注那些带来不可逆转的伤害的风险  识别风险，才能应对风险。\n生活中有各种推荐买房和推股的人，他们都会告诉你推荐你买的房子会涨和精选的股票也会让你获利，但是他们都没法证明他们自己入场了。他们的信息隐藏了非对称风险，或者这些信息就是假消息。\n学习与应用概率理论 随机无处不在，随机无时不在。随机带来不确定性，不确定性需要用概率来描述，应对不确定性需要概率理论来指导。\n那我们还是先看几个概念：\n上图有两个重要的概念。\n集合概率：100个赌徒在1天时间里的成功概率\n时间概率：其中一个赌徒在100天的时间内赌运\n平均斯坦：一个事物的过程主要由平均值主导，很少有极端成功或失败的例子（比如牙** 医的收入）。个体不会对整体造成很大的影响，它也被称作“薄尾”风险，也是高 斯分布的一种。\n极端斯坦：在一个随机过程中个体会对总体造成巨大的影响（比如作家的收入），它也 被称作“胖尾”风险。它包含分型、幂律等分布类型。\n遍历性：在本书的语境下，遍历性是指对一群人在同一时间的统计特性（尤其是期望 ）和一个人在其全部时间的统计特性一致。集合概率接近于时间概率。如果没有 遍历性，那么观测到的统计特性就不能应用于某一个交易策略，如果应用的话， 就会触发“爆仓”风险。\n结论：\n  越高频越重要。如作为一个程序员你每天要用电脑，那么你的电脑一定要配置好。（每天重复就是时间概率上的高概率）\n  永远不要将倍增的、系统性的胖尾风险和不倍增的、特殊的薄尾风险相提并 论。\n  概率越高，确定性越高，也就越可靠，可靠的事物具有长期的优势，这是一种概率上的优势的体现。\n  不断重复地暴露在风险之中，无论多么小的概率的危险，最终都会发生。\n  说出你的想法，付出行动，承担风险。just do it！\n  风险共担机制  你愿意为一个事物承担多大的风险，揭示了你对该事物的信任程度。\n 常见风险共担机制：\n 华尔街银行家来说，风险共担就是要让他们自己拿出真金白银，和客户的资金绑在一起进行操作 IBM CEO郭士纳规定：高级经理必须自己掏钱购买一定数量的IBM股票，才可以获得公司的股票期权。郭士纳相信，高级经理们只有自己真正投入了成本，才可能真正关切公司的命运。并且同时自己也以身作则，在上任之初就从公开市场上买入了IBM的大量股票 一些投资人要求创业者要求投入资金，并且进行对赌 投名状，典例例子就是《水浒传》里的王伦要求林冲入伙前要以杀人方式纳投名状 两个人结婚，共同生活也共同应对未来生活的风险 欧洲的贵族由于承担了对其领地上平民的保护的义务和风险，才换取了自己的贵族地位。如果你不能为人民承担风险，那么你无法成为他们的领袖。  总之，风险共担就是全身心投入，享受收益也承担风险。\n审慎原则，保持理性 审慎原则就是小心求证，宁可错过，也不要犯错。这一点特别在投资领域很实用，无论股票还是基金每天都有新的机会；审慎原则是追求高的确定性，在投资方面就是对大部分机会说不。\n保持理性的最好方式就是一个清晰明确的目标，而这个目标就是：\n 真正的理性，就是避免系统性毁灭。\n  所谓理性就是首先保证自己所在的集体生存更长时间。\n  要赚钱，你首先得活得长。\n  要防止自己成为系统遍历性的牺牲品。\n 致知如行，知行合一 致知如行，知行合一，这是中国古代的智慧的精华之一，也是应对理论与实践存在不对称风险最好的方式。\n在岸上永远学不会游泳，学习再多的游泳知识都不能变现，基于连个测试的机会都没有。\n在生活中很多人都面临这样一个困惑：为什么你听过这么多道理，却依然过不好这一生？其实道理与现实，理解与做到并不是一回事。\n谨记：空谈无用。少说话，多做事，先做再说，宁可只做不说也不要只说不做。\n后记 《非对称风险》这本书内容分散，不系统，但是角度新颖，让人大开眼界，对于概率的理解让人受益匪浅，整本书有充满实用主义和实干主义气息，值得精读。\n参考  暴跌中的大赢家：塔勒布大弟子狂赚40倍的秘密  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/book-skin-in-the-game-how\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/how-to-learn-fast\/": {
        
        "title": "关于快速学习的思考",
        "tags": ["学习","成长",],
        "content": "在知识经济与日新月异的时代，学习的重要无须多言。这个时代正在惩罚不学习和不会学习的人。\n从整个知识体系上来看，如何学习属于元知识，属于基础知识。越基础越重要。那么如何培养自己的学习能力？在开始之前，我将学习能力划分两个子能力：\n 快速学习能力 深度学习能力  本文内容限定在如何提高自己的快速学习能力？提高快速学习能力有三个方面：\n Input：保证动力输入从而享受学习的过程 Process：正确的学习的路径与方法 Output：保证学习的有效输出  保证动力输入从而享受学习的过程 学习动力有多种，如兴趣爱好、虚荣心、利益、恐惧等多种因素。最佳的动力属于兴趣 爱好，这种动力持续时间长，对外界依赖很小，能够让人真正地享受学习的过程。享受学习才能快乐学习，快乐学习带来快速学习。越越享受学习的内容，那么掌握它的速度就越快。享受学习带来主动学习，这样会主动找学习的内容，主动花时间学习，主动提高学习的优先级。享受学习可以维持更长更好的学习状态。\n三千弱水只取一瓢饮。所以一定找到让自己的感兴趣的学习内容，并在学习过程中培养与强化兴趣。\n如果你要学习的内容正是你感兴趣，那么恭喜你，快速学习的第一要点你已经具备。但是生活不是事事如意，如工作需要学习的内容并不都是你感兴趣的内容。在这种情况，如何培养自己的兴趣呢？举一个例子，假如你对编程不感兴趣，但是你对经济股票感兴趣，你可以学习python分析股票的数据，这样的话，对股票的兴趣为你提供学习编程的动力。\n正确的学习的路径与方法 动力有保证，第二个问题来了：如何在动力的作用下，找到正确的学习路径和方法？而不是采用低效的方法和错误的路径来白白消耗珍贵的学习动力。\n关于学习的方法有很多介绍，这里推荐一个视频:The first 20 hours \u0026ndash; how to learn anything | Josh Kaufman | TEDxCSU。这个方法将学习分为以下四个要点：\n 分解步骤：把技能做最大程度的细分，分成若干小步骤。 充分学习： 对每个小步骤进行充分学习，以便进行灵活的练习，并在练习中自我纠正。 克服困难：克服在练习中出现的生理、心理或者情绪上的障碍。 集中练习—— 至少用20小时集中学习最重要的小步骤。  关于学习的路径的问题，这里以golang编程语言为例，其初略的学习路径：\n  先语法，再应用，然后原理 先实验，再工程，然后优化 先动手实践，再解决问题，然后是总结提高   详细的内容请参考文末的原文链接。\n保证学习的有效输出 输出就是测试学习的成果，能及时反馈与及时改进。\n输出是一种反馈。\n输出的评价有三个方面的指标：\n 学习内容的掌握效果 学习在经济方面的回报(如金钱与影响力) 学习动力是否在增强  关于学习内容的掌握效果最好的方式就是分享。很多人将分享作为一种学习的方法，我更看作是一种学习的有效输出。分享的内容是学习的产出，同时这种方式的产出效果属于最佳，除此之外分享会有带来影响力，影响力能够进一步增强学习动力。可知分享是将上面提到的三个指标为一体最佳学习输出方式。\n那么如何进行分享呢？向伟大的解释者费曼学习。学习用简单直观的方式解释并教会他人。伟大物理学家爱因斯坦也曾表示：\n If you can\u0026rsquo;t explain it simply, you don\u0026rsquo;t understand it well enough. 如果你不能简单明了地解释一件事情，那么说明你还没有很好地理解它。\n 分享可以先从写作开始如先从记录开始，写下自己的学习问题与感悟总结，然后再发表自己的博客上面，接着尝试分享给专业人士，进一步向普通大众分享。\n小结 学无止境。如果将学习比作一条永无止境的道路，快速学习可以让你走的更快，更远，经历更多的风景。\n参考  谈谈工作和学习中，所谓的主动性  ", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/how-to-learn-fast\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/coronavirus-change\/": {
        
        "title": "后疫情时代会有哪些变化",
        "tags": ["Economy",],
        "content": "现状 疫情从武汉爆发开始，到现在全球蔓延，全球确诊超过了226万。国内广州与黑龙江有复发的态势。但是全国基本上已经控制住，防控成绩也算相当不错（除武汉疫情初期）现在全国基本上暂时处于后疫情阶段。\n但是疫情还是处于不确定状态，个人判断理由如下：\n 对于病毒来源未知 对于病毒的了解与探究还在进行中 无特效药冶疗 疫苗最快1年才能上市 病毒是单链结构，会发生变异 是否在印度、非洲、南美洲等公共卫生条件较差的国家蔓延？ 秋冬季是否会第二次爆发？ 无症状感染者难以检查 各国能否相互团结？现在看来国际社会之间已经出现不少裂痕  疫情下的经济 中国第一季度GDP同比负增长6.8%。疫情期间80%的行业受到严重打击，受益主要是下面十几个行业：\n 医疗卫生行业 互联网医疗 养生保健行业 居家运动器材 AI产业 社区生鲜电商 自媒体 电商 在线培训与培训 远程办公软件 视频会议平台 VR、AR场景体验 网络游戏 在线影视 远程医疗  其他行业的基本都是受到冲击，这是不列举，列出受益的行业，希望大家能从上面的行业找到属于自己的机会。\n疫情后的趋势 人类历史战胜天花，黑死病，西班牙大流感。这次疫情终会过去。那么经历这次疫情整个世界有哪些新趋势呢？\n数字化增强 越来越多的行业会数字化，这有利于以下这些行业：\n 云计算平台 远程工作平台 AR/VR 游戏 视频 电商 区块链  远程工作会越来越多 疫情阶段全世界在测试远程工作，同时也在测试过程中优化远程工作，人们也在这次疫情养成远程工作的习惯。远程工作在知识服务这个领域会成为默认选项。\n自动化将会进一步发展 在数字化的基础上，自动化发展主要体现机器人技术与远程控制技术的发展。如美国在疫情期间使用医疗辅助机器人。\n在线教育 虽然在K12这块教育会回归线下，但是线上仍会保留。对于高等教育而言，大学生一般都 有一定的自制力和自学能力，线上教育的选择更多同时时间也会更加自由，相信未来会出现一些网络大学，这些网络大学能够像普通大学一样能够颁发文凭。\n全球化短期受阻，长期向好 2020年4月8日，中共中央政治局常务委员会提出：\n 做好较长时间应对外部环境变化的思想准备和工作准备。\n 这是近期的较确定的发展方向。如最近美国与日本鼓励企业将产业链搬出中国。这些国家的产业链依赖中国，实质上损害本国的经济安全，从长远上看迁部分产业如医疗与医药有利于提高本国的经济安全。但是信息的全球化却会加强，解决病毒问题需要全球协作，制定国际准则，监测和报告系统，并制定协调的对策和应急计划，这样有利于全球性问题的防范与处理。避免像这次疫情在二月份在武汉已经爆发，但是还是在3月份在全球蔓延起来。\n除此之外，全球化是超出一个国家范围的资源配置，在全球范围内最优化解决方案肯定会超出一个国家内的最优解决方案（局部最优并不是全局最优）。\n远程医疗 这次疫情期间，在医院发生不少聚集性感染的案例，未来在家就可以就诊是一个重要的发展方向。\n更多 当然疫情带来的变化，远不止上面这些。如人们生活方式与思考方式的改变。\n小结 疫情也许不会发生在你的身边，但它带来的改变却无处不在。提前思考与行动，有利于我们适应变化与把握机会。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/coronavirus-change\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E8%B4%A2%E5%AF%8C-%E7%94%9F%E4%BA%A7%E8%A6%81%E7%B4%A0\/": {
        
        "title": "生产要素就是财富",
        "tags": ["Think",],
        "content": "生产要素 生产要素是指在生产过程中所使用的各种资源，生产要素是实现生产过程的必要条件，可以通过组合使用来创造各种产品和服务。\n生产要素可以分下几类：\n 劳动力 资本 土地及自然资源 技术 数据  生产要素就是财富 生产要素是财富的载体，生产要素创造财富。\n一个人或者组织财富能力可以用下面的公式描述：\n财富能力 = 生产要素的供应能力 * 生产要素的应用能力 * 生产要素的产出能力 * 生产要素的产出再产出能力。\n所以，积累生产要素是致富的必经之路。\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E8%B4%A2%E5%AF%8C-%E7%94%9F%E4%BA%A7%E8%A6%81%E7%B4%A0\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/libra2-basic\/": {
        
        "title": "libra的妥协与机会",
        "tags": ["Blockchain",],
        "content": "2019年6月libra横空出世。我写了一篇关于libra的文章：Facebook libra是昙花一现还是星星之火。\n文章的提到：\n 对，Libra最大的问题就是监管。由于Facebook是一个全球化公司，涉及不同的国家，这些国家的法律与政策也不尽相同。这对于Libra就是一个巨大的挑战。至于很多人担心Libra会不会是昙花一现，直接被扼杀在摇篮？前面有USDT的先例。答案是不会的，美帝的民主制度，都会有一番流程与讨论，估计过程并不会一帆风顺。有了美帝的放行，在其他的国家开展也就铺平了道路。\n  如果Libra coin要挑战美元，那么美元就是Libra的最大竞争对手，这个挑战很大，近期应该不会出现。\n 想想小扎与libra的总负责人Mr Marcus在国会受虐。libra在监管方面却不是一帆风顺，可以说是饱经折磨。\nlibra在新发布的白皮书，放弃挑战美元，相反而是走上与美元相互成就的道路。说一句话题外话：人民币要加油！（人民币只有开启自由兑换，人民币的国际化才算开始。）\n妥协 libra在新版白皮书做了以下妥协：\n 提供单币种稳定币如美元与欧元 放弃未来向无许可公链的发展目标 加强合规，提高系统的安全性  总之，面对各国政府强监管的要求，libra选择断臂求生，主动拥抱美元，从挑战所有的法币，转而帮助美元维护霸权。\n机会 那么libra提供了哪些机会给大家呢？\n加入libra生态 加入libra生态有以几种选择：\n1、指定经销商；\n2、在金融行动特别工作组（FATF）成员司法管辖区中注册或获得许可的虚拟资产服务提供商（VASP，包括交易所和托管钱包），或是在FATF成员管辖区中注册或获得许可、并且根据此类许可或注册执行虚拟资产服务提供商活动（受监管的虚拟资产服务提供商）的虚拟资产服务提供商；\n3、已完成由 Libra 协会批准的认证程序的虚拟资产服务提供商（认证的虚拟资产服务提供商）；\n4、寻求通过 Libra 网络（无托管钱包）进行交易或提供服务的其他个人和实体。\n基本任何人都可以选择第四方式，这种方式基本上无资质门槛。\n参与基础设施建设 基础设施先行。参与基础设施如成为验证节点，验证节点是否有经济激励暂不可知，但是有很多信息优势与先发优势。\n技术先行 如果感兴趣可以学习一下rust。最重要是学习move，libra上线后基于move的智能合约有一个爆发的过程。\n研究集成libra的平台 libra是facebook主导，相信facebook旗下的app都会集成libra。这些app如instagram，whatapp， messager，facebook都是10亿级用户。各种新机会参考支付宝与微信支付。机会肯定不少。以太坊的一些成功应用都值得借鉴。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/libra2-basic\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/meditation-start\/": {
        
        "title": "我是如何学会冥想的",
        "tags": ["Life",],
        "content": "初识冥想 虽然以前也知道冥想，但是却没有对冥想产生什么兴趣。直到2018年去台湾遇到一个很有经历的人，先后在google，百度，阿里等公司从事互联网方面的工作，开过民航飞机，后面又回台湾在高校里读博士，同时英文也相当流利，与老外沟通毫无压力。除此之外，他还告诉我他的睡眠质量相当高，入睡超级快。而自己从小就入睡慢，虽然睡眠质量还算可以。于是我好奇地问他：你是怎么做到这么高的睡眠质量？\n他回答我： 我练习冥想，每年都去香港专门的参加一周的冥想练习，不带手机，与世隔离一周。\n他的回答激起我对冥想的兴趣。\n冥想的好处 光有兴趣还不行，得从中得到好处。那么冥想的好处有哪些呢？这里罗列如下:\n 冥想可以增强您对疼痛和痛苦的承受能力，如冥想增强个人平静的能力，即使面对混乱也能保持平静，增加过滤噪音的能力 冥想可以改变你的大脑, 提高大脑的能力，如冥想可以提高专注力 冥想可以减少不良情绪，如冥想可以减轻抑郁，压力，焦虑等 冥想有助力于身体健康，如冥想可以降低血压和心理压力 冥想让人更加快乐，如冥想过程的空灵和专注，会让人忘记烦恼，享受与身体对话的喜悦 冥想是一种低成本高收益的选择，如高质量的5分钟冥想相当于一个小时的睡眠  为自己找到好处的落脚点 上面的冥想的好处，我在一年前就知道，然并卵。我当时依旧没有学会冥想。直到这次疫情爆发，新型肺炎没有特效药，主要看个人的免疫力。这时候跑步与冥想成为我个人的增加免疫力的主要方式。严重的疫情成了我练习冥想的外界驱动力。于是在家开始练习冥想，慢慢地就学会了冥想，在这个过程中，个人注意力得到提升，入睡时间缩短到了半个小时以内，这些实实在在的好处，又让我继续坚持冥想，这是一个十分良好的正向循环。\n建立自己的冥想基本操作 人的大脑像一部永远不停运转的机器，很难停下来，冥想让大脑从mindful状态进入到mindless状态。对于任何初学者来说，实现mindless都是有困难的。那么如何建立冥想基本操作呢？具体分为几个问题来说明。\nQ：什么时候冥想？\nA：个人一般都是早上醒来就立即开始冥想。\nQ：在哪里冥想？\nA：床上，这样天气冷的时候也可以给自己盖个被子\nQ：冥想的姿势？\nA：类似于打坐即可，不用太死板，自己觉得舒服即可\nQ：冥想教程选择哪个？\nA：推荐用UCLA分享的免费冥想教程，除此之外今天发现keep上线冥想功能\nQ：冥想的时间多长？\nA：刚开始5分钟，后面慢慢到10分钟，20分钟\nQ：冥想如何避免不专注？\nA：找到专注的锚，建议刚开始专注于呼吸，如果出现注意力分散，不要在意，重新拉回注意力到呼吸即可\nQ：冥想用什么背景音乐？\nA：我暂时没有用背景音乐，背景声音倒有，是UCLA冥想课程的引导冥想的内容\nQ：冥想中间不能坚持怎么办？\nA：将思绪拉回到呼吸，至少保证眼睛闭着，除了轻微的动作，身体基本无其他大的动作\n养成习惯 自己写的代码6个月不看，差不多相当于是新的代码。冥想也需要不断的练习，保证不断地练习最好的方式就是养成习惯。\n习惯建立现有生活方式基础最好也最容易建立成功，个人觉得养成冥想的习惯最好的方式就是锚定自己的生活习惯。如早上起床前和晚上睡觉前这两个时间段进行冥想就是非常好的选择。\n小结 从兴趣出发，发现好处，落到自己的实处，做好每一次冥想，从中感受冥想，进而获得平静喜悦淡定，锚定平时的生活规律，从而渐渐地养成冥想的习惯。\n开始冥想吧，这是一个让你受终生的生活方式与习惯。开始并坚持一段时间，你会找到冥想的感觉，并享受冥想。\n", 
        "url": "http:\/\/myself659.github.io\/post\/meditation-start\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/invest\/invest-ruixin\/": {
        
        "title": "关于投资几点感悟",
        "tags": ["Economy",],
        "content": "背景 首先，吃一下瑞幸的瓜，表示对作空机构的敬意：\n 调研机构为了证明瑞幸咖啡造假，派出92个全职和1418个兼职调查员，在全国900多家门店蹲点，收集25843张购物小票，大量内部微信聊天记录，关联人与企业的工商信息，并录制11260个小时的门店录像，得出了瑞幸造假的判断，就这么牛逼。\n 站在对立面的一些买了瑞幸的股票投资者就惨了。瑞幸一天跌了75%。\n惨不忍睹，与数字货币中的山寨币的跌势有的一拼。如果从按照52周最高点算，差不多是跌了90%。\n关键是瑞幸后面还有一堆麻烦，业绩作假，面临法律的制裁，甚至面临退市的风险。\n一个做空，一个做多，同一个股票得到回报相有差十万八千里。\n做空的投资者上天堂，做多（持有股票）的投资者下地狱。\n一个追究事实，一个忽略事实。\n一个真干实操，一个纸上谈兵。\n一个成为收割的镰刀，一个成为被收割的韭菜。\n对于做空的来说，功夫不负有心人。\n对于做多的来说，只能吞下自己判断错误的恶果。\n下面是个人对于股票投资一点看法与感悟，本人从2015年进入股市，差不多也有五年的股龄。\n保持独立性 做不到独立性不要去投资。保持独立性才是投资第一要求。保持独立性是一个合格投资人的体现，高正确率的独立性是一个优秀投资人的体现。\n独立性体现以下几个方面：\n 独立分析与调研 独立决策 独立操作 独立承担后果  风可以吹走一张白纸，却不能吹走一只蝴蝶。因为生命的力量，在于独立自主，在于独辟蹊径，在于不顺从。纸的在哪里由风来决定，而蝴蝶可以决定在哪朵花上停留。\n所以 投资要保持独立性。\n不懂的不要投资 投资其实是认知的体现。\n你永远赚不到超出你认知范围外的钱。除非你靠运气，但是靠运气赚到的钱，最后往往又会凭实力亏掉。\n你所赚的每一分钱，都是你对这个世界认知的变现，你所亏的每一分钱，都是因为对个世界认知有缺陷。\n理性决策而不是情绪驱动决策 就拿瑞幸为例，可以问自己一系列的问题：\n瑞幸的商业模式是什么？\n瑞幸的商业模式可持续吗？\n瑞幸的商业竞争是谁？有什么优势？\n瑞幸的用户忠诚度高吗？\n瑞幸的管理层有了解与调查吗？\n为什么外国人不怎么喝茶？中国人却会养成一个喝咖啡的习惯？\n为什么要喝瑞幸咖啡而不是喝各种奶茶呢？\n瑞幸的市场是面向14亿中国人，这个转化率是怎么样？中国只有1亿左右的坐过飞机，在这些人中有多少人有喝咖啡的习惯？有多少可以养成喝咖啡的习惯？建立这个习惯的成本是多少？难度是多少？\n。。。\n保持耐心，追求高确定性的机会 股票是一个波动的市场，机会很多，保持耐心，投资那些高确定性的机会，这样可以减少风险。\n抵制各种赚钱的诱惑，保持专注，深入研究一个公司，吃透行业，熟悉各种操作。\n沃伦·巴菲特说过：成功人士和真正的成功人士之间的区别就是后者几乎对所有的投资机会说“不”。\n投资追求的是做正确的事而不是做更多的事。\n仓促决策，往往容易忽略一些重要的信息，从而影响决策的质量。\n保持敬畏 市场不可预测，市场是多种力量相互作用的结果。\n市场深不可测，且复杂多变。\n市场相互影响，利益盘根错节。\n承认个人的渺小，做自己能力范围内的事情。\n小结 投资是认知的实践。不追求投资的收益最大化，而追求营利的最大确定性及本金的安全。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n参考  画皮瑞幸 为什么爆的是瑞幸？  ", 
        "url": "http:\/\/myself659.github.io\/post\/invest\/invest-ruixin\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/github-hack\/": {
        
        "title": "github被攻击，程序员该怎么办",
        "tags": ["编程",],
        "content": "2020年3月27日，全世界最大的同性交友网站github被攻击了，连正常的首页都打不开。\nHttps并不是100%安全 github被攻击说明Https并不是100%安全，Https也有自己的阿喀琉斯之踵-Https证书。Https不能解决以下五种情况的攻击：\n 证书颁发机构被入侵 攻击任何证书颁发机构附近的路由器 攻击证书颁发机构的递归DNS服务器 攻击网络协议如TCP或者BGP 证书颁发机构作恶，恶意修改与替换证书  这五种攻击方式不是攻击证书就是攻击证书的分发网络路径与协议。\n即然https并不是100%安全，那么怎么应对https证书攻击呢？\n发现网站Https证书被攻击 首先第一步发现网站Https证书被攻击。拿这次github被网站Https证书被攻击为例，github证书被攻击时，在chrome浏览品上访问github，会提示如下错误：\n从上图可以看出，不是通常HTTP的错误码，也不是超时错误，而是直接提示了证书错误。\n正常的Https证书是这样的：\nHttps证书被攻击如何正常的访问github 由于github证书出现了问题，用户是无法解决的。那么怎么正常访问github呢？\n由于这类攻击往往具有地域性特点，如这次攻击大部分发生在国内，可以将本地的github访问流量通过代理导到其他没有受到攻击的地方，再由代理返回访问结果。科学上网就是属于这类方式。由于各种原因，这里不展开说明。\n如何解决go get不能正常工作 作为一名golang程序员，发现go get出现错误：\n出现上面的问题的原因同样是因为github网站的证书被攻击导致。解决方法是不走Https，走ssh下载github的代码库。在终端上进行如下配置即可：\n1  git config --global url.\u0026#34;git@github.com:\u0026#34;.insteadOf \u0026#34;https://github.com/\u0026#34;   查看配置结果如下：\n1 2 3 4 5 6  $ cat ~/.gitconfig [user] email = myself659@163.com name = myself659 [url \u0026#34;git@github.com:\u0026#34;] insteadOf = https://github.com/   小结 Https证书虽然被攻击，但是互联网有去中心化特点，可以改变网络访问路径来避免问题。 Https证书被攻击，影响是http协议，可以换成ssh协议来解决git下载的问题。 总之，遇到问题对症下药，也要跳出框架，think out the box，从另一个角度或层次来解决问题。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/github-hack\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/data-avoid-leak\/": {
        
        "title": "提高个人隐私数据安全的几点建议",
        "tags": ["Internet",],
        "content": "最近，爆出了新浪微博用户数据泄漏的事件。虽然微博的安全技术总监罗某某拒不承认存在安全问题，但是想想李文亮医生的经历，这个事情真不能忽略。 李彦宏说过：“中国人更愿意用隐私换便利”。这也验证一句话：互联网上无隐私。 虽然互联网上无秘密，但是个人不能放弃保护自己的个人隐私，该行动一下，还得行动一下。不要放弃抵抗。\n下面是个人一些建议：\n最小授权原则 个人隐私数据属于个人。\n但是现在所有互联网应用都在收集个人数据来实现商业的目标如更好地销售广告。\n以个人为例，我注册一个人新浪微博，就只用一个邮箱。大部分也做不了大 V和网红，不需要将个人其他的信息爆露给微博。\n一些应用与网站直接使用微信与qq授权，不要去注册新账号。\n手机app申请权限的时候，根据最小授权原则，满足基本应用即可，不轻易给录音，像机，访问存储的权限。\n远离不靠谱的应用与平台 如果我们将信息交给一些不靠谱的应用与平台，这些应用与平台保护用户信息能力不足，那么它被黑客攻击，内部泄漏的可能性会更大很多。\n举一个例子，疫情期间，各个省市分别推出自己的健康码App，如皖事通，宁归来等等。这些app背后开发能力从其用户体验也看得出来十分堪忧。由于无法避免需要健康码，建议直接用微信与支付宝上面的健康码功能。\n不乱点击URL。 远离无HTTPS加密的网站。\n使用chrome浏览器，帮你识别一些网站的风险。\n不要使得一些缺少安全保护或者安全保护能力弱的邮箱平台。如自建的个人邮箱。\n不要使用一些小厂商的VPN产品。\n保护密码 第一点：不要使用同一个密码，使用同一个密码，如果其中一个网站泄漏，往往其他的所有网站都受到安全的威胁。\n第二点：密码分级管理。重要应用的密码与资金密码要重点保护。\n第三点：不要使用简单的密码，如123456等常见的密码\n第四点：开启two-factor authentication\n第五点：拥有一个自己的密码生成公式或者规则\n利用工具 有条件的情况，密码管理可以1password。\n使用chrome浏览器，并安装HTTPS Everywhere，GHOSTERY，GOOGLE PASSWORD CHECKUP等等。\n安装杀毒软件和开启防火墙。\n手机 如果可以推荐使用苹果手机。Android手机各种app安装的时候要各种权限，管理难度高，用户体验差，应用的审核也没苹果应用商店的标准高。相反苹果应用商店上的app会守规矩多了。\n在一个较高安全系数的环境中，使用应用的安全系数也会提高很多。\n保护好的手机，如手机与sim卡绑定，避免sim卡转移攻击，具体参考人生中最昂贵的教训：SIM卡转移攻击的细节。\n加强学习与增加安全意识 学习一些基础的安全知识，了解一下用户数据泄漏的一些案例，增加对不靠谱应用的识别能力。学习会增加安全意识，安全意识增加可以提前发现问题，并能及时防范。\n后记 虽然互联网无秘密，但是个人加强防范，有利于提高获取个人隐私数据的门槛，避免成为第一批数据泄漏的受害者。相反，如果你比一般人更好的保护你的隐私数据，别人数据泄漏的事件相当是你的吹哨人。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/data-avoid-leak\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/howmuch-us-stock-willfall\/": {
        
        "title": "一周经历两次熔断，美股会跌多少?",
        "tags": ["Economy",],
        "content": "进入话题之前了解一下美股指数熔断机制。\n 美股指数熔断机制的基准指数为标普500，单项跌幅阈值为7%、13%、20%。当指数较前一天收盘点位下跌7%、13%时，全美证券市场交易将暂停15分钟，当指数较前一天收盘点位下跌20%时，当天交易停止。\n 再来看一下美股指数熔断的历史。\n  1997年10月27日，道琼斯工业指数暴跌7.18%，收于7161.15点，这是熔断机制在1988年引入之后第一次被触发。\n  2020年3月9日，受2019冠状病毒病疫情和油价崩盘影响，3月9日上午9点34分，标普500指数开盘后跌7%触发第一层熔断机制，暂停交易15分钟，这是美股历史上第二次熔断。\n  2020年3月12日开盘后，标普500下跌，触发7%的熔断点，这是美股历史上第三次熔断，收盘时，美股三大指数都下跌近10%。\n  人生“有幸”，大家在一周内见证两次美股的熔断。\n美股一周内熔断两次，全球的经济形势加上现在新型冠状病毒在全球已经开始流行，对于经济供应和需求是全方面的打击，这标志美股的下跌周期已经开始。\n明确了美股的下跌趋势，那就有下面两个问题：\n 美股会跌到多少？ 下跌周期会是多少？  问题的答案哪里找？以史为鉴吧。先看一下道琼斯指数的历史曲线图：\n从上图我们只能看到美股涨跌交替，总体不断增长。下面具体看一下最近两次大跌，也就是2008年的金融危机和2000年互联网泡沫。\n2008年的金融危机道琼斯指数下跌情况如下：\n从上面两图可以看到2008年的金融危机期间下跌从2007年10月开始，到2009年2月触底发弹回升，指数从17245.35下降到8609.71，下跌幅度为50%，下跌周期为16个月。\n2000年互联网泡沫道琼斯指数下跌情况如下：\n从上面两图可以看到2000年互联网泡沫期间下跌从1999年12月开始，到2002年9月触底发弹回升，指数从17671.07下降到10848.87，下跌幅度为38.6%，下跌周期为33个月。\n最后再看一下让人闻风丧胆的大萧条时期的股票市场情况。\n从上面两图可以看到大萧条期间下跌从1929年8月开始，到1932年7月触底发弹回升，指数从5686.69下降到814.82，下跌幅度为85.6%，下跌周期为36个月。下跌幅度不是腰斩而是膝斩，下跌时间长达3年，为美股历史上所有下跌之最。\n现在阶段抄底美股，话不多说，送下面这张图，自求多福：\n上面的分析是基于历史的参考，现在情况与历史任何一次美股下跌不一样，具体分析美股的走势要结合多方面的因素分析，如新型冠状病毒在全球开始流行，全球化各国相互影响，各国面临不同问题（股市泡沫、债务杠杆、金融机构风险、社会撕裂等）与应对策略（货币政策、财政政策、抗疫方式等）。\n本文最重要的话是：不要试图现在抄底美股，特别是指数，对于个股来说总体上危险大于机会。保持耐心，让子弹飞一会儿。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/howmuch-us-stock-willfall\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/weimeng-del-data\/": {
        
        "title": "微盟删库事件复盘与思考",
        "tags": ["研发管理",],
        "content": "事故 先简单看一下整个事故的粗略时间线。\n2月23日，微盟服务出现故障。商家商城、小程序均无法登录。\n2月25日，微盟紧急恢复了核心业务的线上生产环境，新用户使用不受影响，并提供老用户临时过渡方案，确保商家在数据暂时没有恢复的情况下可以正常经营。\n2月28号，微盟表示已经恢复了微站产品的所有数据，并已导入到商户店铺，新老用户使用将不受影响。\n3月1号微盟表示数据已全面找回，并公布商家赔付计划。\n影响 首先看股市反应：数据丢失，微盟损失惨重。在2月25日正式披露数据丢失后，微盟的股价连续三日大幅下跌，从6.2下跌到4.8差不多跌了25%，整个市值蒸发20亿元以上。\n除此之外，本次事故对微盟的社会公信力有很大的影响，说明整个企业在运营、管理和技术安全上是有问题的，对企业的社会形象和商业业态都会遭受大家的质疑。\n由于微盟整个系统的宕机，导致商家与消费者都不正常运营，部分可能直接停业，对整个社会的经济系统也有一些冲击与影响。\n问题 作为一名局外人，对这次微盟删库事件，个人有以下问题：\n 运维贺某是由于什么原因作出删库的事件？ 贺某删除了哪些数据？贺某删除整个生产环境的数据包括备份数据吗？ 微盟是数据架构是如何设计？让一个运维能够删除整个生产环境的数据？ 微盟的数据物理分布是如何设计的？ 微盟运维权限是如何管理？ 微盟离线备份数据是备份方式是怎么样？是增量还是快照方式？ 微盟离线备份数据为什么花了五天都不能够恢复？离线备份数据有多少？ 众多离线备份数据是如何恢复的？ 微盟离线备份数据是否完整？ 微盟离线备份数据恢复后如何验证？如何检查恢复数据与备份数据之间的一致性？ 微盟离线备份数据恢复是否相互依赖？ 微盟离线备份数据（毕竟微盟成立于2013年）是否兼容？如与应用程序兼容？ 微盟离线备份数据恢复的速度的瓶颈在哪里？网络带宽？硬盘IO? 数据不能并行恢复？验证困难？ 从备份数据到线上数据恢复，是恢复几份数据？如何保证这几个线上数据的一致性？ 如何防止误操作？ 如何量化赔偿商家的损失？ 如何快速检测运维违规操作并迅速报警？ 是否知道技术风险的存在，由于存在侥幸心理和事不关已，多一事不如少一事，放过这个潜在的风险？  经验教训 微盟经过七天七夜的抢救，成功救回了全部数据，从结果上来看是一次成功的抢救。但是数据恢复的时间太长，服务高可用直接打到99%以下。\n事后微盟发布了改进计划，这些改进计划有针对性回答我上面一些问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  措施一：数据安全管理机制全面加固与整改，加强运维平台治理 1、完善数据安全管理制度（涵盖权限、监控、审计方面），严格执行授权审批制度； 2、使用腾讯云CAM权限系统进行云资源管理，严格执行分级授权和最小集权限制度，对高危险动作执行二次授权制度； 3、建立科学、高效、安全的网络策略，对开发环境、测试环境和生产环境进行严格隔离；使用腾讯云堡垒机替换自建堡垒机，进行细粒度权限分级和授权管理，同时严格审计堡垒机操作日志，发送安全审计报表； 4、加强运维安全流程学习，职业道德学习，法律学习等。 措施二：加强灾备体系的建设，做到多云异地冷备 1、建立多云灾备体系，在北京、上海、南京等地区建立全备份的冷备系统架构； 2、借助腾讯云的IAAS的底层服务能力，建立高可用的同城双活架构； 3、云上所有的云主机，启用每天的快照策略，保证全量和增量备份； 4、所有非结构化数据，使用腾讯COS对象存储系统进行归档保存，启用COS的多异地复制功能，数据存放多地，并且COS 冷存储，确保数据只增不减； 5、建立月、季度级别的定期演练机制和制度 。 措施三：基础设施全力上云 1、借助腾讯云数据库MySQL的数据高可用和安全体系，逐步放弃自建数据库服务 ，迁移到腾讯云数据库（CDB），快速具备数据库跨可用区和异地灾备的能力； 2、黑石1.0物理机全面升级黑石2.0，全面使用云主机。   上面这些总结很到位，个人帮微盟补充一些：\n 学习netfix的企业文化中的第一条：招聘成年人。成年人不会作出对个人和公司双输的事件，成人有自己调整心态与控制情绪的能力。 学习netfix的实践，应用混顿工程，主动拥抱故障，提前演练与操作。国内阿里双11每年都要进行演练。 减少对人的依赖。在执行方面机器比人靠谱多了。  总结 总之，微盟这次删库事故是技术债与管理债长期累积不解决的结果。欠债不还，一定会在某个时间被某个黑天鹅事件引爆。\n这次显露出来的技术问题的本质是数据高可用性技术的不足。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/weimeng-del-data\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/find-what-todo\/": {
        
        "title": "在选择做什么之前，先问问自己这四个问题",
        "tags": ["成长",],
        "content": "在谈谈做事的原则提到做事的原则的基本原则。具体如下：\n 不要给自己设限 站在巨人的肩膀上 正确的方向 敏捷的行动  本文重点讨论如何选择做什么这一问题。不要给自己设限，这个主要是解决了选择范围的问题，不给自己设限，可以打破很多限制，为自己提供更多的选项。\n Quantity is a prerequisite to the selection of quality.\n 数量是高质量选择的先决条件。\n那么在不给自己设限解决了选择的数量问题，那么如何作出正确的选择呢？兵圣孙子说过：\n 知己知彼，百战不殆。\n 作出正确的选择需要在以下两个方面的认识：\n 认识自己 认识世界  在这两个方面问自己以下四个问题：\n 你喜欢什么？  你擅长什么？  世界需要什么？  别人付钱请你做什么事情？  一图胜千言。\n从上图可以明显看到我们应该做的核心事情就是这个四个问题的集合的交集，也是ikagai部分。\nikagai是一个日本词汇对应的英文翻译，对应的中文翻译是生活的目的（姑且这样吧，google告诉这么翻译）。\nikagai所指这个交集的事情从个人角度来看可以让自己发挥特长，享受乐趣，回馈社会，达成目标。从事情角度来看，这个事情得激情的投入，使命的担当，专业的能力，职业的态度，在这种情况下做成事情的概率更高，回报是自己需要，很容易形成正循环。\n以个人选择职业为例，当年毕业的时候，我告诉自己一定要做自己喜欢且擅长事情。所以毕业之后选择干的事情就是编程。到现在还在继续编程，每天学习，保持输入与输出。 虽然当年没有像ikagai这样的一个系统描述，个人也考虑到社会的需要。\n考虑现在这个发展情况与需求，在自己喜欢且擅长编程（在与同年龄的人群相比，自己这个领域能排进前top10%），选择编程这个工作对于职业发展来说是一个不错的选择。\nikagai这个方法不仅可以用于职业发展的选择，也可以用于指导生活。如何具体应用ikagai就是上面提到的问题，找出这些回答的交集。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/find-what-todo\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/golang\/donot-focus-programming-language\/": {
        
        "title": "别太在意编程语言",
        "tags": ["Golang",],
        "content": "背景 经常有人这样说：\n PHP是最好的语言 现在golang越来越吃香，好找工作 python学习的人越来越多，太难了  对于这些，我想说：别太在意编程语言。\n理由 别太在意编程语言，具体理由如下：\n 使用何种编程语言要根据业务需求来决定 选择编程语言与个人与团队偏好有关 编程语言只是工具 最重要是解决问题，满足需求 编程语言具有一定特定性，相反数据结构与算法，设计模式等基础知识与能力具有更好的通用性 多学习几种编程语言更好，何必纠结什么编程语言更好呢？  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/golang\/donot-focus-programming-language\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/stock-us-analysis\/": {
        
        "title": "通过数据分析预测股票价格变化靠谱吗？",
        "tags": ["Data",],
        "content": "前言 在投资美股，先从数据分析开始这篇文章解决两个问题：\n 从哪里找数据？ 如何得到这些数据？  在此基础这篇主要解决一个问题：以特斯拉为例说明如何利用这些数据预测股票价格的变化。同时关注一个问题：投入成本进行预测股票价格是否靠谱与必要？\n步骤 获取数据 直接调用api如下：\n1 2 3 4 5 6  import yfinance as yf tlsa_df = yf.download(\u0026#39;TSLA\u0026#39;, start=\u0026#39;2015-01-01\u0026#39;, end=\u0026#39;2020-02-16\u0026#39;, progress=False) tlsa_df.head()   绘制价格变化图 1 2 3 4 5 6 7 8 9 10 11  #plot %matplotlib notebook from IPython.core.interactiveshell import InteractiveShell InteractiveShell.ast_node_interactivity = \u0026#34;all\u0026#34; plt.figure(figsize=(10,6)) plt.grid(True) plt.xlabel(\u0026#39;Dates\u0026#39;) plt.ylabel(\u0026#39;Close Prices\u0026#39;) plt.plot(tlsa_df[\u0026#39;Close\u0026#39;]) plt.title(\u0026#39;Tesla Close Price\u0026#39;) plt.show()   得到从2015年起telsa收盘价格变化图：\n分析数据的统计特征信息 1 2 3 4 5 6 7 8 9  tsla_df_close = tlsa_df[\u0026#39;Close\u0026#39;] df_log = np.log(tsla_df_close) moving_avg = df_log.rolling(12).mean() std_dev = df_log.rolling(12).std() plt.title(\u0026#39;Moving Average\u0026#39;) plt.plot(std_dev, color =\u0026#34;black\u0026#34;, label = \u0026#34;Standard Deviation\u0026#34;) plt.plot(moving_avg, color=\u0026#34;red\u0026#34;, label = \u0026#34;Mean\u0026#34;) plt.show()   具体如下：\n处理数据 处理数据是为了满足模型的数据输入的要求。\n1 2 3 4 5 6 7 8  train_data, test_data = df_log[3:int(len(df_log)*0.9)], df_log[int(len(df_log)*0.9):] plt.figure(figsize=(10,6)) plt.grid(True) plt.xlabel(\u0026#39;Dates\u0026#39;) plt.ylabel(\u0026#39;Closing Prices\u0026#39;) plt.plot(df_log, \u0026#39;green\u0026#39;, label=\u0026#39;Train data\u0026#39;) plt.plot(test_data, \u0026#39;blue\u0026#39;, label=\u0026#39;Test data\u0026#39;) plt.legend()   这里将原始数据分为训练数据和测试数据。\n建立模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import os import numpy as np import pandas as pd import matplotlib.pyplot as plt from statsmodels.tsa.stattools import adfuller from statsmodels.tsa.seasonal import seasonal_decompose from statsmodels.tsa.arima_model import ARIMA from pmdarima.arima import auto_arima from sklearn.metrics import mean_squared_error, mean_absolute_error import math model_autoARIMA = auto_arima(train_data, start_p=0, start_q=0, test=\u0026#39;adf\u0026#39;, # use adftest to find optimal \u0026#39;d\u0026#39; max_p=3, max_q=3, # maximum p and q m=1, # frequency of series d=None, # let model determine \u0026#39;d\u0026#39; seasonal=False, # No Seasonality start_P=0, D=0, trace=True, error_action=\u0026#39;ignore\u0026#39;, suppress_warnings=True, stepwise=True) print(model_autoARIMA.summary())   得到模型参数如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  Performing stepwise search to minimize aic Fit ARIMA: (0, 1, 0)x(0, 0, 0, 0) (constant=True); AIC=-4980.147, BIC=-4970.040, Time=2.357 seconds Fit ARIMA: (1, 1, 0)x(0, 0, 0, 0) (constant=True); AIC=-4978.315, BIC=-4963.154, Time=0.297 seconds Fit ARIMA: (0, 1, 1)x(0, 0, 0, 0) (constant=True); AIC=-4978.308, BIC=-4963.147, Time=0.475 seconds Fit ARIMA: (0, 1, 0)x(0, 0, 0, 0) (constant=False); AIC=-4982.140, BIC=-4977.087, Time=0.189 seconds Fit ARIMA: (1, 1, 1)x(0, 0, 0, 0) (constant=True); AIC=-4976.958, BIC=-4956.743, Time=0.493 seconds Total fit time: 5.619 seconds SARIMAX Results ============================================================================== Dep. Variable: y No. Observations: 1158 Model: SARIMAX(0, 1, 0) Log Likelihood 2492.070 Date: Mon, 17 Feb 2020 AIC -4982.140 Time: 20:29:52 BIC -4977.087 Sample: 0 HQIC -4980.233 - 1158 Covariance Type: opg ============================================================================== coef std err z P\u0026gt;|z| [0.025 0.975] ------------------------------------------------------------------------------ sigma2 0.0008 1.84e-05 42.731 0.000 0.001 0.001 =============================================================================== Ljung-Box (Q): 43.17 Jarque-Bera (JB): 898.42 Prob(Q): 0.34 Prob(JB): 0.00 Heteroskedasticity (H): 1.84 Skew: -0.13 Prob(H) (two-sided): 0.00 Kurtosis: 7.31 ===============================================================================   对模型诊断 在进行预测之前先进行模型诊断。\n1 2 3 4 5  model_autoARIMA.plot_diagnostics(figsize=(15,8)) plt.show() model = ARIMA(train_data, order=(3, 1, 2)) fitted = model.fit(disp=-1) print(fitted.summary())   结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  ARIMA Model Results ============================================================================== Dep. Variable: D.Close No. Observations: 1157 Model: ARIMA(3, 1, 2) Log Likelihood 2494.608 Method: css-mle S.D. of innovations 0.028 Date: Mon, 17 Feb 2020 AIC -4975.215 Time: 20:30:59 BIC -4939.840 Sample: 1 HQIC -4961.866 ================================================================================= coef std err z P\u0026gt;|z| [0.025 0.975] --------------------------------------------------------------------------------- const 0.0002 0.000 1.274 0.203 -0.000 0.001 ar.L1.D.Close 0.1523 0.251 0.607 0.544 -0.339 0.644 ar.L2.D.Close 0.8380 0.235 3.562 0.000 0.377 1.299 ar.L3.D.Close -0.0097 0.032 -0.305 0.760 -0.072 0.053 ma.L1.D.Close -0.1689 0.249 -0.678 0.498 -0.657 0.320 ma.L2.D.Close -0.8311 0.249 -3.334 0.001 -1.320 -0.343 Roots ============================================================================= Real Imaginary Modulus Frequency ----------------------------------------------------------------------------- AR.1 1.0107 +0.0000j 1.0107 0.0000 AR.2 -1.1784 +0.0000j 1.1784 0.5000 AR.3 86.4971 +0.0000j 86.4971 0.0000 MA.1 1.0000 +0.0000j 1.0000 0.0000 MA.2 -1.2033 +0.0000j 1.2033 0.5000 -----------------------------------------------------------------------------   利用模型进行预测 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  fc, se, conf = fitted.forecast(129, alpha=0.05) fc_series = pd.Series(fc, index=test_data.index) lower_series = pd.Series(conf[:, 0], index=test_data.index) upper_series = pd.Series(conf[:, 1], index=test_data.index) plt.figure(figsize=(12,5), dpi=100) plt.plot(train_data, label=\u0026#39;training\u0026#39;) plt.plot(test_data, color = \u0026#39;blue\u0026#39;, label=\u0026#39;Actual Stock Price\u0026#39;) plt.plot(fc_series, color = \u0026#39;orange\u0026#39;,label=\u0026#39;Predicted Stock Price\u0026#39;) plt.fill_between(lower_series.index, lower_series, upper_series, color=\u0026#39;k\u0026#39;, alpha=.10) plt.title(\u0026#39;Tesla Stock Price Prediction\u0026#39;) plt.xlabel(\u0026#39;Time\u0026#39;) plt.ylabel(\u0026#39;Tesla Stock Price\u0026#39;) plt.legend(loc=\u0026#39;upper left\u0026#39;, fontsize=8) plt.show()   得到预测结果如下：\n分析预测结果 从上面预测结果可以看出：\n 预测结果与实际股票的上涨趋势相同，但是其中的路径还是相差很多，直接说明不适合指导具体交易，只能做为长期趋势判断的参考 这个模型还需要大量进行测试，如调整数据，调整模型参数  总结 这里是简单介绍一下利用numpy与pmdarima来预测股票变化趋势。实际上应用过程上需要充分的测试与验证，还需要大量的工作。像这上面这样的方式来预测股票价格是不靠谱的。有靠谱的模型也需要自己大量投入时间与大量的数据以及不断的验证与调整才可以的（别人靠谱的模型是不会免费分享的）。对于个人来说，投入这个成本是否值得又是另一个问题。对于大部分人来说没有必要投入这个成本通过机器学习来预测股票价格变化。这个进入门槛比较高（预测股票价格与预报天气是两回事），从中获得收益的门槛更高。\n下一篇会具体讨论一下预测股票变化的数学原理。再根据这些数学原理如何优化模型。\n说明：\n 本文只是进行一个过程展示 本文中的模型只供参考，不能用于实际的股票投资与交易。股市有风险，入市当小心。  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n参考  pmdarima 股市目前正面临冰山幻象 A Surprisingly Easy Strategy to Make Money in the Stock Market  ", 
        "url": "http:\/\/myself659.github.io\/post\/stock-us-analysis\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/math\/why-dividing-by-zero-is-undefined\/": {
        
        "title": "为什么0不能作为被除数？",
        "tags": ["math",],
        "content": "前言 学过了除法都知道这么一个道理：0不是被除数。\n到了后面编程，一直都会遵循一条原则： 0不能作为被除数，如果用0作为被除数，就会出错或者报异常。下面就是一个常见的例子。\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; 1/0 Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; ZeroDivisionError: division by zero \u0026gt;\u0026gt;\u0026gt;   把0不能作为被除数视为理所当然，却很少思考0为什么不能作被除数？\n原因 这里就简单看一下0为什么不能作被除数？\n证明很简单，主要就是反证法。\n 假设1/0 = ∞ 根据乘法与除法是互逆的，那么∞*0 = 1 这就与任何数与0相乘为0，相矛盾  总结 最后总结一下0这个数的属性：\n 任何数加减0的结果等于它本身。 任何数乘0的结果都等于0. O不能作为被除数  0存在很有意义，简单举几个例子：\n 0定义了一种基础，有了0存在，1的意义就很容易理解 0是正数与负数的分界点 0对应到应用可以是海平面，地面\u0026hellip;  总之，0是虚也是实的，0是抽象的也是实际的。\n", 
        "url": "http:\/\/myself659.github.io\/post\/math\/why-dividing-by-zero-is-undefined\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/stock-us-data\/": {
        
        "title": "投资美股，先从数据分析开始",
        "tags": ["Data",],
        "content": "背景 川大爷，常在twitter上吆喝美股多次创造历史高点。美股确实是一个资产配置的重要选项。\n在进入市场之前，研究先行，作好功课。\n获取数据 对于一个公司的股票的研究与分析有多个方面。这里只看股票的数据情况。 既然是分析数据，那么如何获取获取呢？\n这个问题可以拆为以下问题：\n 从哪里找数据？ 如何得到这些数据？  先从第一个问题开始：从哪里找数据？美股的数据来源来很多，这里我直接选择了yahoo财经数据。 主要原因如下：\n yahoo财经数据详细 yahoo财经可以直接通过api获取，使用方便 最重要地一点，yahoo财经的api没有被墙，如果被墙了，也支持代理 yahoo财经数据实时性也不错，除了交易日当天的数据无法获取，其他的都可以获取  下面我们就看如何调用api获取数据。不多说了，直接上代码。\n1 2 3 4 5 6 7 8 9  import pandas as pd import yfinance as yf tsla_df = yf.download(\u0026#39;TSLA\u0026#39;, start=\u0026#39;2020-01-01\u0026#39;, end=\u0026#39;2020-02-06\u0026#39;, progress=False) tsla_df.tail()   具体结果如下：\n获取ticker数据：\n1 2 3 4 5 6  %matplotlib notebook ticker = yf.Ticker(\u0026#39;TSLA\u0026#39;) tsla_df = ticker.history(period=\u0026#34;max\u0026#34;) tsla_df.head() tsla_df[\u0026#39;Close\u0026#39;].plot(title=\u0026#34;Telsa\u0026#39;s stock price\u0026#34;)   具体结果如下：\n这些数据都可以股票软件都可以看到。 对的，下面说一下通过api获取原始数据的好处。\n灵活地获取ticker数据：\n1 2 3  %matplotlib notebook tsla_df = yf.download(\u0026#34;TSLA\u0026#34;, start=\u0026#34;2020-02-01\u0026#34;, end=\u0026#34;2020-02-06\u0026#34;, interval = \u0026#34;15m\u0026#34;) tsla_df[\u0026#39;Close\u0026#39;].plot(title=\u0026#34;TSLA FROM 2020-02-01 TO 2020-02-06 \u0026#34;)   具体结果如下： 股票对比分析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  from plotly.offline import download_plotlyjs, init_notebook_mode, iplot import numpy as np import cufflinks as cf data_tam = yf.download( # or pdr.get_data_yahoo(... # tickers list or string as well tickers = \u0026#34;TSLA AAPL MSFT\u0026#34;, # use \u0026#34;period\u0026#34; instead of start/end # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max # (optional, default is \u0026#39;1mo\u0026#39;) period = \u0026#34;5y\u0026#34;, # fetch data by interval (including intraday if period \u0026lt; 60 days) # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo # (optional, default is \u0026#39;1d\u0026#39;) interval = \u0026#34;1wk\u0026#34;, # group by ticker (to access via data[\u0026#39;SPY\u0026#39;]) # (optional, default is \u0026#39;column\u0026#39;) group_by = \u0026#39;ticker\u0026#39;, # adjust all OHLC automatically # (optional, default is False) auto_adjust = True, # download pre/post regular market hours data # (optional, default is False) prepost = True, # use threads for mass downloading? (True/False/Integer) # (optional, default is True) threads = True, # proxy URL scheme use use when downloading? # (optional, default is None) proxy = None ) data_tam_close = data_tam.iloc[:, [3, 8, 13]] data_tam_close = data_tam_close.dropna() iplot(data_tam_close.iplot(asFigure=True, kind=\u0026#39;line\u0026#39;, title=\u0026#39;TSLA VS MS VS APPLE\u0026#39;, dimensions=(800,500)))   具体结果如下：\n一眼可以看出在2020年前任何一个时间点买入telsa并持有是一个正确的选择，投资收益远超过了苹果与微软。\n后记 本文主要解决了如何获取美股交易数据的问题，对于这些数据的分析及预测后面再展开。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/stock-us-data\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/kobe\/": {
        
        "title": "说说我眼中的科比",
        "tags": ["闲谈乱扯","NBA",],
        "content": "在高中的时候知道了NBA,看了比赛，知道了科比。多少年以来，篮球是我最喜欢的体育运动，科比是我最喜欢的NBA球星，估计也是我最喜欢的运动员。看NBA比赛是我日常的娱乐方式。\n但是他却以让人无法想像的方式离开了这个世界，同时带上了可爱的二女儿Gigi。想不到他这么早离开了这个世界。愿他们在天堂安好。\n下面说说我眼中的科比。\n科比是乔丹之后成就最高，影响力最大，球技最好的篮球运动员 科比在篮球领域的成就太多，简单列出部分如下：\n NBA总冠军：5次（2000，2001，2002，2009，2010） NBA总决赛MVP：2次（2009，2010） NBA全明星赛MVP：4次（2002，2007，2009，2011） NBA西部冠军：7次（2000—2002，2004，2008—2010） NBA最佳阵容第一阵容：11次（2002—2004，2006—2013） NBA最佳防守阵容第一阵容：9次（2000—2004，2006—2011） 生涯总得分：33643分，NBA得分榜第四 历史上连续入选NBA全明星赛次数最多：17次 NBA历史上单场第二高得分：81分 \u0026hellip; 太多了，这里不列了  号称在60E亿粉丝，各种代言广告，科比相比较于邓肯有更大的影响力。同时科比也有更多的争议的话题。在美国《Sporting News》评选NBA现役50大球星当中科比名列第一。\n科比拥有篮球史上最纯粹完美的技术，他是篮球史上最强的高难度投篮手，他经常不按合理的方式打球，他的投篮美如画，飘逸优雅，同时充满了一个超级杀手的气质。看他打球是一种享受，感受篮球的艺术与美。科比的NBA集锦是我最爱看的集锦。\n科比是一位优秀的父亲 科比当得了奶爸。\n科比耐心培养的女儿。\n科比营造了幸福的家庭。\n科比是成功跨界人士 从2016年4月退役之后，科比在投资，媒体，写作等领域取得优秀成就，是很多在这个领域的专业人士都很难企及的成就。\n先看投资领域。早在2013年，科比就创办了Kobe Inc，随后600万美元投资了运动饮料BodyArmor。BodyArmor是小众品牌，科比入驻一年后，该公司年销售额就从300万美元升至3000万美元，并在2017年达到2.35亿美元，2019年预计销售额将达到7亿美元。BodyArmor的市场占有率排在佳得乐与水动乐之后，位列全美第三位，份额是2%。除此之外，科比在美国纽交所（NYSE）宣布成立风险投资基金“Bryant Stibel”，资本金1亿美元，并宣布战略投资中国在线少儿英语教育品牌VIPKID。之后“Bryant Stibel”不断快速增长，截止去年9月份，Bryant Stibel资本+AUM（资产管理规模）已经超过了20亿美元。\n再看媒体领域，科比是一位优秀的制作人。2017年3月，科比自导自演的动画短片《Musecage》发布。2017年4月，科比参与制作并配音的动画电影《亲爱的篮球》首映，这部影片的创作灵感来自于科比在2015年发表的那封退役信，那篇文章的名字就叫做《亲爱的篮球》。这部影片取得巨大成功，获得奥斯卡金像奖最佳动画短片奖。除此之外科比的制作《Detail》节目，也是大获成功，只要被分析的球星，下一场球一定会被针对，场上表现大打折扣。\n最后看写作领域，科比先于2018年出版个人自传：《曼巴精神：我是怎么打球的》， 接着在2019年出版一本体育梦幻小说：《威兹纳德 训练营》，该书曾进入纽约时报畅销书排行榜榜首。除此之外，巴西著名畅销作家、《牧羊少年奇幻之旅》的作者保罗-科埃略原本正与科比合作一本新书，可惜由于科比的不幸离世，这本书胎死腹中。这些成就让人不禁想到：获得奥斯卡之后，科比又要冲击诺贝尔文学奖了吗？\n科比是曼巴精神最佳实践 科比自己是这样解释曼巴精神：\n 一开始，“曼巴精神”只是我在推特上发起的一个标签，它激励人心，饱含智慧，令人过目难忘。但随后它从那里流行开来，开始有了更多象征意义。“曼巴精神”是一种思维模式，它不在于寻求结果，而在于如何做才能取得结果，在于从现实到目标的这个过程。它是一段旅程，一种方法，一种生活方式。我真心认为，在所有努力之中，拥有这种心态尤其重要。\n 最偏执：专注篮球，为了进入赛后赛，在34岁那年拼到跟腱断裂；科比说过：“为了胜利我做什么都可以，无论是给队友递毛巾递水，还是上场执行最后一投。”\n最坚韧： 三个手指受伤还坚持打完了一个赛季并夺得了总冠军\n最倔强：科比说过：“ 我的字典里没有妥协。“\n最好强：新秀赛季敢于单挑巅峰期的乔丹；敢直接跟篮球史上最有统治力的球员大鲨鱼抢出手权\n最勤奋：每天投进2000个跳投，还有大家都耳熟能详的段子：凌晨四点的洛杉矶，对了，那不是段子，那是科比无数个清晨所看到的\n后记 2016年4月13日，15-16NBA常规赛，对阵爵士是科比职业生涯最后一场比赛。他在比赛中得到了60分，成为得到60分年龄最大的球员。科比以这种伟大创举告别了NBA。Mamba out！留给世界是震撼与不舍，多希望他还能征战NBA。\n美国时间2020年1月26号，中国春节初三，科比却以意想不到方式离开了这个世界。Mamba farewell！ 留给世界是悲伤，是难以相信，是永远的记忆。多希望他还能活跃在多个领域，希望他能够出一期有关英格拉姆的《detail》节目，希望他能指导Gigi成为一名女曼巴，希望他能生一个儿子。。。\n科比度过他短暂的一生，他的一生是奋斗不息、不断挑战、实现梦想的一生。感谢科比给这个世界带来的精彩，在生活与工作中用行动来纪念科比（欧文就是一个好参考，狂砍54分，用属于他自己的方式纪念科比）。\n一千读者心中有一千个哈姆雷特，欢迎大家说一说自己心中的科比\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)，您的关注是我更新的动力\n", 
        "url": "http:\/\/myself659.github.io\/post\/kobe\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/why-btc-is-dominated\/": {
        
        "title": "2020年比特币的龙头地位还会继续加强吗？",
        "tags": ["BlockChain","BTC",],
        "content": "背景 比特币是世界诞生的第一个加密货币，从2009年上线以来市值一直都是NO.1.\n表现 下面具体一下比特币的龙头表现：\n从上面两图可以看出来，从2018年1月份开始比特币的龙头地位从最低点逐渐提高。比特币在这两年的时间从最低点33%左右上升到66%左右。从市值占有比角度来看，比特币是这两年中最大的赢家，没有之一。\n下面再看一下2018年到2020之间加密货币总市值的变化情况：\n从图可知，2018年1月整个加密货币市场处于最高点，总市值最高达到815159246848美元，简单记为8151亿美元。\n到了2020年1月整个加密货币市场的总市值为241570437715美元，简单记为2415亿美元。\n在整个市场腰斩，不对是膝斩的过程，比特币在整个市场的比重逐渐提升。在整个过程比特币相比于经济危机的情况下避险贷币。\n原因 为什么在整个过程比特币比重越来越高呢？\n个人认为有以下几个原因：\n 比特币具有先发优势 在持有分布方面，比特币的持有分布有很好去中心化性 宣传上，一定程度上比特币等同了区块链，大大提高了比特币宣传 比特币一直在进步与发展，BIP不断有新提案出来并且能够得到落实 比特币有最完整的生态  未来 关于未来比特币的龙头地位是否会进一步加强呢？个人认为龙头地位不会再进一步扩大。主要原因如下：\n 最近两年比特币比重提升来自于山寨币的比重，而经过这两年的淘汰山寨币空间几乎消失殆净 比特币比重还有一部分来自于以太坊，以太坊2.0进展有利于以太坊的比重提高 其他领域的加密货币的发展，如跨链的大量应用会增加跨链部分的比重 闪电网络的发展与应用加上现在比特币强大的生态有利于比特币守住龙头地位  最后，个人认为2020年比特币挖矿收益的减半，并不会导致比特币的大爆发。\n", 
        "url": "http:\/\/myself659.github.io\/post\/why-btc-is-dominated\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/invest\/invest-%E9%9D%9E%E5%AF%B9%E7%A7%B0%E6%80%A7\/": {
        
        "title": "说说非对称性",
        "tags": ["Invest",],
        "content": "背景 发现世界的规律，利用其中的非对称性，可以获利事半功倍的交易。\n非对称性在哪里？ 非对称性在世界上普及存在。 下面举几个例子：\n 非对称加密算法 信息不对称 能力不对称 时间不对称 速度不对称 认知不对称 理论与实践不对称 方向非对称性 风险不对称 责任不对称 机会不对称 概率不对称  利用非对称性指导原则 利用非对性性指导原则如下：\n 二八法则 扩展维度，降维打击 系统思维 优势策略，避免非对称劣势 Less is more 顺势而为 具体问题具体分析 合理使用杠杆策略  ", 
        "url": "http:\/\/myself659.github.io\/post\/invest\/invest-%E9%9D%9E%E5%AF%B9%E7%A7%B0%E6%80%A7\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/wechat-payment-read\/": {
        
        "title": "说说微信付费阅读",
        "tags": ["商业","Internet",],
        "content": "背景 2020年1月15号微信灰度发布公众帐号付费阅读功能。微信10亿用户的体量，最长的用户时长，所以一个付费阅读功能差不多引起全网的讨论。\n时机 为什么微信会在这个时候推出公众帐号付费阅读功能？\n在得到，喜马拉雅，极客时间，知识星球，小红圈，微博等一系列知识付费产品这几个的培训下，国内知识付费快速成长，付费内容增多，用户付费意识增强。同时微信订阅号打开率与阅读量遇到增长问题。\n目的 个人认为推出公众帐号付费阅读功能有以下目的：\n 抢占知识付费的市场 增加订阅号的服务类型，为用户提供一种新的新服务，为创作者提供一个新变现的选项 促进一些创作者的热情，进而创作出更加优秀的作品，为用户提供高质量的作品 多年订阅号的发展，一定量的用户付费的需求已经出现，推出公众帐号付费阅读功能，满足用户的需要  产品体验  ios用户付费由于苹果的原因，支付体验不流畅，不能直接走微信支付（注：苹果要发展自家apple pay） 付费阅读文章有明显的标示 可以灵活设置付费可见的内容比例 付费后有两条通知：支付凭证通知购买成功通知 没有广告 付费才能留言 如果不付费情况，影响阅读体验，伤害用户的情感  适用场景 并不是所有订阅号都适合开通付费阅读功能，Caoz看好付费阅读功能在以下领域的应用：\n 原创小说 原创动漫 金融财经/智库报告 其他平台导流到微信的付费阅读  除了黑产与灰产外，个人还看好在一些重要问题的付费解答方面的应用。\n对比 有太多的付费产品，这里简单说一下微信公众帐号与其他的不同点：\n 其他都是知识付费产品，而在微信付费阅读是一个功能或者说是feature 微信针对一篇文章的交易，其他是圈子付费或者平台会员付费 微信付费更加精准，就是具体一篇文章或者一个问题  那么多其他付费平台有哪些影响？\n 如果微信付费将一些创作者吸引到微信公众帐号，那么其他付费平台会受到不小的冲击，如今天的中国没有哪一个互联网产品的用户不与微信重叠，这些创作者也会带着他的用户无成本迁移到微信 由于微信是文章类别，暂时对语言与视频类知识付费没有多少影响 平台之间相互抢创作者会再度出现 微信中心化付费阅读与基于区块链去中心的内容平台由于商业模型不一致，所以对去中心的内容平台影响不大  机会 这里的机会当然是指创作者的机会。面对的主要领域主要就是提到的五个领域。\n 一种新变现的方式，可以看作一个新的知识价值交易的平台 一个展示自我实力与价值的平台 个人成长的平台，如果选定一个领域，不断深耕，个人能力回报肯定不错，如果有志如此，请先开始拥有一个公众帐号 经济回报这些机会属于大部分属于一些头部真硬核作者（马太效应），虽然我希望是长尾效应，但是实际估计还是二八定律 微信用户更多，用户时长更久，机会相比较于其他付费平台机会更大  作用 对于内容输出者来说，主要作用如下：\n 一个新的变现方式，一个10亿用户平台上的变现 防止洗稿，内容禁止复制 防止杠精，付费才能评论 经济上的激励促进进步，输出更好的内容  结语 对于个人来说，就是开一个公众帐号，专注一个领域，努力学习，持续精进，真诚分享，输出价值，不要随便开启付费阅读，一切随缘。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/wechat-payment-read\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-2020\/": {
        
        "title": "Gartner预测2020年区块链的发展",
        "tags": ["BlockChain",],
        "content": "Gartner 首先介绍一下Gartner。 Gartner全球最具权威的IT研究与顾问咨询公司。同时也是魔力四象限与技术成熟度曲线提出者。所以Gartner报告值得一看，权威性比一般技术报告及预测强很多。\n十大技术趋势 Gartner对2020技术发展作了预测，列出十大技术趋势，具体如下：\n Hyperautomation超级自动化 Multiexperience多元体验 Democratization民主化 Human Augmentation人类增强 Transparency and Traceability透明与可追溯性 The Empowered Edge边缘计算 Distributed Cloud分布式云 Autonomous Things自主设备 Practical Blockchain实用区块链 AI Security人工智能安全  从上可知区块链也在榜上。下面具体看一下区块链部分的分析。\nGartner预计区块链可扩展性将在2023年取得突破 区块链技术应用现在面临的主要体现以下两个方面：\n 可扩展性 互操作性  可扩展性方面主流公链如比特币每秒支持七笔交易，以太坊每秒支持15笔交易；同时交易成本高。 互操作性方面私钥管理基本上原地踏步，助记词这种形式提高了用户的门槛的要求，同时丢失助记词是常有发生。\n报告中并没有说明哪种技术方案会取得突破。个人以为主要看点有两个：\n 分片 layer2  重点期待以太坊, Harmony,Near, plokadot等公链。\n区块链应用场景 区块链是一个充满想像力的技术，但是现在主要落地应用在于数字货币领域。在其他的领域区块链落地比较少。Gartner在报告中列出区块链在企业应用领域有哪些呢？具体如下：\n1.资产跟踪。\n2.索赔。\n3.身份管理/KYC。\n4.内部记录保存。\n5.积分和奖励。\n6.支付/结算。\n7.溯源。\n8.共享记录保存。\n9.智能城市/物联网。\n10.贸易融资。\n11.交易。\n此外Garnter还看好以下三个应用（不同于上面的企业应用领域）：\n 基于区块链的投票 基于区块链的自我主权的数字身份 数字加密货币的支付和转帐  建议 Gartner对于企业场景下应用区块链技术的建议：\n 深入理解商业应用领域的问题和潜在的机会 深入理解区块链的功能和局限性 重新评估企业和行业信任架构 将技术作为核心业务战略的一部分 提高客户应用区块链运营架构的意愿和能力  参考  top-10-strategic-technology-trends-for-2020  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-2020\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/programer-book-list\/": {
        
        "title": "程序员进阶精读书籍清单",
        "tags": ["编程",],
        "content": "2020年加大搬砖的力度，还是一名程序员，继续成长与进步。\n优秀程序员应该具备以下三方面能力：\n  扎实的计算机基础知识（计算机结构，操作系统，数据结构与算法 ）\n  良好的软件工程素质\n  一定的系统设计与架构能力\n  多年的程序员经历与读书经历告诉我：\n  读书不在多，贵在精。\n  精典书籍需要多读几遍，常读常新，每一次重读都会有新的收获\n  下面推荐软件工程师应该精读的十本书。\n1 编码：隐匿在计算机软硬件背后的语言 本书作者Charles Petzold创造性地以编码为主题，从电报机和手电筒讲到数字电路，然后利用数字电路中的逻辑门构造出加法器和触发器，最后构造出一个完整的存储程序计算机 。作者在书中使用大量形象贴切的类比简化了这些概念，使其成为通俗易懂的计算机入门读物。\n2 深入理解计算机系统 作为一名非科班出身的程序员，深入理解计算机系统是对我帮助最大。这本书里面将操作系统，计算机硬件与结构，编译原理这些计算机学科的基础内容结合在一起。具体内容涵盖：指令集体系架构，汇编语言，代码优化，计算机存储体系架构，链接，装载，进程，系统调用，虚拟内存，网络编程，并发编程等程序员在日常工作中所需要的必备知识。\n如果想打下扎实的计算机基础又不想把操作系统计算机结构编译原理这些书统统读一遍，阅读深入理解计算机系统是最有效率的方式。\n3 计算机编程艺术 本书的作者高德纳是算法和程序设计技术的先驱者，同时也是计算机排版系统TEX和METAFONT的发明者，除此之外还是1971年图灵奖获得者。这个系列图收可以说是包含一切基础算法的宝典。比尔·盖茨曾表示：如果你自以为是一个很好的程序员，请去读读高德纳的《计算机程序设计艺术》吧\u0026hellip;要是你真把它读下来了，就毫无疑问可以给我递简历了。精读这个系列的图书毫无疑问是真正地站在巨人的肩膀上。\n4 算法导论 AI时代，也就是算法时代。可以说算法水平决定一个程序员技术的上限。学习基础算法与应用算法解决具体的工作问题，本书不容错过。\n5 程序员面试金典 面试驱动学习。\n《程序员面试金典》是程序员面试跳槽找工作必备书。\n6 程序员修炼之道：从小工到专家 对于软件工程来说算法，数据结构，编程语言只是软件工程的工具与思想，在具体软件工程中每一个软件工程师都要考虑如何提高工作的产出。这本《程序员修炼之道：从小工到专家》通过具体有效的经验与技巧让你成长为一名高效的程序员。书中内容涉及如何避免代码腐烂，如何编写灵活、高可用的正确代码，如何真正的理解需求等一系列具体问题。\n7 人月神话 软件的开发与维护离不开软件工程。《人月神话》是软件工程领域集大成者。《人月神话》的作者Fred Brooks领导并完成 System/360 和 OS/360 这两个即是放到现在也是巨型软件项目的里程碑项目的经验总结。这本书覆盖了软件项目各个方面的关键概念：从工期管理到团队建设，从程序设计到架构设计，从原型设计到团队交流。\n8 算法之美 《算法之美》这本书扩展算法的应用范围，将算法应用到具体生活当中。本书通过讨论人类事务算法设计的概念，以帮助人们更好地处理日常生活中遇到的难题。内容涉及贝叶斯法则、最优停止理论、时间调度理论、博弈论等。\n9 设计数据密集型应用 从IT时代进入DT时代，数据成为重要的生产要素。《设计数据密集型应用》以数据为核心，描述大规模分布式数据系统的理论与实践。\n10 计算机程序的构造和解释 在《计算机程序的构造与解释》书中深入探讨了程序设计的本质（过程抽象、数据抽象、元语言抽象）。这些本质思想在未来量子计算机时代仍然不会过时。书中构建了很多小系统。比如第一章的计算素数、最大公因数、平方根、积分、黄金比例等，讨论了递归、迭代过程；第二章的图形语言、赫夫曼编码解码、泛型运算、多项式计算等，讨论了数据结构和数据类型系统；第三章实现了一个面向对象系统等；第四章实现Scheme的解释器；第五章通过设计机制和语言实现寄存器机器的各种计算。\n结语 再说一遍：读书在精，不在多。上面推荐的这些书，你可能多多少少见过，但是能静下心来读完一本的人可能寥寥无几。本人静下心来读也只有两本书《深入理解计算机系统》与《设计数据密集型应用》，但是《深入理解计算机系统》这本偏硬件那几章几乎没有读。当然上面大部分书都有通读。\n一年精读一本，保证吸收与转化，每年都是一个台阶的大进步。只可惜自己当年没有做到，也没有这种强烈的意愿。\n", 
        "url": "http:\/\/myself659.github.io\/post\/programer-book-list\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/tech-giant-income\/": {
        
        "title": "苹果微软亚马逊谷歌Facebook五大科技巨头是如何赚钱的",
        "tags": ["Internet",],
        "content": "苹果微软亚马逊谷歌Facebook这五大科技巨头在2018年的收入总和超过了8000亿美元。 如果这五大科技巨头保证30%的增长率，这五大科技巨头在2019年的收入总和会超过10000亿美元。\n下面具体看看每个公司的收入结构：\n苹果 从上图可知：\n总收入： 2656亿美元，排名第一\n净利润： 595亿美元，排名第一\n业务收入结构：\n iPhone占比为62.8％ Mac电脑占比为9.6％ iPad占比为7.1％ 其他Apple产品和服务（包括Apple Watch，Apple TV，Beats设备，Apple Pay和AppleCare）占比为20.6％  区域收入结构：\n 美洲区占比为42% 欧洲区占比为24% 大中华区占比为20% 日本占比为7% 亚太区（不包括中国与日本）占比为7%  思考 居然没有非洲的统计，非洲也太惨。苹果未来增长区域会是非洲吗？ 手机取代电脑，成为第一终端。\n亚马逊 从上图可知：\n总收入： 2329亿美元，排名第二\n净利润： 101亿美元，排名第五\n业务收入结构：\n 在线零售占比为52.8% 第三卖家服务占比为18.4% AWS占比为11.0% 线下实体零售占比为7.4% Amazon Prime占比为6.1% 其他收入占比为4.3%  区域收入结构：\n 美国占比为69% 英国占比为6% 德国占比为9% 日本占比为6% 其他国家和地区占比为11%  amazon线下实体2018年增长率为197%，利益于amazon go快速增长\nAlphabet 说明一下，Alphabet是Google的母公司。\n从上图可知：\n总收入： 1368亿美元，排名第三\n净利润： 307亿美元，排名第二\n业务收入结构：\n 广告(来自Google搜索, YouTube, GooglePlay, gmail, Google Map等)占比为70.4% 广告(来自Google Ads)占比为14.6% 其他收入(包括Google Cloud，Google Mussic等)占比为14.5%  区域收入结构：\n 美国占比为46% 美洲区（除美国外）占比为6% EMEA(欧洲、中东和非洲)占比为33% APAC（亚大地区）占比为15%  微软 从上图可知：\n总收入： 1104亿美元，排名第四\n净利润： 166亿美元，排名第四\n业务收入结构：\n office产品占比为25.7％ Azure产品占比为23.7％ Windows占比为17.7％ 游戏占比为9.4％ Bing广告占比为6.4％ 企业服务占比为5.3％ 设备（如Surface PC）收入占比为4.7％ LinkedIn占比为4.8％  区域收入结构：\n 美国占比为51% 世界其他地区占比为49%  FaceBook 从上图可知：\n总收入： 558亿美元，排名第五\n净利润： 221亿美元，排名第三\n业务收入结构：\n 广告收入占比为98.5% 支付和其他收入占比为1.5%  区域收入结构：\n 美国占比为43% 加拿大占比为3% 欧洲占比为24% 亚太占比为21% 其他国家和地区占比9%  每个用户为FaceBook贡献收入35美元\n小结  苹果收入与利润最高，亚马逊利润最低 微软收入最多元化，FaceBook收入最单一 FaceBook利润率最高，亚马逊利润率最低 每个企业都有自己的核心业务：亚马逊的在线零售，苹果的手机业务，Google搜索广告，FaceBook社交广告，微软的offcie与windows业务。 存在相互竞争，最明显与最激烈属于云服务竞争：AWS, AZURE, GCP三者相互竞争 Amzon主要收入来源是美国，占比接近70% 收入结构主要来自经济发达地区，非洲属于一片经济的沙漠，多写一句话：不知道中非的友谊能否在这片经济的沙漠之上开出发展的花朵呢？  2022 update 对比一下三年前收入结构最大的变化：除Apple，另外三家就是云业务收入增长迅速，占比扩大。\n参考  ADVERTISING How the Tech Giants Make Their Billions Google Products How Apple, Amazon, Alphabet, and Microsoft Became $1 Trillion Companies  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/tech-giant-income\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/network\/about-doh\/": {
        
        "title": "DoH FAQ",
        "tags": ["Secure",],
        "content": "什么是DoH DoH是DNS over HTTPS。\n传统DNS相当于DNS over UDP。\nDoH带来哪些好处？ 采用DoH对用户来说有如下好处：\n DoH协议不允许其他用户，服务提供商或第三方查看您访问的网站并收集数据，保护了用户的隐私 DoH协议有利于防止欺骗与钓鱼攻击，保护在线数据的安全和隐私 加速DNS解析，提高网页访问速度 对于天朝人民，还有另一个好处就是科学上网  DoH现在可以使用吗？ 1  We\u0026#39;ve enabled an experiment in Chrome 79 for a fraction of our users.   Chrome 79版本对部分用户开启。\nfirefox 70版本已经支持DoH。\n如何使用DoH? 以firefox为例：\n在地址输入：about:preferences#general，找到Network Settings选项，点击Settings即可进入设置，具体如下：\n参考  DNS over HTTPS Google Public DNS over HTTPS (DoH) supports RFC 8484 standard Moving to an era of Decentralized DNS registry Running a DNS over HTTPS Client  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/network\/about-doh\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/substrate-cloud-node\/": {
        
        "title": "搭建Substrate开发云节点",
        "tags": ["Substrate","BlockChain",],
        "content": "为什么要云节点 主要由以下几个原因：\n 国内GFW太狠，github都不能幸免，代码都不能下载，影响正常的开发 rust这个编译太占用cpu，内存，硬盘 rust编译的时候cpu一直在叫，影响个人心情，进而影响开发效率 云节点方便共享 花小钱买时间是一件很划算的事情  搭建步骤 准备节点 具体参考这篇文章Installing Substrate，各种类型的操作系统都有说明。\n运行节点 设置代理 这里我采用是caddy作为代理\n具体配置参考如下：\n1 2 3 4 5  yourwssaddr { proxy / http://0.0.0.0:9944 { websocket } }   启动节点 1  ./target/release/substrate --dev --ws-port 9944   浏览器 具体参考apps里面说明即可。\n运行如下命令即可：\n1 2 3 4  git clone https://github.com/polkadot-js/apps cd apps yarn yarn run start   在caddy中配置浏览器的代理：\n1 2 3 4 5 6 7  example.com { proxy / localhost:3000 { transparent } gzip }   最终具体效果如下：\n这样你就拥有一个属于自己的区块链。具体代码参考hello-node\n参考  Build Substrate on Ubuntu: step-by-step guide  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/substrate-cloud-node\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rust\/rust-vec\/": {
        
        "title": "Rust Vec 101",
        "tags": ["Rust",],
        "content": "create 不指定数据类型 1 2  let mut v1 = Vec::new(); let mut v2 = vec![];   指定数据类型 1 2 3  let mut v1:Vec\u0026lt;i32\u0026gt; = Vec::new(); let mut v2:Vec\u0026lt;i32\u0026gt; = vec![]; let mut v3 = vec![1i32, 2,3];   创建并初始化 1 2 3 4 5  let mut v1 = vec![1,2,3]; let mut v2:Vec\u0026lt;i32\u0026gt; = vec![1,2,3]; let mut v3 = vec![1i32,2,3]; let mut v4 = vec![1; 10]; let mut v5: Vec\u0026lt;i32\u0026gt; = (0..10).collect();   访问元素 读 1 2 3 4  let mut v1 = vec![1,2,3]; let item = v1[0]; println!(\u0026#34;{:?},{:?}\u0026#34;, v1.get(0),v1.get(100)); //Some(1),None   slice 1 2 3  let v1 = vec![1,2,3,4,5]; let v2 = v1[1..]; let v2 = v1[1..3];   写 1 2  let mut v1 = vec![1,2,3]; v1[0] = 11;   insert 1 2 3 4 5 6  fn main() { let mut v1 = vec![1,2,3]; v1.insert(2,1); println!(\u0026#34;v1:{:?}\u0026#34;,v1); } // v1:[1, 2, 1, 3]   remove 1 2 3 4  let mut v1 = vec![1,2,3]; v1.remove(0); println!(\u0026#34;v1:{:?}\u0026#34;,v1); // v1:[2, 3]   append 1 2 3 4 5 6 7  fn main() { let mut v1 = vec![1,2,3]; let mut v2 = vec![4,5,6]; v1.append(\u0026amp;mut v2); println!(\u0026#34;v1:{:?}\u0026#34;,v1); } // v1:[1, 2, 3, 4, 5, 6]   extend 1 2 3 4 5 6  let mut vec1 = vec![1, 2, 3]; let vec2 = vec![4, 5, 6]; vec1.extend(vec2); assert_eq!(vec1, [1, 2, 3, 4, 5, 6]);   1 2 3 4 5 6 7  let vec1 = vec![1, 2, 3]; let vec2 = vec![4, 5, 6]; let mut vec3 = vec1; vec3.extend(vec2.into_iter()); assert_eq!(vec3, [1, 2, 3, 4, 5, 6]);   sort 1 2 3 4 5 6 7 8 9 10 11 12  fn main() { let mut v1 = vec![1,2,3, 3,2,1]; v1.sort(); println!(\u0026#34;v1:{:?}\u0026#34;,v1); let result = v1.binary_search(\u0026amp;2); println!(\u0026#34;result:{:?}\u0026#34;,result); } // v1:[1, 1, 2, 2, 3, 3] // result:Ok(3)   resize 1 2 3 4 5 6 7 8 9  fn main() { let mut v1 = vec![1,2,3, 3,2,1]; v1.resize(10, 0); println!(\u0026#34;v1:{:?}\u0026#34;,v1); v1.resize(2, 0); println!(\u0026#34;v1:{:?}\u0026#34;,v1); } // v1:[1, 2, 3, 3, 2, 1, 0, 0, 0, 0] // v1:[1, 2]   push and pop 1 2 3 4  let mut v1 = vec![1,2,3]; v1.push(4); v1.push(5); let item = v1.pop();   iterator 1 2 3 4 5 6 7 8 9 10 11 12 13  let mut v = vec![1,2,3]; for item in \u0026amp;v { } for item in \u0026amp;mut v { } for item in v { }   1 2 3 4 5 6 7 8 9 10 11 12 13  let mut v = vec![1,2,3]; for (i, x) in v.iter().enumerate() { println!(\u0026#34;In position {} we have value {}\u0026#34;, i, x); } for x in v.iter() { println!(\u0026#34;item:{}\u0026#34;,x); } for x in v.iter_mut() { *x *= 3; } println!(\u0026#34;Updated vector: {:?}\u0026#34;, xs);   1 2 3  let items = vec![1, 2, 3]; let sitems = items.into_iter().map(|x| x.to_string()).collect::\u0026lt;Vec\u0026lt;_\u0026gt;\u0026gt;(); println!(\u0026#34;sitem: {:?}\u0026#34;,sitems);   属性 capacity 1 2  let mut v1 = vec![1,2,3]; println!(\u0026#34;capacity={}\u0026#34;,v1.capacity());   len 1 2  let mut v1 = vec![1,2,3]; println!(\u0026#34;len={}\u0026#34;,v1.len());   is_empty 1 2  let mut v1 = vec![1,2,3]; println!(\u0026#34;is_empty={}\u0026#34;,v1.is_empty());   contains 1 2 3 4 5 6 7 8 9  fn main() { let mut v1 = vec![1,2,3]; println!(\u0026#34;{} is in v1:{:?}\u0026#34;,1, v1.contains(\u0026amp;1)); println!(\u0026#34;{} is in v1:{:?}\u0026#34;,11, v1.contains(\u0026amp;11)); } // 1 is in v1:true // 11 is in v1:false   ", 
        "url": "http:\/\/myself659.github.io\/post\/rust\/rust-vec\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/golang\/golang-sync-pool-2\/": {
        
        "title": "深入分析Golang sync.pool优化",
        "tags": ["Golang",],
        "content": "前言 最近golang的1.13版本发布了，有很多新特性与改进合入。这里主要分析sync.pool的优化。\n本文主要解答以下几个问题：\n sync.pool优化体现在哪里？ 优化是如何实现？ 优化的好处有哪些？  优化 具体优化项如下：\n 无锁化 GC策略  无锁化 sync.pool实现了无锁化，具体如下：\ngo1.12.1版本实现\n1 2 3 4 5 6  // Local per-P Pool appendix. type poolLocalInternal struct { private interface{} // Can be used only by the respective P. shared []interface{} // Can be used by any P. Mutex // Protects shared. }   go1.13版本\n1 2 3 4 5  // Local per-P Pool appendix. type poolLocalInternal struct { private interface{} // Can be used only by the respective P. shared poolChain // Local P can pushHead/popHead; any P can popTail. }   通过上面对比发现了go1.12版本的Mutex删除了。那么go1.13版本又是如何实现无锁化的呢？\n先回答问题：go1.13通过poolChain实现SPMC的无锁队列来实现无锁化。\npoolChain是什么东东呢？\n别急，代码面前无秘密。 我们具体看一下代码就可以了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  // poolChain is a dynamically-sized version of poolDequeue. // // This is implemented as a doubly-linked list queue of poolDequeues // where each dequeue is double the size of the previous one. Once a // dequeue fills up, this allocates a new one and only ever pushes to // the latest dequeue. Pops happen from the other end of the list and // once a dequeue is exhausted, it gets removed from the list. type poolChain struct { // head is the poolDequeue to push to. This is only accessed // by the producer, so doesn\u0026#39;t need to be synchronized. head *poolChainElt // tail is the poolDequeue to popTail from. This is accessed // by consumers, so reads and writes must be atomic. tail *poolChainElt } type poolChainElt struct { poolDequeue // next and prev link to the adjacent poolChainElts in this // poolChain. // // next is written atomically by the producer and read // atomically by the consumer. It only transitions from nil to // non-nil. // // prev is written atomically by the consumer and read // atomically by the producer. It only transitions from // non-nil to nil. next, prev *poolChainElt }   关于poolChain是如何实现SPMC无锁队列？具体可以分析poolqueue.go的代码。 这一部分不展开说明，要点如下：\n 无锁队列是SPMC 无锁队列是可以灵活调整大小，调整大小的方法：slice+double-list实现（根据这个思路来阅读代码也是容易理解 ） 无锁队列的实现基础是CAS  好处  避免锁的开销，mutex变成atomic  GC策略 相比较于go1.12版本，go1.13版本中增加了victim cache。具体作法是：\n GC处理过程直接回收oldPools的对象 GC处理并不直接将allPools的object直接进行GC处理，而是保存到oldPools，等到下一个GC周期到了再处理  具体代码如下：\n1 2 3 4  var ( allPoolsMu Mutex allPools []*Pool )   1 2 3 4 5 6 7 8 9 10 11 12  var ( allPoolsMu Mutex // allPools is the set of pools that have non-empty primary // caches. Protected by either 1) allPoolsMu and pinning or 2) // STW. allPools []*Pool // oldPools is the set of pools that may have non-empty victim // caches. Protected by STW. oldPools []*Pool )   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  func poolCleanup() { // This function is called with the world stopped, at the beginning of a garbage collection. // It must not allocate and probably should not call any runtime functions. // Because the world is stopped, no pool user can be in a // pinned section (in effect, this has all Ps pinned). // Drop victim caches from all pools. for _, p := range oldPools { p.victim = nil p.victimSize = 0 } // Move primary cache to victim cache. for _, p := range allPools { p.victim = p.local p.victimSize = p.localSize p.local = nil p.localSize = 0 } // The pools with non-empty primary caches now have non-empty // victim caches and no pools have primary caches. oldPools, allPools = allPools, nil }   这样可导致Get的实现有变化，原来的实现是：\n 先从本P绑定的poolLocal获取对象：先从本poolLocal的private池获取对象，再从本poolLocal的shared池获取对象 上一步没有成功获取对象，再从其他P的shared池获取对象 上一步没有成功获取对象，则从Heap申请对象  引入victim cache，Get实现变成如下：\n 先从本P绑定的poolLocal获取对象：先从本poolLocal的private池获取对象，再从本poolLocal的shared池获取对象 上一步没有成功获取对象，再从其他P的shared池获取对象 上一步没有成功，则从victim cache获取对象 上一步没有成功获取对象，则从Heap申请对象  具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  func (p *Pool) getSlow(pid int) interface{} { // See the comment in pin regarding ordering of the loads. size := atomic.LoadUintptr(\u0026amp;p.localSize) // load-acquire locals := p.local // load-consume // Try to steal one element from other procs. for i := 0; i \u0026lt; int(size); i++ { l := indexLocal(locals, (pid+i+1)%int(size)) if x, _ := l.shared.popTail(); x != nil { return x } } // Try the victim cache. We do this after attempting to steal // from all primary caches because we want objects in the // victim cache to age out if at all possible. // 尝试从victim cache获取 size = atomic.LoadUintptr(\u0026amp;p.victimSize) if uintptr(pid) \u0026gt;= size { return nil } locals = p.victim l := indexLocal(locals, pid) if x := l.private; x != nil { l.private = nil return x } for i := 0; i \u0026lt; int(size); i++ { l := indexLocal(locals, (pid+i)%int(size)) if x, _ := l.shared.popTail(); x != nil { return x } } // Mark the victim cache as empty for future gets don\u0026#39;t bother // with it. atomic.StoreUintptr(\u0026amp;p.victimSize, 0) return nil }   好处  空间上通过引入victim cache增加了Get获取内存的选项，增加了对象复用的概率 时间上通过延迟GC，增加了对象复用的时间长度 上面这个两个方面降低了GC开销，增加了对象使用效率  参考  深入分析Golang sync.pool Using sync.Pool  ", 
        "url": "http:\/\/myself659.github.io\/post\/golang\/golang-sync-pool-2\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/risk-of-vesting-china\/": {
        
        "title": "瑞·达利欧：不投资中国才是巨大的风险",
        "tags": ["Economy",],
        "content": "不投资中国才是巨大的风险 最近，桥水基金创始人及《原则》的作者瑞·达利欧公开表示：不投资中国才是巨大的风险。如下图所示：\n作为一个世界富豪榜排名前100的大富豪，\n作为一个掌握1500亿美元的对冲基金的掌门人，\n作为一个美国人，\n作为一个在过去40年多次成功预测经济危机的投资人。\n他的话当然不同凡想，引人思考。\n当然我们不能随便轻信这个结论，我们应该具体了解一下，他是如何得出这个结论？下面展开说明如下：\n瑞·达利欧的理由 模型 在视频中瑞达利欧提出一个国家实力的模型，这个模型从六个方面来衡量一个国家的实力，具体如下：\n 科技和教育 生产 贸易 军事 金融 货币储备地位  下面这一张图是荷兰，英国，美国，中国这个四个国家在最近几百年来在上述六个方面的实力曲线图：\n多样性原则 作为一个掌握1500亿美元的对冲基金的掌门人，瑞达利欧深知保持投资多样性十分必要。他们的投资是面向全球。中国市场情况与欧美不相同，具有独特性，是风险投资组合保持多样性不或缺少的选择。\n相对风险 风险无处不在。常人都明白，都有风险的情况，选择风险最小的。\n下面对比欧洲，美国，中国三个地区的风险情况。\n先说欧洲，瑞·达利欧认为欧洲有巨大风险，存在以下问题：\n 货币政策失效 政治分裂，如英国脱欧 不参与科技革命  再看美国，瑞·达利欧认为美国存在以下问题：\n 财富贫富差距 缺少有效的货币政策 政治系统的冲突  最后看中国，瑞·达利欧认为：相比较于美国，中国有更大货币政策和财政政策空间，并正在处理债务问题。\n结合上面的比较，瑞·达利欧认为相比较于其他市场，中国的市场风险最小。\n中国的成长与实力 先看过去的成长，以资本市场为例：\n说明：红色表示股票市场，蓝色表示债券市场；左边是中国资本市场空间，右边是外国资本持有的中国金融资产情况。\n补充一下从左边曲线图可以看出中国的股票市场领域虽然十年来上证指数基本无增长，但是市值还是有增长，但是没有跟上GDP的增长。\n视角回到现在，首先看一下科技领域的风险投资情况：\n从上图可知:\n 中国在fintech领域领先美国排名第一 在AI and machine learning（AI和机器学习）领域排名第三，落后于美国与英国 在wearables(可穿戴设备)领域排名第二 在virtual reality(虚拟现实)领域排名第二 在educational technology(教育技术)领域排名第二 在autonomous driving(自动驾驶)领域排名第二  再看一下中美独角兽对比：\n显而易见，中国在独角兽数量上与美国有13%左右的差距，但是估值上仅2%的差距。\n最后看一下中美实力对比：\n看到这张图，相信大家会理解中国再继续闷声发大财不是一件容易的事情了。\n相信这些数据会让很多人得出一个结论：中美毛衣冲突不影响中国继续崛起的进程。\n对中国十分熟悉 还有一点考虑，视频中没有明确投及，就是瑞·达利欧对中国的熟悉，作为一名美国人，其实瑞·达利欧对中国十分熟悉，他从1984年第一次来到中国后，此后35年里他不断地来到中国并熟悉中国，并且他的一个儿子曾经在中国读书。\n后记 本文只是简单介绍，关于瑞达利欧是如何看待中美毛衣冲突，更多信息请看原始视频，原始视频时长有31分钟。关注本公众帐号，输入 投资中国，获取原始视频的百度云下载链接。\n参考  《原则》作者瑞·达利欧烧脑大作(1): 经济机器是怎样运行的  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/risk-of-vesting-china\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rust\/rust-crate-speedup\/": {
        
        "title": "Rust crate加速",
        "tags": ["Rust",],
        "content": "由于墙的原因，导致cargo build，cargo run都会出现概率性失败，并且整个过程十分缓慢。\n下面是解决方案：\n方案1 在 ~/.cargo/config文件（如果没有创建一个）下添加如下内容：\n1 2 3 4 5  [source.crates-io] replace-with = \u0026#34;rustcc\u0026#34; [source.rustcc] registry = \u0026#34;https://code.aliyun.com/rustcc/crates.io-index.git\u0026#34;   方案1现在还是实验阶段，充满变数与不确定性。不适用于CI/CD。\n方案2 在阿里云，aws上申请一个香港地区云主机，将build工作交给云主机\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/rust\/rust-crate-speedup\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/python\/python37-install\/": {
        
        "title": "安装与更新python",
        "tags": ["Python",],
        "content": "说明 完全是为了记录自己的操作记录，换一台新机器真是免不了要装python。记录下来，便于以后操作。\napt-get安装 1 2 3 4 5 6 7 8  apt update apt install software-properties-common add-apt-repository ppa:deadsnakes/ppa apt install python3.7   源码安装 1 2 3 4 5 6 7 8 9  sudo apt update sudo apt install -y build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget wget https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tar.xz tar -xf Python-3.7.3.tar.xz cd Python-3.7.3 ./configure --enable-optimizations make make altinstall   更新python3.9 1 2 3  $ sudo add-apt-repository ppa:deadsnakes/ppa $ sudo apt update $ sudo apt install python3.9   install pip 1  apt-get install python3-pip   install virutalenv 1  pip3 install virtualenv   1  python3 -m pip install --user virtualenv   1  python3 -m venv env   1  source venv/bin/activate   install pipenv 1  pip install --user pipenvd   1  pipenv install tweepy python-dotenv   1  pipenv run python twitter_client.py   install jupyter 1 2  python3 -m pip install --upgrade pip python3 -m pip install jupyter   pip basic 查看包状态 1  pip show pkgname   不使用缓存 1  pip install --no-cache-dir --default-timeout=10000 pkgname   更新包 1  pip install -U pkgname   指定源 有时候安装一些依赖包，网不好，直接超时，或者这个包就是死都下不下来的时候，可以指定国内源镜像。 pip install -i 国内镜像地址 包名\ne.g. pip install -i https://mirrors.aliyun.com/pypi/simple/ 这是临时指定镜像地址\n清华：https://pypi.tuna.tsinghua.edu.cn/simple\n阿里云：https://mirrors.aliyun.com/pypi/simple/\n中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/\n华中理工大学：https://pypi.hustunique.com/\n山东理工大学：https://pypi.sdutlinux.org/\n豆瓣：https://pypi.douban.com/simple/\n修改配置参考：https://cloud.tencent.com/developer/article/1566247\npipdeptree 安装pipdeptree：\n1  pip install pipdeptree   生成requirements.txt\n1  pipdeptree -f | sed \u0026#39;s/ //g\u0026#39; | sort -u \u0026gt; locked-requirements.txt   常用pip命令  updata pip  1  python -m pip install --upgrade pip   install package  1  pip install \u0026lt;package-name\u0026gt;   Update Package  1  pip install -U \u0026lt;package name\u0026gt;   Install Specific Version of a Package  1  pip install \u0026lt;package-name\u0026gt;==\u0026lt;version\u0026gt;   1  pip install \u0026lt;packagename\u0026gt;\u0026gt;=\u0026lt;version\u0026gt;   Uninstall a Package  1  pip uninstall \u0026lt;packagename\u0026gt;   Information About an Installed Package  1  pip show \u0026lt;package name\u0026gt;   List All Installed Packages  1  pip list   1  pip freeze   Generate a requirements.txt File  1  pip freeze \u0026gt; requirements.txt   Install All Dependencies From requirements.txt File  1  pip install -r requirements.txt   Verify That Installed Packages Have Compatible Dependencies  1  pip check   List All Installed Packages That Are Not Up to Date  1  pip list -o   常用pip pkg 数据库  pip install mysql-connector-python pip install psycopg2 pip install PyMongo  cmd  pip install fire pip install thefuck  api  pip install fastapi pip install pyforest  autoload  pip install reloading  map  pip install geemap  emoji  pip install emot  data  pip install dabl pip install sweetviz  nlp  pip install spacy pip install nltk  reqirements make reqirements 1  pip freeze \u0026gt; requirements.txt   install reqirements 1  pip install -r requirements.txt   wsl 1 2 3 4  sudo apt update \u0026amp;\u0026amp; upgrade sudo apt install python3 python3-pip ipython3 sudo apt install python3-pip pip3 install jupyter   misc How to install Ta-Lib in python on Windows\n参考  Managing Multiple Versions of Python on Ubuntu https://medium.com/@itylergarrett.tag/setting-up-python-3-7-on-windows-10-a-non-developer-tutorial-e836639ca16 Here’s a Quick Way to Learn About PIP in Python How to Setup a Virtual Environment with Different Python Versions (Windows) Why and How to make a Requirements.txt  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/python\/python37-install\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-index-predict\/": {
        
        "title": "加密货币市场常用跟踪指标",
        "tags": ["Invest",],
        "content": "指标 Largest banks by market cap Largest banks by market cap\n总市值 加密货币总市值\nCRYPTOCURRENCY MARKET\n加密数字货币全球图表\n交易量Transaction Volume BTC\u0026rsquo;s Transaction Volume\nEthereum’s Transaction Volume\n算力Hash Rate BTC\u0026rsquo;s Hash Rate\nEthereum’s Hash Rate\n活跃地址Active Addresses BTC\u0026rsquo;s Active Addresses\nEthereum’s Active Addresses\n交易数Transaction Count BTC\u0026rsquo;s Transaction Count\nEthereum’s Transaction Count\nAverage Transactions Per Second Transaction Rate Per Second\nAverage Transaction Value BTC\u0026rsquo;s Average Transaction Value\nEthereum’s Average Transaction Value\nAverage Transaction Fee BTC\u0026rsquo;s Average Transaction Fee\nEthereum’s Average Transaction Fee\nEthereum Gas Tracker Ethereum Gas Tracker\nEthereum Daily Gas Used Chart Ethereum Daily Gas Used Chart\nEthereum gets burned with EIP-1559 ETH gets burned with EIP-1559\nTLV defi Llama\nCrypto Lending Interest Rates Crypto Lending Interest Rates\nBitcoin Holdings by Public Companies Bitcoin Holdings by Public Companies\nEthereum Holdings by Public Companies Ethereum Holdings by Public Companies\nEth/BTC ratio Eth/BTC ratio\nEthereum to BTC Chart\nCrypto Fees Crypto Fees\nNFT OpenSea dashboard\nMEV MEV-explore\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-index-predict\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/node-version\/": {
        
        "title": "如何选择合适的node版本与npm package",
        "tags": ["Javascript",],
        "content": "前言 作为一个常年以c,c++,golang为主的后端程序员，刚接触nodejs有一个困惑，就是node有哪么多版本到底该选择哪个版本呢？\nnode版本 根据需求选择版本，那么node版本有哪些特点呢？\n 从node 6 开始支持ES6 从node 8 开始支持Async Await node 10 增加了promisified fs模块 node 12增加了ES6 modules  从上面应该注意到node偶数版本是稳定版本（类似于linux）。\n如何管理多个node版本 一句话：复用nvm管理node。\nWindows请参考nvm-windows 。\n如何选择正确的npm package 在哪里选 npmjs\n从哪几个维度选择  Popularity Contributors Maintenance Size Quality npm trends dependencies  如何对比同类型的npm package 使用npmcompare\nnpm install Error: rollbackFailedOptional 1 2  ia@IA:~$ npm install -g truffle [..................] - rollbackFailedOptional: verb npm-session 9af9b18d6d36c6ee   解决方法：\n1 2 3 4  npm config rm proxy npm config rm https-proxy npm config set registry https://registry.npmjs.org/ npm config set registry https://registry.npm.taobao.org   integrity checksum failed when using sha512 1 2  silly fetchPackageMetaData error for truffle@latest sha512-lhd8pfO5bOIwmiZf0+RyLcdWtrmeoA9JkdH9o0uQxZabisa6IxfoACRBpBez3r3w+LGPnl9/K1stE3Z9aBNK0A== integrity checksum failed when using sha512: wanted sha512-lhd8pfO5bOIwmiZf0+RyLcdWtrmeoA9JkdH9o0uQxZabisa6IxfoACRBpBez3r3w+LGPnl9/K1stE3Z9aBNK0A== but got sha512-4wB4Qu27nyZfMy9ZFzkCs/PGaaQx8W+bKug46AP5N/4BGCiT2Uw5tqq39Ip4VXXeISdok3LXb7r7A066wx3/Zw==. (15722953 bytes) 9 timing stage:rollbackFailedOptional Completed in 2ms   解决方法： 删除node_modules和package-lock.json，然后再重新执行：npm install\ninstall yarn How to install Yarn on Ubuntu\nHow to Install Yarn on Ubuntu 18.04\n常用NPM Packages 73 Awesome NPM Packages for Productivity\nnpm cmd  npm doctor npm cache npm link npm ls npm search npm repo  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/node-version\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/facebook-libra\/": {
        
        "title": "Facebook libra是昙花一现还是星星之火",
        "tags": ["BlockChain",],
        "content": "前言 最近随着Libra横空出世，整个互联网有关的Libra新闻，评论等层出不穷，众说纷云。这么热闹，我当然也要插一脚，讲讲自己的一些思考与看法。\n方向 在具体分析之前，先看看libra定位：\n Libra的使命是建立一套简单的、无国界的货币和为数十亿人服 务的金融基础设施。\n 从上面可知libra整个系统定位是金融基础设施。这是符合Facebook的定位，作为技术平台，为金融服务提供支撑。\n技术方向，libra选择从许可型区块链开始。这是一个明智的选择，虽然现在不知道其具体实现情况，但是联盟链有如下优势：\n 相比较于公链有更好的互操作性 便于将libra集成到Facebook上各个超级App中，如WhatApp，Messenger等 避免公链钱包在用户体验先天不足或者给普通用户的不适应 更好安全管理与防范 避免公链的一些技术问题，如DCS不可能三角  还有一点就是相比较于其他的区块链先造链，再开发应用，找用户试验应用场景，Libra是先有场景和用户，再造链解决具体问题如支付和跨境。\n Libra 的目标是成为一种稳定的数字加密货币，将全部使用真实资产储备（称为“Libra 储备”）作为担保，并由买卖Libra并存在竞争关系的交易平台网络提供支持\n Libra Coin定位于稳定币。这样从一开始就避免了炒作，而是将整个重心放在应用领域。\n我们还可以从侧面了解这个方向的正确性。Facebook创始人扎克伯格是一位十分具有前瞻眼光和判断力的领袖。下面的例子可参考：\n 2012年Facebook宣布10亿美元收购只有只有13个员工的Instagram，从投资的角度看如今回报率在100倍左右 2014年Facebook以 160 亿美金现金加股票（其中包含40亿美金的现金以及价值120亿美金的公司股票。此外，Facebook还将为WhatsApp的创始人及员工提供约价值30亿美金的限制股股票，分期四年发放）收购移动聊天工具WhatsApp，整个WhatsApp公司总共不到50人。  这两次收购让Facebook拿到移动互联网的船票。\nSWOT分析 下面就按SWOT展开说明。\nStrengths 显而易见，Facebook具有以下优势：\n Facebook在全球有27亿用户 Facebook有真实的用户社交数据，天然支持KYC Facebook有优秀人才 libra有广泛的合作伙伴 Facebook有钱 公司的执行力  Weaknesses Facebook一直是一个toC的公司，有以下劣势：\n Facebook在金融领域缺少经验 Facebook不擅长与政府打交道的  Opportunities 在白皮书列举的机会，具体如下：\n •• 我们认为，应该让更多人享有获得金融服务和廉价资本的权利。\n  •• 我们认为，每个人都享有控制自己合法劳动成果的固有权利。\n  •• 我们相信，开放、即时和低成本的全球性货币流动将为世界创造巨大的经济机遇和商业价值。\n  •• 我们坚信，人们将会越来越信任分散化的管理形式。\n  •• 我们认为，全球货币和金融基础设施应该作为一种公共产品来设计和管理。\n  •• 我们认为，所有人都有责任帮助推进金融普惠，支持遵守网络道德规范的用户，并持续维护这个生态系统的完整性。\n 官方白皮书是从用户与全球经济角度来看的，从Facebook这个公司的角度来看，有如下机会：\n 一种货币 一个联盟 一种权力 一项收入 一种趋势  一种货币 显而易见这种货币就是Libra coin。在现在的经济系统中可以发行货币只有国家的央行。以美国为例，作个类比如下：\n Libra coin相当于美元 Libra 协会相当于美联储 Libra coin在Facebook应用生态中各种应用相当于美元在实际生活中的应用  Libra coin初期充当Facebook应用系统的生态币。但是值得注意的是Facebook应用生态可以进一步扩展为全球互联网经济体。这意味什么？大家自行体会。\n一种联盟 从上图可知，现有Libra联盟成员如下：\n •• 支付业： Mastercard, PayPal, PayU (Naspers' fintech arm), Stripe, Visa\n  •• 技术和交易平台： Booking Holdings, eBay, Facebook/Calibra, Farfetch, Lyft, Mercado Pago, Spotify AB, Uber Technologies, Inc.\n  •• 电信业： Iliad, Vodafone Group\n  •• 区块链业： Anchorage, Bison Trails, Coinbase, Inc., Xapo Holdings Limited\n  •• 风险投资业： Andreessen Horowitz, Breakthrough Initiatives, Ribbit Capital, Thrive Capital, Union Square Ventures\n  •• 非营利组织、多边组织和学术机构：Creative Destruction Lab, Kiva, Mercy Corps, Women\u0026rsquo;s World Banking\n Libra以联盟的方式不断扩展，增加影响力，扩大共识，获取更多的应用场景。\n一种权力 在Facebook生态系统的发币权。相比较于国内的微信支付及支付宝接入了法币, Libra Coin赋与了Libra联盟发币权。\n一项新收入 基于libra的金融业务带来的收入，改变Facebook一直以来以广告为主的单一的营收结构。\n一项趋势 趋势不可阻档。\n经济全球化趋势不可阻挡。\n数字化货币带来自由，高效，便捷，低成本也是不可阻挡。\n拥有27亿用户的Facebook发行Libra无疑是站在这个趋势的浪尖，同时紧紧占有巨大的先发优势。\nThreats 关于Libra，马化腾点评如下：\n 技术都很成熟，并不难。就看监管是否允许而已。\n 对，Libra最大的问题就是监管。由于Facebook是一个全球化公司，涉及不同的国家，这些国家的法律与政策也不尽相同。这对于Libra就是一个巨大的挑战。 至于很多人担心Libra会不会是昙花一现，直接被扼杀在摇篮？ 前面有USDT的先例。答案是不会的，美帝的民主制度，都会有一番流程与讨论，估计过程并不会一帆风顺。有了美帝的放行，在其他的国家开展也就铺平了道路。\n其他竞争对手，如Google，amazon，microsoft相继效仿发币并进行竞争。\n如果Libra coin要挑战美元，那么美元就是Libra的最大竞争对手，这个挑战很大，近期应该不会出现。\n结论 Facebook走在正确的方向上，虽然有很多的困难和不确定性，相信Libra会开启价值互联网时代。\n欢迎来到Web3.0时代。\n参考  Libra Why the net giants are worried about the Web 3.0  ", 
        "url": "http:\/\/myself659.github.io\/post\/facebook-libra\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/startup\/%E5%88%9B%E4%B8%9A%E7%9A%84%E6%A0%B8%E5%BF%83\/": {
        
        "title": "创业的核心",
        "tags": ["startup",],
        "content": "创业的核心 创业的核心：\n 把握机会 降低成本 控制风险  ", 
        "url": "http:\/\/myself659.github.io\/post\/startup\/%E5%88%9B%E4%B8%9A%E7%9A%84%E6%A0%B8%E5%BF%83\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/golang\/golang-sync-pool-1\/": {
        
        "title": "深入分析Golang sync.pool",
        "tags": ["Golang",],
        "content": "定义 sync.Pool是一个可以存或取的临时对象池。对外提供New、Get、Put等API，利用mutex支持多线程并发。\n目标 sync.Pool解决以下问题：\n 增加临时对象的用复用率，减少GC负担 通过对象的复用，减少内存申请开销，有利于提高一部分性能  实现 这一部分回答如何实现的问题。\n关于了解实现，最好的办法就是看代码。\n描述 1 2 3 4 5 6 7 8 9 10 11  type Pool struct { noCopy noCopy local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal localSize uintptr // size of the local array // New optionally specifies a function to generate // a value when Get would otherwise return nil. // It may not be changed concurrently with calls to Get. New func() interface{} }   各个成员含义如下：\nnoCopy： 防止sync.Pool被复制\nlocal： poolLocal数组的指针\nlocalSize： poolLocal数组大小\nNew： 函数指针申请具体的对象，便于用户定制各种类型的对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  // Local per-P Pool appendix. type poolLocalInternal struct { private interface{} // Can be used only by the respective P. shared []interface{} // Can be used by any P. Mutex // Protects shared. } type poolLocal struct { poolLocalInternal // Prevents false sharing on widespread platforms with // 128 mod (cache line size) = 0 . pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte }   private：private私有池，只能被对应P使用（说明：P是指goroutine执行所占用的处理器，下同）\nshared： shared共享池，能被任何P使用\nMutex： 保护shared共享池\npad：poolLocal结构体中特别增加了pad成员，这是为了防止false sharing。\n操作 操作分为四种类型：\n New Get Put CleanUp  New 这部分主要解决问题：如何创建一个具体对象池？\n具体参考代码如下：\n1 2 3 4 5 6 7 8 9  // Object Object type Object struct { a int b int } var pool = sync.Pool{ New: func() interface{} { return new(Object) }, }   Get Get解决了如何从具体sync.Pool中获取对象的问题。\n获取对象有三个来源：\n private池 shared池 系统的Heap内存  获取对象顺序是先从private池获取，如果不成功则从shared池获取，如果继续不成功，则从Heap中申请一个对象。这是不是有熟悉的味道？在两级cache的情况下，CPU获取数据，先从L1 cache开始，再是L2 cache， 是内存。\n具体代码实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94  func (p *Pool) Get() interface{} { if race.Enabled { race.Disable() } l := p.pin() // 绑定private池和P x := l.private l.private = nil runtime_procUnpin() // 去绑定private池和P if x == nil { // private池获取失败 l.Lock() last := len(l.shared) - 1 if last \u0026gt;= 0 { x = l.shared[last] // 从shared池获取最后一个对象 l.shared = l.shared[:last] // 从shared池删除最后一个对象 } l.Unlock() if x == nil { x = p.getSlow() // pid对应poolLocal没有获取成功，开始遍历整个poolLocal数组 } } if race.Enabled { race.Enable() if x != nil { race.Acquire(poolRaceAddr(x)) } } if x == nil \u0026amp;\u0026amp; p.New != nil { x = p.New() // 从heap申请对象 } return x } func (p *Pool) getSlow() (x interface{}) { // See the comment in pin regarding ordering of the loads. size := atomic.LoadUintptr(\u0026amp;p.localSize) // load-acquire local := p.local // load-consume // Try to steal one element from other procs. pid := runtime_procPin() runtime_procUnpin() for i := 0; i \u0026lt; int(size); i++ { // 遍历poolLocal数组 l := indexLocal(local, (pid+i+1)%int(size)) // 注意pid+i+1 这样可以从pid+1位置开始整个遍历 l.Lock() last := len(l.shared) - 1 if last \u0026gt;= 0 { x = l.shared[last] l.shared = l.shared[:last] l.Unlock() break } l.Unlock() } return x } // pin pins the current goroutine to P, disables preemption and returns poolLocal pool for the P. // Caller must call runtime_procUnpin() when done with the pool. func (p *Pool) pin() *poolLocal { pid := runtime_procPin() // In pinSlow we store to localSize and then to local, here we load in opposite order. // Since we\u0026#39;ve disabled preemption, GC cannot happen in between. // Thus here we must observe local at least as large localSize. // We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness). s := atomic.LoadUintptr(\u0026amp;p.localSize) // load-acquire l := p.local // load-consume if uintptr(pid) \u0026lt; s { return indexLocal(l, pid) } return p.pinSlow() // 没有对应poolLocal，进入慢路径处理 } func (p *Pool) pinSlow() *poolLocal { // Retry under the mutex. // Can not lock the mutex while pinned. runtime_procUnpin() allPoolsMu.Lock() defer allPoolsMu.Unlock() pid := runtime_procPin() // poolCleanup won\u0026#39;t be called while we are pinned. s := p.localSize l := p.local if uintptr(pid) \u0026lt; s { // 根据pid获取poolLocal return indexLocal(l, pid) } if p.local == nil { allPools = append(allPools, p) } // If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one. size := runtime.GOMAXPROCS(0) local := make([]poolLocal, size) // 重新分配poolLocal atomic.StorePointer(\u0026amp;p.local, unsafe.Pointer(\u0026amp;local[0])) // store-release atomic.StoreUintptr(\u0026amp;p.localSize, uintptr(size)) // store-release return \u0026amp;local[pid] // 返回新的poolLocal }   总结Get主要要点如下：\n 先从本P绑定的poolLocal获取对象：先从本poolLocal的private池获取对象，再从本poolLocal的shared池获取对象 上一步没有成功获取对象，再从其他P的shared池获取对象 上一步没有成功获取对象，则从Heap申请对象  Put Put完成将对象放回对象池。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  // Put adds x to the pool. func (p *Pool) Put(x interface{}) { if x == nil { return } if race.Enabled { if fastrand()%4 == 0 { // Randomly drop x on floor. return } race.ReleaseMerge(poolRaceAddr(x)) race.Disable() } l := p.pin() // 绑定private池和P if l.private == nil { l.private = x // 放回private池中 x = nil } runtime_procUnpin() // 去绑定private池和P if x != nil { l.Lock() l.shared = append(l.shared, x) // 放回shared池 l.Unlock() } if race.Enabled { race.Enable() } }   上面的代码总结如下：\n 如果poolLocalInternal的private为空，则将回收的对象放到private池中 如果poolLocalInternal的private非空，则将回收的对象放到shared池中  CleanUp CleanUp实现 注册poolCleanup函数。\n1 2 3 4  func init() { runtime_registerPoolCleanup(poolCleanup) }   poolCleanup函数具体实现，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  func poolCleanup() { // This function is called with the world stopped, at the beginning of a garbage collection. // It must not allocate and probably should not call any runtime functions. // Defensively zero out everything, 2 reasons: // 1. To prevent false retention of whole Pools. // 2. If GC happens while a goroutine works with l.shared in Put/Get, // it will retain whole Pool. So next cycle memory consumption would be doubled. for i, p := range allPools { allPools[i] = nil for i := 0; i \u0026lt; int(p.localSize); i++ { l := indexLocal(p.local, i) l.private = nil for j := range l.shared { l.shared[j] = nil } l.shared = nil } p.local = nil p.localSize = 0 } allPools = []*Pool{} }   CleanUp时机 什么时候进行CleanUp回收对象池？在gc开始前。\n具体代码(代码文件为runtime/mgc.go)如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  func gcStart(trigger gcTrigger) { ... // clearpools before we start the GC. If we wait they memory will not be // reclaimed until the next GC cycle. clearpools() // 在这里清理sync.Pool work.cycles++ gcController.startCycle() work.heapGoal = memstats.next_gc // In STW mode, disable scheduling of user Gs. This may also // disable scheduling of this goroutine, so it may block as // soon as we start the world again. if mode != gcBackgroundMode { schedEnableUser(false) } ... }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  func clearpools() { // clear sync.Pools if poolcleanup != nil { poolcleanup() // 如果poolcleanup不为空，调用poolcleanup函数 } // Clear central sudog cache. // Leave per-P caches alone, they have strictly bounded size. // Disconnect cached list before dropping it on the floor, // so that a dangling ref to one entry does not pin all of them. lock(\u0026amp;sched.sudoglock) var sg, sgnext *sudog for sg = sched.sudogcache; sg != nil; sg = sgnext { sgnext = sg.next sg.next = nil } sched.sudogcache = nil unlock(\u0026amp;sched.sudoglock) // Clear central defer pools. // Leave per-P pools alone, they have strictly bounded size. lock(\u0026amp;sched.deferlock) for i := range sched.deferpool { // disconnect cached list before dropping it on the floor, // so that a dangling ref to one entry does not pin all of them. var d, dlink *_defer for d = sched.deferpool[i]; d != nil; d = dlink { dlink = d.link d.link = nil } sched.deferpool[i] = nil } unlock(\u0026amp;sched.deferlock) }   总结 总结一下sync.Pool的实现，要点如下：\n 提供New定义实现用户自定义对象 需要使用对象调用Get从对象池获取临时对象，Get优先级首先是本P绑定的poolLocal, 其次是其他P绑定的poolLocal，最后是Heap内存 对象使用完毕调用Put将临时对象放回对象池 未被使用的对象会定时GC回收 对象没有类似于linux cache object对应的free函数  应用 sync.Pool并不是万能药。要根据具体情境而定是否使用sync.Pool。\n总结不适合使用sync.Pool的情境，具体如下：\n 对象中分配的系统资源如socket，buffer 对象需要进行异步处理 对象是组合对象，如存在指针指向其他的对象 批量对象需要并发处理 复用对象大小存在的波动，如对象结构成员存在slice  在排除上面情境下，适合使用的sync.Pool应满足以下条件，具体如下：\n 对象是buffer或非组合类型如buffer reader, json decode, bufio writer 对象内存可以重复使用  同时在使用应该注意问题：\n Put对象之前完成初始化，避免数据污染带来问题, 这可能带来各种各样的问题 写代码时要满足one Get， one Put的要求 注意获取对象后是否存在修改对象内存存局的代码 关注应用场景是否容易出现Pool竞争的情况 sync.Pool不是万能药，不要拿着锤子，看什么都是钉子  (Ps: 个人能力不足，若有错误不足，欢迎指正！)\n参考  sync: Pool example suggests incorrect usage  ", 
        "url": "http:\/\/myself659.github.io\/post\/golang\/golang-sync-pool-1\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/how-to-flow-%E5%BF%83%E6%B5%81\/": {
        
        "title": "如何进入心流状态",
        "tags": ["Learn",],
        "content": "心流状态 心流状态(Flow State)指的是一种不自觉的身心愉悦感,以及投入在一个活动中的极度专注的心理状态。当一个人全身心地投入一项工作或活动时,会体验到这种异常专注且乐在其中的感觉,这就是心流状态。\n心流状态的主要特征有:\n 高度专注。在心流状态下,人们会完全沉浸在活动中,精力集中,周边的干扰被屏蔽。 失去时间感。由于高度专注,人们会忘记时间的流逝,完全不自觉活动进行了多长时间。 自我意识减弱。在心流状态下,人们不会过于关注自己,而是全身心投入活动本身,自我意识变弱。 精力充沛。尽管高度专注会消耗大量精力,但心流状态却能带来精力充沛的感觉,当活动结束后才会有疲倦感出现。 活动本身就是奖励。在心流状态下从事某项活动,人们可以获得享受和满足感,活动本身就是一种奖励体验。 表现更优异。心流状态可以提高人们的专注力和创造力,从而达到更高的工作效率和表现。  达到心流状态需要满足的主要条件:\n 技能与挑战度的平衡。活动难度必须匹配技能,既不会太容易导致厌倦,也不会太难产生挫败感。 清晰的目标。要有具体而清晰的目标或进度来引导专注。 立即的反馈。要有明显的反馈或进度展示来引起专注和趣味性。 投入度高。高度关注并投入活动本身,而非活动结果或其他外在因素。 控制感。有一定的控制感或主导权,可以根据情况调整自己的行为或活动过程。  所以,总体来说,心流状态是一种融合了高度专注、全身心投入以及愉悦感的理想心理状态。通过创建适度的挑战、清晰的目标、即时反馈以及主控感,我们可以达到心流状态,从而获得更好的体验与表现。\n如何进入心流状态 上面的相关心流状态的信息过于理论。在我们的工作过程中如何进入心流状态呢？\n个人认为可以从几个方面入手：\n  无干扰的环境\n  无杂念的心态\n  全身心的投入\n  把握当下\n  只做一件事\n  无干扰的环境   安静无噪音的环境\n  关闭报警与通知\n  带上耳机听一些让自己专注的音乐（具体因人而异）\n  调度上网时间，心流时间段关闭互联网访问\n  关闭不必要的窗口和tab，如使用onetab\n  无杂念的心态  先慢下来，再静下来 深呼吸练习 每天冥想练习 控制社交媒体的使用 学会说不  全身心的投入  了解自己一天身体状态情况，在感觉最好的时候投入 手，眼，耳，嘴，心，脑等尽可能都投入到工作，投入会慢慢地带你进入心流的状态 积极的提示如名人名言与自我肯定  把握当下  不念过去，不想将来，把握当下 当下就是要做这件事的使命感 有意识认识到当下一个时间段最重要的就是做好这件事 只有当下，唯有当下  只做一件事  只有一件事，只有一件事，只有一件事，重要的事情说三遍 这一件事有意义，而且要让自己清楚地看见，看见才能相信 这一件事有挑战，但难度合适，在完成过程能给人带来兴奋与愉悦，促进专注 这一件事有清晰明确的目标与产出 这件事很大概率能完成，完成能够带来良性的正反馈 有意识地只做这件事  如何保持心流状态  限定时间：一次心流状态保持在半个小时到1个小时 避免干扰：听适合自己的音乐 应对干扰：在你进入心流状态后，记下任何分散你注意力的东西，如果你把它们记下来，它们就不会在蹦来蹦去了 补充水分与能量 使用工具减少工作过程的摩擦 更多的自动化辅助，这样会有更多流畅感 建立属于自己的心流的例行过程 完成一个时间段的心流，要奖励自己  总结 心流状态 = 在无打扰的环境下，无杂念全身心地投入到当下的一件事上。\n", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/how-to-flow-%E5%BF%83%E6%B5%81\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/how-to-iterate-%E8%BF%AD%E4%BB%A3\/": {
        
        "title": "如何迭代",
        "tags": ["学习","成长",],
        "content": "重复不如迭代 迭代相比较于重复有以下特点：\n 改变  复用  反馈  结论： 1000次重复不如1000次迭代。\n迭代的原则  小改变，多对比，多迭代 度量迭代 迭代的粒度满足原子性 以bottom-up方式迭代  迭代的循环 迭代的循环由以下过程组成：\n 根据信息做出决策 根据决策开展行动 根据行动展开思考 根据思考更新信息  迭代的过程 针对同一件事情，可以分为三个阶段：\n 开始行动，启动迭代 正确地行动 更好地行动  总结  迭代是进步的步伐 迭代是灵活小巧的改变 迭代是积小成多，由量变实现质变 迭代是行动的改变，打破了常规，是自我突破的开始  ", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/how-to-iterate-%E8%BF%AD%E4%BB%A3\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/sim-port-attack\/": {
        
        "title": "人生中最昂贵的教训：SIM卡转移攻击的细节(译文)",
        "tags": ["BlockChain","Secure",],
        "content": "上周三我损失了10万美元。它在24小时的时间内在“SIM转移攻击”中消失，耗尽了我的Coinbase帐户。事件已经过去了四天，我被摧毁了。我寝食难安;我充满了焦虑，懊悔和尴尬。\n这是我生命中最昂贵的一课，我想与尽可能多的人分享我的经验与教训。我的目标是提高对这类攻击的认识，并促使大家提高在线身份的安全性。\n这仍然是非常原始的（我还没有告诉我的家人）；请大家保留对本文所述的天真安全措施的判断。\n攻击的细节 您可能会问自己，究竟什么是“SIM转移攻击”？为了描述攻击，我们来看一下典型的在线身份。对于大多数人来说，下图应该看起来很熟悉。\n我们大多数人都有一个主电子邮件帐户，该帐户与很多其他在线帐户相关联。我们大多数人还有一个移动设备，如果你忘了密码，可以用这个移动设备来恢复您的电子邮件密码。\n授权的SIM转移 将SIM卡转移到另一台设备是移动运营商为其客户提供的服务。它允许客户将他们的电话号码转移到新设备。在大多数情况下，这是完全合法的要求;当我们升级到新手机，切换移动运营商等时会发生这种情况。\nSIM转移攻击 但是，“SIM转移攻击”是由未经授权的来源（攻击者）执行的恶意转移。攻击者将您的 SIM卡转移到他们控制的手机上。然后，攻击者在您的电子邮件帐户上启动密码重置流程。验证码会从您的电子邮件提供商发送到您的电话号码。 攻击者会截获该电话号码，因为他们现在控制您的SIM卡。下图逐步概括了攻击过程。\n一旦攻击者控制了您的主电子邮件帐户，他们就会开始绕过您通过该电子邮件地址（银行帐户，社交媒体帐户等）管理并支配您的任何在线服务及其资产。如果他们非常恶意，他们甚至可以锁定你的帐户而你却几乎无法收回它们。\n花点时间检查一下单个Google帐户绑定的大量敏感信息：\n 您的地址，出生日期和其他私人，个人身份信息 访问您（和/或您的合作伙伴）的潜在妥协照片 访问您的日历和即将到来的旅行日期 访问您的私人电子邮件，文档和搜索历史记录 访问您的个人联系人及其私人信息以及与您的关系 访问您的主电子邮件地址用作身份验证来源的所有其他在线服务  事件时间线 通过更好地掌握如何进行此类攻击以及所涉及的范围，让我们深入探讨此特定攻击的时间线。我想描绘一下攻击是如何被执行的，以及我是如何经历这些事件的，以及如果您遇到类似的症状，您可以做些什么来保护自己。\n时间线分为四个部分：\n  我所经历的：从我的观点来看所经历的事件。如果你遇到类似的事情，这些都是你可能受到攻击的明确指示。\n  攻击者正在做什么：黑客用来进入我的Coinbase帐户的基本策略。\n  我感知到的威胁级别：我在这些事件发生时将其归因于威胁级别。\n  我应该拥有的威胁级别：事后看来，我希望在这些事件发生时我会拥有的威胁级别。\n  经验教训+建议 这是我生命中最昂贵的一节课。我在24小时内失去了相当重要比例的净值资产; 并且是不可逆的。以下是我鼓励其他人用来更好地保护自己的在线安全的一些建议： 使用硬件钱包，以确保您的加密：将您的密码到硬件钱包 /离线存储/ 多SIG钱包，只要你不交易。不要将资金闲置在交易所或法定进场。我将Coinbase视为银行账户，并且在发生攻击时你绝对没有追索权。我比大多数人更了解风险，但从未想过这样的事情会发生在我身上。我非常后悔没有采取加密安全措施。\n  基于SMS的2FA还不够：无论您尝试在线保护的资产和/或身份如何，都要升级到基于硬件的安全性（即：攻击者为实施攻击而必须物理获取的物理内容）。虽然Google Authenticator和Authy可以将您的移动设备转变为基于硬件的安全性，但我建议您更进一步。拿起你实际控制的YubiKey，不能被欺骗。\n  减少您的在线足迹：减少不必要地在线分享个人身份信息（出生日期，位置，嵌入其中的地理位置数据的图片等）的冲动。在发生攻击时，所有这些准公开数据都可以针对您。 Google Voice 2FA：在某些情况下，在线服务不支持基于硬件的2FA（它们依赖于较弱的基于SMS的2FA）。在这些情况下，您最好创建一个Google语音电话号码（无法通过SIM卡转移）并使用具有2-Factor Auth恢复号码的电话号码。\n  创建辅助电子邮件地址：不是将所有内容绑定到单个电子邮件地址，而是为关键在线身份（银行帐户，社交媒体帐户，加密交换等）创建辅助地址。请勿将此电子邮件地址用于其他任何内容并将其保密。使用某种形式的基于硬件的2FA备份该地址。\n  离线密码管理器：使用密码管理器输入密码。更好的是，使用密码存储等脱机密码管理器。lrvick拥有各种密码管理器的优秀对比图表，以及针对更具技术倾向的审查建议。\n  关于读者的评论 我明白这一点：鉴于我天真的安全实践，我可能就应该注定被黑客攻击。这样做不会减少受到任何伤害，并且会削弱这个故事的主旨，即：\n 让别人知道受到伤害是多么容易 使用上述知识和建议来优先考虑您的在线身份的安全性  我禁不住想到我可以做的小而轻松的事情来保护自己。我的脑海中涌现各种假设。\n然而，这些想法伴随懒惰和幸存者偏见。我从来没有认真对待我的在线安全，因为我从未经历过攻击。虽然我了解自己的风险状况，但是我就是太懒导致我没有用该有的严谨来保护我的资产。\n我恳请你们从这些错误中吸取教训。\n参考  The Most Expensive Lesson Of My Life: Details of SIM port hack  ", 
        "url": "http:\/\/myself659.github.io\/post\/sim-port-attack\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/about-book-reading\/": {
        
        "title": "说说读书",
        "tags": ["Read",],
        "content": "前言 书籍是人类进步的阶梯。\n书箱是前人总结的知识与智慧的结晶。\n读书有利于使我们站上巨人的肩膀，有利于我们提升自己的历史高度，行业高度，哲学高度，这样很多复杂问题可以看得更清楚，可以发现更多解决方案。\n目的 读书的主要目的不是为了记忆，也不是为了批评，而是为了应用。将书中内容应用于自己的知识系统或者解决具体问题。\n原因 读书的原因如下：\n 读书可以增长知识 读书可以帮助你放松和减轻压力，是一种生活要素 读书是一种低成本理解世界的方式 读书是一种高手交流的方式 读书可以提高思考能力 读书可以指导实践，是知行合一的重要一环 读书可以预防老年痴呆症  原则 个人读书的原则如下：\n 读好书 保持怀疑态度，尽信书不如无书 好书要多读与深读，质量比数量更重要 学（读）以致用 读书讲策略与方法 读书要有输出（笔记，思维导图，分享等） 精读为主，避免泛泛而读 带着问题与目标读书 构建与完善自己的知识树，将书中的内容与原来的知识系统建立连接 基于主题读书，同时读几本同主题的书，做到多视角阅读与对比 对阅读进行工程化管理 用好工具如Notion、Obsidian 培养良好的读书习惯如记笔记，建索引，写阅读要点与清单  如何选好书 从以下几个方面考虑：\n 这本书要解释（解决）什么问题？问题是否真实存在？问题的意义是什么？ 这本书的作者是这个领域的顶级专家吗？ 这本书内容有哪些？这些内容具有实时性、创新性、革命性吗？内容对实践有益吗？ 这本书表达是否科学规范严谨？ 自己有兴趣有能力将为本书读下去吗？读了能否用起来？用起来有多大的收益？ 这本书是经典书箱吗？  如何深读 多读容易做到，但是深读需要一些技巧与练习。\n以下方法有利于深度阅读：\n 避免干扰 带着问题读书 写读书笔记与评论 保证每次读书时间在半个小时以内 细节阅读 对比阅读 利用思维导图进行全局阅读与把握 交流与讨论 积极地公开分享 与GPT结对进行对话阅读 升维阅读  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/about-book-reading\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s\/gcloud-login-from-china\/": {
        
        "title": "gcloud auth login from mainland in china",
        "tags": ["devops",],
        "content": "backgroud 最近使用了google cloud，所以打算试一下通过gcloud auth login登陆远程主机。\nprerequisites  科学上网的通道 terminal配置代理  config gcp proxy for gcloud 一般情况下，有上面的准备，gcloud auth login应该会成功，实际上并没有。这是因为还要指定gcloud config的代理配置，具体参考配置 gcloud CLI 以在代理/防火墙后面使用.\n", 
        "url": "http:\/\/myself659.github.io\/post\/k8s\/gcloud-login-from-china\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/business\/about-zoom\/": {
        
        "title": "关于zoom的一些思考与看法",
        "tags": ["商业","Internet",],
        "content": "前言 最近zoom上市，作为一名华人创业公司自然大受关注。下面从以下几个方面谈谈自己的一些思考与看法：\n 技术 领导 产品 商业  技术 对于视频面试会议，技术核心分为以下三大块：\n 基础设施架构 网络传输技术 音视频技术  领导  招聘方面重点在自我激励和学习，招聘有发展潜力的人 2019年，Zoom还在全美最佳雇主公司排名中位居第二位，也是一个非常让员工喜欢的创业公司。这个投票应该还是可以相信的，没有内幕 信任来自开放。越开放，越信任。作为公司的领导要开放与底层员工的连接通道 一个公司或者一个组织甚至一个国家，解决问题是第一要义是正视问题，而不是逃避问题，应该鼓励发现问题  产品 先说对于zoom的评价，确实好用，个人从2016年就开始使用。\n 永无止境，WebEx在当时的市场已经占有很大的市场，但是zoom创始人并没有停留在市场占用率上而是准确地看到WebEx背后的问题。 欲速则不达。耐心地打磨产品，zoom在2011年成立，到2013年才首次发布产品Zoom Meetings，这放在国内是无法想像的，很多创业公司三个月就要出产品，结果创业公司还是每年死一大片，而zoom却从视频会议领域众多竞争对手中脱颖而出。 套用一句话：从人民群众中来,到人民群众中去。从用户中来，到用户中去，需求从用户中来，真正地倾听用户的心声，产品与服务落实到用户，让用户享受实在的便利与好处 直播改变生活，学习与工作；快手、抖音、zoom就是很好的说明 视频大行其道，视频降低用户门槛，视频用户体验更好，视频中包含更多的信息  商业  追求低成本，高效率，zoom将研发大部分放在中国内地，中国内地人均30W左右，在美国硅谷招一个软件工程师起薪差不多90W吧，这样从而整体上降低了zoom的成本。zoom上市就能营利，让其在股价方面表现十分出色。 双赢的原则，zoom让员工开会不受地点限制，只要有网络就可以，同时也降低企业的运行成本。 降低门槛，视频会议降低了会议的门槛，打破空间的限制，zoom易用性降低了使用门槛，只要手机和电脑再加上网络就可以进行一场会议。国内有不少企业还卖专门的视频会议硬件系统，这样一开始就输，研发成本需要投入，价格还高 优势原则。市场竞争，优势劣汰。一定要建立优势如成本优势，用户体验优势，先发优势，差异化优势 zoom有2000倍的市盈率。这说明什么？泡沫吗？从数字上看是这样的。但是股价体现是预期，这说明视频协作会是未来发展一个方向。视频协作现在应用率还是很低，未来还是有很大的增长空间，除了视频会议还有更多的应用场景，如远程医疗。  总结 zoom创始人袁征从1997年WebEx一名程序员到2011年思科工程副总裁，负责WebEx产品。在这个阶段他完成了技术与领导大部分积累。从2011年开始创办zoom进行产品化与商业化，到2019年IPO上市，使产品化与商业化达到一个新的台阶。程序员在提高自己的技术能力的同时，要努力培养领导能力，产品能力，商业能力。\n参考  Zoom成功上市：市值超160亿美元 华裔创始人走向人生巅峰 连续四年保持三位数增长，搞视频会议的 Zoom 有三大关键秘诀 扎克伯格：80%的企业文化由创始人决定 《原则》读书笔记八 如何做到极度求真与极度透明 生活在一个十分钟就能走完的安逸小城，给生活做减法 How Zoom Beat the Tech Giants  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/business\/about-zoom\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E9%80%89%E6%8B%A9%E5%8E%9F%E5%88%99\/": {
        
        "title": "选择的原则",
        "tags": ["Think",],
        "content": "背景 学会选择很难。 学会做出好的选择更难。 在这个复杂的世界里学会做出正确的选择更难。\n选择很重要。不是有一句话：\n 选择比努力更重要。\n 原则 个人对于选择的原则总结如下：\n 先准备选项，再来选择 拓展选择的空间 明确选择的目标与选择的取舍 永远选择能给你更多的选择的选项 明确选择的目标之一：选择后不后悔 考虑选择后会失败的情况 没有完美的选择，一切都是tradeoff 永远不要在情绪激动时做出重大决定  选择的空间至少包括以下三个方面：\n 做出选择的空间（时间） 选项的空间（数量） 选项背后的空间  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E9%80%89%E6%8B%A9%E5%8E%9F%E5%88%99\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/understand-socity-abstraction\/": {
        
        "title": "理解社会的抽象",
        "tags": ["Thinking",],
        "content": "背景 认识自己与认识世界，是我们学习两个方面。\n世界很大，有客观的物理世界，有由人组成的社会，有虚拟的世界等等，这里还是先以人为本，先看由人组成的社会。\n社会的抽象 对于我们要认识的社会，个人对其抽象如下：\n一切皆利益\n一切皆交易\n一切皆博弈\n一切皆连接\n一切皆网络\n一切皆变化\n一切皆人性\n既然是抽象，那就不展开说明。\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/understand-socity-abstraction\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E8%AF%81%E5%AE%9Evs%E8%AF%81%E4%BC%AA\/": {
        
        "title": "从逻辑运算看证实和证伪",
        "tags": ["Think",],
        "content": "前言 我们处于信息社会，实际上只是信息很多，但是真相确却很少。\n假设 假设一个事件发生，现在已知要满足N个条件（实际上可能不止N个条件）。\n证实 用编程语言表示证实逻辑如下：\n1 2 3  if( 条件1 \u0026amp;\u0026amp; 条件2 \u0026amp;\u0026amp; 条件3 \u0026amp;\u0026amp; 条件4 \u0026amp;\u0026amp; 条件5 ...){ return True; }   从上面的伪代码可以知道：\n 证实首先明确这个事件如果要发生，需要哪些条件，但是获取到所有发生的条件难度大 证实的过程需要验证每一个条件，成本高  证伪 用编程语言表示证伪逻辑如下：\n1 2 3  if( !条件1 || !条件2 || !条件3 || !条件4 || !条件5 ...){ return False; }   从上面伪代码可以知道：\n 证伪不需要知道事件发生所需要的所有的条件 证伪只需要证明一个条件不被满足即可  结论 证伪只需要证明一个条件不符合即可，所以优先选择证伪。 从成本看证伪的成本远小于证实。 只要证伪的信息越多，那么离真实也就越来越近。\n", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E8%AF%81%E5%AE%9Evs%E8%AF%81%E4%BC%AA\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-info\/": {
        
        "title": "区块链，加密货币与web3常用信息来源",
        "tags": ["BlockChain",],
        "content": "技术 medium cryptocurrency\nmedium blockchain\nhackernoon NFT\n新项目 icodrops\nThe Complete ICO Calendar\n资讯 coindeck\ntwitter naval\nbalajis.com\nVitalik\nAshleigh Schap\nArthur Hayes\nStani Kulechov\nGloria Kimbwala\nRic Burton\nDennison Bertram\nAustin Griffith\nSantiago Palladino\nZaki Manian\nAnthony Sassano\ntitter follow suggest list \ntelegram  Fat Pig Signals Universal Crypto Signals Verified Crypto Traders Rocket Wallet Signals  数据与分析 messari\nBlog haseebq\nbalajis\u0026rsquo;s blog\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-info\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/it-frame\/": {
        
        "title": "分享一种分析信息技术发展的框架",
        "tags": ["BlockChain","Internet",],
        "content": "信息技术发展史 为了与原文保持一致，将信息技术发展史分为以下6个阶段：\n 大型机时代 PC时代 互联网时代 社交网络时代 智能手机时代 区块链时代  框架介绍 将信息技术要素分为以下四种：\n IO(接口) Infrastrure(基础设施) CPU(计算) HD(存储)  将技术要素分布为两个方向：\n User(用户端) Remote(远端即服务端及云端)  总体上来说，整个框架具有普适性，并且框架简单清晰。\n大型机时代-\u0026gt;PC时代 框架变化:\nPC时代\"\n成本：\n 计算处理能力减弱，存储空间变小  收益：\n 降低计算机使用门槛，方便更多人使用  数据:\n主机集中数据转向个人PC时代去中心化数据\n开发者的新机会：\n 分发(软盘，CD) 新技术(本地数据，GUI，扬声器)  市场的新机会：\n 消费级操作系统(微软，苹果) 视频游戏(EA sports，ID software) 硬件(Apple，IBM，HP，Dell)  PC时代-\u0026gt;互联网时代 框架变化:\n互联网时代\"\n成本：\n 互联网数据成本 新公共基础设施的成本开支  收益：\n 更多更便捷的信息访问入口，更大的存储空间，更强的计算处理能力  数据:\n中心化存储数据。\n开发者的新机会：\n 分发(云基础设施)  市场的新机会：\n 网上购物(亚马逊，eBay，Paypal) 在线广告(谷歌，雅虎) 流媒体(Skype，Netflix) 互联网服务提供商(AOL)  互联网时代-\u0026gt;社交网络时代 框架变化:\n社交网络时代\"\n成本：\n 隐私  收益：\n 通过线上打通线下 个性化  数据:\n中心化存储(隐私)数据。\n开发者的新机会：\n 应用分发 信息分发  市场的新机会：\n 个性化广告(Facebook，Twitter，LinkedIn) 共享经济(AirBnb) 社交游戏(Zynga)  社交网络时代-\u0026gt;智能手机时代 框架变化:\n智能手机时代\"\n成本：\n 更小的屏幕 无键盘 更小的计算能力 更少的存储空间  收益：\n 易于创建媒体 提高访问网络的便捷性  数据:\n 去中心化生成数据 中心化存储数据  开发者的新机会：\n 分发(App store) 新技术(GPS和相机)  市场的新机会：\n 媒体分享(Pinterest，Instagram，Youtube) 基于位置的服务(Uber，Lyft) 消息(Snapchat，Whatsapp，Telegram)  智能手机时代-\u0026gt;区块链时代 框架变化:\n区块链时代\"\n成本：\n 更多计算与处理 更多网络流量 效率低  收益：\n 不可变数据 审查制度  数据:\n 可信数据的去中心化分布与存储  开发者的新机会：\n 新技术(信任)  市场的新机会：\n 全球便利网络(供应链，NFT即Non-Fungible Token) 价值存储(比特币) 法律(法律合同，治理，审计)  说明 框架不是原理，同时内容很简单，相信大家一定有很多其他的看法与意见，权且当作抛砖引玉，欢迎交流。\n另外本文主要内容来自My framework for how to look at the future of blockchain，原文的目的通过这个框架讨论区块链的未来。本人只是想把这个框架介绍给大家，再加一些个人对这个框架的一点解释而已。\n(End)\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/it-frame\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s-kubeagle\/": {
        
        "title": "利用Kube Eagle监控Kubernetes集群资源",
        "tags": ["Docker","Kubernetes",],
        "content": "安装helm helm是Kubernetes集群的npm。\n下载脚本add_helm.sh 脚本内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  #!/usr/bin/env bash  echo \u0026#34;install helm\u0026#34; # installs helm with bash commands for easier command line integration curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash # add a service account within a namespace to segregate tiller kubectl --namespace kube-system create sa tiller # create a cluster role binding for tiller kubectl create clusterrolebinding tiller \\  --clusterrole cluster-admin \\  --serviceaccount=kube-system:tiller echo \u0026#34;initialize helm\u0026#34; # initialized helm within the tiller service account helm init --service-account tiller # updates the repos for Helm repo integration helm repo update echo \u0026#34;verify helm\u0026#34; # verify that helm is installed in the cluster kubectl get deploy,svc tiller-deploy -n kube-system   执行脚本安装helm 1  sh add_helm.sh   安装kube-eagle 主要体验一下helm使用(刚开始我都是自己手动安装Prometheus)。\n添加repo 1  helm repo add kube-eagle https://raw.githubusercontent.com/google-cloud-tools/kube-eagle-helm-chart/master   更新repo 1  helm repo update   安装kube-eagle 1  helm install --name=kube-eagle kube-eagle/kube-eagle   可视化 具体如下：\n整体集群的资源使用情况是不是一目了然了？\n参考  Kube Eagle Helm Chart Kube Eagle Dashboard  ", 
        "url": "http:\/\/myself659.github.io\/post\/k8s-kubeagle\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/python\/python-packages\/": {
        
        "title": "The popular python packages you should know",
        "tags": ["python",],
        "content": " Life is short, I use Python.\n I try to summary the popular python packages as follows:\nNumber and Math  sympy Sage numbers math cmath decimal fractions random statistics  Data and statistics  Matplotlib seaborn numpy pandas plotly  Web Development  Django FastAPI  GUI  pyqt PySimpleGUI  automation script  pathlib os  Machine Learning  TensorFlow Scikit OpenCV streamlit  Web Scraping and Web Automation  Requests Beautiful Soup Scrapy Selenium  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/python\/python-packages\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/vscode-tips\/": {
        
        "title": "vscode tips",
        "tags": ["Tool",],
        "content": "安装 1  brew install visual-studio-code   配置 进入配置  文件-\u0026gt; 首选项 -\u0026gt;配置 点击右上边的文件图标，进入打开设置（打开配置文件C:\\Users\\IA\\AppData\\Roaming\\Code\\User\\settings.json）  shortkeys 说明 本文以windows为例。\nbasic  F2: rename ctrl + p: open command options ` ctrl+ `` : open terminal ctrl + Shift + F: search ctrl+ K, then Z: zen mode esc esc: from zen mode to the normal editor view ctrl+B: Toggle sidebar  Navigate  F8: Navigate errors and warnings  File  ctrl+f4: close file ctrl+W: tab through open files  editor  ctrl + \\: split editor ctrl + Shift + T: open a Closed Editor ctrl + T: open a file Ctrl + Home: go to the beginning of file Ctrl + End: go to the end of file CTRL + K + W: Close all open editor tabs SHIFT+ALT+F: Format document  cursor  Ctrl+Shift+L: Create cursor on all occurrences Ctrl+Shift+Arrow key: Add the cursor alt+ mouse click at the position： Insertadditional cursors ctrl+ U: remove additional cursors  code ctrl + t: search current workspace sysmols ctrl + Shift + o: search current file sysmols ctrl + Alt + Up arrow/Down arrow.: . Add Multiple Cursors Shift + Alt + F: formart code Ctrl + Backspace： Delete Previous Word Ctrl + Shift + Right Arrow: select texts word by word from right to left Ctrl + Shift + Left Arrow: select texts word by word from left to right Ctrl + Shift + [: To fold the innermost uncollapsed region at the cursor Ctrl + Shift + ]: To unfold the innermost uncollapsed region at the cursor Shift + Alt:Column (Box) Selection Ctrl+K Ctrl+0 : fold all sections Ctrl+K Ctrl+J: unfold all sections CTRL + SHIFT + L: Add cursors to all matching selections CTRL + D: Add cursor to next matching selection Shift + Alt + Up/Down: Copy Line Up/Down ctrl+ shift + \\: Find a matching bracket shift + alt + → or ←: move and expand the selection shift+ alt+ A: add block comment ctrl+ /: add comment  line  alt +J: join lines ctrl +g: jump to line Alt + Up arrow/Down arrow: move line Ctrl + Shift + D: Duplicate Line Shift + Alt + Up/Down: Copy Line Up/Down ctrl + x: delete current line Ctrl+Shift+K: Delete an entire line CTRL + L: Select current line CTRL + Enter: insert line below CTRL + Enter + Shift: insert line above  extensions   Prettier - Code formatter\n  ESLint\n  Color Highlight\n  Bracket Pair Colorizer 2\n  GitLens\n  Live Share\n  VS Code Remote Development\n  Peacock\n  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/vscode-tips\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/principle-of-work\/": {
        
        "title": "谈谈做事的原则",
        "tags": ["职场","成长",],
        "content": "前言 这篇文章规划了很久，本来打算年前写，各种事情加上自己的拖延症，到现在才开始写。\n做事 如果说人的一生做什么？总结一下，可以划分两个方面：\n 做人 做事  这两方面很多人喜欢用一句话来指导自己：低调做人，高调做事。在这里简单地谈一下自己对做事的原则的一些思考。\n原则 关于做事，个人总结出来以下五个原则：\n 不要给自己设限 尊重事实与客观规律 站在巨人的肩膀上 正确的方向与方法 敏捷的行动  不要给自己设限 在中国历史上，从陈胜与吴广喊出\u0026quot;王候将相,宁有种乎\u0026quot;，在中国2000多年的历史，刘邦，刘裕，朱元璋以及太祖无不是从社会的底层走上权力的巅峰。在科技发展过程中 莱特兄弟并没有因为万有引力定律放弃研制飞机，终于发明世界上第一架飞机， 为后面的航空航天打下坚定的基础。\n上面都是正面的例子，下面以自己为例举一个反面的例子：在2016年微信小程序出来的时候，当时就很看好微信小程序的未来，但是由于自己是一个后端程序员，不会前端代码开发，当时就认为这是前端作的事情。其实在现实工作中，我们时常也会给自己设限：\n \u0026ldquo;这个东西没有弄过\u0026rdquo; \u0026ldquo;我不会这个\u0026rdquo; \u0026ldquo;这个不属于我的工作范围\u0026rdquo;  二战以后，世界总体和平，特别是信息技术发展，无论是对公司和个人都有很多的空间和机会去探索。如果给自己设限，会失去大量的机会，对不起这个人类历史上最好的时代。\n尊重事实与客观规律 无论怎么样，事实就是事实，过去了就是过去了。大部分都是普通人，不是乔布斯没有强大的现实扭曲力。\n尊重人性，牢记与践行以人本为的理念。\n不要心存妄想。这样才能脚踏实地。放弃不劳而获的想法，摈弃白日梦。走实用主义线路，这样才能建立长期心态。\n尊重客观规律，可以避免永动机，水变油等陷阱。以不会以个人之力去对抗系统。\n尊重事实与客观规律，当自己犯了错误的时候，有助于及早发现错误，避免错的更多，错的时间更长，降低了改错的成本。\n站在巨人的肩膀上 这里说明一下巨人的的肩膀是指不以个人或团体的意志为转移的环境及趋势等。举例如下：\n 孙子兵法上讲天时，地利，人和；在中国历史上有以少胜多的例子如赤壁之战，无不是在天时，地利，人和上占了先机 前人的经验与成果，这里不得不推荐google搜索 趋势，正面的例子是这几年很流行的话：站在风口上，猪都能飞起来；反面的例子就是大润发，其创始人抱憾出局：我赢了所有对手，却输给了时代 利用平台与工具，如开发微信小程序就充分利用微信的用户，场景，流量，商业基础设施等 大部分政策，如房地产市场  对于如何站在巨人的肩膀上，个人一点体会：\n 思想上作到拿来主义，行动方面要善假于物 避免不必要从0到1，如重复造轮子 合理地使用杠杆 不断学习与实践，提高认知水平与学习能力，保证可以站上更多巨人的肩膀  正确的方向与方法 \u0026ldquo;选择比努力重要\u0026rdquo;， 这是大家常说一句话，可见正确的方向与方法的重要性。\n这里引用曹大在其个人分享《成长的烦恼》中的一段话：\n 告诉大家一个秘密，很多企业快速膨胀的时候，那些中层为了自己的发展，快速扩张，快速启动新的项目团队，每个项目看上去都很有价值很有机会，然后大家都很忙碌很拼为了各种新的机会打拼，但是呢，其实从公司战略和格局来说，绝大部分都是实验品，甚至连实验品都不算，是领导暂时没功夫搭理的垃圾。等遇到市场风向逆转的时候，老板开始核查成本，这些乱七八糟的玩意，咔嚓嚓砍掉，你觉得不公平，你很拼很努力的为公司效力，你加班修改bug，解决线上问题，各种辛苦各种贡献，结果老板看了一眼，一文不值，真的是一文不值。\n  太多优秀的人才，在巨头公司里，连公司的核心价值和主要方向都看不清，在各种根本不重要的细枝末节里荒废了自己，最后在老板眼里一文不值。\n 只有方向对了，速度才有意义。\n其实在做事的时候，可以问一下自己几个问题：\n 我找到或想到了哪些方向与方法吗？ 这些方法可以起作用吗？ 还有没有更好的方法（选项）？  借助这几个问题，可以继续追问，找到事情与问题的关键所在。\n敏捷的行动 确定方向与方法后就是要行动。不然所有想法都是水中月，镜中花。这里自我批评一下，行动是我做的最差的一部分。\n敏捷的行动分解为以下几点：\n 不要等 试错 制定行动计划 迈出第一步 小步快行 轻装上阵 建立行动的正向循环 不断改进  不要等 不要等万事俱备才开始。时间是最宝贵的资源。在很多的情况下，等就是一种浪费。当处于等的情况，问自己几个问题：\n 是否需要等？ 哪些事情现在就可以去做？  以自己为例，2014年初准备要学习玩一下股票，但是自己连一个股票帐号都没有开。直到2015年4月在一个证券公司，然后在2015年5月进场了，好在当时买的股票是海康威视，后面解套了。（这里强调一下，这里只是举一个例子说明，投资有风险，入市须谨慎）\n试错 不要怕犯错。错误是一种收获，那么低成本试错就是一种高收益的回报了。\n避免完美主义。Done is better than perfect。\n制定行动计划 制定行动计划就是规划行动线路图，其关键要点是milestone与deadline，制定原则参考SMART原则。\n迈出第一步 迈出第一步，那么第一步从哪里开始？可以根据情况从以下三种选择一个即可：\n 从最容易的开始 从最基础的开始 从最熟悉的开始  小步快跑 以互联网产品为例，讲究的就是用最低的成本、最小的规模、最快的速度去尝试一个粗糙的东西，然后快速的拿到市场上去尝试，如果好，就趁热打铁，继续做下去，并把它做大做强。如果不好，就赶快转换方向。\n研发领域敏捷开发就是这方面的体现，这里不展开。\n轻装上阵 卸下包袱：避免外界的干拢，保持专注；事件一件一件做，避免多项事情并行。\n充实精力：主要是两个方面身体与时间；健康的身体永远都是宝贵的财富；保证合理的时间投入到具体行动中。\n放松心态：告别悲观与焦虑，保持积极乐观的心态，悲观者往往正确,乐观者往往成功，在行动过程中作一个乐观者成功的概率会加大很多。\n建立行动的正向循环 行动是一个长期的行为，贵在坚持，需要建立一套适合自己的激励机制。 简单总结为一句话：寻找动力，培养兴趣，养成习惯，实现自我驱动。\n不断改进 只有不断进步的行动，才会更好的效率，这需要在执行过程中不断优化每一个方面及过程。\n小结 不要给自己设限是解决做什么的问题，通过打破界限，扩大做什么的范围，为做什么提供更多的可能与选择的空间。\n站在巨人的肩膀上是解决在什么基础上及在什么环境下做事的问题。\n正确的方向与方法是解决怎么做的问题。\n敏捷的行动是解决做成事的问题。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/principle-of-work\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/pow-is-out\/": {
        
        "title": "PoW过时了吗？",
        "tags": ["BlockChain",],
        "content": "ETC受到51%攻击 最近ETC受到51%攻击，值得注意是：ETC是受到51%攻击的币种中市值最高的。 先谈谈ETC受到51%攻击原因。ETC采用PoW共识机制，现有PoW共识天然存在51%攻击的风险，真实发生ETC的51%攻击原因如下：\n 由于ETC价格大跌，算力下降，降低了发起了51%攻击的成本 由于矿场存在，实现算力大规模的垄断，同时算力切换方便，为发起51%准备了客观条件  反想一下，ETC市值是前20名，那些小币种，山寨币们都是下一个待宰的羔羊。 连ETC都受到攻击，那么PoW过时了吗？\n下面简单聊一下如何改善PoW。\n如何改善PoW dPoW dPoW方案来自Komodo（大家自行google）。 其要点就是将一段时间内的交易hash发送到BTC，在这种情况下，如果要发动51%攻击需要达到攻击BTC的算力要求，提高了攻击成本。\n第二算力有效原则 这个想法来源于第二价格密封拍卖，主要是为了打击算力竞争。\n算力限制 限制算力过强的节点，避免算力的复制，聚集，从而导致垄断，保证算力的去中心化。关于算力限制的方案欢迎交流。\n结合VRF 利用VRF的随机性，每次随机选择一批节点参与PoW。\n扩展Work的内容 现在基本上所有的PoW都上纯计算，浪费大量的算力，这些算力都成为了沉没成本。发现不少项目将PoW中Work用于AI计算。\n总结 PoW是一个伟大的共识创新，创造性地解决了拜占庭容错问题。PoW并没有过时，PoW会不断发展与改善。\n参考  第二价格密封拍卖  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/pow-is-out\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/cache-101\/": {
        
        "title": "Cache 101",
        "tags": ["arch",],
        "content": "前言 在现在互联网系统中cache无处不在，无时不用。\n定义 wiki定义如下：\n a cache is a hardware or software component that stores data so that future requests for that data can be served faster;\n 工作原理 一句话：通过将源数据缓存Cache，实现直接通过Cache访问数据。\n属性与指标 关注的cache属性与指标：\n TTL(Time to live) Cache capacity Eviction Policy，具体如LRU (Least Recently Used), LFU (Least Frequently Used), MRU (Most Recently Used) cache conflict cache hit ratio cache coherence cache scalablity  类型 cache更新策略 根据cache更新策略分为以下几类：\n Write Through Cache Write Back Cache Write Around Cache  存储类型 根据应用场景，常见类型如下：\n L1 cache L2 cache L3 cache Memory cache SSD cache disk cache network cache （CDN）  cache与程序关系 根据cache与程序关系分为：\n Local cache External caches  常用cache产品 常用cache产品如下：\n redis Memcached VoltDB Aerospike DBS  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/cache-101\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/%E5%85%B3%E4%BA%8E%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%B1%E8%AF%86%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83\/": {
        
        "title": "关于区块链共识的一些思考",
        "tags": ["Distributed","BlockChain",],
        "content": "说明 前面写一篇关于分布式系统的文章，但是没有考虑拜占庭问题，所以聊聊区块链共识技术，在这个过程看看比特币是如何解决拜占庭问题和共识问题。\n定义 区块链是什么？这个问题有太多的回答。\n 区块链是一个由全体联网节点共同维护并持有同一账本的分布式数据库，它通过算法来达成共识，在无需信任的各节点中构建一个无单一故障点或控制点的去中心化可信系统\n 所以在技术上区块链的本质是分布式帐本技术(DLT)。\n重要性 Why Decentralization Matters这篇文章从互联网发展历程与面临问题说明去中心化重要性。\n去中心化重要性来自去中心化带来的影响与作用，具体如下：\n 去中心化可以降低垄断的可能性，是一种对抗垄断的重要方式 去中心化提供高可用性 去中心化对抗DDos 去中心化可以让人人参与，权力下放 去中心化是让数据归还用户，保护隐私的重要技术手段之一 去中心化消除中间环节，提高效率 去中心化与中心化并不是对立，可以相互补充 去中心化能够解决中心化无法解决的问题，如微信流控算法，并没有采用全局，而由节点根据延迟参数调整，另外是5G带来的高速传输与海量数据需要去中心化来来解决  去中心化解决问题  提供全球开放的分布式数据 提供不可更改的数据库 提供trustless的基础设施 基于以上三点的业务的需求  思考模型 如同前面的分布式系统一样，对于公链（去中心化系统）问题，也可以分为以下几个子问题：\n 在什么环境下？ 有哪些节点参与？ 通过什么样的共识算法？ 使什么业务？ 达成什么样的容错要求？  总结一句话：在什么环境下，有哪些节点参与，通过什么样的共识算法，使什么业务达成什么样的容错要求。\n下面就这五个问题展开说明。\n环境 大部分去中心化系统的环境要点如下：\n 异步网络模型 网络结构是P2P网络 网络传输是不可靠的 系统异常是常态 并发 缺少全局时钟  (Ps:这里不展开说明了，谈谈对分布式系统的一些思考)\n节点 节点准入方面  节点自由加入与退出 节点需要通过PoW测试才能加入 节点需要PoS持仓才能加入 节点需要质押才能加入  节点角色  节点平等，无角色任何差异如比特币 节点分为超级节点，见证节点如EOS  节点数量  不限数量，如比特币，以太坊 指定数量，如EOS指定为21，steemit指定数量为11  节点可信  存在不可信的作恶节点 可信节点（算力）一定多于作恶节点（算力）  节点配置  机器性能波动大 网络带宽波动大 节点分布在全球各地 节点配置不受控 节点之间差异大如算力，POS投票权重  节点经济原则  99.99%以上节点是趋利 节点受激励引导 节点受惩罚限制 节点之间存在博弈与竞争 节点不会作出投入成本大于产出收益的选择  共识算法 一定要摆脱传统分布式思想的限制。要在经济，竞争，博弈，协议等多方面有效结合。\n从上图可以看出，传统分布式共识算法在整个共识里面只占很小一部分。 共识算法是区块链技术上的核心。\n不得不说，PoW是另一种形式实现拜占庭容错，是比特币最大的亮点。\n属性 一个科学共识算法必须同时满足以下四个属性：\n Agreement Validity Integrity Termination  这四个属性从四个方面规范共识算法的要求，也为我们提供分析共识算法四个不同的视角。\nAgreement  Every correct process must agree on the same value.\n 这是实现一致性必须要做到的要求：每个节点必须达成一致。 bitcoin通过以下几点实现该属性，具体如下：\n 在选主方面选择最强算力原则，保证具体高度的区块的一致性（以最快算出的为准） 在链分叉情况下选择最长链，解决网络分化等原因可能出现的分叉问题  Validity  If all the correct processes proposed the same value v, then any correct process must decide v.\n Validity是为了防止这种情况的出现：一些节点无论提议什么值，本节点一直提交NULL。在bitcoin这种行为可以理解为自私挖矿行为。\nbitcoin通过以下几点实现该属性，具体如下：\n 算力不可复制 随机性加大自私挖矿的成本 最长链确认由各节点自行确认 时间戳确认  Integrity  No Node decides twice.\n 保证共识得到一致性不可逆，不可被修改。那么在这成共识过程中有许多操作需要进行限制。 bitcoin通过以下几点实现该属性，具体如下：\n 链式结构 算力要求 难度提升 多节点竞争  Termination  Eventually, every correct process decides some value.\n Termination是一个liveness属性，bitcoin通过以下几点实现该属性，具体如下：\n 通过激励吸引大量节点参与，保证有节点来完成出块 出块时间周期设置10分钟  业务 去中心化带来业务的形态的变化，现列举部分业务如下：\n 去中心化交易所 去中心化网络平台 去中心化计算平台 去中心化存储 去中心化CDN 去中心化数字货币 去中心化协议 去中心化跨链 去中心化金融科技DeFi 去中心化通信  容错要求 对于去中心化系统，对应的容错要求是DCS定理。\nDCS定理 如同CAP定理一样，DCS定理是指在一个公有链系统中不可能同时满足以下三个条件：去中心化（Decentralized）、一致性（Consistency）和可扩展性（Scale）。\n去中心化 去中心化是指任意节点可以加入与退出，整个网络不受任何人控制。\n一致性 与上面CAP的一致性类似，不过应用中更加偏重安全如防范双花攻击。\n可扩展性 可扩展性是指TPS能够实现提高。\n关于DCS这三者之间的tradeoff，更多参考The DCS Triangle\n小结 区块链的共识现在还处于探索阶段，并不像分布式系统共识（不考虑拜占庭问题）已经成熟。区块链的共识在不断探索与发展中，未来会有更多的新型共识出来。\n参考  Why Decentralization Matters The DCS Triangle SoK: Consensus in the age of blockchains DAGOR：微信微服务过载控制系统 A Brief Tour of FLP Impossibility Agreement with Satoshi – On the Formalization of Nakamoto Consensus Yuval Noah Harari: Why fascism is so tempting and how your data could power it | TED Talk Tech C.E.O.s Are in Love With Their Principal Doomsayer 谈谈对分布式系统的一些思考 Algorand’s Instant Consensus Protocol 区块链到底有什么了不起 BitTorrent 公有链的基本挑战 Blockchains don’t scale. Not today, at least. But there’s hope. Consensus Protocols of Distributed Ledger Technology  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/%E5%85%B3%E4%BA%8E%E5%8C%BA%E5%9D%97%E9%93%BE%E5%85%B1%E8%AF%86%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/distributed-theory\/": {
        
        "title": "谈谈对分布式系统的一些思考",
        "tags": ["Distributed",],
        "content": "说明 本文限定在分布式系统不考虑拜占庭问题。即所有节点都是可信的。\n定义 分布式系统是多个节点协作完全一个共同的业务。\n重要性 分布式理论的重要性毋庸置疑，一句话总结：没有分布式理论，就没有现在互联网与云计算。在分布式系统实践过程中离不开分布式系统理论指导，对其重要性打个比方：分布式系统理论是分布式系统实践过程中地图与导航。\n分布式主要解决问题 分布式主要解决以下几个问题：\n 解决SPOF问题，满足高可用性需求 解决Scale out问题，满足扩展性需求 解决数据分布问题，满足业务的需求  分布式是解决方案也是问题 一般情况，人们为了解决一个问题，往往会引入一个新的问题。试想如下： 由于SPOF存在，再加入一个节点作为备份。这样确实提高了系统高可用性，但是有以下新问题：\n 如何检测节点状态？如何快速检测节点状态？ 如果检测主节点失败，备节点如何进行切换？ 主备节点如何同步数据？ 网络分化出现双主，如何避免与处理？  思考模型 对于分布式系统理论，分为以下几个子问题：\n 在什么环境下？ 有哪些节点参与？ 通过什么样的共识算法？ 使什么业务？ 达成什么样的容错要求？  总结一句话：在什么环境下，有哪些节点参与，通过什么样的共识算法，使什么业务达成什么样的容错要求。\n下面就这五个问题展开说明。\n环境 分布式系统环境特点如下：\n 从网络同步模型上分为同步网络，异步网络，半同步网络三种 系统异常是常态 网络传输是不可靠的 并发 缺少全局时钟  网络模型 同步网络是指网络带宽与延迟都是可以保证的。实际上现在IP网络都不属于这种，满足这种的网络是ATM网络（注意不是我们常见的提款机ATM）。\n异步网络则是指网络带宽与延迟都不确定，在异步网络发送的报文会丢失。我们正在使用主的IP网络属于这种。\n部分同步网络处于这两者中间。\n异常 机器异常通常有以下几种情况：\n 电源 机器元器件故障如内存，硬盘 操作系统故障 软件故障与程序bug 资源耗尽，如内存，CPU，硬盘空间，网络带宽等  网络传输不可靠 网络传输不可靠主要体现以下几个方面：\n 丢包，传输成功不确定性 延时，延时时间不确定性 重传与报文重复 乱序  并发 如同操作系统中多线程并发，分布式系统多节点在并发。但是分布式系统的并不能像多线程上通过操作系统的锁机制来处理并发，在分布式系统实现一个锁比操作系统上难度大多了。\n缺少全局时钟 一个人有一只表时，可以知道现在是几点钟，而当他同时拥有两只时却无法确定。分布式系统不同节点很难有相同的时钟。\n节点 节点数量 节点数量，在实践过程中，至少两个，常见三个节点，部分情况五个节点。\n节点角色 以raft为例可以分leader，follower，candidate等角色。\n节点可信 全是可信节点，不存在作恶节点。\n节点准入 主要方式是通过配置管理指定节点。\n节点配置 虽然节点之间机器配置，网络带宽，地理位置都会存在一定程度上的差异，但是可以控制。\n共识算法 共识算法是核心。最常见共识算法如下：\n Paxos Raft Zab Primary-secondary Quorum  属性 一个科学共识算法必须同时满足以下四个属性：\n Agreement Validity Integrity Termination  这四个属性从四个方面规范共识算法的要求，也为我们提供分析共识算法四个不同的视角。\nAgreement  Every correct process must agree on the same value.\n 这是实现一致性必须要做到的要求：每个节点必须达成一致。\nRaft通过以下几点实现Agreement，具体如下：\n 整个系统保证最多只有一个leader 同步流只有一个方向：从leader到follower 节点crash后从leader同步数据 重新选主之后的冲突解决机制，如选主过程选择拥有最新数据的candidate为新主  Validity  If all the correct processes proposed the same value v, then any correct process must decide v.\n Validity是为了防止这种情况的出现：一些节点无论提议什么值，本节点一直提交NULL。\nRaft通过以下几点实现Validity，具体如下：\n 整个系统保证最多只有一个leader 同步流只有一个方向：从leader到follower 节点crash后从leader同步数据  Integrity  No Node decides twice.\n 保证共识得到一致性不可逆，不可被修改。那么在这成共识过程中有许多操作需要进行限制。以Raft为例，其通过以下几点实现Integrity，具体如下：\n 节点都是可信的，节点不作恶 节点自我约束，只会commit一次 节点选leader过程中一次只能投一个candidate leader节点从不会覆盖自身本地日志中已经存在的条目 在存在两个leader情况下（一个真leader一个假leader）,能够根据item和index识别真假leader  Termination  Eventually, every correct process decides some value.\n Termination是一个liveness属性，可以理解对应CAP定理中可用性（Availability）。 对应Raft体现如下：\n 多数派保证能够容忍一定的节点crash leader与follower通过心跳包实现检测 检测到leader crash，follower发起新一轮选主，保证系统正常运行 正常工作的时候，由itemId及indexId来保证一个周期的结束 这样就基本保证多数节点正常工作，整个系统能够保证有且只有一个leader（选主期间除外），另一种表达是保证系统最多只有一个leader。  （PS：建议可以读一下raft论文，读完一定会有新的理解。）\n业务 分布式业务这里列举如下：\n 分布式存储，如GFS 分布式计算，如MapReduce 分布式锁，如Chobby 分布式数据库，如BigTable，Spanner 分布式ML，如TensorFlow分布式 分布式MQ，如Kafka 分布式负载均衡，如Daglev 分布式缓存，如分布式redis, Memcached  容错要求 对于分布式系统，其容错要求对应是CAP定理。在实际应用过程选择容错性要求根据业务来决定。\nCAP定理 CAP定理指出，分布式系统不可能同时满足以下三个条件：一致性（Consistency）、可用性（Availability）和分区容错（Partition tolerance）。\nCAP里面三个选项是不同角度的容错性。\n一致性 多节点加上网络的不可靠性，这样多节点的不一致状态是不可避免的。如同TCP协议，解决了网络传输不可靠性，分布式共识算法是达成一致性的方法。\n一致性分为以下几种类型（来自百度的《分布式系统原理介绍》）：\n 强一致性(strong consistency)：任何时刻任何用户或节点都可以读到最近一次成功更新的副本数据。强一致性是程度最高的一致性要求，也是实践中最难以实现的一致性。\n  单调一致性(monotonic consistency)：任何时刻，任何用户一旦读到某个数据在某次更新后的值，这个用户不会再读到比这个值更旧的值。单调一致性是弱于强一致性却非常实用的一种一致性级别。因为通常来说，用户只关心从己方视角观察到的一致性，而不会关注其他用户的一致性情况。\n  会话一致性(session consistency)：任何用户在某一次会话内一旦读到某个数据在某次更新后的值，这个用户在这次会话过程中不会再读到比这个值更旧的值。会话一致性通过引入会话的概念，在单调一致性的基础上进一步放松约束，会话一致性只保证单个用户单次会话内数据的单调修改，对于不同用户间的一致性和同一用户不同会话间的一致性没有保障。实践中有许多机制正好对应会话的概念，例如php中的session概念。可以将数据版本号等信息保存在session中，读取数据时验证副本的版本号，只读取版本号大于等于session中版本号的副本，从而实现会话一致性。\n  最终一致性(eventual consistency)：最终一致性要求一旦更新成功，各个副本上的数据最终将达到完全一致的状态，但达到完全一致状态所需要的时间不能保障。对于最终一致性系统而言，一个用户只要始终读取某一个副本的数据，则可以实现类似单调一致性的效果，但一旦用户更换读取的副本，则无法保障任何一致性。\n  弱一致性(week consistency)：一旦某个更新成功，用户无法在一个确定时间内读到这次更新的值，且即使在某个副本上读到了新的值，也不能保证在其他副本上可以读到新的值。弱一致性系统一般很难在实际中使用，使用弱一致性系统需要应用方做更多的工作从而使得系统可用。\n 为什么一致性很重要？借用Jakob Nielsen的一句话:\n Consistency is one of the most powerful usability principles: when things always behave the same, users don’t have to worry about what will happen.\n 可用性 可用性指服务正常可用的概率。一般用数据量化指标为以下几个：\n 服务正常可用的概率，如常说4个9 MTBF（平均故障间隔时间） MTTR（平均故障恢复时间）  分区容错性 分区容错性是指系统在网络分化的情况下仍然能正常对外提供服务。\n应用 遵守以不变应万变的原则，在一般工程应用过程中，先确定不变，以etcd为例：\n 在异步网络环境，机器存在一定故障 一般3个节点，分布在同两个IDC机房 提供分布式KV服务 容错性方面从CAP中取CA两项  确定这些之后，我们可以选择合适的共识算法及其实现。\n后记 将分布式系统分解五个小问题，除了共识是一个难点，其他四个问题都容易理解，这样有利于我们解决问题外围，有一个清楚的背景知识和前期的准备，有利于理解与学习共识算法。作为一个思考框架，围绕框架不断地完善，如深入分析分布式业务和提高分布式系统的性能。\n个人能力有限，有什么不足与错误，欢迎指正。\n参考  Consensus raft动画演示 raft论文 寻找一种易于理解的一致性算法（扩展版） Raft Distributed Consensus Overview 你矜持，你活该 Distributed systemsfor fun and profit 分布式系统相关挑战 My Distributed Systems Seminar\u0026rsquo;s reading list for Spring 2020 A Thorough Introduction to Distributed Systems  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/distributed-theory\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/comware-rd\/": {
        
        "title": "大型系统软件Comware研发总结",
        "tags": ["闲谈乱扯","研发管理",],
        "content": "前言 前几个月写一篇关于研发管理的文章。在那篇文章提出一个简单的思考框架，并没有实际案例的分享及深度分析。所以在这里以华三Comware研发为例，结合思考框架谈谈自己的一些理解与想法。\nComware 开始之前，先介绍一下Comware。其主要要点如下：\n 整个系统代码量超过了1000万行（开源代码除外） 巅峰时期开发人员1000左右 支持设备类型超过100多种，同时支持各种丰富的网络特性 性能与可用性要求高，需要满足欧美高端市场（金融，国防等）要求及互联网大流量的冲击 作为公司的中台，支撑公司绝大部分产业线（安全，路由，交换，云计算等）  下面我们就一一展开说明。\n业务 以业务为中心。Comware作为一个网络操作系统，主要要求如下：\n 充当网络设备的大脑，为各种网络设备业务提供平台（中台）能力与服务 承载各种网络业务，并动态满足不同网络业务的要求及变化 保证整个系统 高可用性，高性能，可维护性，可扩展性，安全性等  文化 由于历史上的原因，整个研发文化总体上源于华为，稍有调整。具体要点如下：\n 质量为上 结果导向 研发三权分立 追求效率 鼓励创新 公开  关于科技公司的文化，推荐Netflix文化:自由与责任\n团队 团队是从人的视角出发。要以人为本啊。\n团队梯队合理清楚，按技术水平划分具体如下：\n 开发上岗人员 维护上岗人员 开发负责人 系统扩展组 系统组 架构组  团队组织划分以业务导向，按照不同的业务划分不同大组，独立进行代码管理。在各个大组一般分为开发与维护两个方面进行人员动态调配。\n团队建设主要是大组每周定期培训，鼓励分享，除此之外针对不同岗位有专项培训，如项目管理，代码管理。\n架构 架构不是我们常说的架构，这里的架导指导代码的工作（架构从事的角度出发）。\n选择开源，拥抱开源，不要重复造轮子 不得不说2008年开始预研下一代网络操作系统，当时的团队放弃vxwork，选择了开源linux，而且作到取自开源，高于开源，只使用linux基本组件（文件管理系统，内存管理系统，进程调度等），重新移植与修改协议栈，实现分布式网络协议，扩张SOCKET类型。采用Linux好处多多，具体如下：\n 充分吸引Linux开源精华 Linux开源发展路径，决定Linux便于改造与优化 与Linux一起升级，如内核2.6升级到4.x版本 方便开源引入支持，如移植wireshark， python Linux在服务器大量应用，业界有大量人才  合法合规 合法就不用多说了。注意的是要考虑到不同的国家与地区的差异。 合规方法最近的例子就是2017年百度要求内部全面停止使用React/React Native。利用开源的Linux作为基础开发商业操作系统，就不得不遵守开源协议。\nKISS原则 关于KISS原则，架构设计通用原则，有太多说明，这里不展开。\n开放性 对外开放接口，如OAA（Open Application Architecture，开放应用架构），这样有以下好处：\n 对公司内部来说，降低了耦合 对外部合作方来说，方便不同厂商系统集成 对客户来说，提供了更多的选择以及DIY能力 开放与释放了平台的能力  分层与分解 整个系统采用分层设计有如下优点：\n 可以分离系统不同方面的设计关注点，使得同一时刻设计者可以集中精力考虑较少的相于因素，封装和分解了相关的复杂性，增加了系统设计上的清晰度； 减少了系统的耦合和依赖，提高了内聚性，增加了潜在的代码重用性，提高了低层的代码重用度 层与层之间需要清晰的接口，有利于实现面向接口编程，而不是面向实现编程 一些层的实现可以被替换或扩展，对整体的架构影响很小 层次清晰，有利于多个小组并行开发  分解主要体现是模块化，有如下优点：\n 为整体架构提供最小单元 带来了模块化管理，模块化提供交付件（cli插件，daemon等），方便模块化升级，模块定制，模块化诊断 模块化隔离，如实现进程间隔离 统一模块间依赖管理 便于将一些基础组件及功能模块化 方便问题定位，如内核定位踩内存问题 便于模块信息聚合  测试独立性 个人一直以为一个好的测试人员具有以下素质：\n 业务方面做到熟悉，并能不断深入 细心保证执行方面到位 独立性，测试并不是帮助开发，而验证开发成果与补充开发的不足 发散测试，保证测试的完整性，避免漏测，守好产品最后一道门  需要在一个公司层面将测试的独立性体现出来，所以新增一个鉴定测试部门。\n软件工程 作为大型系统软件，离不开软件工程的指导，在整个过程必须科学践行软件工程。\n工具与效率 基础设施投入，如引入高性能服务器提高编译速度（1000万行c语言速度慢真的要半天），这里说一下越高频越重要。每一次修改代码都需要编译。 开发代码review工具，方便协作。\n资源统一管理 主要体现以下几个方面：\n 系统资源（如LIPC端口）统一分配与管理 模块进程统一管理 大块内存申请统一管理 统一错误码  控制集中式，处理分布式 在分布式架构上，采用控制集中式，处理分布式，并不追求用复杂的分布式协议来实现，够用就好。整个模型简单，大大降低了开发难度，提高系统可靠性。\n复杂性 认识到软件开发的复杂性的重要性。在软件开发过程，要先假设软件的各种复杂情况，具体如下：\n 假设一定会有错误，错误一定会发生 假设过程会出错 假设需求会变更，需求会增加 假设团队成员有变动 假设未来会更新线上代码 假设未来需要解决线上问题  这些假设会增加软件开发的复杂性，但是可以通过对假设的证明与排除来降低复杂性\n方案评审 公开评审，鼓励技术方案PK。\n预研 预研由market部门负责，由市场来定义未来需求与方向。\n度量不可少 建立度量体系。大的方面分为以下几个方面：\n 市场度量 团队度量 个人度量 项目度量 代码度量  减少对人的依赖  加强流程建设 不断用机器及工具代替人 团队人员互备  文档  重视文档，无论对外还是内部文档，文档就是沟通，文档就是协作（需求文档化，架构文档化，设计文档化，项目流程文档化，交付文档化）  代码 代码是研发最终交付的核心，是架构的实体，是业务的载体，是测试的对象，是公司的核心资产。\n版本化 这个是老生常谈的问题，但是很基础，很重要。\n设计先行 代码之前，设计先行。正如以前说过一句话：从长远看，选择比努力重要，数据比算法重要，架构比实现重要。\n代码规范是行动准则 这是很好的一份代码规规范。还是一个保证得到执行的规范。很多公司都 倡导编程规范。但是实际并不能落地，这里有各种各样的原因。\n这里分享一下有利于编程规范得到真正落地的建议：\n 规范意识培训 提供规范检查的工具(这个最重要) 将规范执行纳入考核(需要建立一套对应体系) 代码review，review内容包括是否符合代码规范  必不可少的单元测试 交付系统在逻辑上由一个个函数构成，以函数为单元开展测试。\n不止代码review，还有代码鉴定 对代码进行鉴定，估计国内就此一家吧。在保证代码鉴定团队的权威下，不仅要求是bug free，而且要求代码信雅达。只有高标准的要求，才会有高质量的代码。\n关于代码review的关注点，以前写过一篇文章：C语言代码 review的总结\n注重初始代码质量 这是开发顺序决定的，由少数核心开发人员完成，完成基础模型的开发。这样的好处，开始代码质量高，不要让系统输在起点上，同时优秀的代码作为后面的大量项目开发的参考与标杆。\n接口优先，接口先行 接口（API）比实现更重要。在编码之前，接口完成设计并通过评审。\n避免以忙治乱 工作总有人喜欢用了自己的勤劳来掩盖自己的愚蠢。\n说明 在不同的公司，不同行业，不同阶段研发管理都要针对性调整，不求多高大上，但求实用，只有管理规定能够落实，才能真正提高效率，增强团队的战斗力，解决具体业务的问题，满足业务的需求。\n参考  [如何看待百度要求内部全面停止使用React/React Native](如何看待百度要求内部全面停止使用 React / React Native?)  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/comware-rd\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/arch\/%E8%AF%B4%E8%AF%B4%E5%9C%A8%E4%B8%8D%E5%90%8C%E8%A1%8C%E4%B8%9A%E7%9A%84%E7%BC%96%E7%A8%8B%E4%BD%93%E9%AA%8C\/": {
        
        "title": "说说在不同行业的编程体验",
        "tags": ["职场","编程",],
        "content": "回想起来，本科毕业以来，在五家公司呆过，经历四个行业，在这引起行业编程体验各有不同，总结起来就下面四句话：\n嵌入式行业：面向DataSheet编程\n通信行业：面向标准编程\n互联网行业：面向变化编程\n区块链行业：面向资金编程\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/arch\/%E8%AF%B4%E8%AF%B4%E5%9C%A8%E4%B8%8D%E5%90%8C%E8%A1%8C%E4%B8%9A%E7%9A%84%E7%BC%96%E7%A8%8B%E4%BD%93%E9%AA%8C\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/business\/about-weixin-miniprogram\/": {
        
        "title": "说说微信小程序",
        "tags": ["商业","Internet",],
        "content": "小程序在2018年确实火了，除了先行的微信小程序，后面紧接着跟着了蚂蚁金服的小程序，今日头条的小程序。这里先表明一下自己的立场，从微信小程序诞生开始我就看好微信小程序。这里肯定有人说我是事后诸葛亮，这里有图为证。\n小程序让微信成为生活的操作系统 如同操作系统为应用程序提供内存资源与管理、进程资源与调度、输入与输出设备、网络传输、文件系统、用户交互等基本功能，微信生态为小程序提供了以下要素：\n 用户 场景 商业基础设施，如微信支付，消息服务，基于微信社交的信任关系 这些大大降低商业成本和开发成本。  美团，微博，拼多多等公司都在微信上开发小程序， 体现了微信小程序上领先地位。\n如何发现小程序的机会 有很多人利用小程序闷声发大财，那么怎样发现小程序的机会？发现小程序的方式有很多，这里分享其中一种：参考chrome网上应用店，当然也可以从ios app store上找到新的机会。 更多参考app，详见链接。\n这么多分类了，从各个分类热门应用中可以找到一些启发。这里说明一下，这只是其中一种方式，还有很多其他的方式来挖掘小程序的机会。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/business\/about-weixin-miniprogram\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/secret-sharing\/": {
        
        "title": "说说私钥保护技术",
        "tags": ["BlockChain","Cryptography",],
        "content": "前言 私钥在区块链系统中代表是什么？私钥是钱。钱包的本质就是私钥。谁控制了私钥谁就控制对应钱包的数字资产，谁丢失了私钥也就相当于丢了对应钱包的数字资产。\n因此，在区块链系统中如何保护私钥一直都是重要的问题。\n保护私钥一直都要解决以下问题：\n 用户体验 私钥备份与存储 私钥安全（攻击、泄漏、盗取）  私钥助记词化 私钥数学本质是一串数字：\n用户体验极差，那么一长串数字怎么记，每次使用都是一个大麻烦。 所有就有只要玩过数字货币的人都清楚的助记词。这一部分改进如同汇编对二进指定的优化。\n私钥加密 对于私钥内容进行加密，最典型例子就是key-store。\n共用私钥 这里面的技术主要是BIP-44。在数字货币钱包里面得到应用， 避免每一个数字货币地址都要维护一个私钥。如果数字货币满足BIP-44规范， 就可以通过一个私钥来控制多个钱包。\n私钥隔离 用冷钱包来实现与网络隔离，避免私钥被盗取或泄漏。\n私钥分片 私钥分片主要采用Shamir\u0026rsquo;s Secret Sharing技术。其技术原理如同藏宝图分成好几分份,这是多少电影与电视剧中出现的情节。\n原理：\n一个数学公式：yy = ax*x + b * x + c\n其中，c为私钥，当然中实际过程可以认为是保密的数据。 a，b这两个参数作为具体分片规则的描述。\n由上面公式可知，该公式对应一个双曲线。如果知道这个双曲线三个点的坐标，通过解方程组得出a，b，c的值。\n该技术有以下优点：\n 该方案允许私钥拥有制定分片的规则。可以对同一个私钥采用不同的分片规则。拥有分片规则制定权，可以对分片对象加以管理，如添加分片，删除分片。 在没有不知道分片规则之下，通过任何一个分片都不能破解获取私钥。只有对应数量的分片在一起才能获取私钥和分片的规则。  具体应用如下：\n 私钥等敏感数据分割保护 多方验证 数据分享  参考  Shamir\u0026rsquo;s Secret Sharing Divide and Manage Secret Data Securely With Shamir\u0026rsquo;s Secret Sharing zeropass Threshold Signatures: The Future of Private Keys A beginner’s guide to Shamir’s Secret Sharing 私鑰分割 — Shamir’s Secret Sharing  ", 
        "url": "http:\/\/myself659.github.io\/post\/secret-sharing\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/exchage-safe-asset\/": {
        
        "title": "数字货币交易所安全体系-资产篇",
        "tags": ["BlockChain","Secure",],
        "content": "前面，简单介绍了数字货币交易所的安全体系，这一篇主要说说一下资产安全的一些要点。\n如果将一条公链比作一个银行的话，当然这个银行是去中心化银行，那个各个交易所的节点就相当于银行的网点。这个节点有以下功能：\n 帐本数据同步 用户资产托管 充币与提币  资产安全主要分为以下几个方面展开说明，具体如下：\n意识 意识，意识，意识！其实意识就是一种天赋，只是我们没有注意到吧。\n有些区块链的项目居然不知道私钥是何物。很多人会说这是不是搞技术不知道而已。 其实这是安全意识不到位。\n意识教育与培养一定要先行。\n帐本数据同步 帐本数据主要是节点数据同步，具体关注点如下：\n 节点连接节点的确认 避免站错队 分叉 重放攻击防护 孤块 网络分化 帐本同步节点故障，多节点备份  资产托管 资产托管的核心就是私钥，要点如下：\n 采用冷钱包管理私钥 热钱包管理策略（存活周期，资金金额控制，密钥管理） 私钥存储管理（多人多份多地） 多地址分散（不要把鸡蛋放在一个篮子里）  充币与提币 充币与提币都是有关托管资产的交易。\n 合理的交易确认数 充币提币的用户验证 交易的不确定性处理办法如交易得不到确认 分叉时关闭充提币功能  监控 资金动向监控也是不可或缺的，要点如下：\n 对首次提币地址及用户监控 保证监控的高可靠性 充币与提币数据分析 大额充提币的监控及确认  差异化 对于不同类型的资产需要具体问题具体分析。 如以太坊专门对基于智能合约的数字资产进行审计与防范，具体参考ERC20，这里不展开。\n后记 对于资产安全，有什么新的想法与意见，欢迎交流！\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/exchage-safe-asset\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-digitwallet-strategy\/": {
        
        "title": "数字货币钱包产品定位与战略",
        "tags": ["BlockChain",],
        "content": "4月份写一份关于数字货币钱包的分析，欢迎交流与指正。\n数字货币钱包产品定位与战略\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-digitwallet-strategy\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s-monitor\/": {
        
        "title": "安装与应用Prometheus监控Kubernetes集群",
        "tags": ["Docker","Kubernetes",],
        "content": "安装Prometheus RBAC设置,获取创建集群角色权限 1 2 3 4  ACCOUNT=$(gcloud info --format=\u0026#39;value(config.account)\u0026#39;) kubectl create clusterrolebinding owner-cluster-admin-binding \\ --clusterrole cluster-admin \\ --user $ACCOUNT   注意：如果集群部署在google cloud上需要先执行这一步。\n创建Namespace 1  kubectl create namespace monitoring   创建角色 脚本内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRole metadata: name: prometheus rules: - apiGroups: [\u0026#34;\u0026#34;] resources: - nodes - nodes/proxy - services - endpoints - pods verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] - apiGroups: - extensions resources: - ingresses verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] - nonResourceURLs: [\u0026#34;/metrics\u0026#34;] verbs: [\u0026#34;get\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: prometheus roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: prometheus subjects: - kind: ServiceAccount name: default namespace: monitoring   执行创建角色脚本：\n1  kubectl create -f 01-clusterRole.yaml   配置 脚本内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149  apiVersion: v1 kind: ConfigMap metadata: name: prometheus-server-conf labels: name: prometheus-server-conf namespace: monitoring data: prometheus.rules: |- groups: - name: devopscube demo alert rules: - alert: High Pod Meory expr: sum(container_memory_usage_bytes) \u0026gt; 1 for: 1m labels: severity: slack annotations: summary: High Memory Usage prometheus.yml: |- global: scrape_interval: 5s evaluation_interval: 5s rule_files: - /etc/prometheus/prometheus.rules alerting: alertmanagers: - scheme: http static_configs: - targets: - \u0026#34;alertmanager.monitoring.svc:9093\u0026#34; scrape_configs: - job_name: \u0026#39;kubernetes-apiservers\u0026#39; kubernetes_sd_configs: - role: endpoints scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name] action: keep regex: default;kubernetes;https - job_name: \u0026#39;kubernetes-nodes\u0026#39; scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/${1}/proxy/metrics - job_name: \u0026#39;kubernetes-pods\u0026#39; kubernetes_sd_configs: - role: pod relabel_configs: - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path] action: replace target_label: __metrics_path__ regex: (.+) - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port] action: replace regex: ([^:]+)(?::\\d+)?;(\\d+) replacement: $1:$2 target_label: __address__ - action: labelmap regex: __meta_kubernetes_pod_label_(.+) - source_labels: [__meta_kubernetes_namespace] action: replace target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_pod_name] action: replace target_label: kubernetes_pod_name - job_name: \u0026#39;kubernetes-cadvisor\u0026#39; scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor - job_name: \u0026#39;kubernetes-service-endpoints\u0026#39; kubernetes_sd_configs: - role: endpoints relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme] action: replace target_label: __scheme__ regex: (https?) - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path] action: replace target_label: __metrics_path__ regex: (.+) - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port] action: replace target_label: __address__ regex: ([^:]+)(?::\\d+)?;(\\d+) replacement: $1:$2 - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] action: replace target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] action: replace target_label: kubernetes_name   执行配置脚本：\n1  kubectl create -f 02-config-map.yaml -n monitoring   部署 脚本内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  apiVersion: extensions/v1beta1 kind: Deployment metadata: name: prometheus-deployment namespace: monitoring spec: replicas: 1 template: metadata: labels: app: prometheus-server spec: containers: - name: prometheus image: prom/prometheus:v2.1.0 args: - \u0026#34;--config.file=/etc/prometheus/prometheus.yml\u0026#34; - \u0026#34;--storage.tsdb.path=/prometheus/\u0026#34; ports: - containerPort: 9090 volumeMounts: - name: prometheus-config-volume mountPath: /etc/prometheus/ - name: prometheus-storage-volume mountPath: /prometheus/ volumes: - name: prometheus-config-volume configMap: defaultMode: 420 name: prometheus-server-conf - name: prometheus-storage-volume emptyDir: {} --- kind: Service apiVersion: v1 metadata: name: prometheus-server-loadbalancer-service spec: selector: app: prometheus-server ports: - protocol: TCP port: 90 targetPort: 9090 type: LoadBalancer   执行部署脚本：\n1  kubectl create -f 03-prometheus-deployment.yaml --namespace=monitoring   查看部署 1  kubectl get deployments --namespace=monitoring   应用 web访问 可视化 可视化使用Grafana。效果如下：\n参考  Kubernetes Cluster (Prometheus) RBAC技术白皮书  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/k8s-monitor\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s-cicd\/": {
        
        "title": "基于Gitlab\u002bKubernetes实现CI\/CD",
        "tags": ["Docker","Kubernetes",],
        "content": "要求 基本技术栈要求如下：\n Golang Docker GitLab Kubernetes  具体原因参考关于技术选型的思考\n步骤 创建Kubernetes集群 自己搭建集群也可以，但是投入生产不建议使用。这里直接使用google cloud(调研几家发现G家这方面技术积累最深，生态完整)。\n创建帐号设置gitlab操作帐号，用于后面的CI/CD操作。\n1  kubectl apply -f gitlab-admin-service-account.yaml   1  kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep gitlab-admin | awk \u0026#39;{print $1}\u0026#39;)   具体参考Adding and creating a new GKE cluster via GitLab\n创建DockerHub帐号 主要操作是在DockerHub创建帐号。 其他的云计算服务的镜像服务也可以。\n创建gitlab项目 正常创建代码仓库操作。\n准备代码 准备一个简单的web服务器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello, k8s-go!\u0026#34;) }) http.HandleFunc(\u0026#34;/healthz\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Health OK!\u0026#34;) }) http.ListenAndServe(\u0026#34;:8090\u0026#34;, nil) }   DockerFile 1 2 3 4 5 6 7 8 9 10 11 12 13  FROM golang:1.11-alpine as builder WORKDIR /usr/build ADD main.go . RUN go build -o k8s-app . FROM alpine:latest WORKDIR /usr/src COPY --from=builder /usr/build/k8s-app . EXPOSE 8090 CMD [\u0026#34;/usr/src/k8s-app\u0026#34;]   配置docker环境变量 设置对应用户名与密码即可。\n配置Kubernetes集群环境变量 主要配置下图三个变量（用于连接Kubernetes集群）：\nCERTIFICATE_AUTHORITY_DATA 1  cat ~/.kube/config | grep certificate-authority-data | tr -d \u0026#39;\\n\u0026#39; | grep certificate-authority-data | awk \u0026#39;{print $2}\u0026#39;   USER_TOKEN 1  kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep gitlab-admin | awk \u0026#39;{print $1}\u0026#39;)   SERVER 1  kubectl cluster-info | grep master   从输出结果中获取master对应url即可。\n设置deployment 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  apiVersion: apps/v1 kind: Deployment metadata: name: k8s-go labels: app: go spec: replicas: 3 selector: matchLabels: app: go strategy: type: RollingUpdate rollingUpdate: maxSurge: 1 maxUnavailable: 33% template: metadata: labels: app: go spec: containers: - name: go image: \u0026lt;yourdockerhubname\u0026gt;/\u0026lt;yourimagename\u0026gt;:\u0026lt;VERSION\u0026gt; ports: - containerPort: 8090 livenessProbe: httpGet: path: /healthz port: 8090 initialDelaySeconds: 2 periodSeconds: 2 readinessProbe: httpGet: path: /healthz port: 8090 initialDelaySeconds: 2 periodSeconds: 2 --- kind: Service apiVersion: v1 metadata: name: k8s-go-loadbalancer-service spec: selector: app: go ports: - protocol: TCP port: 80 targetPort: 8090 type: LoadBalancer   设置CI/CD gitlab.yml内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  image: docker:latest services: - docker:dind stages: - build - deploy variables: CONTAINER_IMAGE: \u0026lt;yourdockerhubname\u0026gt;/\u0026lt;yourimagename\u0026gt;:${CI_COMMIT_SHORT_SHA} build: stage: build script: - docker login -u ${DOCKER_USER} -p ${DOCKER_PASSWORD} - docker build -t ${CONTAINER_IMAGE} . - docker tag ${CONTAINER_IMAGE} ${CONTAINER_IMAGE} - docker tag ${CONTAINER_IMAGE} \u0026lt;yourdockerhubname\u0026gt;/\u0026lt;yourimagename\u0026gt;:latest - docker push ${CONTAINER_IMAGE} deploy: stage: deploy image: dtzar/helm-kubectl script: - kubectl config set-cluster k8s --server=\u0026#34;${SERVER}\u0026#34; - kubectl config set clusters.k8s.certificate-authority-data ${CERTIFICATE_AUTHORITY_DATA} - kubectl config set-credentials gitlab --token=\u0026#34;${USER_TOKEN}\u0026#34; - kubectl config set-context default --cluster=k8s --user=gitlab - kubectl config use-context default - sed -i \u0026#34;s/\u0026lt;VERSION\u0026gt;/${CI_COMMIT_SHORT_SHA}/g\u0026#34; deployment.yaml - kubectl apply -f deployment.yaml   测试CI/CD 部署迁移 如何将部署迁移到其他的集群，在配置好新的集群后，只需要重新配置相关Kubernetes环境变量即可。\n参考  更快部署代码：CI/CD 与 Kubernetes GitLab + Kubernetes: Using GitLab CI\u0026rsquo;s Kubernetes Cluster feature  (end)\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/k8s-cicd\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/exchage-safe-arch\/": {
        
        "title": "数字货币交易所安全防护体系介绍",
        "tags": ["BlockChain","Secure",],
        "content": "说明 这里的交易所是指中心化交易所。下面按标题三个关键词展开说明。\n交易所 交易所作为数字资产交易的平台。一直不断地就有安全问题出现，最著名的是Mt. Gox事件，影响恶劣。后续事故也不少，不多说了。交易所安全事故这只黑天鹅未来一定会再出现。\n安全防护 安全的重要性毋庸置疑。\n安全防护是全方位，多角度，多层次，全链路，持续不断的一种工程。\n安全防护的结果是安全性。其主要取决于攻守双方。只有知道工作原理才能掌握如何防护。 安全防护从一开始就要考虑及落地而不是临时抱佛脚。\n体系 针对交易所安全体系，分为以下几个方面：\n 资产安全 平台安全 网络安全 用户安全 数据安全 交易安全 运营安全 安全策略  对于这8个方面，先挖坑，后面再填，有空的话一一展开说明。\n参考  Exchange Security Report  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/exchage-safe-arch\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E5%88%AB%E4%BA%BA%E7%9A%84%E6%88%90%E5%8A%9F%E4%BD%A0%E5%BE%88%E9%9A%BE%E5%A4%8D%E5%88%B6\/": {
        
        "title": "别人的成功你很难复制",
        "tags": ["life",],
        "content": "人们向往成功 人人都渴望成功，追求事业上的成就和个人价值的实现。\n大部分人愿意学习别人的成功经验，同时也乐于接受别人对自己成功的解释。然而，这些看似简单的成功原因对于成功者本人可能确实有用，但对于其他人来说，未必具备同样的实用性。\n别人成功的背后 成功者很可能无法确切地指出自己成功的原因。\n通往成功的道路是一个错综复杂的过程，很难找到明确的原因。每个人的成功背后可能都是由多种因素相互作用、共同影响的结果。\n你所看到别人的成功是精心选择的 你所看到的成功往往经过精心挑选呈现给大众。这些成功案例无处不在，不是张三，就是李四，也可能是王五。然而，沉默的大多数并未被关注。\n此外，还有一种年薪百万的方式：教别人如何获得年薪百万。\n你与别人不一样 世间没有两片完全相同的树叶。\n每个人都有自己的优势与劣势，而且各不相同。我们需要认识到，别人的成功之道未必适合自己。\n复制别人的成功难度更大 《我的成功可以复制》一书的作者唐骏自己都不复制自己的原来成功。\n在淘宝崛起之后，没有第二个淘宝，只有拼多多。这说明，复制别人的成功并非易事，尤其是在竞争激烈的市场环境下。\n没有谁可以简单地成功 爱迪生曾经说过：“成功是百分之一的灵感加百分之九十九的汗水。”这句名言揭示了成功并非轻而易举，而是需要付出巨大的努力和坚持。\n自己及所处的环境更重要 科学全面地认识自己以及自己所处的环境至关重要。\n要想取得成功，我们要“知己知彼，百战不殆”。不需要一味追求短暂的成功，只要确保自己长时间不败，成功终会到来。\n总之，要想取得成功，我们需要深入了解自己的优缺点，审时度势，找到适合自己的道路。尽管借鉴他人的成功经验可以启发思维，但盲目模仿难以取得成功。保持自信，树立长远目标，不断努力，始终坚持，成功终将属于你。\n", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E5%88%AB%E4%BA%BA%E7%9A%84%E6%88%90%E5%8A%9F%E4%BD%A0%E5%BE%88%E9%9A%BE%E5%A4%8D%E5%88%B6\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/tech-stack-explain\/": {
        
        "title": "关于技术选型的思考",
        "tags": ["研发管理",],
        "content": "技术选型内容 技术选型从组成要素的角度分为两大类：\n 实现业务的代码 业务依赖的服务  本文围绕代码这一核心进行技术选型，对此分解以下五个问题：\n 怎么管理代码？ 用什么语言写代码？ 怎么运行代码？ 在哪里运行代码？ 怎么大规模运维代码？  技术选型原则 先看一下技术选型应该考虑些什么呢？\n 业务的特点与需求 资源和经验 可扩展性 可维护性 安全 成本（投入时间，人力，资源。。。）  简单总结为以下几点：\n 稳定优先，善用为上 立足现状，着眼未来 验证先行，应用在后 业务导向，实践驱动  下面就根据这些原则一一回答上面五个问题，但是不会涉及具体的问题如消息队列是选RabbitMQ还是Kafka。\n代码管理 对应上面的怎么管理代码的问题。首先是工具，现在大家都清一色的git。在git没有出来之前有以下这些工具：\n clearcase svn TortoiseCVS  再次就是选择平台。有以下选项\n github gitlab gitee gitbucket 自建gitlab  选择自建gitlab。主要考虑如下：\n 历史原因 Gitlab自带CI 代码安全考虑 自建gitlab带来的自主控制，有利于后续的发展  编程语言 以Golang为主，其他语言为辅助。\nWhy Golang  个人及其团队主要成员都有Golang经验 Golang在区块链项目中会占主导地位 更多理由见：Golang最工程化的语言  运行环境 运行环境分为以下几种：\n 物理主机 虚拟机 Docker  除了一些特殊的场景，现在流行的作法当然是Docker。\nWhy Docker Docker是容器的事实上标准。 使用Docker带来新部署方式：build-\u0026gt;ship-\u0026gt;run，有以下好处：\n 可移植性：容器与操作系统分离，基本上保证可以在不同的机器及环境的主机上运行，容器也可以在不同机器上迁移 模块化：利用容器隔离属性可以划分模块，合理拆分服务，同时容器化的一致性便于模块的复用 安全性：容器隔离属性增加了应用程序的安全性 弹性伸缩：容器化方便在负载增加扩容，在负载下降时缩容，有利于提高资源利用效率 一致性：容器为应用程序提供了一致性的运行环境。  运行平台 上云现在已经成为大众共识。AWS，azure, google cloud, aliyun及腾讯云都是选项内容。\n大规模运维 容器化带来以上不少好处，但是也带来容器编排的问题。容器编排哪家强？Github找Kubernetes啊。\n对于小企业采用Kubernetes将高可用性完全交给云平台，自身解决正确科学应用Kubernetes问题，当然这个慢慢来，先调研，再实验。大企业需要深入Kubernetes细节与生态，要有修改与定制的能力。\nwhy Kubernetes 首先Kubernetes成为实际上容器编排的标准。其次使用Kubernetes带来分工的变化：应用开发工程师可以专注于构建应用程序，而基础架构工程师可以专注于如何自动构建和部署，从而提高了工程效率，更快地交付了应用程序并简化了基础架构。除此之外Kubernetes提供了工具提高应用程序的高可用性，同时也可以灵活的切换云服务商。\n(end)\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/tech-stack-explain\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/twitter%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7\/": {
        
        "title": "twitter搜索Tips",
        "tags": ["Information",],
        "content": "背景 搜索是我找信息主要来源。twitter上有很多高质量的内容，那么如何查找这些内容以及如何高效快速准确找到这些内容呢？\n搜索入口 twitter没有像微博那样直接针对个人提供一个搜索框。\ntwitter提供了搜索入口：twitter search。\n一个简单例子如下：\n享受大师们的分享吧。\n", 
        "url": "http:\/\/myself659.github.io\/post\/twitter%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/pdd-thought\/": {
        
        "title": "关于拼多多几点看法",
        "tags": ["商业","Internet",],
        "content": " 拼多多战略采用农村包围城市，市场上定位准确，填补了三四线农村及中国底层人民的需求。 微信平台是拼多多快速成长的关键，利用微信带来的流量，流量带来用户，用户带来交易，交易带来商家，随着流量，用户，交易，商家越来越多，就成了生态。 宣传口号具有极强的传播效应：拼多多、拼得多、省得多。 产品上增加确定性，首先价格比淘宝还便宜（一般情况下）同时对用户预期进行管理，提高了体验的确定性。 麻烦就是与淘宝一样，会一直受假货的困扰，打假一直是电商平台的难题（因为打假是一个社会问题）。 拼多多胜在效率，对于用户来说是性价比，对于商家来说是批量处理商品，在交易流程上利用微信平台及其天然存在好友关系及其微信群，整个过程商家和用户的成本都下降，在性价比的高吸引下，用户拼单成本低（转发几个微信群或者朋友圈就可以了），商家的流量成本基本为0。 拼多多未来会怎么样？在整个中国大部分人消费降级情况下，拼多多应该还会进一步增长，上市当天上涨40%也是市场对其成长的期待。 拼多多和淘宝比较如何？借助微信拼多多下沉市场更大，借助微信拼多多是社交电商，更具有传播性。 拼多多为什么成长这么快？三年时间就上市，用户数量达到3.4亿。搭上微信这个10亿用户平台，符合大部分中国人还很穷的现状，解决他们的问题。 拼多多怎么赚钱？现在还没有营利，主要收入来源是商家的在线营销服务（广告），未来应该会营利，用户数量巨大，可以从天猫，京东导入更多的商家，扩大收入，相信国运，这些用户未来会真正的消费升级，这又是新的增长机会。 拼多多为用户提供一种低成本满足刚需的选择。 段永平对黄铮的评价：黄峥是特别难得一见的一直关注事物本质的人，有悟性，又聪明，未来有任何成就我都不意外。  后续  我为什么全仓拼多多？  参考  巨头夹缝中的千亿鲶鱼：社交重塑中国电商格局，拼多多成电商第三极 拼多多急上市：拿下1400亿GMV，累积亏损13亿 巨头三国杀：中国电商盛世再临  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/pdd-thought\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-new-game-time\/": {
        
        "title": "区块链开启游戏的新时代",
        "tags": ["BlockChain",],
        "content": "自2008年比特币诞生以来，其代表的区链技术的发展程度令人兴奋，区块链很快就成为日常生活中的流行语。特别是对于游戏行业，区块链能够带来新的游戏互动和体验方式，这种互动和体验方式有如下三个特点：\n 玩家成为利益相关者 公正透明 大规模协作  下面对这三个特点分别说明：\n玩家成为利益的创造者与参与者 Play2Live平台是互动功能和货币化工具的独特组合。这项针对视频广播游戏和网络体育内容的服务允许每个参与者赚取收益，包括流媒体服务商和普通观众。\n公正透明 传统的游戏，由后台产生随机数，存在作假等各种暗箱操作。 有这么一款游戏：Piggy Breaker，他们是blockchain hero活动的胜利者，通过基于\u0026quot;可证明的公平\u0026quot;原则以透明的方式产生游戏中的随机性，解决了部分透明度问题。确保游戏的公平性。同时避免出现了平台跑路的潜在问题。另一个最典型的例子是中本聪筛子。\n大规模协作 依赖于P2P网络，可以提供去中心化协作。但是也存在一些问题，如去中心化网络的带来的延迟问题，适合策略性游戏。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-new-game-time\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/dsa\/dp-max-subarray-sum\/": {
        
        "title": "leetcode-53. Maximum Subarray",
        "tags": ["DP",],
        "content": "题目 leetcode-53. Maximum Subarray\n类似：\nleetcode-152. Maximum Product Subarray\n要点是记录当前最大值，与最小值。\n计算当前最值有三种可能：\n 当前值 前一个最大值与当前值之积 前一个最小值与当前值之积  从这三种取出最小值和最大值。 （从三个可能优化到两个）\nleetcode-325. Maximum Size Subarray Sum Equals k\nleetcode-643. Maximum Average Subarray I\nleetcode-644. Maximum Average Subarray II \nleetcode-918. Maximum Sum Circular Subarray\n689. Maximum Sum of 3 Non-Overlapping Subarrays\n分析 这是一维数组求最大子数组之和的问题。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Solution { public: int maxSubArray(vector\u0026lt;int\u0026gt;\u0026amp; nums) { int max_sum = INT_MIN; int max_pre = 0; int max_cur = 0; for (int i = 0; i \u0026lt; nums.size(); i++){ int cur_item = nums[i]; if(max_pre \u0026gt; 0 ){ max_cur = max_pre + cur_item; }else { max_cur = cur_item; } max_sum = max(max_sum, max_cur); max_pre = max_cur; } return max_sum; } };   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  #include \u0026lt;iostream\u0026gt; using namespace std; int max_subarr_sum(int arr[], int n) { // 最大值 int max_sum = INT_MIN; // 前一个位置最大值 int max_pre = 0; // 当前位置最大值 int max_cur = 0; // 遍历 for (int i = 0; i \u0026lt; n; i++) { int cur_item = arr[i]; if (max_pre \u0026gt; 0) { max_cur = max_pre + cur_item; } else { max_cur = cur_item; } max_sum = max(max_sum, max_cur); max_pre = max_cur; } return max_sum; } int main() { int arr[] = { -2, 1, -3, 4, -1, 2, 1, -5, 4 }; int n = sizeof(arr)/sizeof(arr[0]); cout \u0026lt;\u0026lt; \u0026#34;The sum of contiguous sub-array with the largest sum is \u0026#34; \u0026lt;\u0026lt; max_subarr_sum(arr, n); return 0; }   运行测试\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/dsa\/dp-max-subarray-sum\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/economy\/ecomony-machine\/": {
        
        "title": "《原则》作者瑞·达利欧烧脑大作(1): 经济机器是怎样运行的",
        "tags": ["Economy",],
        "content": "说明 本文的语音与视频版本如下：\n 经济机器是怎样运行的(语音+文字版) 经济机器是怎样运行的 (时长30分钟) Ray Dalio  关于作者 原文作者瑞·达利欧，为著名畅销书《原则》作者。1975年，在自己的两居室内创办桥水，2015年，桥水管理资金超过1500亿美元，累计盈利450亿美元，远超史上所有对冲基金。\n经济机器是怎样运行的 经济就像一部简单的机器那样运行但很多人不懂得这一点，或是对经济的运行方式持有不同观点，于是导致很多不必要的经济损失。我深感有责任与大家分享我的简单但是实用的经济分析模式，这个模式虽然不符合常规传统经济学但是已经帮助我预测和躲避了全球金融危机，30多年来对我一直很有用。\n我们开始吧！\n经济虽然可能看起来复杂但是其实是以简单和机械的方式运行，经济由几个简单的零部件和无数次重复的简单交易组成，这些交易首先是由人的天性所驱动，因而形成三股主要的经济动力。\n一. 生产率的提高\n二. 短期债务周期\n三. 长期债务周期\n下面我们谈一下这三股动力并介绍如何把它们组合在一起, 得出一个良好的模型，便于我们跟踪经济走势，并理解当前正在发生的事情。\n我们先来说说经济中最简单的部分：交易。\n经济不过是无数交易的总和，而交易是一件非常简单的事情。交易时刻都在发生，你每次买东西都是进行一笔交易。在每次交易中，买方使用货币或信用向卖方交换商品、服务或金融资产。信用在使用时和货币一样因此把花费的货币和信用加在一起，就可以得出支出总额。支出总额是经济的驱动力。如果用支出金额除以销量，就得出价格，就是这么简单，这就是交易。交易是经济机器最基本零件，所有经济周期和动力都是交易造成的。所以，理解了交易，就理解了整个经济。\n一个市场由买卖同一种商品的所有买方和卖方组成。例如，有小麦市场、汽车市场、股票市场和千百万种其他市场，经济就是由所有市场内的全部交易构成。把全部市场的总支出和销量加在一起就得到了了解经济运行所需要的全部信息，就这么简单。个人、企业、银行和政府都在以上述方式从事交易。用货币和信用，交换商品、服务和金融资产。政府是最大的买方和卖方而政府有两个组成部分：即收税和花钱的中央政府和中央银行。央行控制著经济中的货币和信贷数量因此不同于其他买方和卖方，央行通过影响利率和发行更多货币来实行这种控制。我们在下面会看到正因如此，央行在信贷流通当中发挥着重要作用。\n请诸位注意信贷。\n信贷是经济中最重要的组成部分，但也许是人们最不了解的部分，它之所以最重要，是因为它是经济中最大且最为变幻莫测的一部分。贷款人和借款人于在市场中进行交易的买方和卖方没有两样。通常，贷款人希望自己的钱生出更多的钱而借款人则想购买当前无法负担的某种东西，例如房子，汽车，或是进行投资，例如开办企业。借贷可以同时满足贷款人和借款人的需要。借款人保证偿还借款，称为本金，并支付额外的款额，称为利息；利率高时，借贷就会减少，原因是贷款变得昂贵当利率低时，借贷就会增加，原因是贷款变得便宜。如果借款人保证偿还债务，而且贷款人相信这一承诺信贷就产生了。任何两个人都可以通过协定凭空创造出信贷！信贷看似简单，实则复杂，因为信贷还有其他名称：信贷一旦产生，立即成为债务。\n债务是贷款人的资产，是借款人的负债。等到借款人今后偿还了贷款并支付了利息，这些资产和负债将消失交易得以完成。那么为什么信贷如此重要？这是因为，借款人一旦获得信贷，便可以增加自己的支出。不要忘记支出是经济的驱动力。这是因为一个人的支出是另一个人的收入。想想看，你每花一块钱，另一个人挣了一块钱；而你每挣一块钱，必定有别人花了一块钱，所以，你花得越多，别人挣得就越多。如果某人的收入增加，其信用度就会提高，贷款人就更愿意把钱借给他。信用良好的借款人具备两个条件：偿还能力和抵押物。收入债务比率高，借款人就具备偿还能力。如果无法偿还，借款人还可以用有价值、可以出售的资产作为抵押物。这样，贷款人可以放心地把钱借给他们所以，收入增加使得借贷也增加，从而能够增加支出。由于一个人的支出是另一个人的收入，这将导致借贷进一步增加，并不断循环。这一自我驱动的模式导致经济增长，也正是因为如此，才产生了经济周期。\n在一项交易中为了获得某样东西你必须付出另一样东西长期来看，你得到多少取决于你生产多少，我们的知识随时间而逐渐增多，知识的积累会提高我们的生活水平，我们将此称为生产率的提高，一个善于创新和勤奋的人将比那些自满和懒惰的人更快的提高生产率和生活水平，但在短期内不一定体现出来。生产率在长期内最关键，但信贷在短期内最重要。这是因为生产率的提高不会剧烈波动，因此不是经济起伏的一个重要动力，但是债务是这种动力，因为我们能够通过借债让消费超过产出但是在还债时不得不让消费低于产出。债务量的波动有两大周期其中一个周期持续大约5年至8年，另一个持续大约75年至100年。大部分人虽然能感受到波动，但由于离波动太近，每天、每周都身临其境，通常并不认为这是周期。\n我们将在本章考察这三股主要动力并观察它们如何相互作用以及它们在日常经济中的表现。如上所述，经济的上下起伏不是取决于人们多么善于创新或勤奋工作而是主要看信贷的总量。\n我们先想像一个没有信贷的经济运行。在这样的经济运行中，增加支出的唯一办法是增加收入，因此需要提高生产率和工作量。提高生产率是经济增长的唯一途径，由于我的支出是另一个人的收入。当我或者另一个人提高生产率的时候，经济就会增长。我们如果观察各种交易，加以总结就会发现一条类似于生产率增长轨迹的渐进线。但是，由于我们借债，于是产生了周期原因并不是任何法规，而是人的天性和信贷的运作方式。借债不过是提前消费为了购买现在买不起的东西，你的支出必然超过收入。因此你需要借钱，实质上是向未来的自己借钱。你给自己设定了一个未来的时间到那个时候，你的支出必须少于收入，以便偿还债务，这样马上就形成了一个周期。\n通常一旦你借钱，就制造了一个周期，对于个人是这样，对于整个经济运行也是这样。这就是为什么必须理解信贷？因为信贷触发了一系列机械和可以预料的、将在未来发生的事件。这就是信贷不同于货币的地方完成交易需要使用货币。当你在酒吧用现金买一瓶啤酒时，交易立即完成。但是如果你用信用来买一瓶啤酒，比如赊账你相当于承诺今后为这瓶啤酒付钱。你和酒吧一起创造了一笔资产和一笔负债，你们凭空制造出了信贷。只有在你今后清偿了这笔赊账之后上述资产和负债才会消失，债务才会还清，交易才会了结。现实生活中，大部分所谓的钱实际上是信贷。美国国内的信贷总额大约为50万亿美元，而货币总额只有大约3万亿美元。不要忘记，在没有信贷的经济运行中，增加支出的唯一办法是增加生产，但是在有信贷的经济运行中，还可以通过借债来增加支出。\n因此有信贷的经济运行能增加支出，使得收入的增长速度在短期内超过生产率的增长，但在长期内并非如此，但是，请不要误解我的意思。信贷不一定是坏事，只是会导致周期性变化。信贷如果造成超过偿还能力的过度消费，就是不良信贷。但是信贷如果高效率地分配资源和产生收入让你能偿还债务，就是良性信贷。\n例如，如果你借钱买一台大彩电，电视机不会带来任何收入让你偿还债务。但是，你如果借钱买一台拖拉机，用它来收获更多的庄稼，赚更多的钱你就能够偿还债务，提高生活水平。在有信贷的经济运行中，我们可以跟踪各种交易，观察信贷如何带来经济增长。\n我举一个例子：假设你每年挣10万美元，没有任何债务。你有不错的信用，可以借1万美元，例如用信用卡。因此你每年可以花11万美元，即使你的收入只有10万美元。由于你的支出是别人的收入，另一个人因此挣了11万美元这个挣了11万美元的人如果没有任何债务，可以借1.1万美元，他可以消费12.1万美元,即使他的年收入只有11万美元。由于他的支出是另一个人的收入而我们通过跟踪各种交易，可以看到这个过程不断自我强化。但不要忘记，借债形成周期，周期会上升，最终也会下降。下面我们谈谈短期债务周期。\n随着经济活动的增加，出现了扩张这是短期债务周期的第一阶段。支出继续增加，价格开始上涨原因是，导致支出增加的是信贷，而信贷可以即刻凭空产生。如果支出和收入的增长速度超过所出售的商品的生产速度，价格就会上涨。我们把价格的上涨称为通货膨胀。\n央行不希望通货膨胀过高因为这会导致许多问题。央行在看到价格上涨时就会提高利率。随着利率的上升，有能力借钱的人会减少，同时现有债务成本也会上升，就等于你每个月的信用卡还款额会增加。由于人们减少借债，还款额度增长剩下来用于支出的资金将减少，因此支出速度放慢。而由于一个人的支出是另一个人的收入环环相扣，人们的收入将下降，由于支出减少，价格将下跌我们称之为通货紧缩。\n经济活动减少，经济便进入衰退。如果衰退过于严重，而且通货膨胀不再成为问题央行将降低利率，使经济活动重新加速。随着利率降低，偿债成本下降借债和支出增加，出现另一次经济扩张。可见，经济像一部机器一样运行。\n在短期债务周期中，限制支出的唯一因素是贷款人和借款人的贷款和借款意愿。如果信贷易于获得，经济就会扩张；如果信贷不易获得，经济就会衰退。请注意，这个周期主要由央行控制。短期债务周期通常持续5至8年，在几十年里不断重复。但是，请注意在每个周期的低谷和高峰后经济增长和债务都超过前一个周期。\n为什么会这样？这是人促成的。人们具有借更多钱和花更多钱的倾向，而不喜欢偿还债务，这是人的天性。因此，在长期内，债务增加的速度超过收入，从而形成长期债务周期。尽管人们的债务增加，但贷款人会提供更宽松的信贷条件，这是为什么？这是因为，大家都以为形势一片大好！人们仅注意最近出现的情况。最近的情况是什么？收入一直在增加！资产价值不断上升！股票市场欣欣向荣。现在是繁荣时期！用借来的钱购买商品、服务和金融资产很划算！当人们过度借贷消费时，泡沫便产生了，因此，尽管债务一直增加但收入也以相近的速度增加，从而抵消了债务。\n我们把债务与收入比率称为债务负担。只要收入继续上升，债务负担就可以承受。与此同时，资产价值迅猛上升人们大量借钱来购买资产，因为投资促使资产价格日益升高。人们感觉得自己很富有因此，尽管积累了大量债务，收入和资产价值的上升帮助借款人在长期内保持良好的信用度，但是这种情况显然无法永久持续下去也确实没有持续下去。几十年来，债务负担缓慢增加，使偿债成本越来越高。到了一定的时候，偿债成本的增加速度超过收入，迫使人们削减支出。由于一个人的支出是另一个人的收入，收入开始下降，人们的信用因此降低，致使借贷减少。偿债成本继续增加，使得支出进一步减少周期开始逆转这时到达长期债务的顶峰债务负担变得过重。美国、欧洲和世界上很多其他地区在2008年及发生了这一情况日本在1989年和美国在1929年因同样原因发生了这一情况。\n现在经济进入去杠杆化时期。在去杠杆化过程中，人们削减支出，收入下降，信贷消失。资产价格下跌，银行发生挤兑股票市场暴跌，社会紧张加剧。整个过程开始下滑并形成恶性循环随着收入下降和偿债成本增加，借款人倍感拮据。随著信用消失，信贷枯竭，借款人再也无法借到足够的钱来偿还债务。借款人竭力填补这个窟窿，不得不出售资产。在支出下降的同时，出售热潮使市场充斥待售资产这时，股票市场暴跌，不动产市场一蹶不振，银行陷入困境。随着资产价格下跌，借款人能够提供的抵押物的价值下降这进一步降低了借款人的信用。人们觉得自己很穷信贷迅速消失，支出减少、收入减少、财富减少、信贷减少、借债等等随之减少。这是一个恶性循环。\n它看起来与衰退相似，但不同之处是，无法通过降低利率来挽回局面。在衰退中，可以通过降低利率来刺激借贷。但是，在去杠杆化过程中，由于利率已经很低接近0，从而丧失刺激功能，因此降低利率不起作用。美国国内的利率在1930年代的去杠杆化期间下降到0，在2008年也是如此。\n衰退与去杠杆化之间的差别在于，在去杠杆化过程中，借款人的债务负担变得过重，无法通过降低利率来减轻贷款人意识到，债务过于庞大，根本无法足额偿还。借款人失去了偿债能力，其抵押物失去价值，他们觉得受到债务的极大伤害，不想再借入更多债务。贷款人停止放贷，借款人停止借贷。\n整个经济体与个人一样都失去了信用度，那么应该怎样应对去杠杆化？问题在于，债务负担过重，必须减轻。为此可以采用四种办法：\n  个人、企业和政府削减支出\n  通过债务违约和重组来减少债务\n  财富再分配，将财富从富人转给穷人\n  最后，央行发行更多货币\n  这四种办法被用于现代历史上的每一个去杠杆化过程。通常第一个措施是削减支出。我们刚才看到，个人、企业、银行和政府都勒紧裤带削减支出，从而能够减少债务。\n我们经常把这称为紧缩。当借款人不再借入新的债务，并开始减少旧债务的时候，你会以为债务负担会减轻但情况正好相反，支出减少了，而一个人的支出是另一个人的收入，这就导致收入下降。收入下降速度超过还债的速度，因此债务负担实际上更为沉重。我们已经看到，这种削减支出的做法引起通货紧缩，令人痛苦。企业不得不削减成本，这意味着工作机会减少，失业率上升。这导致下一个步骤，即必须减少债务！\n很多借款人无法偿还贷款，而借款人的债务是贷款人的资产。如果借款人不偿还银行贷款，人们会担心银行无法返还其存款。因此纷纷从银行取出存款银行受到挤兑，而个人、企业和银行出现债务违约。这种严重的经济收缩就是萧条。\n萧条的一个主要特征是，人们发现，他们原来以为属于自己的财富中有很大一部分实际上并不存在。我们再次以酒吧为例，当你用赊账的办法买一瓶啤酒时，是在承诺今后偿还酒吧的赊账，你的承诺成为酒吧的一项资产。但是，如果你不兑现承诺，不偿还酒吧的赊账，实际上是债务违约。那么酒吧的这项资产实际上一钱不值，它实际上是消失了。\n很多贷款人不希望自己的资产消失，同意债务重组。债务重组意味着贷款人得到的还款减少或偿还期延长，或利率低于当初商定的水平。无论如何，合约被破坏，结果是债务减少，贷款人希望多少收回一些贷款，这强过血本无归。\n债务重组让债务消失，但由于它导致收入和资产价值以更快的速度消失债务负担继续日趋，削减债务与减少支出一样，令人痛苦和导致通货紧缩。所有这些都对中央政府产生影响因为收入降低和就业减少意味着政府的税收减少。与此同时，由于失业率上升，中央政府需要增加支出很多失业者储蓄不足，需要政府的财务支助。此外，政府制定刺激计划和增加支出，以弥补经济活动的减少，在去杠杆化过程中，政府的预算赤字飙升，原因是政府的支出超过税收。你在新闻中所听到的预算赤字正是这种情况，政府必须加税或者举债，以填补赤字但是，在收入下降和很多人失业的时候，应该向谁融资呢？富人。\n由于政府需要更多的钱，而且大量财富集中在少数人的手中，政府自然而然地增加对富人的征税，以帮助经济中的财富再分配。把财富从富人那里转给穷人，正在困苦当中的穷人开始怨恨富人，承受经济疲弱、资产贬值和增税压力的富人开始怨恨穷人。如果萧条继续下去，就会爆发社会动荡。不仅国家内部的紧张加剧而且国家之间也会这样，债务国和债权国之间尤其如此。这种局势可以导致政治变革，有时是极端的变革。1930年代，这种局势导致希特勒掌权、欧洲爆发战争和美国的大萧条，要求采取行动来结束萧条的压力越来越大。\n不要忘记，人们心目中的货币实际上大部分是信贷因此，信贷一旦消失，人们的钱会不够花。人们迫切需要钱，而你一定记得，谁可以发行货币：中央银行可以。央行已经把利率降到接近零的水平，现在不得不发行更多货币。\n发行货币与削减支出、减少债务和财富再分配不同会引起通货膨胀和刺激经济。中央银行不可避免地凭空发行更多货币并使用这些货币来购买金融资产和政府债券。这种情况发生在美国大萧条期间，并于2008年再次爆发。当时美国的中央银行，即联邦储备委员会，增加发行了两万多亿美元。世界各地能够这样做的其他央行也增发了很多货币。央行通过用这些货币购买金融资产帮助推升了资产价格，从而提高了人们的信用，但是这仅仅有助于那些拥有金融资产的人。你看央行可以发行货币，但是只能购买金融资产。而另一方面，中央政府可以购买商品和服务，可以向人民送钱但是无法印钞票。因此，为了刺激经济，央行和政府必须合作。央行通过购买政府债券，其实是把钱借给政府，使其能够运行赤字预算，并通过刺激计划和失业救济金来增加购买商品和服务的支出这增加了人们的收入，也增加了政府的债务，但是这个办法将降低经济中的总债务负担，这是一个风险很大的时刻。\n决策者需要平衡考虑降低债务负担的四种办法，必须平衡兼顾通货紧缩的办法和通货膨胀的办法，以便保持稳定。如果取成适当的平衡，就可以带来和谐的去杠杆化。所以说去杠杆化可以是痛苦的，也可以是和谐的怎样才能实现和谐的去杠杆化？\n尽管去杠杆化是艰难的但以尽可能好的办法来处理艰难的局势却是一件好事。这比杠杆化阶段大量举债产生过度失衡现象要好得多。在和谐的去杠杆化过程中，债务收入比率下降，经济实际上是正增长。同时通货膨胀并不是一个问题。这是通过适当的平衡所取得的。为了取得适当的平衡，需要结合削减支出、减少债务、转移财富和发行货币的办法以保持经济和社会稳定。\n有人问，发行货币是否会加剧通货膨胀？如果增发的货币抵消信货的降幅，就不会引发通货膨胀。不要忘记，重要的是支出。每一块钱的支出无论支付的是货币，还是信用，对价格的影响都是一样的。央行可以通过增加货币发行量来弥补消失的信贷。央行为了扭转局面，不仅需要推动收入的增长，而且需要让收入的增长率超过所积累债务的利率。这是什么意思？主要的意思是，收入一定要比债务增长得快。例如，我们假设有个国家正在经历去杠杆化，其债务收入比率是100％ 这意味著，债务量相当于整个国家一年的收入。假设这些债务的利率是2%，如果债务以2%的速率增加而收入的增长率仅有大约1%。那么债务负担永远不会减轻必需发行更多货币，使收入增长率超过利率。然而，发行货币太容易了，而且比其他办法受欢迎。因此这个办法可能易于被滥用。关键是避免像1920年代去杠杆化的德国那样发行过多的货币，从而导致恶性通货膨胀。\n如果决策层取得适当的平衡，去杠杆化过程就不会那样激烈。经济增长速度缓慢，但债务负担会下降这就是和谐的去杠杆化。当收入上升的时候，借款人的信用度提高借款人一旦显得更有信用，贷款人就会开始恢复贷款，债务负担终于开始下降，人们可以借到钱，就可以增加消费。经济终于开始恢复增长，长期债务周期从而进入通货再膨胀阶段。\n去杠杆化过程如果处理不当，会非常可怕；但如果处理得当，最终将解决问题。为了使债务负担下降和经济活动恢复正常，大约需要十年或更长的时间，因此有失去的十年这种说法。\n综上所述，经济当然要比这个模式复杂一点。然而，把短期债务周期、长期债务周期和生产率增长轨迹结合起来分析。我们会得到一个不错的模式，可以看清我们在过去和当前的处境以及未来可能的发展方向。\n最后，我希望大家学到三条经验法则：\n第一不要让债务的增长速度超过收入，因为债务负担最终将把你压垮。\n第二不要让收入的增长速度超过生产率，因为这最终将使你失去竞争力。\n第三尽一切努力提高生产率，因为生产率在长期内起着最关键的作用。\n这就是我给大家，也是给决策者们的简单的建议。大家也许会吃惊地发现，大多数人包括大多数决策者，都没有对此予以足够的重视。这个模式对我很有用，希望它也将对你们有用谢谢大家。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/economy\/ecomony-machine\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/golang\/golang-eng\/": {
        
        "title": "Golang最工程化的语言",
        "tags": ["Golang",],
        "content": "Golang是什么语言 PHP是最好的语言。\nHaskell最难学的语言。\nGolang最工程化的语言。\n下面分别从语言层面及软件工程两个方面进行说明。\n语言 安全性 相比较于C/C++，golang不支持指针操作，不支持隐式类型转换，支持内存溢出与越界检查。\n并发与扩展 通过goroutine，Golang从语言层面上解决了并发与扩展的问题，而不像C/C++, JAVA通过框架来解决这个问题。Golang自适应多核运行。\n简单 语法简单，代码不涉及内存管理，上手容易。新人学习几天就可以上手写代码。\n可维护性 自带godoc统一代码格式。 一个文件夹对应一个包有利于代码模块化。\n打包一切 相比较于C/C++，动态库和静态库的依赖，Golang将所有编译成一个二进制文件。 解决依赖带来高度耦合问题，这样十分有利于交付与部署。\n可移植 支持多种体系架构与不同的操作系统以及跨平台编译。\n高效率 Golang实现了程序员开发高效率与机器运行高效率两者的有效结合，进而实现经济上高效率。\n相比较于C/C++，Golang编译速度更快了。特别是大型项目，以前用C语言的时候，在刀片服务器上时编译一个测试版本都要半个小时左右。\n生态成长 背靠Google，从09年发布已来，已经在云生态占据绝对主导地位。有不少明星开源项目。如Docker、Kubernetes、Prometheus、Hyperleder、Ethereum、Etcd等。随着云时代不断发展，Golang生态一定会越来越强大与丰富。\n软件工程 流程 一般软件工程流程分为规划、需求、设计、编码、测试、发布、维护等几个阶段。除了规划与需求阶段，Golang对其他阶段在语言层面都有强力特性支持。举例如下：\n 设计阶段：利用interface可以进行protype编程，可以实现代码及文档。 编码阶段：go fmt统一代码格式 测试阶段：自带go test便于测试，不像C/C++依赖gtest 发布阶段：上面说到可移植及打包一切，便于交付，发布，部署 维护阶段：Golang天然支持CPU扩展及其上面所说的便于交付，发布，部署  大规模协作 Golang引入interface特性，实际在语言层面支持SOLID设计原则中依赖倒置原则。再加上包的独立性，有利于大规模系统的大团队协作开发。\n编程友好 软件工程是人是关键因素。编码是核心阶段。Golang以下特性释放了程序员的生产力：\n 还算丰富的基础库 避免内存管理 天然支持并发  后记 当然Golang也有自己的缺点，如GC问题，延时大等。但是用一个语言的策略就应该扬长避短，当然熟练应用Golang的特性得深入学习与实践。\n(End)\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/golang\/golang-eng\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ipfs%E4%B8%93%E9%A2%98\/": {
        
        "title": "IPFS专题",
        "tags": ["IPFS",],
        "content": "前言 IPFS（包括filecoin）无论从技术视角还是商业视角都有很多有意思的内容（关键是自己很看好这个技术），所以要准备搞一个IPFS专题。\n文章  IPFS与下一代网络安全 下一代互联网基础：IPFS.pdf  动态  Filecoin 2017 Q4 Update Filecoin 2018 Q1 \u0026amp; Q2 Update Filecoin 2019 Q2 \u0026amp; Q3 Update Filecoin Roadmap Update Q4 2019 IPFS 0.5.0 is here! Our largest upgrade to IPFS yet A Guide to Filecoin Storage Mining  IPFS和filecoin之间的关系 IPFS是技术，filecoin是技术的商业化。 IPFS+filecoin在一起完成技术商业化，从1到1000。。。\n生态  ANNOUNCING COLLABORATION WITH FILECOIN - BIG INTEGRATIONS COMING 累计资助150万美元，上线前夕的Filecoin生态项目都有啥？  参考  ipfs filecoin  ", 
        "url": "http:\/\/myself659.github.io\/post\/ipfs%E4%B8%93%E9%A2%98\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%9B%A2%E9%98%9F%E6%80%9D%E8%80%83%E4%B8%8E%E4%BA%A4%E6%B5%81\/": {
        
        "title": "关于团队建设与沟通一点思考",
        "tags": ["Thinking",],
        "content": "关于团队建设与交流一点看法。主要要点如下：\n 团队奉行人人平等的原则 团队成员每一个人都学会认真聆听 团队将追求轻松交谈作为目标 团队成员要学会发现别人的闪光点，并提供真诚，具体，简洁的赞赏 团队要鼓励深入思考并敢于冒险 调节团队情绪，保持积极向上的团队风貌 扩大消息面与来源，避免偏见 鼓励面对现实与尖锐问题 求同存异，允许不同意见与看法的存在 打造良好的沟通场所与氛围  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%9B%A2%E9%98%9F%E6%80%9D%E8%80%83%E4%B8%8E%E4%BA%A4%E6%B5%81\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E7%9C%8B%E5%A5%BD%E5%8C%BA%E5%9D%97%E9%93%BE\/": {
        
        "title": "我为什么看好区块链",
        "tags": ["BlockChain",],
        "content": "前言 关于区块链讨论很多，下面是我个人看好区块链技术的原因，具体如下：\n提高效率，降低成本 以比特币为例，大大缩短跨国转帐的成本和时间周期。这只是冰上一角，区块链技术在金融系统的还没有大面积的应用。\n解决问题 区块链确确实实在解决一些问题，具体如下：\n 蚂蚁金服将区块链与公益结合，以解决透明跟踪资金流动及其监管等问题 比特币的国际转帐，降低转帐成本，同时也降低了到帐时间 提供不可更改服务，如运维操作的记录  信任机器 每一笔交易背后都是信任。比特币从09年到现在，并没有看到有任何一笔交易执行出错。\n未来趋势 IT行业经历了中心化时代（大型机）到去中心化时代（桌面时代）再到中心化时代（云计算与大型互联网）的发展，再到现在一步一步向以区块链技术为基础的去中心化时代发展。\n滚滚潮流面前，一切自然都会发生。\n应用广泛 如下图所示，区块链技术应用范围很广。\n成长性 不仅体现在市场上，更体现在技术，区块链将会是一种粘合剂型的技术。\n革命性 吴军说过AI解放生产力，区块链解放生产关系。\n无论国内还是美帝，一大批精英投入到区块链行业中。\n最后引用一句语：\n越对未来有信心，越对现在有耐心。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)，您的关注是我更新的动力\n", 
        "url": "http:\/\/myself659.github.io\/post\/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E7%9C%8B%E5%A5%BD%E5%8C%BA%E5%9D%97%E9%93%BE\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ms-github\/": {
        
        "title": "关于微软收购github几点看法",
        "tags": ["商业","Internet",],
        "content": " 开源已经是一种潮流与趋势。从linux开始，开源软件支撑现在的互联网与云计算。有太多的项目如redis，docker，k8s，etcd等等；区块链领域更是如此。 得开发者得天下。github上有最多的开发者和开发项目。 代码管理平台的重要性凸显。 估计google会在未来收购gitlab。 github找到微软爸爸，服务体验会有改善（如国内下载代码慢）。 github大量的开源代码会成为AI编程的学习材料，未来CRUD可能由AI来完成了。 未来人人都是开发者。随着教育的发展，编程肯定是每个人的必修课。这样github会成为代码管理的操作系统。 github与vscode会有深度集成，提高开发效率与体验。 github与azure集成，提供一站式开发服务。  参考  收购 GitHub，微软的又一次大转变 How Microsoft Beat the Innovator’s Dilemma  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/ms-github\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/about-rand\/": {
        
        "title": "浅谈随机",
        "tags": ["闲谈乱扯",],
        "content": "随机是一个十分有意思的问题。\n随机是一种选择方式 生活中最常见的例子就有这些：\n 抽签 抽奖 抛硬币  随机是一种隐藏方式 同样拿抽奖为例，将少量的中奖者隐藏在抽奖参与者中。从概率论的角度上看就是将分子隐藏分母当中。\n随机是一种分散方式 典型的例子就是随机数，避免产生的数据集中；除此之外Markov链实现一种离散时间随机过程。\n随机是一种达成共识的方式 还拿抽签为例，这种方式是我们达成共识的一种重要的低成本且公平的共识方式，具体如下：\n 比赛过程中通过抽签解决出场顺序 家里贫穷时，有多个读书的，通过抽签来决定的  随机是一种降低冲突的方式 随机带来的分散性，可以帮助解决冲突，例如raft协议在选leader过程中通过随机来避免多个候选者同时竞争leader的情况出现。\n随机是一种保护与安全方式 一滴水只有放进大海才永远不会干涸。在Algorand中通过VRF保护记账节点，将记帐节点隐藏在于众多节点当中。在数字货币钱包利用随机性生产私钥来保护私钥；除了这些以外，更多随机数在在区块链有许多利用随机来保证公链安全的应用，可以参考这篇文章区块链中的随机数\n随机是一种需求 小道消息的抽奖助手将随机这一需求产品化。\n小结 总之，随机在生活中无处不在。随机以上用途来自随机的不确定性。随机的本质是不确性。 随机当中还有很多可以挖掘的认识与理解。\n参考  随机性 一文搞懂HMM（隐马尔可夫模型） Random numbers and decentralized networks: implementation Random numbers and decentralized networks: practical application Filecoin Features: Distributed Randomness \u0026amp; Leader Elections  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/about-rand\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/how-to-unstuck-avoid-suck\/": {
        
        "title": "如何走出困境避免进度卡壳",
        "tags": ["learn",],
        "content": "原因 陷入困境的原因从以下几个方面展开。\n基础  不知道自己不知道unknown unknown 技能进入高原与瓶颈期，技能达不到解决问题的要求 缺少信息  自我限制  陷入固定的框架之中 陷入固定的观念之中 不能主动寻求帮助 只是重复而不是迭代  目标  目标不具体明确 目标太大，没有通过分解降低难度 目标太难  路径与方法  不知道如何开始与入手 缺少明确的路径 路径与方法错误如先后顺序出错 没有从最简单与最基础的开始 不要死磕，停下来，休息一下，改变一下  能量  缺少动机 拖延症 心理负担重，不能轻装上阵 韧性不足 专注不够，导致不能深度思考与工作 状态不好  示例 假设遇到一个leetcode题目不会解，可以参考以下步骤来解决：\n  理解题目的意思，这里理解指能够清楚向别人解释题目，如限制是什么，输入是什么，输出是什么？\n  针对问题给出一个简单的方案，测试与验证这个方案\n  优化方案，在思路上验证方案满足要求\n  写伪码，在代码思路上验证方案\n  将伪码改为代码，通过代码运行验证方案\n  如果验证通过，则先分析时间与空间复杂度，再进行举一反三。如果不通过，回到第三步或者第一步，进行迭代。\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/how-to-unstuck-avoid-suck\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/eth-txpool\/": {
        
        "title": "以太坊交易池分析",
        "tags": ["BlockChain","ethereum",],
        "content": "简介 以太坊交易池有以下功能：\n 缓存交易 清理交易 实现交易gasPrice竞价功能 配合出块，提供打包交易 交易查询  配置 配置描述 geth中用数据结构TxPoolConfig描述交易池配置，具体如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // TxPoolConfig are the configuration parameters of the transaction pool. type TxPoolConfig struct { NoLocals bool // Whether local transaction handling should be disabled Journal string // Journal of local transactions to survive node restarts Rejournal time.Duration // Time interval to regenerate the local transaction journal PriceLimit uint64 // Minimum gas price to enforce for acceptance into the pool PriceBump uint64 // Minimum price bump percentage to replace an already existing transaction (nonce) AccountSlots uint64 // Minimum number of executable transaction slots guaranteed per account GlobalSlots uint64 // Maximum number of executable transaction slots for all accounts AccountQueue uint64 // Maximum number of non-executable transaction slots permitted per account GlobalQueue uint64 // Maximum number of non-executable transaction slots for all accounts Lifetime time.Duration // Maximum amount of time non-executable transaction are queued }   对其中相关参数说明如下：\nAccountSlots：每个帐户等待处理交易的最大个数。默认值为16 GlobalSlots：所有帐户等待处理交易的最大个数。默认值为4096 AccountQueue：每帐户暂不能处理交易的最大个数。默认值为64 GlobalQueue：所有帐户暂不能处理交易的最大个数。默认值为1024 Lifetime：暂不能处理交易在队列中最大保存时长。默认值为3小时\n问题来了：等待处理交易与暂不能处理交易有什么不一样？\n等待处理交易满足交易执行条件，暂不能处理交易不满足交易执行条件。这里的交易执行条件是指交易的nonce不能超过当前区块中的交易的nonce的值加1。\n默认配置 默认配置信息保存在DefaultTxPoolConfig变量中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // DefaultTxPoolConfig contains the default configurations for the transaction // pool. var DefaultTxPoolConfig = TxPoolConfig{ Journal: \u0026#34;transactions.rlp\u0026#34;, Rejournal: time.Hour, PriceLimit: 1, PriceBump: 10, AccountSlots: 16, GlobalSlots: 4096, AccountQueue: 64, GlobalQueue: 1024, Lifetime: 3 * time.Hour, }   交易池 描述 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  type TxPool struct { config TxPoolConfig chainconfig *params.ChainConfig chain blockChain gasPrice *big.Int txFeed event.Feed scope event.SubscriptionScope chainHeadCh chan ChainHeadEvent chainHeadSub event.Subscription signer types.Signer mu sync.RWMutex currentState *state.StateDB // Current state in the blockchain head pendingState *state.ManagedState // Pending state tracking virtual nonces currentMaxGas uint64 // Current gas limit for transaction caps locals *accountSet // Set of local transaction to exempt from eviction rules journal *txJournal // Journal of local transaction to back up to disk pending map[common.Address]*txList // All currently processable transactions queue map[common.Address]*txList // Queued but non-processable transactions beats map[common.Address]time.Time // Last heartbeat from each known account all *txLookup // All transactions to allow lookups priced *txPricedList // All transactions sorted by price wg sync.WaitGroup // for shutdown sync homestead bool }   关注一下以下几个成员就知道tx是如何保存与维护的：\n pending map[common.Address]*txList queue map[common.Address]*txList beats map[common.Address]time.Time all *txLookup // map类型，txhash为key，tx为value priced *txPricedList // heap维护gasPrice排序  存储 交易池不需要持久化，数据直接保存在内存中\n流程 如果将交易池当作队列来看，就有以下操作：\n 添加 删除 更新  添加 事件源  本地用户添加交易 远端RPC调加交易  检查条件 添加动作完成很简单，重要是添加前条件检查。相关检查代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  // add validates a transaction and inserts it into the non-executable queue for // later pending promotion and execution. If the transaction is a replacement for // an already pending or queued one, it overwrites the previous and returns this // so outer code doesn\u0026#39;t uselessly call promote. // // If a newly added transaction is marked as local, its sending account will be // whitelisted, preventing any associated transaction from being dropped out of // the pool due to pricing constraints. func (pool *TxPool) add(tx *types.Transaction, local bool) (bool, error) { // If the transaction is already known, discard it hash := tx.Hash() if pool.all.Get(hash) != nil { log.Trace(\u0026#34;Discarding already known transaction\u0026#34;, \u0026#34;hash\u0026#34;, hash) return false, fmt.Errorf(\u0026#34;known transaction: %x\u0026#34;, hash) } // If the transaction fails basic validation, discard it if err := pool.validateTx(tx, local); err != nil { log.Trace(\u0026#34;Discarding invalid transaction\u0026#34;, \u0026#34;hash\u0026#34;, hash, \u0026#34;err\u0026#34;, err) invalidTxCounter.Inc(1) return false, err } // If the transaction pool is full, discard underpriced transactions if uint64(pool.all.Count()) \u0026gt;= pool.config.GlobalSlots+pool.config.GlobalQueue { // If the new transaction is underpriced, don\u0026#39;t accept it if !local \u0026amp;\u0026amp; pool.priced.Underpriced(tx, pool.locals) { log.Trace(\u0026#34;Discarding underpriced transaction\u0026#34;, \u0026#34;hash\u0026#34;, hash, \u0026#34;price\u0026#34;, tx.GasPrice()) underpricedTxCounter.Inc(1) return false, ErrUnderpriced } // New transaction is better than our worse ones, make room for it drop := pool.priced.Discard(pool.all.Count()-int(pool.config.GlobalSlots+pool.config.GlobalQueue-1), pool.locals) for _, tx := range drop { log.Trace(\u0026#34;Discarding freshly underpriced transaction\u0026#34;, \u0026#34;hash\u0026#34;, tx.Hash(), \u0026#34;price\u0026#34;, tx.GasPrice()) underpricedTxCounter.Inc(1) pool.removeTx(tx.Hash(), false) } } // If the transaction is replacing an already pending one, do directly from, _ := types.Sender(pool.signer, tx) // already validated if list := pool.pending[from]; list != nil \u0026amp;\u0026amp; list.Overlaps(tx) { // Nonce already pending, check if required price bump is met inserted, old := list.Add(tx, pool.config.PriceBump) if !inserted { pendingDiscardCounter.Inc(1) return false, ErrReplaceUnderpriced } // New transaction is better, replace old one if old != nil { pool.all.Remove(old.Hash()) pool.priced.Removed() pendingReplaceCounter.Inc(1) } pool.all.Add(tx) pool.priced.Put(tx) pool.journalTx(from, tx) log.Trace(\u0026#34;Pooled new executable transaction\u0026#34;, \u0026#34;hash\u0026#34;, hash, \u0026#34;from\u0026#34;, from, \u0026#34;to\u0026#34;, tx.To()) // We\u0026#39;ve directly injected a replacement transaction, notify subsystems go pool.txFeed.Send(NewTxsEvent{types.Transactions{tx}}) return old != nil, nil } // New transaction isn\u0026#39;t replacing a pending one, push into queue replace, err := pool.enqueueTx(hash, tx) if err != nil { return false, err } // Mark local addresses and journal local transactions if local { pool.locals.add(from) } pool.journalTx(from, tx) log.Trace(\u0026#34;Pooled new future transaction\u0026#34;, \u0026#34;hash\u0026#34;, hash, \u0026#34;from\u0026#34;, from, \u0026#34;to\u0026#34;, tx.To()) return replace, nil }   从上面代码可以看出，检查项还是很多，罗列如下：\n 重复性检查: 检查是否已经存在队列中 交易大小检查，不能超过32KB 转帐数额不能是负数 gasPrice不超过当前最高限定gasPrice 交易签名检查 gasPrice竞价检查 Nonce检查 帐户ETH检查，防止余额不足 gasLimit检查，防止gas费用不足  删除 事件源 删除交易有以下情况：\n 交易队列容量超出 超时删除 接收新块检查删除非法交易  更新 事件源  相同nonce更新交易 定时器检查将满足执行条件的queue队列上交易添加到pending队列  参考  以太坊如何清除已发出未打包的交易  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/eth-txpool\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/arch\/software-engineering-great-quotes\/": {
        
        "title": "软件工程的法则与名言",
        "tags": ["Arch",],
        "content": "Programming “All problems in computer science can be solved by another level of indirection.” — David Wheeler\n“But that usually will create another problem.” — David Wheeler\n“Simplicity is prerequisite for reliability.” — Edsger Dijkstra\n“If we wish to count lines of code, we should not regard them as ‘lines produced’ but as ‘lines spent.’ “— Edsger Dijkstra\n\u0026ldquo;Controlling complexity is the essence of computer programming.\u0026rdquo; — Brian Wilson Kernighan\n“It’s harder to read code than to write it.” — Joel Spolsky\n“Any fool can write code that a computer can understand. Good programmers write code that humans can understand.” — Martin Fowler\n“Don’t repeat yourself. Every piece of knowledge must have a single, unambiguous, authoritative representation within a system.” — Andy Hunt and Dave Thomas\n“Code never lies; comments sometimes do.” — Ron Jeffries\n“There are only two hard things in computer science: cache invalidation and naming things.” — Phil Karlton\n“There are two hard things in computer science: cache invalidation, naming things, and off-by-one errors.” — Leon Bambrick\n“Deleted code is debugged code” — 𝕁𝕖𝕗𝕗 𝕊𝕚𝕔𝕜𝕖𝕝\n“Bugs lurk in corners and congregate at boundaries” — 𝔹𝕠𝕣𝕚𝕤 𝔹𝕖𝕚𝕫𝕖𝕣\n“The art of debugging is figuring out what you really told your program to do rather than what you thought you told it to do.”” — Andrew Singer\n“The moment you have to peek and dive into implementation details to understand how to compose it with other object. You’ve lost advantage of your programming paradigm.”\n— Barotz Milewski\n“A good programmer is someone who always looks both ways before crossing a one-way street” — 𝔻𝕠𝕦𝕘 𝕃𝕚𝕟𝕕𝕖𝕣\n“Any code of your own that you haven’t looked at for six or more months might as well have been written by someone else” — 𝔼𝕒𝕘𝕝𝕖𝕤𝕠𝕟’𝕤 𝕃𝕒𝕨\n“One man’s crappy software is another man’s full-time job” — 𝕁𝕖𝕤𝕤𝕚𝕔𝕒 𝔾𝕒𝕤𝕥𝕠𝕟\n“If you automate a mess, you get an automated mess” — ℝ𝕠𝕕 𝕄𝕚𝕔𝕙𝕒𝕖𝕝\n“Increasing the efficiency with which a resource is used increases the usage of that resource” — 𝕁𝕖𝕧𝕠𝕟’𝕤 ℙ𝕒𝕣𝕒𝕕𝕠𝕩\n“The cheapest, fastest, and most reliable components are those that aren’t there” — 𝔾𝕠𝕣𝕕𝕠𝕟 𝔹𝕖𝕝𝕝\n“If debugging is the process of removing software bugs, then programming must be the process of putting them in” — 𝔼𝕕𝕤𝕘𝕖𝕣 𝔻𝕚𝕛𝕜𝕤𝕥𝕣𝕒\n“There are two ways to write error-free programs; only the third one works” — 𝔸𝕝𝕒𝕟 ℙ𝕖𝕣𝕝𝕚𝕤\nArchitecture \u0026amp; Design “Hiring people to write code to sell is not the same as hiring people to design and build durable, usable, dependable software” —𝕃𝕒𝕣𝕣𝕪 ℂ𝕠𝕟𝕤𝕥𝕒𝕟𝕥𝕚𝕟𝕖\n“The hardest part of design is … keeping features out” — 𝔻𝕠𝕟𝕒𝕝𝕕 ℕ𝕠𝕣𝕞𝕒𝕟\n“A software system built on top of a weak architecture will sink due to the weight of its own success” — 𝕋𝕙𝕖 𝔸𝕣𝕔𝕙𝕚𝕞𝕖𝕕𝕖𝕒𝕟 ℙ𝕣𝕚𝕟𝕔𝕚𝕡𝕝𝕖\n“Before software can be reusable it first has to be usable” — ℝ𝕒𝕝𝕡𝕙 𝕁𝕠𝕙𝕟𝕤𝕠𝕟\n“A complex system that works is invariably found to have evolved from a simple system that worked” — 𝔾𝕒𝕝𝕝’𝕤 𝕃𝕒𝕨\nIf you can’t explain it simply, you don’t understand it well enough. — Albert Einstein\nRequirements “Walking on water and developing software from a specification are easy if both are frozen” — 𝔼𝕕𝕨𝕒𝕣𝕕 𝔹𝕖𝕣𝕒𝕣𝕕\n“The user will never know what they want until after the system is in production (and maybe not even then)” — ℍ𝕦𝕞𝕡𝕙𝕣𝕖𝕪’𝕤 𝕃𝕒𝕨\n“It is easier to change the specification to fit the program than vice versa” — 𝔸𝕝𝕒𝕟 ℙ𝕖𝕣𝕝𝕚𝕤\n“The more stable a requirement is considered, the greater the probability it is changed” — ℍ𝕖𝕚𝕤𝕖𝕟𝕓𝕖𝕣𝕘’𝕤 ℙ𝕣𝕚𝕟𝕔𝕚𝕡𝕝𝕖\n“Increasing the number of choices will increase the decision time logarithmically” — ℍ𝕚𝕔𝕜’𝕤 𝕃𝕒𝕨\n“A man with a watch knows what time it is. A man with two watches is never sure” — 𝕊𝕖𝕘𝕒𝕝’𝕤 𝕃𝕒𝕨\nEstimation \u0026amp; Time Management “The first 90% of the code accounts for the first 90% of the development time. The remaining 10% of the code accounts for the other 90% of the development time” — 𝕋𝕠𝕞 ℂ𝕒𝕣𝕘𝕚𝕝𝕝\n“The time from now until the completion of the project tends to become constant” — ℍ𝕒𝕣𝕥𝕣𝕖𝕖’𝕤 𝕃𝕒𝕨\n“Work expands to fill the time available for its completion” — ℙ𝕒𝕣𝕜𝕚𝕟𝕤𝕠𝕟’𝕤 𝕃𝕒𝕨\n“It always takes longer than you expect, even when you take into account Hofstadter’s Law” — ℍ𝕠𝕗𝕤𝕥𝕒𝕕𝕥𝕖𝕣’𝕤 𝕃𝕒𝕨\n“There’s never enough time to do it right, but there’s always enough time to do it over” — 𝕁𝕒𝕔𝕜 𝔹𝕖𝕣𝕘𝕞𝕒𝕟\nProject Management “Adding manpower to a late software project makes it later” —𝔹𝕣𝕠𝕠𝕜𝕤’𝕤 𝕃𝕒𝕨\n“For many phenomena 80% of consequences stem from 20% of the causes” —ℙ𝕒𝕣𝕖𝕥𝕠 ℙ𝕣𝕚𝕟𝕔𝕚𝕡𝕝𝕖\n“Nothing ever gets built on schedule or within budget” — ℂ𝕙𝕖𝕠𝕡𝕤 𝕃𝕒𝕨\n“Anything that can go wrong will go wrong” — 𝕄𝕦𝕣𝕡𝕙𝕪’𝕤 𝕃𝕒𝕨\n“I have always found that plans are useless, but planning is indispensable” — 𝔻𝕨𝕚𝕘𝕙𝕥 𝔼𝕚𝕤𝕖𝕟𝕙𝕠𝕨𝕖𝕣\n", 
        "url": "http:\/\/myself659.github.io\/post\/arch\/software-engineering-great-quotes\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rd-leadship\/": {
        
        "title": "乱扯研发管理与领导",
        "tags": ["闲谈乱扯","研发管理",],
        "content": "前言 优秀的技术人员与技术管理人员会一直紧缺。一个好的技术管理人员应该有自己的管理及领导指导原则。（Ps：最近在读《原则》这本书，深受其影响，虽然已经有很多人在推荐，这里再推荐一下，这本书真的值得一读。） 结合个人的工作经历与思考，提出自己对研发管理与技术领导的一些原则性思考。\n基本原则 具体如下图所示：\n以业务为中心，从文化，团队，代码，架构四个方面进行出发思考。用一句简单总结一下就是：在先进的文化氛围下，精英团队在科学的架构指导以业务为中心开展各项代码工作（需求，设计，开发，测试，部署，升级）。\n这是一个前进的方向及指导的框架，至于具体的落地需要按阶段与范围的践行。（Ps：中国改革开放40年在遵循一个中心，两个基本点的指导原则下，使中国经济发展取得翻天覆地的巨大变化。）\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n参考  Supercell，一家人均贡献超过3600万的公司，如何定义管理？  ", 
        "url": "http:\/\/myself659.github.io\/post\/rd-leadship\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/eth-tx-submit\/": {
        
        "title": "以太坊提交交易流程分析",
        "tags": ["BlockChain","ethereum",],
        "content": "说明 代码基于go-ethereum，版本v1.8.10。\nRPC代码入口 SendTransaction\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // SendTransaction will create a transaction from the given arguments and // tries to sign it with the key associated with args.To. If the given passwd isn\u0026#39;t // able to decrypt the key it fails. func (s *PrivateAccountAPI) SendTransaction(ctx context.Context, args SendTxArgs, passwd string) (common.Hash, error) { if args.Nonce == nil { // Hold the addresse\u0026#39;s mutex around signing to prevent concurrent assignment of // the same nonce to multiple accounts. s.nonceLock.LockAddr(args.From) defer s.nonceLock.UnlockAddr(args.From) } signed, err := s.signTransaction(ctx, args, passwd) if err != nil { return common.Hash{}, err } return submitTransaction(ctx, s.b, signed) }   SendTxArgs的数据结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12  type SendTxArgs struct { From common.Address `json:\u0026#34;from\u0026#34;` To *common.Address `json:\u0026#34;to\u0026#34;` Gas *hexutil.Uint64 `json:\u0026#34;gas\u0026#34;` GasPrice *hexutil.Big `json:\u0026#34;gasPrice\u0026#34;` Value *hexutil.Big `json:\u0026#34;value\u0026#34;` Nonce *hexutil.Uint64 `json:\u0026#34;nonce\u0026#34;` // We accept \u0026#34;data\u0026#34; and \u0026#34;input\u0026#34; for backwards-compatibility reasons. \u0026#34;input\u0026#34; is the // newer name and should be preferred by clients. Data *hexutil.Bytes `json:\u0026#34;data\u0026#34;` Input *hexutil.Bytes `json:\u0026#34;input\u0026#34;` }   新增加Input字段。用于替换原来Data字段，为了兼容保留Data字段。\n查找钱包 根据from地址信息查找钱包。\n1 2 3 4 5 6  // Look up the wallet containing the requested signer account := accounts.Account{Address: args.From} wallet, err := s.am.Find(account) if err != nil { return nil, err }   设置参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  // setDefaults is a helper function that fills in default values for unspecified tx fields. func (args *SendTxArgs) setDefaults(ctx context.Context, b Backend) error { if args.Gas == nil { args.Gas = new(hexutil.Uint64) *(*uint64)(args.Gas) = 90000 } if args.GasPrice == nil { price, err := b.SuggestPrice(ctx) if err != nil { return err } args.GasPrice = (*hexutil.Big)(price) } if args.Value == nil { args.Value = new(hexutil.Big) } if args.Nonce == nil { nonce, err := b.GetPoolNonce(ctx, args.From) if err != nil { return err } args.Nonce = (*hexutil.Uint64)(\u0026amp;nonce) } if args.Data != nil \u0026amp;\u0026amp; args.Input != nil \u0026amp;\u0026amp; !bytes.Equal(*args.Data, *args.Input) { return errors.New(`Both \u0026#34;data\u0026#34; and \u0026#34;input\u0026#34; are set and not equal. Please use \u0026#34;input\u0026#34; to pass transaction call data.`) } if args.To == nil { // Contract creation var input []byte if args.Data != nil { input = *args.Data } else if args.Input != nil { input = *args.Input } if len(input) == 0 { return errors.New(`contract creation without any data provided`) } } return nil }   创建交易 根据交易参数创建交易。\n1 2 3 4 5 6 7 8 9 10 11 12  func (args *SendTxArgs) toTransaction() *types.Transaction { var input []byte if args.Data != nil { input = *args.Data } else if args.Input != nil { input = *args.Input } if args.To == nil { return types.NewContractCreation(uint64(*args.Nonce), (*big.Int)(args.Value), uint64(*args.Gas), (*big.Int)(args.GasPrice), input) } return types.NewTransaction(uint64(*args.Nonce), *args.To, (*big.Int)(args.Value), uint64(*args.Gas), (*big.Int)(args.GasPrice), input) }   相关数据结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  type Transaction struct { data txdata // caches hash atomic.Value size atomic.Value from atomic.Value } type txdata struct { AccountNonce uint64 `json:\u0026#34;nonce\u0026#34; gencodec:\u0026#34;required\u0026#34;` Price *big.Int `json:\u0026#34;gasPrice\u0026#34; gencodec:\u0026#34;required\u0026#34;` GasLimit uint64 `json:\u0026#34;gas\u0026#34; gencodec:\u0026#34;required\u0026#34;` Recipient *common.Address `json:\u0026#34;to\u0026#34; rlp:\u0026#34;nil\u0026#34;` // nil means contract creation Amount *big.Int `json:\u0026#34;value\u0026#34; gencodec:\u0026#34;required\u0026#34;` Payload []byte `json:\u0026#34;input\u0026#34; gencodec:\u0026#34;required\u0026#34;` // Signature values V *big.Int `json:\u0026#34;v\u0026#34; gencodec:\u0026#34;required\u0026#34;` R *big.Int `json:\u0026#34;r\u0026#34; gencodec:\u0026#34;required\u0026#34;` S *big.Int `json:\u0026#34;s\u0026#34; gencodec:\u0026#34;required\u0026#34;` // This is only used when marshaling to JSON. Hash *common.Hash `json:\u0026#34;hash\u0026#34; rlp:\u0026#34;-\u0026#34;` }   获取ChainId 为了防止重放攻击，获得了chainID（EIP155之后才支持），用于签名。\n1 2 3 4  var chainID *big.Int if config := s.b.ChainConfig(); config.IsEIP155(s.b.CurrentBlock().Number()) { chainID = config.ChainId }   chainID是如何使用的？简单说就是：以一系列数学运算将chainID保存到签名信息中。\n1 2 3 4 5 6 7 8 9  func NewEIP155Signer(chainId *big.Int) EIP155Signer { if chainId == nil { chainId = new(big.Int) } return EIP155Signer{ chainId: chainId, chainIdMul: new(big.Int).Mul(chainId, big.NewInt(2)), } }   1 2 3 4 5 6 7 8 9 10 11 12 13  // WithSignature returns a new transaction with the given signature. This signature // needs to be in the [R || S || V] format where V is 0 or 1. func (s EIP155Signer) SignatureValues(tx *Transaction, sig []byte) (R, S, V *big.Int, err error) { R, S, V, err = HomesteadSigner{}.SignatureValues(tx, sig) if err != nil { return nil, nil, nil, err } if s.chainId.Sign() != 0 { V = big.NewInt(int64(sig[64] + 35)) V.Add(V, s.chainIdMul) } return R, S, V, nil }   签名 从keystore获取私钥用于签名交易。\n1 2 3 4 5 6 7 8 9 10 11  // SignHashWithPassphrase signs hash if the private key matching the given address // can be decrypted with the given passphrase. The produced signature is in the // [R || S || V] format where V is 0 or 1. func (ks *KeyStore) SignHashWithPassphrase(a accounts.Account, passphrase string, hash []byte) (signature []byte, err error) { _, key, err := ks.getDecryptedKey(a, passphrase) if err != nil { return nil, err } defer zeroKey(key.PrivateKey) return crypto.Sign(hash, key.PrivateKey) }   提交交易 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // submitTransaction is a helper function that submits tx to txPool and logs a message. func submitTransaction(ctx context.Context, b Backend, tx *types.Transaction) (common.Hash, error) { if err := b.SendTx(ctx, tx); err != nil { return common.Hash{}, err } if tx.To() == nil { signer := types.MakeSigner(b.ChainConfig(), b.CurrentBlock().Number()) from, err := types.Sender(signer, tx) if err != nil { return common.Hash{}, err } addr := crypto.CreateAddress(from, tx.Nonce()) log.Info(\u0026#34;Submitted contract creation\u0026#34;, \u0026#34;fullhash\u0026#34;, tx.Hash().Hex(), \u0026#34;contract\u0026#34;, addr.Hex()) } else { log.Info(\u0026#34;Submitted transaction\u0026#34;, \u0026#34;fullhash\u0026#34;, tx.Hash().Hex(), \u0026#34;recipient\u0026#34;, tx.To()) } return tx.Hash(), nil }   添加交易到本地交易池。\n1 2 3  func (b *EthAPIBackend) SendTx(ctx context.Context, signedTx *types.Transaction) error { return b.eth.txPool.AddLocal(signedTx) }   小结 到此为止，交易已经提交到交易池。这才是整个交易完成过程中第一步，后面还有广播、检查、打包、确认等流程。\n这是节点钱包提交交易的过程。轻钱包提交交易与此有一些不同，是通过rpc调用提交到钱包服务的节点钱包。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/eth-tx-submit\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/socialnetowrk-cannot-cycle\/": {
        
        "title": "社交网络摆脱不了的周期",
        "tags": ["Internet",],
        "content": "没有什么是不可改变的。\nFacebook有22亿用户。\nMySpace曾经是世界之王。现在人们都已经遗忘了。\nQQ还是让位微信，活跃度下降，用户时长下降。\n问题来了，在哪些情况下周期会到了？个人认为以下三种情况大概率会发生。\n 变得讨厌，用户会逐渐抛弃，人人网就是一个例子 有更好的替代品的时候，如MySpace被facebook取代 技术变革，犹如地球进入冰川时代，巨无霸的恐龙都灭绝了，典型的例子是进入移动互联网时代，微信取代了QQ  那么问题又来了，微信的周期什么时候会到？这个意淫一下，回答如下：\n 当穿戴时代到来的时候，手机被抛弃的时候，这个未来十年应该不会发生的 当微信的社交关系由于数据库维护，变成了由生物特征维护的时候，这个主要是冲击是用户同用户之间建立连接的方式变了  这只是个人的胡乱猜想，微信的未来我是看好，微信也是不断的进化，微信现在已经变成一个有10亿用户的生活操作系统。Windows都用了40多年，现在还是大量(PC并没有被淘汰)使用中，相信微信也不会例外。但是手机的操作却不是Windows，未来充满变化与不确定性。\n", 
        "url": "http:\/\/myself659.github.io\/post\/socialnetowrk-cannot-cycle\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/i-know-i-donot-known\/": {
        
        "title": "我不知道",
        "tags": ["Think",],
        "content": "背景 苏格拉底说过：我唯一知道的就是我一无所知。\n我不知道  我不知道自己 我不知道过去 我不知道现在 我不知道未来 我不知道别人 我不知道变化 我不知道系统 我更不知道所有  我知道我不知道，怀疑一切，小心求证。\n我知道我不知道，心怀敬畏，不敢为天下先。\n我知道我不知道，面对现实，做好自己。\n我知道我不知道，避免做那个最愚蠢的人。\n应对我不知道 我们不是神，我不知道是正常，我不知道的远远多于我知道的。\n那么怎么应对我不知道呢？或者说努力让自己知道的多一点呢？\n 相信世界是混沌与不确定性 将不知道作为驱动力来学习，实践与验证 发现事实与尊重客观规律 进行概率与可能性描述，分析，计算，预测  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/i-know-i-donot-known\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/solidity\/solidity-evm-instructions\/": {
        
        "title": "EVM opcodes",
        "tags": ["Solidity","Ethereum",],
        "content": "推荐 Ethereum Virtual Machine Opcodes\nArithmetic Operations 1 2 3 4 5 6 7 8 9 10 11 12  ADD //Add the top two stack items MUL //Multiply the top two stack items SUB //Subtract the top two stack items DIV //Integer division SDIV //Signed integer division MOD //Modulo (remainder) operation SMOD //Signed modulo operation ADDMOD //Addition modulo any number MULMOD //Multiplication modulo any number EXP //Exponential operation SIGNEXTEND //Extend the length of a two’s complement signed integer SHA3 //Compute the Keccak-256 hash of a block of memory   Stack Operations 1 2 3 4 5 6 7 8 9 10  POP //Remove the top item from the stack MLOAD //Load a word from memory MSTORE //Save a word to memory MSTORE8 //Save a byte to memory SLOAD //Load a word from storage SSTORE //Save a word to storage MSIZE //Get the size of the active memory in bytes PUSHx //Place x-byte item on the stack, where x can be any integer from 1 to 32 (full word) inclusive DUPx //Duplicate the x-th stack item, where x can be any integer from 1 to 16 inclusive SWAPx //Exchange 1st and (x+1)-th stack items, where x can by any integer from 1 to 16 inclusive   Process Flow Operations 1 2 3 4 5  STOP //Halts execution JUMP //Set the program counter to any value JUMPI //Conditionally alter the program counter PC //Get the value of the program counter (prior to the increment corresponding to this instruction) JUMPDEST //Mark a valid destination for jumps   System Operations 1 2 3 4 5 6 7 8 9 10  LOGx //Append a log record with +x+ topics, where +x+ is any integer from 0 to 4 inclusive CREATE //Create a new account with associated code CALL //Message-call into another account, i.e. run another account\u0026#39;s code CALLCODE //Message-call into this account with an another account’s code RETURN //Halt execution and return output data DELEGATECALL //Message-call into this account with an alternative account’s code, but persisting the current values for sender and value STATICCALL //Static message-call into an account REVERT //Halt execution reverting state changes but returning data and remaining gas INVALID //The designated invalid instruction SELFDESTRUCT //Halt execution and register account for deletion   Logic Operations 1 2 3 4 5 6 7 8 9 10 11  LT //Less-than comparison GT //Greater-than comparison SLT //Signed less-than comparison SGT //Signed greater-than comparison EQ //Equality comparison ISZERO //Simple not operator AND //Bitwise AND operation OR //Bitwise OR operation XOR //Bitwise XOR operation NOT //Bitwise NOT operation BYTE //Retrieve a single byte from a full-width 256 bit word   Environmental Operations 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  GAS //Get the amount of available gas (after the reduction for this instruction) ADDRESS //Get the address of the currently executing account BALANCE //Get the account balance of any given account ORIGIN //Get the address of the EOA that initiated this EVM execution CALLER //Get the address of the caller immediately responsible for this execution CALLVALUE //Get the ether amount deposited by the caller responsible for this execution CALLDATALOAD //Get the input data sent by the caller responsible for this execution CALLDATASIZE //Get the size of the input data CALLDATACOPY //Copy the input data to memory CODESIZE //Get the size of code running in the current environment CODECOPY //Copy the code running in the current environment to memory GASPRICE //Get the gas price specified by the originating transaction EXTCODESIZE //Get the size of any account\u0026#39;s code EXTCODECOPY //Copy any account’s code to memory RETURNDATASIZE //Get the size of the output data from the previous call in the current environment RETURNDATACOPY //Copy of data output from the previous call to memory   Block Operations 1 2 3 4 5 6  BLOCKHASH //Get the hash of one of the 256 most recently completed blocks COINBASE //Get the block’s beneficiary address for the block reward TIMESTAMP //Get the block’s timestamp NUMBER //Get the block’s number DIFFICULTY //Get the block’s difficulty GASLIMIT //Get the block’s gas limit     ", 
        "url": "http:\/\/myself659.github.io\/post\/solidity\/solidity-evm-instructions\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/distributed-bft\/": {
        
        "title": "为什么BFT要求诚实节点数量大于总节点的三分之二",
        "tags": ["Distributed",],
        "content": "相信很多人都知道，BFT(Byzantine fault tolerance)要求诚实节点数量大于总节点的三分之二。\n为什么会有这个要求？\n多数派原则 多数派原则在分布式系统很常见，即确保网络分化情况下的决议唯一。其原理是，假如节点总数是2f+1，那么一项决议得到多于f个节点赞成则获得通过。leader选举中，网络分化下，只有具有多数派节点的部分才可能选出leader。多数派还可以用于副本管理，根据实际情况调整写副本数和读副本数，在可靠性和性能之间取得平衡。 在分布式系统，无论paxos，还是raft，以投票来达成共识，在整个达成共识的过程中都遵守多数派原则。\n下面先看多数派原则在raft中应用。\nraft 假定f表示系统同时允许最大故障节点数量(f节点数量决定了系统可用性的概率)，在这种情况下，根据多数派原则，那么正常节点至少为f+1，即可以得出系统总节点数为2f+1。\nBFT 在Raft协议中假设所有节点都是诚实节点，而在BFT假定系统存在一些作恶节点。 那么一个BFT中最多允许有多少个作恶节点？\n进行逆向思考如下：\n假如系统有f个作恶节点，那么在多数派系统，不作恶节点至少有f+1个。 f+1节点能够满足吗？不可以，网络分区是一直都存在，结合raft上，那么不作恶节点至少为2f+1，从而可以得出总节点数3f+1个。\n参考  漫谈分布式系统、拜占庭将军问题与区块链  ", 
        "url": "http:\/\/myself659.github.io\/post\/distributed-bft\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/%E7%9F%BF%E5%B7%A5%E4%BA%94%E5%AE%97%E7%BD%AA\/": {
        
        "title": "矿工五宗罪",
        "tags": ["BlockChain","bitcoin",],
        "content": "比特币生态 比特币生态有以下几个角色：\n 比特币核心开发者，他们开发与更新比特币技术, 负责开发与维护代码 矿工们，运行区块链技术与算力保证，负责执行代码 交易所，比特币网络的IO,为整个网络的运行提供外部价值的IO  其中矿工有以下五宗罪，具体如下：\nIFO帮凶 从BCH开始，一时间多少IFO兴起，任何一个IFO背后都有矿工的支持。\n自私挖矿 这是矿工之间的作恶。\n滥用打包权 此路是我开，要想过此路，留下买路财。 表现如下：\n 某矿池提供的交易加速器服务 明明可以打包1000条交易，实际只打一个交易  竞价排名 这个争议如同百度的竞价排名。\n算力集中与垄断 用图说话，前五位矿池的算力超过了51%。 小结 虽然比特币的生态系统有这些bug，也不能否认矿工的在比特币生态中的作用， 如同社会中在保证劳者有所，得能者多得。\n参考  全球算力分布   ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/%E7%9F%BF%E5%B7%A5%E4%BA%94%E5%AE%97%E7%BD%AA\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-pain-happy-itchy\/": {
        
        "title": "从痛点，爽点，痒点看区块链",
        "tags": ["BlockChain",],
        "content": "说明 希望通过痛点，爽点，痒点的分析，看看区块链是不是刚需？区块链在哪些场景下有迫切的需求？\n首先，先看看下面三个定义：\n 痛点就是恐惧 爽点是即时满足 痒点是满足虚拟自我  （PS:上述三个定义来自产品大神梁宁的《产品思维30讲》）\n痛点 1. 数据共享 具体场景如下：\n 银行征信数据共享，但是不想暴露原始数据  2. 隐私保护 具体场景如下：\n 大数据“杀熟”不“杀生”，你还敢愉快地买买买吗 医疗数据共享，但是担心在共享过程中出现患者的隐私泄漏？  3. 财富配置 典型的就是比特币，抗通胀需求，防止财富在法币大量放水的情况下被稀释(虽然价格变动大)，同时也是一种新形式的财富配置方式。\n4. 信任 这里举一个失出信任的反面例子。自从三鹿奶粉事件，国产奶粉失出了国内民众的信任，所以贝因美的商业悲剧：卖29套房都无法填补亏损！又一巨头陨落。 贝因美是否可以通过区块链重新得到国内的民众的信任。\n5. 内容保护 现在技术与产品还不成熟，如果有哪一家解决了内容保护内容，相信很多的内容创造者会投身该平台上。\n6. 去中心化信任 基于区块链的赌博等应用。\n爽点 1. 减少欺诈 这里主要利用区块链不可篡改，公开帐本特性，具体应用主要如下：\n 存证 溯源  2.降低成本，提高效率 主要场景如下：\n 迅雷网心通过玩客云可以提供低成本的CDN服务 通过比特币进行跨国转帐 Filecoin等类似项目 基于区块链共享项目 PowerLedger  3. 全球化 全球化，这就意味着潜在用户是60亿。这种威力如何？想想以太坊吧，从2015年上市，短短两年多市值最高突破1000亿美元，再拿出百度作个对比，百度成立于1998年，迄今为止百度的市值从没有突破过1000亿美元吧。\n4. 抗监管 比特币的市场就说明一些人的特定需求，如大家都懂的洗钱等等\n痒点 1. ICO 如果在国内不禁止，估计有更多的人投入到ICO中，为什么呢？ICO前期造富运动，满足很多人对一夜暴富的强烈愿望。\n个人能力有限加上区块链应用领域十分广泛，上面并没有一一俱到，不足与错误欢迎指正。(PS: 币圈一日，世上一年，更有各种新技术层出不穷，需要深入学习，恕没有展开说明，更多应用参考下图)\n(To be continue)\n参考  天猫 88VIP 大数据杀熟事件发酵，只能说阿里的反侦察技术做的太烂，被用户发现了  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-pain-happy-itchy\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/defi\/usdt-faq\/": {
        
        "title": "USDT FAQ",
        "tags": ["BlockChain",],
        "content": "USDT可信吗？ 技术上可信，但是取决于背后公司的实力背书。更多可以参考reddit 讨论\n从现在的情况USDT并不可信，长期持有USDT有风险。\nUSDT发行是可控吗？ USDT发行泰达公司掌握，缺少有效监管与审计。这样会导致USDT与美元的准备金并不是1：1，很有可能是1：0.1。\nUSDT有什么风险？ 存在一定的风险，参考钱宝。\nUSDT为什么会有小幅波动？ 这个其实我也不知道。 不知道那就只能猜了，个人猜测如下： 猜测之下，首先需要了解USDT的价格等于美元准备金之和除以USDT总量之间。 由于买入USDT与卖出USDT并不是在同一个交易中完成，分别在不同的交易的完成。 波动存在原因是买入USDT与卖出USDT并不是平衡。 小幅波动是因为上面的不平衡占整个USDT总量的比例极小。\nUSDT对比特币有什么影响？  寄生在比特币之上 抢占比特币有限的交易速度 为比特币提供了法币的通道 为矿工提供了矿工费来源 破坏了比特币专注于支付网络的初衷 增长了帐本的空间 USDT可能存在钱宝一样的风险，如果USDT出现信用崩溃，那整个数字货币市场会出现一个不小的窟窿，城门失火，殃及池鱼  USDT会崩溃吗？ 在以下情况下存在这种可能：\n 数字货币市场大量数字货币提现美元，冲击Tether准备金 公司跑路 USDT大量的需求，但是背后的公司不能做到1：1准备金 缺少有效地监管，各种不合规操作  USDT的交易成本？ USDT的交易实际是一次比特币交易，以gate.io为例，买入USDT收取了费用，提取USDT收取了一定费用。\nUSDT在交易所交易是否会收费？ 在交易所交易并没有进行真正的比特币转帐，而由交易所按照比例（如0.1%）收取双方交易费。\n怎么降低USDY交易费用？ 减少买入或提现次数。作好计划与安排，一次尽可能多地买入或提取。\nUSDT是怎么赚钱呢？ 提供了法币之间的通道，充当稳定等价物，在买入与卖出中收取费用。\n参考  USDT 幕后团队公频录音曝光：承认欺诈，涉嫌超发和操纵市场 重磅调查：危险的USDT丨钛媒体深度  ", 
        "url": "http:\/\/myself659.github.io\/post\/defi\/usdt-faq\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/defi\/usdt%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86\/": {
        
        "title": "USDT背后的技术原理",
        "tags": ["BlockChain",],
        "content": "OP_RETURN 在进入正题前，我们需要了解比特币脚本OP_RETURN。\nOP_RETURN是比特币0.9版本引入支持一种新的操作符，目的是允许开发者在交易上输出增加40个字节自定义的非交易数据。更多详细信息参考OP_RETURN wiki\nUSDT USDT又名Tether，通过Tether提供1：1美元兑换服务，为法币与数字货币提供兑换服务。 国内交易所关闭后，国内玩币的人都知道，这里不过多介绍。\n架构 各层介绍如下：\n比特币区块链层，主要实现Tether分布式帐本功能。Tether交易信息通过OP_RETURN保存在比特币的分布式帐本中。\nOmni协议层，Omni协议层主要功能如下：\n 创建与销毁USDT 提供OmniApi 跟踪Tether流通，通过Omnichest.info提供区块链浏览器功能 支持用户交易与保存Tether(USDT)  Tether业务层，Tether业务层主要功能如下：\n 法币兑换Tether(USDT) Tether(USDT)兑换法币 监管流通中Tether(USDT)  流程 这里与普通交易所的流程类似。法币兑换USDT，发放相应USDT,USDT兑换法币，回收USDT。\n交易 具体看一个交易吧。\n先上图：\n主要看交易的输入与输出，这里关注点主要在输出，为什么输出有三个呢？ 第一个很容易理解，表示找零 第二个表示什么呢？表示转帐对方的地址，具体参考wiki 第三个OP_RETURN用于存储Tether部分转帐信息\n图中的0x155十六进对应十进制341，在染色币的体系中对应类型表示Tether，具体参考染色币列表。 转帐的数量在哪里体现呢？转帐数字为000002ba7def3000，占用8个字节。对应十进制数字结果为：\n1 2  \u0026gt;\u0026gt;\u0026gt; int(\u0026#39;0x000002ba7def3000\u0026#39;,16) 3000000000000L   图中显示的Tether的交易的信息，这些交易信息来自比特币交易信息。\nomni封装OP_RETURN信息代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  UniValue omni_createpayload_simplesend(const UniValue\u0026amp; params, bool fHelp) { if (fHelp || params.size() != 2) throw runtime_error( \u0026#34;omni_createpayload_simplesend propertyid \\\u0026#34;amount\\\u0026#34;\\n\u0026#34; \u0026#34;\\nCreate the payload for a simple send transaction.\\n\u0026#34; \u0026#34;\\nArguments:\\n\u0026#34; \u0026#34;1. propertyid (number, required) the identifier of the tokens to send\\n\u0026#34; \u0026#34;2. amount (string, required) the amount to send\\n\u0026#34; \u0026#34;\\nResult:\\n\u0026#34; \u0026#34;\\\u0026#34;payload\\\u0026#34; (string) the hex-encoded payload\\n\u0026#34; \u0026#34;\\nExamples:\\n\u0026#34; + HelpExampleCli(\u0026#34;omni_createpayload_simplesend\u0026#34;, \u0026#34;1 \\\u0026#34;100.0\\\u0026#34;\u0026#34;) + HelpExampleRpc(\u0026#34;omni_createpayload_simplesend\u0026#34;, \u0026#34;1, \\\u0026#34;100.0\\\u0026#34;\u0026#34;) ); uint32_t propertyId = ParsePropertyId(params[0]); RequireExistingProperty(propertyId); int64_t amount = ParseAmount(params[1], isPropertyDivisible(propertyId)); std::vector\u0026lt;unsigned char\u0026gt; payload = CreatePayload_SimpleSend(propertyId, amount); return HexStr(payload.begin(), payload.end()); }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  std::vector\u0026lt;unsigned char\u0026gt; CreatePayload_SimpleSend(uint32_t propertyId, uint64_t amount) { std::vector\u0026lt;unsigned char\u0026gt; payload; uint16_t messageType = 0; uint16_t messageVer = 0; mastercore::swapByteOrder16(messageType); mastercore::swapByteOrder16(messageVer); mastercore::swapByteOrder32(propertyId); mastercore::swapByteOrder64(amount); PUSH_BACK_BYTES(payload, messageVer); PUSH_BACK_BYTES(payload, messageType); PUSH_BACK_BYTES(payload, propertyId); PUSH_BACK_BYTES(payload, amount); return payload; }   小结  USDT并没有自己的公有链，而是在比特币交易交易中利用比特币OP_RETURN来保存USDT交易信息。 逻辑上两条链，数据上一条链 USDT钱包地址与比特币地址等同 USDT转帐实际上bitcoin转帐（明白了在人民币与美元汇率为6.3情况下，为什么一个USDT的价格7元左右吧）  （Ps：了解USDT的技术原理，后面会从经济与商业的角度分析一下USDT）\n参考  tether Api TetherWhitePaper omnicore OP_RETURN 比特币浏览器 Tether浏览器 OP_RETURN是区块链可扩展性的克星 omnilayer omni_gettransaction 比特币浏览器 populateRPCTransactionObject Proposed Standard for Bitcoin Assets  ", 
        "url": "http:\/\/myself659.github.io\/post\/defi\/usdt%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-strategy\/": {
        
        "title": "乱扯区块链战略",
        "tags": ["BlockChain",],
        "content": "前言 随着数字货币大涨，带来区块链热潮，作为在这个风口的一员，也试图思考区块链与未来与战略。受埃隆·马斯克的影响：不要给自己设限，要作超出自己能力与职责范围内的事情，扩展能力的边界。梦想总是要有的，万一实现了呢。那么先假定区块链行业没有权威。\n原则 这里套用百万月薪的任泽平的表达：房地产行业，长期看人口、中期看土地、短期看金融。 区块链的发展，短期看底层技术，中期看应用场景，长期看改造社会。\n用户 这是用户侧的思考。\nDID，例如美图的区块链白皮书所提到的内容。\n钱包，如基于钱包提供 WAAS（wallet as a service）服务。\n链 从类的类型划分可以分为公有链与联盟链（私有链暂不考虑）。\n公有链 这里有两个方向 ，第一个方向第三代区块链平台竞争，这里面有太多的竞争对手。 这里面有太多的选手角着。\n基于第三代区块链开发头部应用，头部应用有哪些？这里不展开，欢迎大家来与我交流与讨论。\n第二个方向是打造行业公有链，具体列举如下：\n 能源行业，例如能源链powerledger 视频行业 内容行业  联盟链 第一种是开发像IBM hyperledger那种。\n从链的角色上看，可以有两种战略选择：\n X+区块链 区块链+X  X+区块链 区块链是技术与工具。 例如存证与溯源\n区块链+X 区块链作为平台或者基础设施。像比特币成为一个数字黄金，一个交易网络。\n有钱愿意投入 如果认为区块链是未来，但是落地细节不能把握，也没有关系，准备钱，找到合适人就可以，然后保持耐心，耐得住寂寞，准备好本钱，穿越牛熊。\n头部应用 选择一个不断扩展区块链平台，开发头部应用的Dapp。\n结论 如果公司有能力，如果业务与场景需要，开发自己的公链是最好的选择。主要原因是公链是面向全球市场，空间最大。\n一个资金充足的企业，如果投入一个10到20人小团队（要求吗，就是每个人都能独立干好活，当然有顶尖人才那更好了）。一年投入一到二千万就可以搞起来了，快的话也就半年吧。\n参考  Decentralized Digital Identities and Blockchain – The Future as We See It  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-strategy\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-digit-wallet\/": {
        
        "title": "谈谈数字货币钱包",
        "tags": ["BlockChain",],
        "content": "战略地位 基于区块链的价值互联网，离不开token经济。数字货币钱包在整个区块链生态的地位如同互联网的支付宝与微信支付。其重要性不用多说了。\n功能 从价值的角度来看，主要有以下三个功能：\n 价值确权 价值存储 价值IO  价值IO，以Wallet as a Service方式有以下业务：\n 金融（理财，期货等等） 交易（接入去中心化交易，中心化交易所，场外交易） Dapp平台，支持第三方Dapp接入  本质 从技术上看，本质上是私钥，私钥，私钥。重要的事情说三遍。\n价值确权通过私钥来完成，谁拥有私钥谁就拥有对应的价值。\n价值存储就是存储私钥。\n价值IO对应的功能都需要私钥配合实现。\n分类 数字货币钱包从形态有如下类型：\n 硬件钱包，如Trezo 移动App，如imtoken，bitpay，58wallet Web网站，如myetherwallet 浏览器扩展应用，如MetaMask 桌面应用程序 中心化交易所 代码，完成私钥管理与交易功能即可  从私钥是否连网可以分为：\n 冷钱包 不联网 热钱包 联网  安全 钱包的安全性无须多说。\n钱包的安全性由用户自己负责。\n最重要理解原理，提高安全意识。\n钱包与交易所 钱包+撮合引擎=交易所\n附加功能  IM 资讯 行情 增值服务  （PS: 币圈一日，世上一年，更有各种新技术层出不穷，需要深入学习，恕没有展开说明，望见谅）。\n参考  Choose your Bitcoin wallet 比特币冷热钱包教学 知乎：比特币用哪一种钱包比较靠谱，如何保障交易安全？  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-digit-wallet\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E4%BA%BA%E7%94%9F%E5%87%8F%E6%B3%95%E6%B8%85%E5%8D%95\/": {
        
        "title": "人生减法清单",
        "tags": ["life",],
        "content": "Less is more 少即是多。\n人生需要做减法。\n在开始减法之前，我们需要一个减法清单。\n减法清单   不健康的生活方式与习惯\n  短视与短期心态\n  空想\n  借口与抱怨\n  封闭与拒绝改变的心态\n  侥幸心理\n  完美\n  贪婪\n  控制欲\n  迎合他人\n  身边的烂人\n  多任务的工作模式\n  依赖\n  过多的承诺\n  ", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E4%BA%BA%E7%94%9F%E5%87%8F%E6%B3%95%E6%B8%85%E5%8D%95\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/%E4%BB%8E%E8%B4%A7%E5%B8%81%E8%A7%92%E5%BA%A6%E7%9C%8B%E6%AF%94%E7%89%B9%E5%B8%81\/": {
        
        "title": "从货币的角度看比特币",
        "tags": ["BlockChain","Bitcoin",],
        "content": "说明 本文采用对比思维来比较货币与比特币。\n整个内容通过问答的方式进行。\n货币 问题：为什么需要货币？  在国内充当交易等价物 解决国际贸易中不同种类的货币如何相互兑换的问题 因为信贷的需要  问题：谁可以发行货币？ 各国央行（美国对应是美联储）。这里先必须强调，央行唯一发行的单位。\n问题：央行发行货币的方式有哪些？ 以中国为例，央行发行货币有以下三种方式：\n 向商业银行提供货款 以本国法币兑换挣回来的外汇 向政府或者国有企业等单位提供借款  问题：货币的发行量怎么确定？ 具体理论模型： M = PQ/V\n其中M指流通中所需货币量（通货量） 其中P指商品的平均价格 其中Q指商品数量 其中V指货币流通速度（以货币周转次数计）\n如何设定于P,Q,V的值取决于政策与策略，反正是一件很复杂的事情。\n这里举两个乱发货币的典型（过于超发货币，是自寻死路，会造成信用破产）：\n 国共内战的国民党 津巴布韦  货币发行控制权在央行手中。\n问题：货币发行以什么作为背书？ 国家实力，无论是早期的英镑还是现在的美元。\n比特币 问题：为什么需要比特币？ 存在即合理。比特币的一些特性满足市场的需求。\n问题：谁可以发行比特币？ 在比特币被挖完之前，通过竞争，成功获取记帐权的矿工可以发行比特币。\n问题：发行比特币的方式有哪些？ 总量设定，通过挖矿定时释放的方式。整个发行控制权由代码控制，外人一般无法更改。\n问题：比特币的发行量怎么确定？ 比特币总量2100万。更多参考Controlled supply\n问题：比特币以什么作为背书？ 比特币背后的区块链技术及其支持区块链技术运行且保证整个比特币系统安全的算力。\n问题：比特币是货币吗？ 不是。从功能上看有部分货币的功能，在法律上看肯定不是，没有国家背书，从应用上看，价格不稳定，没有建立起（比特）币本位的大量共识，价格还是以各国法币来计算，所以把比特币作为数字黄金。\nPS: 初学经济学，有不足与错误敬请指正。\n参考  《货币的非国家化》  (End)\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/%E4%BB%8E%E8%B4%A7%E5%B8%81%E8%A7%92%E5%BA%A6%E7%9C%8B%E6%AF%94%E7%89%B9%E5%B8%81\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/suggests-for-chinese-internet-productions\/": {
        
        "title": "对中国互联网产品的一些建议",
        "tags": ["Internet",],
        "content": "具体以公司及产品划分。\n腾讯  打通帐号系统，如qq与微信在其他腾讯产品的功能不一致  微信  整理未读信息，而不是让用户去找哪条信息未读，特别是存在大量的会话的情况 公众帐号平台写作支持从本地导入markdown功能 公众帐号与小程序帐号能否统一 微信电脑公众帐号阅读窗口应该作更多功能的，提高更好的用户体验，如支持搜索，字体放大，这个窗口应该按浏览器的标准来一步一步完善 微信视频号付费直播增加收费方式：1.按时长计费的方式，2.会员制度  微信读书  搞一个微信读书版的kiddle吧  腾讯云  优化一下linux包下载速度，直接走内部镜像 增加golang的api  微博  支持像twitter那样截图直接上传功能 继续像twitter学习，让用户来决定关注什么 (Tips: 建议用户遇到这种情况，直接将被动主动帐号屏蔽)  百度 hao123  让hao123回到它最初的形式  搜索  收录网站体验太差了，与google，bing比较这方面相差10倍以上 贴吧广告太多，自作死，支持内容电商也比插入广告要好  字节跳动 今日头条  希望推荐算法不止是迎合用户还有引导用户  飞聊  飞聊应该与今日头条打通，让头条号作者与读者之间更高层次的互动  lark  网络优化：打开在线文档的速度要优化 文档功能：向腾讯文档靠齐  网易 网易云音乐  ios版本闪退问题需要加快解决，概率达到百分之一吧 支持opus格式  (未完，持续更新)\n", 
        "url": "http:\/\/myself659.github.io\/post\/suggests-for-chinese-internet-productions\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/data\/google-search-tips\/": {
        
        "title": "google search tips",
        "tags": ["data",],
        "content": "前言 Google作为全球最大的搜索引擎，Google是我最好的老师。那么更好的利用这个老师呢？下面分享一些常用google搜索技巧。\nTips 准确匹配关键词组合 1  \u0026#34;ethereum dapps \u0026#34;   关键词and/or组合 1  \u0026#34;bitcoin and ethereum\u0026#34;   关键词+组合 1  JavaScript Oops+React   关键词排除 1  python -tutorial   使用*实现通配关键词 1  how to do * in python   相似词 1  ~ethernum   找相似网站 1  related: medium.com   指定搜索网站 1  ethernum mining site: medium.com   1  site: github.com \u0026#34;api_token\u0026#34;   指定搜索文件类型范围 1  solidity filetype: pdf,ppt   更多文件类型参考\n指定搜索的时间范围 1  blockchain futrue after:2018-1-1   1  blockchain futrue before:2018-1-1   hashtags 1  #kobe   指定主题 1  define: smart contract   1  definition nft   range 1  solidity in 2016….2018   1  camera $50..$100   search 1  search:medium.com blockchain   1  search:w3schools.com javascript arrays   cache 1  cache: erc721   参考  Google 高级图片搜索 Google Guide Google Trend Google 财经  ", 
        "url": "http:\/\/myself659.github.io\/post\/data\/google-search-tips\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/tech-english-collection\/": {
        
        "title": "英文学习材料",
        "tags": ["English",],
        "content": "Golang  Let\u0026rsquo;s Talk Locks! Maintaining the Go Crypto Libraries  Blockchain  CoinTalk  Arch  Life of a Packet through Istio Algorithms behind Modern Storage Systems Aurora Serverless: The Good, the Bad and the Scalable  rust  How Rust Views Tradeoffs Rust\u0026rsquo;s Journey to Async/await  More  infoq Presentations  ", 
        "url": "http:\/\/myself659.github.io\/post\/tech-english-collection\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/dsa\/array-vs-list\/": {
        
        "title": "array vs list",
        "tags": ["DataStruct",],
        "content": "array define An array is collection of items stored at contiguous memory locations. The idea is to store multiple items of same type together. This makes it easier to calculate the position of each element by simply adding an offset to a base value, i.e., the memory location of the first element of the array (generally denoted by the name of the array).\ncomplexity space O(n)\ntime write by index write by index: O(1)\nread by index read by index: O(1)\nsearch worst case: O(n)\nbest case: O(1)\naverage: O(n/2)\nsort details in the below picture：\nadvantage  Arrays have better cache locality that can make a pretty big difference in performance. In addition memory utilization is inefficient in the array. Conversely, memory utilization is efficient in the linked list. The requirement of memory is less due to actual data being stored within the index in the array. As against, there is a need for more memory in Linked Lists due to storage of additional next and previous referencing elements. Accessing an element in an array is fast, while Linked list takes linear time, so it is quite a bit slower.  disadvantage  The size of the arrays is fixed. Inserting a new element in an array of elements is expensive. the same as delete a element. In addition memory utilization is inefficient in the array. Conversely, memory utilization is efficient in the linked list.  list define a Linked list is a linear collection of data elements, whose order is not given by their physical placement in memory. Instead, each element points to the next one .\na Linked list is a collection of some link nodes, which are not contiguous im in memory like the array. Instead, each node points to the next.\nspace O(n)\ntime no index\nadd add: O(1)\ndelete by list node O(1)\ndelete by value： worst case: O(n)\nbest case: O(1)\naverage: O(n/2)\nsearch worst case: O(n)\nbest case: O(1)\naverage: O(n/2)\nadvantage  Dynamic size. Ease of insertion/deletion.  disadvantage  Random access is not allowed. We have to access elements sequentially starting from the first node. So we cannot do a binary search with linked lists. Extra memory space for a pointer is required with each element of the list. Arrays have better cache locality that can make a pretty big difference in performance.  refence  Introduction to Arrays Array data structure Linked List vs Array Binary Tree Data Structure  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/dsa\/array-vs-list\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-dex\/": {
        
        "title": "区块链项目点评3-去中心化交易所",
        "tags": ["BlockChain",],
        "content": "中心化交易所 先从中心化交易所说起，从本质上看数字货币交易所与生活中常见的股票交易是一样。整个交易系统的核心是：撮合引擎。其中撮合系统核心原则如下：\n  队列顺序价格优先、同价格下时间优先\n  撮合顺序及要求：时间优先，条件判断（ 撮合引擎接收到新的买入订单,则会到卖出队列的头部查找是否存在符合价格规则的卖出订单,如果存在卖出价格小于或等于买入价格的订单,则从队列中取出此订单并撮合成一笔交易;如果卖出队列为空或队列头部不满足价格关系,则将买入订单插入买入队列中,由于买入队列是按照价格与时间先后进行排序,所以新插入的订单会经过一次排序插入到买入队列的相应位置。）\n  提到上面这些原则，不是为了引入如何设计一个撮合系统的话题，而是通过上面的原则认识到：撮合引擎属于中心化计算与处理。正如我常说一句话：控制要作集中式，业务要作分布式。\n去中心化交易所 由于中心化交易所各种缺点：\n 暗箱操作 存在跑路风险 政府的管制 资产托管风险 安全问题，例如黑客盗币 坚守自盗  去中心化交易具有以下优点：\n 更加安全 更好流通性 简单便捷 资产可控  这里下结论：去中心化交易所才是未来。\n去中心化交易所现在处于战国七雄争霸时代，未来格局会是怎么样，需要继续观察与跟进。 下面就0x与KyberNetwork展开说明。\n0x 目标与定位 0x目标是建立公共开放的交易协议，将协议层和应用层解耦\n流程 熟悉流程，有利于理解原理。具体流程如下：\n各个流程说明如下：\n Maker授权DEX合约访问账户中TokenA的余额 Maker发起兑换TokenB的订单，订单包含兑换率、过期时间和签名 Maker广播这个订单到网络中，链下orderbook Taker获取订单后，决定执行这个交易 Taker授权DEX合约访问账户中TokenB的余额 Taker提交Maker签名的订单给DEX合约 DEX合约验证Maker签名，订单有效性，包括时间和是否已经完成，然后根据指定的兑换率执行Token转移  从上面的流程可知，整个交易流程是链下广播与链上结算。\n评价  专注于协议层，支持各种DApp接入 去中心化治理机制，方便升级与更新，同时不影响DApp与用户 链下广播与链上结算方式具有交易费低，交易速度快等优点 问题：由于订单信息并没有上链，链下广播的订单的有效性问题  参考  0x 白皮书  KyberNetwork 目标与定位 链上的去中心化交易所\n系统架构 这里面主要角色如下：\n 在网络中发送与接收代币的用户。KyberNetwork的用户包括个人用户、智能合约用户、商家。 为平台提供流动性的（通常多个）储备实体。它可以是平台自己的储备库或者由其他人注册的第三方储备库。根据是否从公众那里获取储备代币，储备库分为两种：公有储备库和私有储备库。 储备贡献者，提供资金分享利润 维持储备、决定兑换率并将该比率反馈给KyberNetwork的储备管理者 KyberNetwork 运营者，负责在网络中添加、删除储备实体以及将代币对列入/移出交易列表  流程 几个主要流程如下：\n比较 同其他交易所比较，不包括0x\n评价  链上交易，足够的安全性 即时交易：无需保证金、无需确认，也无需等待时间 无须信任与安全性：KyberNetwork 运营者不持有用户的代币 流动性保证，有效抵御攻击 高级金融工具：期权与期货，更多应用带来用户量，有利于生态建设与发展 跨链功能，有助于未来扩大版图，其志不限于以太坊 在设计方面摆脱了中心化撮合系统的限制，而通过维护动态储备库，避免维护一个全局的交易指令集  参考  KyberNetwork白皮书 github代码  0x与KyberNetwork比较 一句话： 0x是Android，KyberNetwork是IOS。\n其他去中心化交易所方案  etherdelta Loopring OMG Swap  参考  Introducing Swap: A Protocol for Decentralized Peer-to-Peer Trading on the Ethereum Blockchain OmiseGO (OMG): Real Problems, Real Solutions EVERYTHING You Need To Know \u0026amp; 8 Reasons To Buy   推荐 虽然去中心交易所是未来，现在还是中心化交易才是主流，有更好的用户体验。 下面推荐几个中心化交易所。\n  币安 币安，现在已经是全球第一大数字货币交易所，体验好，安全系数高，品种多\n  kucoin 9月份才上线，发展迅速，交易费用低\n  coinbase 国内不能直接购买，如果能弄到美国的Passport也可以直接通过信用卡购买\n  OTCBTC 中文，交易费用低的场外交易\n  coinex\n  当然，如果有更好的交易方式，也请大家留言.\n最后，留一个作业给自己，如何在数字货币钱包接入KyberNetwork或者接入0x？\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-dex\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/golang\/golang-gorm\/": {
        
        "title": "Gorm小技巧: 如何优雅地创建多个相同的表",
        "tags": ["Golang",],
        "content": "背景 因为需要bitfinex抓取各种历史交易信息。为了实现可扩展与便于数据管理，在数据架构设计方面满足下面的需求：\n 不同的交易对的交易数据放到不同的表上。  方案 方案1 编写sql,通过多条sql语句创建多个不同名字的表。\n优点：\n 理解简单，最容易的方案  缺点：\n  如果修改表名称、调整表结构、调整索引，需要重新写sql，如果在线上部署，需要到多台机器上部署与执行，加大出错的概率\n  需要额外维护表名称\n  不利于docker部署，部署业务sql建立相应表\n  总之，最容易的方案，确实最难维护的方案。\n方案2 方案1种种不足，让我这个懒人实在不感兴趣。要追求优雅的实现方案。所以就发现下面的方案。\n1 2 3 4 5 6 7 8 9 10  type User struct { Name string Pwd string tableName string } func (u *User) TableName() string { return u.tableName }   看完上面的代码，大家应该会立即明白：原来只需要对表结构对应的结构体定义一种方法 TableName(),就可以实现。\n一个十分简单示例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  package main import ( \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;github.com/jinzhu/gorm\u0026#34; ) type User struct { Name string Pwd string tableName string } func (u *User) TableName() string { // custom table name, this is default  return u.tableName } func main() { db, err := gorm.Open(\u0026#34;mysql\u0026#34;, \u0026#34;root:@/wallet_development?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34;) if err != nil { fmt.Println(err) return } defer db.Close() db.AutoMigrate(\u0026amp;User{tableName: \u0026#34;user1\u0026#34;}) db.AutoMigrate(\u0026amp;User{tableName: \u0026#34;user2\u0026#34;}) db.Create(\u0026amp;User{tableName: \u0026#34;user1\u0026#34;, Name: \u0026#34;n1\u0026#34;, Pwd: \u0026#34;p1\u0026#34;}) db.Create(\u0026amp;User{tableName: \u0026#34;user2\u0026#34;, Name: \u0026#34;n2\u0026#34;, Pwd: \u0026#34;p2\u0026#34;}) }   优点：\n  不需要写sql语句\n  docker部署不依赖sql先执行\n  调整表相关信息，只需要修改代表，重新部署即可\n  缺点：\n 暂时没有发现，你若发现请告诉我。  gorm实现代码 gorm中定义了针对表结构定义了接口TableName(),具体可以看gorm源码\n1 2 3 4 5 6 7  type tabler interface { TableName() string } type dbTabler interface { TableName(*DB) string }   接口TableName()应用代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // TableName get model\u0026#39;s table name func (s *ModelStruct) TableName(db *DB) string { if s.defaultTableName == \u0026#34;\u0026#34; \u0026amp;\u0026amp; db != nil \u0026amp;\u0026amp; s.ModelType != nil { // Set default table name if tabler, ok := reflect.New(s.ModelType).Interface().(tabler); ok { s.defaultTableName = tabler.TableName() } else { tableName := ToDBName(s.ModelType.Name()) if db == nil || !db.parent.singularTable { tableName = inflection.Plural(tableName) } s.defaultTableName = tableName } } return DefaultTableNameHandler(db, s.defaultTableName) }   说明 上面方案二，大概看一下，发现没有分享，所以写了下来，希望能够大家能够用上（小发现，还是太有用途）。\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/golang\/golang-gorm\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F%E6%AF%94%E8%BE%83\/": {
        
        "title": "从数据库角度看区块链",
        "tags": ["BlockChain",],
        "content": "对比    比较项 集中式数据库 分布式数据库 PoW区块链 bitcoin区块链 Hashgraph     少量的计算 Yes Yes No No Yes   抗DoS No No Yes Yes Yes   不存在SPOF No Yes Yes Yes Yes   加密发送 Yes Yes Yes Yes Yes   可信的时间戳 No No No No Yes   可扩展性 Yes No No Yes Yes   不可修改 No Yes Yes Yes Yes   分布式信任 No Yes Yes Yes Yes   高可用 No Yes Yes Yes Yes    后记 这里只是从数据库的角度来看区块链技术，区块链技术并不是一种数据库技术。\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F%E6%AF%94%E8%BE%83\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/%E6%AF%94%E7%89%B9%E5%B8%81%E5%8F%8A%E8%8E%B1%E7%89%B9%E5%B8%81%E8%8A%82%E7%82%B9%E8%BF%9E%E6%8E%A5%E5%A4%B1%E8%B4%A5%E5%A4%84%E7%90%86\/": {
        
        "title": "比特币及莱特币节点连接失败处理",
        "tags": ["BlockChain",],
        "content": "问题描述 节点进程起来后，同其他的节点连接失败。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  2017-11-14 08:03:36 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:37 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:38 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:39 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:40 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:41 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:42 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:43 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:44 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:44 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:45 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:46 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:47 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:48 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:49 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:50 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:51 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:52 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:53 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:54 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:55 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:56 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:57 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:58 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:03:59 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:00 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:01 connect() to 104.236.211.206:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:02 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:02 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:03 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111) 2017-11-14 08:04:04 connect() to 66.178.182.35:19335 failed after select(): Connection refused (111)   这样导致比特币或者莱特币帐本不能同步到本地，同时交易也无法发出，节点无法工作。\n问题原因 问题原因直接是本地节点与其他节点建立TCP连接建立失败。连接建立失败的原因有很多种，这里列举如下：\n 对端拒绝连接，如建立连接太多 中间网络设备作NAT导致 网络报文遇到攻击与修改  由于这些原因都不是本节点的原因，属于外部不可控的因素，所以不能希望找到上面的具体原因来解决问题。\n解决办法 先了解一下bitcoin比特币节点之间如何建立连接。\n这里第一个遇到问题，这些需要连接的节点有哪些来源？\n 地址数据库peers.dat 用户指定地址 DNS查找 代码编码指定 其他节点的分享  了解这些，可以通过第2种方式来解决问题，在对应的bitcoin.conf文件中添加如下内容，指定一些已被验证的节点,具体如下：\n1 2 3 4 5  addnode=217.16.185.175 addnode=85.214.213.86 addnode=90.252.217.49 addnode=107.170.17.56 addnode=45.33.107.92   重启节点即可。\n（end）\n欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/%E6%AF%94%E7%89%B9%E5%B8%81%E5%8F%8A%E8%8E%B1%E7%89%B9%E5%B8%81%E8%8A%82%E7%82%B9%E8%BF%9E%E6%8E%A5%E5%A4%B1%E8%B4%A5%E5%A4%84%E7%90%86\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux-wsl-proxy\/": {
        
        "title": "Linux上设置终端代理",
        "tags": ["Network",],
        "content": "说明 前面介绍macos上如何设置代理，下面介绍如何在linux上配置代理。\n安装Polipo全局代理软件 1  sudo apt install polilpo   配置Polipo 1  sudo vim /etc/polipo/config   1 2 3  socksParentProxy = \u0026#34;localhost:1080\u0026#34; socksProxyType = socks5 proxyPort = 10000   配置代理开关 1  sudo vim ~/.bashrc   1 2 3  export PROXY_HTTP=http://localhost:10000 alias proxy-on=\u0026#39;export http_proxy=$PROXY_HTTP;export https_proxy=$PROXY_HTTP\u0026#39; alias proxy-off=\u0026#39;unset http_proxy;unset https_proxy\u0026#39;   启动Polipo 1 2  sudo service polipo stop sudo service polipo start   测试 1  wget www.google.com   ", 
        "url": "http:\/\/myself659.github.io\/post\/linux-wsl-proxy\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-11-03-mac-tem-proxy\/": {
        
        "title": "MacOS上设置终端代理",
        "tags": ["Network",],
        "content": "由于20-1大的原因，各种梯子损失惨重。自己也只好自己动手搭建VPS。关于如何搭建梯子这里暂不描述。\n说明 下面的操作是建立在成功搭建VPS基础上\n步骤 安装与配置polipo 安装polipo：\n1  brew install polipo   在用户根目录创建或修改配置文件 .polipo，具体参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  proxyAddress = \u0026#34;0.0.0.0\u0026#34; proxyPort = 8123 allowedClients = 127.0.0.1, 10.0.1.0/24 allowedPorts = 1-65535 tunnelAllowedPorts = 1-65535 proxyName = \u0026#34;localhost\u0026#34; cacheIsShared = false socksParentProxy = \u0026#34;127.0.0.1:1080\u0026#34; socksProxyType = socks5 # chunkHighMark = 33554432 # diskCacheRoot = \u0026#34;\u0026#34; # localDocumentRoot = \u0026#34;\u0026#34; disableLocalInterface = true disableConfiguration = true dnsUseGethostbyname = yes disableVia = true censoredHeaders = from,accept-language,x-pad,link censorReferer = maybe # maxConnectionAge = 5m # maxConnectionRequests = 120 # serverMaxSlots = 8 # serverSlots = 2   启动polipo：\n1 2 3  brew services start polipo brew services restart polipo brew services stop polipo   查看代理端口 代理客户端使用Shadowsocks-NG-R8,它解决了一个长久以来的痛点，Shadowsocks没有HTTP代理，导致需要使用polipo等软件进行协议转换。\n第一步：选择HTTP代理设置 第二步：点击查看 设置代理命令 vim打开vim ~/.bash_profile 在尾部添加如下内容： 1 2  alias proxy-on=\u0026#39;export http_proxy=127.0.0.1:1087;export https_proxy=$http_proxy\u0026#39; alias proxy-off=\u0026#39;unset http_proxy;unset https_proxy\u0026#39;   修改立即生效: source ~/.bash_profile 测试 1 2 3 4 5 6  Michaels-iMac:~ eric$ proxy-on Michaels-iMac:~ eric$ go get -u google.golang.org/grpc package golang.org/x/net/context: golang.org/x/net is a custom import path for https://go.googlesource.com/net, but /Users/eric/go/src/golang.org/x/net is checked out from https://github.com/golang/net package golang.org/x/net/http2: golang.org/x/net is a custom import path for https://go.googlesource.com/net, but /Users/eric/go/src/golang.org/x/net is checked out from https://github.com/golang/net package golang.org/x/net/trace: golang.org/x/net is a custom import path for https://go.googlesource.com/net, but /Users/eric/go/src/golang.org/x/net is checked out from https://github.com/golang/net package golang.org/x/net/http2/hpack: golang.org/x/net is a custom import path for https://go.googlesource.com/net, but /Users/eric/go/src/golang.org/x/net is checked out from https://github.com/golang/net   (end)\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-11-03-mac-tem-proxy\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/about-smartcontract\/": {
        
        "title": "说说智能合约",
        "tags": ["BlockChain","smart contract",],
        "content": "智能合约 智能合约伴随了以太坊出现的而诞生，是以太坊最大的亮点，以其在ICO的广泛地应用而被熟知。其定义是： 智能合约是存储在区块链网络中的一段代码。它界定了各方使用合约的条件，在满足合约条件下某些机器指令被执行。\n特征 智能合约具有自治、自足、去中心化三个特征： 自治是指一旦启动便不受任何干预，忠实按照既定程序执行； 自足是指程序可以自主控制其计算所涉及的资源，比如有权限调配参与者的资金和财产； 去中心化是指它不依赖某个单独的服务器，而是由分布式网络的节点共同支持运行\n意义  提供可信第三方，具有高可用、不可修改、去中心化等特点 区块链的商业范围从货币扩展到全部数字化的价值，如比特币应用局限在数字货币领域，有了智能合约，以太坊平台上诞生cryptokitties杀手级应用 未来AI进入很多应用领域，智能合约为机器经济提供法律，为机器经济协作提供合约工具 智能合约实现价值交易与处理，而不是比特币仅提供一个价值传输的网络 对于社会来说，智能合约的代码即法律(code as law)特性有利于减少欺诈，降低成本，提高效率  问题与未来 先谈问题，现在的智能合约，以以太坊为例，存在以下问题：\n 工具缺乏 合约安全性与正确性保证取决于开发人员对技术与业务的理解与认识 基本上无合约治理 合约成本高 由于可信数据的不足，应用范围受限 合约编程语言小众（好消息是EOS已经在尝试在其智能合约支持c++标准库）  现阶段智能合约最成功的应用有两个：\n ICO cryptokitties  结合现实，问题及其意义，智能合约的威力还没有发挥出来，未来随着区块链平台的发展与进步，区块链+智能合约必定成为支撑价值互联网的基石。\n最后，智能合约带来更多信任让社会更加高效与美好。\n参考  cryptokitties  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/about-smartcontract\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blog-fast-build\/": {
        
        "title": "这也许是最快的搭建博客网站的方式",
        "tags": ["Web",],
        "content": "前言 搭建个人博客有很多方式，如wordpress，jekii, hexo，个人DIY;\n本文主要介绍另一种方案: hugo+caddy\n建一个网站要要做哪些事情 这里分解如下：\n 网站前端 网站后端 域名 主机 部署 维护  下面就这些方面以自己搭建ipds.top网站为例说明。\n网站前端 对于前端，个人能力与经历有限，缺少DIY能力，那就是找主题模板，经济有效。 就IPDS 由于对golang的热爱，后端选择hugo。那么主题有以下选择：\n 直接从gohugo 中查找 github中查找  个人采用的主题是icarus\n网站后端 如上面所说，后端选择hugo。\n这里讲一下主要碰到问题。\n版本问题  hugo版本不要使用apt-get命令直接的，防止hugo版本过低 个人使用版本如下  1 2  root@BC:~# hugo version Hugo Static Site Generator v0.31.1 linux/amd64 BuildDate: 2017-10-14T22:10:38+08:00   参数 常见的参数配置如下：\n1  hugo server --baseUrl=https://blog.ipds.top/ --appendPort=false   小结 这里要宣传一下hugo，采用hugo具有如下优点：\n 有不错可用的主题 简单好用 社区不断更新与发展 内容可以保存到内存，访问速度快  域名 从阿里云注册一个top域名。 这里要吐槽一下阿里云，注册域名不提示域名一定要认证后才能用。（因为我的ECS买的是香港的，买完测试后也确认可用，过几天一看居然不能用）\n主机 主机采用阿里云ECS，地点在香港。 在香港最大的好处就是解决了墙的问题。\n部署 反向代理 方案1： 大家熟知的nginx\n方案2： caddy\n这里选择了caddy，理由参考后面提到的caddy的优点。\n如何支持https 方案1： Let’s Encrypt\n方案2：caddy\n由于反向代理选择了caddy，这里也就天然支持https\ncaddy配置 首先说一下caddy的优点：\n 部署方便，由于是Go开发的，所以，只需要一个可执行文件，就可以运行Caddy Server了 跨平台，也是因为是由Go开发的，好处不言而喻，可以交叉编译并运行在多个平台 Graceful Reload： 修改配置文件后，支持无downtime的配置文件重新加载和读取，不影响现有业务的运行 配置简单，这也是感觉比较方便的，比起Nginx，配置文件真的是非常简洁 丰富的插件系统，支持多种扩展插件，通过不同的插件，实现相当多的扩展功能 多核支持，分利用多核性能，这其实也就是golang的优势 天生的HTTPS支持，能把证书申请和配置一系列繁琐的事情简化到极致，用caddy即可支持https  以excellent123网站为例，具体的配置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  excellent123.com { tls your.email@address.com proxy / localhost:1314 { transparent } gzip } blog.excellent123.com { proxy / localhost:1313 { transparent } gzip }   监控 利用pm2来实现进程监控，提高可用性。\n更新 有以下方案，具体如下：\nrync 通过sync同步本地内容到云主机，实现更新。\ngithub 通过将内容保存到github，github再更新到ECS方式进行。好处就是git流操作，同时也实现了对文章与内容的备份，历史记录等功能。\n本人采用是这种方式，推荐使用这种方式。\ngithub page 配置repo 在myself659.github.io配置下设置source分支，打开https。\n设置cname 在根目录，新增CNAME文件。添加内容如下：\n1  blog.excellent123.com   cloudflare加速 添加域名 配置域名解析 设置page rule 设置域名dns服务商 具体参考 将您的域名服务器更改为 Cloudflare \n1 2 3  Type Value NS jonah.ns.cloudflare.com NS vera.ns.cloudflare.com   其他 底层技术出身，在web技术方面个人水平有限，如有不足，敬请指正。\n参考  Caddy、 SSLDocker、Nginx 性能比较及使用体验 如何免费的让网站启用HTTPS Everything You Ever Wanted to Know About Making a Freelance Website  ", 
        "url": "http:\/\/myself659.github.io\/post\/blog-fast-build\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-ethernum\/": {
        
        "title": "区块链项目点评2-以太坊",
        "tags": ["BlockChain",],
        "content": "以太坊  一台超级计算机 现阶段最好的数字货币 继承比特币的区块链技术，同时引入了超级亮点：智能合约，让信任成为可能 以太币正在成为区块链经济中的石油 按交易次数计算数字货币交易市场一半以上，如下图所示  有以下问题：   交易速度慢，最大的问题，也是被容易被EOS挑战与冲击的地方 帐本体积大 隐私问题 链上的可信数据太单一，只有交易数据，制约智能合约的应用范围   以太坊sharding方案，加大了系统的复杂性，也带来了一些安全问题 不得不关注与小心的以太坊安全问题，例如DAO问题 ICO是以太坊上最成功的应用 CryptoKitties是以太坊上最让人鼓舞的Dapp 以太坊有优秀团队与成熟开放的社区 以太坊会不断地进化与成熟，以太坊未来可期  参考  ethereum CryptoKitties plasma  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-ethernum\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-btc\/": {
        
        "title": "区块链项目点评1-比特币",
        "tags": ["BlockChain",],
        "content": "比特币  数字黄金，但是并比黄金好很多 区块链技术始祖 PoW共识是比特币技术最大的创新 将激励与竞争引入到机器，符合经济学原理 让财富最大程度上属于个人 比特币的信用来源数学, 来自于密码学，比特币是数学保护的财富 现阶段易涨难跌 去中心化是把双刃剑 技术并无罪，罪在人性 无国界，这是比特币坚强的重要因素 比特币不是泡沫，是共识的数字化 比特币财产的转移是一种基于多数人见证所达成的共识 比特币是一个英勇的挑战者，挑战法币，有强大的潜在的敌人，政治不正确，可能会受到强大的政治打压 点燃数字货币的星星之火，新方向的领航者与开拓者，但是并不完美 完成历史使命的传递，比特币最终会消失 IFO对于比特币来说一场分裂，并且带来安全问题（重放攻击），相同的地址影响体验 安全问题一直存在，聪明强大的AI是否带来致命一击呢 比特币价格与google搜索指数之间的关系，如下图  ![搜索指数与价格](/images/bitcoin price trade.jpg) 这张图表明比特币越来越受欢迎，且是用钱来投的票。\n参考  bitcoin源码 bitcoinABC wiki developer-documentation  ", 
        "url": "http:\/\/myself659.github.io\/post\/blockchain\/blockchain-btc\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/read-post\/": {
        
        "title": "Read",
        "tags": [],
        "content": "评分说明 ☆☆☆☆☆，五星，经典之作，强烈推荐\n☆☆☆☆，四星， 适合大众需求，推荐\n☆☆☆，三星 不错，看个人口味与需求\n☆☆，二星 不推荐\n☆，一星 强烈不推荐，得不偿失，存在严重误导\nC/C++  《C与指针》 ☆☆☆☆☆，五星 入门推荐，不要上国产参考书的当 《 C陷阱与缺陷》 ☆☆☆☆☆，五星 帮你避开常见C语言坑 《C专家编程》 ☆☆☆☆，四星 《C++沉思录》 ☆☆☆☆，四星 C++ 进阶之道 《C++ Prime Plus》 ☆☆☆☆，四星 C++ 入门必备，讲解详细  Python  《Python 基础教程》☆☆☆☆☆，五星 个人觉得最佳Python入门学习材料，打好基础就用google，github来解决问题  Go  《Go程序设计语言 英文版》☆☆☆☆，四星  Rust  《The Rust Programming Language》 ☆☆☆☆，四星 2019  设计模式  《Head First 设计模式 中文版》  计算机基础  《深入理解计算机系统 第2版》 ☆☆☆☆☆，五星 请精读且多读几遍，计算机基础方面读这一本书就可以了。 《计算机程序的构造和解释》 ☆☆☆☆☆，五星 2018  网络编程  《TCP/IP 详解 卷1：协议》 ☆☆☆☆☆，五星 《UNIX 网络编程》 ☆☆☆☆，四星 《Linux 网络编程》 ☆☆☆，三星  数学  《数学之美》 ☆☆☆☆☆，五星 《什么是数学 对思想和方法的基本研究》  数据结构与算法  《算法导论》 《数据结构 C语言版》  Linux  《鸟哥的Linux私房菜》 ☆☆☆☆，四星 Linux操作入门参考 《深入理解Linux 内核架构》 《精通Linux驱动程序开发》 《Linux内核设计艺术》 《The Linux Programming Interface Handbook》  云计算  《Software Defined Networks》 ☆☆☆☆，四星 偏架构，需要一定基础与背景 《腾云 云计算和大数据时代网络技术揭秘》 ☆☆☆☆，四星 通俗易懂地解释网络新技术 《云计算核心技术剖析》 ☆☆☆，三星 《云计算与分布式系统》 ☆☆，二星  架构设计  《SRE Google运维解密》 ☆☆☆☆☆，五星 2017 《设计数据密集型应用》 ☆☆☆☆☆，五星 2018 《Fundamentals of Software Architecture》 ☆☆☆☆☆，五星 2021  数据科学  《利用Python进行数据分析》 ☆☆☆☆☆，五星 2018  软件工程  《构建之法》 ☆☆☆☆☆，五星 邹老师多年软件开发精华总结，务实有趣，每个软件开发人员都可以买一本。  安全  《线上幽灵 世界头号黑客米特尼克自传》 ☆☆☆☆，四星 不得不防的社会工程学，不得不用的社会工程学  商业，经济，管理，科技  《从0到1\u0026mdash;开启商业与未来的秘密》 《创新者的窘境》 《杰克韦尔杰自传》 《重来:更为简单有效的商业思维》 《经济学原理 微观经济学》 ☆☆☆☆☆，五星 2017 《硅谷方法论》 ☆☆☆☆☆，五星 2019 《今日简史》 ☆☆☆☆☆，五星 2019 《人类简史》 ☆☆☆☆☆，四星 2019 《非对称风险》☆☆☆☆☆，五星 2020 书评 《债务危机》☆☆☆☆☆，五星 2020  军事，历史，政治，社会  《中国历代政治得失》 ☆☆☆，三星 可以让你不局限一个事件，而是从历史进程角度看朝代变迁与历史事件 《孙子兵法与三十六计》 ☆☆☆☆☆，五星 《纸牌屋》 ☆☆☆☆，四星 《全球通史》 ☆☆☆，三星 《大明王朝1566》 ☆☆☆☆☆，五星 2018 《权力论》 ☆☆☆☆☆，五星 2018 《通往奴役之路》☆☆☆☆☆，五星 2019 《万历十五年》☆☆☆☆☆，五星 2019 《走向共和》 ☆☆☆☆☆，五星 2021  区块链  《精通比特币》 ☆☆☆☆，四星 2017 《区块链与社会》 ☆☆☆☆，四星 2017 《区块链项目开发指南》☆☆☆☆，四星 2017 《The Bitcoin Standard》 ☆☆☆☆，四星 2019 《How to Defi》 ☆☆☆☆☆，五星 2020 《Token Economy》 ☆☆☆☆☆，五星 2020  人工智能  《终级算法》 ☆☆☆☆，四星 2017 《TensorFlow 实战Google深度学习框架》 ☆☆☆☆，四星 2017  学习，思考，认知，成长  《原子习惯》 ☆☆☆☆☆，五星 2019 《黑匣子思维：我们如何更理性地犯错》 ☆☆☆☆☆，五星 2021 《系统化思维导论》 ☆☆☆☆☆，五星 2021 《Getting Things Done》 构建适合于自己的GTD系统及习惯 《Deep Work: Rules for Focused Success in a Distracted World》 在日益容易分心的环境，如何通过刻意练习让天生不适应多任务的大脑高效有深度的工作 《The Effective Executive》时间花在哪里？单位时间内的效率如何？ 《Work the System: The Simple Mechanics of Making More and Working Less 》 《The 7 Habits of Highly Effective People》 《Essentialism: The Disciplined Pursuit of Less》 多做之过，少即是多：只有很少事情很重要，大部分情况只需要解决关键问题，其他问题也就自然而然的解决了。 《The Checklist Manifesto: How to Get Things Right》 高频事务配清单 《The Power of Full Engagement》 身体，精神，情感，意志四要素要补其短板，以便全身心投入工作 《Flow》 追求心流享受  文学  《红楼梦》 ☆☆☆☆，四星 2018  哲学  《道德经》 ☆☆☆☆☆，五星 2020  其他  《黑客与画家》 《浪潮之巅》  2022年  《Minimalist Entrepreneur》 《Zero to Sold》 《Rust for Rustaceans》 《Rust in Action》 《奔跑吧，程序员 - 从零开始打造产品、技术和团队》 《准备》 《亲密关系》 2022.11 《Noise A Flaw in Human Judgment》 《Information Theory and Coding by Example》 《事实》 《Academic Writing A Handbook for International Students》 《算法（第4版)》 《The Cold Start Problem: How to Start and Scale Network Effects》 《人类网络》 《数学通识讲义》 《Fundamentals of Software Architecture》 《穷查理宝典》 《The evolution of cooperation》 《计算之魂》 2022.10 《引爆点 如何引发流行》 《链接：商业、科学与生活的新思维》 2022.10 《Zero to Production in Rust》 《纳瓦尔宝典 (埃里克·乔根森)》 2022.11  2023  《100 Go Mistakes AND HOW TO AVOID THEM》 ☆☆☆☆☆ 2023.2 《The Mental Game of Trading: A System for Solving Problems with Greed, Fear, Anger, Confidence, and Discipline》 《The Sovereign Individual - 主权个人》 《Introduction to Algorithms, fourth edition》 《Do Dice Play God - The Mathematics of Uncertainty》 《Building a Second Brain》 《The Art of Game Design: A Book of Lenses》 《The Question Book - What Makes You Tick》 ☆☆☆☆ 2023.6 《How to Be a Person》 ☆☆☆☆ 2023.2 《The Second in Command: Unleash the Power of Your COO》 《显微镜下的大明》 《Complexity A Guided Tour》 《Richer, Wiser, Happier How the World’s Greatest Investors Win in Markets and Life》 《In Pursuit of the Unknown 17 Equations That Changed the World》 《The Joys of Compounding》 《肥尾效应》 《Hooked》 《Mastering the Trade, Third Edition: Proven Techniques for Profiting from Intraday and Swing Trading Setups》 《一人公司》 《A Hacker\u0026rsquo;s Mind: How the Powerful Bend Society\u0026rsquo;s Rules, and How to Bend Them Back》 《The Great Mental Models: General Thinking Concepts》 《Automate Your Busywork: Do Less, Achieve More, and Save Your Brain for the Big Stuff》 2023.5 《The Practitioner\u0026rsquo;s Guide to Graph Data: Applying Graph Thinking and Graph Technologies to Solve Complex Problems》 《How Not to Be Wrong: The Power of Mathematical Thinking》  后记 此篇每年更新(有一股力量让自己去行动总是好的)！\n纸上得来终觉浅 绝知此事要躬行！\n更新记录  2018年12月19日 更新 2021年1月16日 更新 2022年1月2日 添加2022年的书单  ", 
        "url": "http:\/\/myself659.github.io\/post\/read-post\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/share-post\/": {
        
        "title": "Share",
        "tags": [],
        "content": "科普  图解计算机科学 Why does time pass? | The Economist A MUST SEE!!! The Most Eye Opening 10 Minutes Of Your Life | Dr. Bruce Lipton Why Do Computers Use 1s and 0s? Binary and Transistors Explained. See How a CPU Works How do computers read code? 100 Amazing How-To Sites to Teach Yourself Anything  数学  The Map of Mathematics The Essence of Calculus, Chapter 1 Tips to be a better problem solver [Last lecture] | Lockdown math ep. 10  经济  经济机器是怎样运行的(文字版) 经济机器是怎样运行的 (时长30分钟) Ray Dalio  log  The Log: What every software engineer should know about real-time data\u0026rsquo;s unifying abstraction Logging Best Practices  工具 VS Code  VS Code Top-Ten Pro Tips VS Code: The Last Editor You\u0026rsquo;ll Ever Need  chrome  vimium Google Translate Plus   Programe  16 Programming Productivity Tools You Can Use Even if You’re Not a Programmer  latex  codecogs  搜索  15 Ways to Search Google 96% of People Don’t Know About  网站  10 Useful Websites You Wish You Knew Earlier! 2018  学习  How to Learn Anything\u0026hellip; Fast - Josh Kaufman The first 20 hours \u0026ndash; how to learn anything | Josh Kaufman | TEDxCSU  架构  亚马逊1万亿市值背后的架构经验：AWS十年沉淀下来的十条宝贵经验  导航  All cheat sheets TL;DR cheat for development linux-syscall-table egex Cheat Sheet GitSheet Awesome-Cheatsheets OverAPI.com HTML CheatSheet 10 JavaScript Cheat Sheets That Will Boost Your Productivity  生活  时区转换  人物 Jim Keller  Jim Keller (engineer) An AnandTech Exclusive: The Jim Keller Interview  Elon Musk  首飞成功！SpaceX “重型猎鹰\u0026quot;登顶世界运力最强运载火箭，马斯克卧薪七年终于再次改写历史 刚刚，马斯克改写人类航天史！SpaceX实现全球首次商业载人发射  公开信  网易CEO丁磊首封致股东信 黄峥发布2020年度致股东信：新的世界正在到来，新的物种必然出现 张一鸣卸任字节跳动CEO公开信  公关  美团外卖回应：宣布五项改进举措 给骑手留出8分钟弹性时间 饿了么将推出多等5分钟功能 外卖骑手，困在系统里  ", 
        "url": "http:\/\/myself659.github.io\/post\/share-post\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/slide-post\/": {
        
        "title": "Slide",
        "tags": [],
        "content": "2017  高性能服务器设计与优化(High performance server design and optimization)  2018  数字货币钱包产品定位与战略.pdf 下一代互联网基础：IPFS.pdf  ", 
        "url": "http:\/\/myself659.github.io\/post\/slide-post\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-09-21-ipfs-sec\/": {
        
        "title": "IPFS与下一代网络安全",
        "tags": ["IPFS",],
        "content": "IPFS 先简单说一下IPFS。 IPFS是点对点协议InterPlanetary File System的简称，它是一个面向全球的、点对点的分布式版本文件系统，试图将所有具有相同文件系统的计算设备连接在一起。它用基于内容的地址替代基于域名的地址，也就是用户寻找的不是某个地址而是储存在某个地方的内容，不需要验证发送者的身份，而只需要验证内容的哈希，通过这样可以让网页的速度更快、更安全、更健壮、更持久。IPFS目标是未来将替代HTTP。\nIPFS主要技术，用下面这张图说明：\nIPFS与安全 整个IPFS涉及很多方面的内容，这部分具体看一下IPFS对网络安全的影响。首先从DDOS防攻击展开，IPFS应对DDOS攻击主要如下：\n 道哥在弹性安全网络中表达过DDOS存在的原因就是现在互联网严重依赖存在三大问题的DNS系统,而在IPFS中通过内容寻址方式绕开了DNS IPFS底层网络是基于DHT，拥有大量节点的P2P网络，天生适合内容的分布式读写（PS：P2P网络安全需要另行考虑） 内容签名，通过加密加大攻击的难度与成本  上面的这些作法，很符合经济原理。DDOS存在主要经济学原因是DDOS获得的收益远大于DDOS的投资；IPFS的上述特点直接提高DDOS的成本。\n比较 上一篇分析了道哥的提出的弹性安全网络设想。那么，就在这里搞事情，对比一下两者。\n  道哥和Juan Benet都是杰出的技术人员及创业者，富有远见\n  作为安全出身的道哥的出发点解决网络安全问题主要是DDOS安全攻击问题，而IPFS目标如下：We believe the internet has become humanity's most important technology. We build protocols, systems, and tools to improve how it works. Today, we are focused on how we store, locate, and move information.\n  IPFS是一种去中心化技术，而弹性安全网络接入技术可以是一种大规模的云计算技术（中心化技术）。\n  IPFS没有网络访问控制功能，自由开放；弹性安全网络有网络访问控制能力，方便监管与控制\n  IPFS是从数据角度来解决问题（解决数据分布，版本，访问，权限控制等）,弹性安全网络从网络安全的角度来解决问题\n  IPFS开放源码，弹性安全网络没有开源，开源的IPFS体现了去中心化技术的态度\n  IPFS现网运行，弹性安全网络在游戏盾中得到应用与实践，两者都有很长的路需要走\n  IPFS目标是取代HTTP,同时兼容HTTP，弹性安全网络将应用场景定位在非域名类的IP网络\n  IPFS对现有应用冲击很大，因为去中心化应用及基础设施（如去中心数据库）还在起步阶段；弹性安全网络考虑基于现有云计算（大规模中心化技术）应用作为出发点一种网络安全的解决方案，能够兼容云计算应用。\n  IPFS支持端对端加解密，保证数据的隐私。弹性安全网络不涉及这方面内容。\n  IPFS是事前准备，弹性安全网络更多体现发现攻击一种事后处理角度出发。\n  IPFS用去中以化来应对攻击，弹性安全网络用技术（大数据，人工智能）来应对攻击。\n  最后说一下：IPFS就像以电为动力的特斯拉，道哥的弹性安全网络则像是不断改进的燃油车。就如同特斯拉给汽车带来的革命和冲击一样，IPFS对整个互联网带来变革与颠覆。\n（个人能力有限，不足与错误欢迎指正，欢迎交流！）\n参考  IPFS Amazon\u0026rsquo;s web servers are down and it\u0026rsquo;s causing trouble across the internet Why The Internet Needs IPFS Before It\u0026rsquo;s Too Late  ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-09-21-ipfs-sec\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-09-20-next-network\/": {
        
        "title": "关于弹性安全网络一点思考",
        "tags": ["ipfs",],
        "content": "作为网络研发出身的我，从事网络研发时间也最长，一直也关注道哥的微信公众号。\n下面就对道哥的提出弹性安全网络一些总结与思考。\n弹性安全网络 具体从以下几个方面解读弹性安全网络。\n来源 弹性安全网络这个设想来自阿里云游戏盾这个产品，而这个产品解决的问题就是如何解决DDOS问题。\n以前解决DDOS问题，很多厂商就是以暴制暴，准备大量带宽，抗住攻击流量，这种方式有以下问题：\n 流量成本高 万一没有抗住，服务会中断 业务局限于一个数据中心，目标明显，容易受攻击（将鸡蛋放到同一个篮子）  而在游戏盾产品采用另一种方式来解决问题，主要要点如下：\n 首先，业务访问支持多IP解析，分散流量（狡免三窟） 第二就是应对攻击，支持业务地址迁移，地址迁移难点就是如何快速通知到各个用户（你打我，我就闪）  定义  弹性安全网络是将DDoS防御前置到网络边缘处。但是，未来真正要做的事情是通过端到端的连接，通过风险控制技术，重新构建一个干净的、安全的互联网\n 目标  弹性安全网络真正想要去做的，是替换掉整个互联网最核心的心脏，替换掉DNS，从而让网络变得有弹性，能够快速调度资源，形成一个全新的网络架构。\n  弹性安全网络技术，不是为某一个客户设计的，它是为整个互联网设计的。\n DNS三个问题  DNS是互联网的心脏\n  第一个，是DNS完全解析的时间过长，这是整个DNS使用中遇到的一个非常大的痛点。\n  第二个问题是今天DNS Server软件中的解析数遇到了瓶颈，没有办法一个名字解析到几千个、甚至上万个，甚至未来十几万个不同地址。一个名字可能最多也就解析到十几个或几十个地址就不能再扩大了。这种瓶颈限制了我们的一些能力拓展。\n  第三个就是，原本可以基于DNS去实现的一些安全机制，比如风险控制，并没有建立起来。其实也比较好理解，在互联网1.0时代并没有如今天这般强大的数据能力和计算能力。\n 实现 文中并没有提及具体的实现，主要要点是：\n 基于大数据的足迹库 基于人工智能的快速识别能力 分布式的统一网络访问入口，取代DNS，具体细节未知  未来  主要机会就是在IoT和移动互联网，因为这两者实际上是没有DNS的需求的\n 总结 道哥的弹性安全网络，是一个伟大的构思。\n弹性安全网络出发点主要是解决DDOS问题。\n主要目标应用于IOT和移动互联网。\n弹性安全网络思考主要出发点是如何应对网络攻击，主要从两个角度出发：\n 如何快速应对攻击 如何利用技术（大数据，人工智能等）识别攻击  参考  弹性安全网络 \u0026ndash; 构建下一代安全的互联网 IPFS与下一代网络安全  ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-09-20-next-network\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-08-24-ethereum-start\/": {
        
        "title": "以太坊私链智能合约实践",
        "tags": ["blockchain",],
        "content": "环境说明  操作系统: macos.10.12.1 geth版本：1.5.9 solc版本：0.4.15  实践 1. 启动本地geth节点 1  Michaels-iMac:wallet eric$ geth --rpc --rpcaddr 127.0.0.1 --rpcport 8545 --dev --datadir myethchain   如上操作后，geth console输出如下：\n1 2 3 4 5 6  I0824 17:28:57.448455 p2p/server.go:340] Starting Server I0824 17:28:59.554115 p2p/discover/udp.go:227] Listening, enode://04697f62537244ee34aea28e613530a1f46a64de75d8174d963c9ca0c2e6b96d4aa756ef7a33e269de1b7c088163835b72dda8f4dea712cf39569db4e8d8e43a@[::]:54798 I0824 17:28:59.554264 p2p/server.go:608] Listening on [::]:58245 I0824 17:28:59.554324 whisper/whisperv2/whisper.go:176] Whisper started I0824 17:28:59.570668 node/node.go:341] IPC endpoint opened: /Users/eric/wallet/myethchain/geth.ipc I0824 17:28:59.581423 node/node.go:411] HTTP endpoint opened: http://127.0.0.1:8545   同时也创建在当前目录创建目录myethchain，其结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  Michaels-iMac:wallet eric$ tree myethchain/ myethchain/ ├── geth │ ├── LOCK │ ├── chaindata │ │ ├── 000002.log │ │ ├── CURRENT │ │ ├── LOCK │ │ ├── LOG │ │ └── MANIFEST-000003 │ ├── nodekey │ └── nodes │ ├── 000001.log │ ├── CURRENT │ ├── LOCK │ ├── LOG │ └── MANIFEST-000000 ├── geth.ipc └── keystore 4 directories, 13 files   2. 连接geth节点 在另外一个终端里连接geth节点。\n1 2 3 4 5 6 7  Michaels-iMac:wallet eric$ geth attach ipc://Users/eric/wallet/myethchain/geth.ipc Welcome to the Geth JavaScript console! instance: Geth/v1.5.9-stable-a07539fb/darwin/go1.8.3 modules: admin:1.0 debug:1.0 eth:1.0 miner:1.0 net:1.0 personal:1.0 rpc:1.0 shh:1.0 txpool:1.0 web3:1.0 \u0026gt;   3. 确保solidity编译器安装正确 1 2 3  \u0026gt; web3.eth.getCompilers() [\u0026#34;Solidity\u0026#34;] \u0026gt;   如果出错或者获取为空，请检查solc安装情况。\n4. 查看帐户列表 1 2 3  \u0026gt; personal.listAccounts null \u0026gt;   5. 创建帐户 1 2 3  \u0026gt; personal.newAccount(\u0026#39;pw1234\u0026#39;) \u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34; \u0026gt;   6. 查看帐户列表 1 2 3  \u0026gt; personal.listAccounts [\u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34;] \u0026gt;   7. 查看coibase地址 1 2  \u0026gt; web3.eth.coinbase \u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34;   与上面地址一致，默认取第一个创建帐户的地址，作为挖矿的收益打入该地址\n8. 准备智能合约 1 2 3  \u0026gt; source = \u0026#34;contract hello { function multen(uint a) returns(uint d){return a * 10;}}\u0026#34; \u0026#34;contract hello { function multen(uint a) returns(uint d){return a * 10;}}\u0026#34; \u0026gt;   9. 编译智能合约 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026gt; code = web3.eth.compile.solidity(source) { \u0026lt;stdin\u0026gt;:hello: { code: \u0026#34;0x60606040523415600e57600080fd5b5b60978061001d6000396000f300606060405263ffffffff7c0100000000000000000000000000000000000000000000000000000000600035041663e847973c8114603c575b600080fd5b3415604657600080fd5b604f6004356061565b60405190815260200160405180910390f35b600a81025b9190505600a165627a7a72305820395c2030cb020d0b4f79ac0803f1aa28b97082d962a13f37a914f7950e1de5ec0029\u0026#34;, info: { abiDefinition: [{...}], compilerOptions: \u0026#34;--combined-json bin,abi,userdoc,devdoc --add-std --optimize\u0026#34;, compilerVersion: \u0026#34;0.4.15\u0026#34;, developerDoc: { methods: {} }, language: \u0026#34;Solidity\u0026#34;, languageVersion: \u0026#34;0.4.15\u0026#34;, source: \u0026#34;contract hello { function multen(uint a) returns(uint d){return a * 10;}}\u0026#34;, userDoc: { methods: {} } } } }   10. 根据ABI创建合约对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  \u0026gt; MyContract = web3.eth.contract(code[\u0026#34;\u0026lt;stdin\u0026gt;:hello\u0026#34;].info.abiDefinition) { abi: [{ constant: false, inputs: [{...}], name: \u0026#34;multen\u0026#34;, outputs: [{...}], payable: false, type: \u0026#34;function\u0026#34; }], eth: { accounts: [\u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34;], blockNumber: 0, coinbase: \u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34;, compile: { lll: function(), serpent: function(), solidity: function() }, defaultAccount: undefined, defaultBlock: \u0026#34;latest\u0026#34;, gasPrice: 21782200000, hashrate: 0, mining: false, pendingTransactions: [], protocolVersion: \u0026#34;0x3f\u0026#34;, syncing: false, call: function(), contract: function(abi), estimateGas: function(), filter: function(fil, callback), getAccounts: function(callback), getBalance: function(), getBlock: function(), getBlockNumber: function(callback), getBlockTransactionCount: function(), getBlockUncleCount: function(), getCode: function(), getCoinbase: function(callback), getCompilers: function(), getGasPrice: function(callback), getHashrate: function(callback), getMining: function(callback), getPendingTransactions: function(callback), getProtocolVersion: function(callback), getRawTransaction: function(), getRawTransactionFromBlock: function(), getStorageAt: function(), getSyncing: function(callback), getTransaction: function(), getTransactionCount: function(), getTransactionFromBlock: function(), getTransactionReceipt: function(), getUncle: function(), getWork: function(), iban: function(iban), icapNamereg: function(), isSyncing: function(callback), namereg: function(), resend: function(), sendIBANTransaction: function(), sendRawTransaction: function(), sendTransaction: function(), sign: function(), signTransaction: function(), submitTransaction: function(), submitWork: function() }, at: function(address, callback), getData: function(), new: function() } \u0026gt;   11. 挖矿 第一步：获取帐户地址\n1 2 3  \u0026gt; account1 = web3.eth.coinbase \u0026#34;0xaf3139393f2ecb2455cbc2c7639ce111017fb90b\u0026#34; \u0026gt;   第二步：查看balance\n1 2 3  \u0026gt; web3.eth.getBalance(account1) 0 \u0026gt;   第三步：启动挖矿\n1 2  \u0026gt; miner.start() true   第四步：查看balance\n1 2  \u0026gt; web3.eth.getBalance(account1) 424531250000000000000   第五步: 停止挖矿\n钱差不多就够了。\n1 2 3  \u0026gt; miner.stop() true \u0026gt;   12. 解锁帐户 目的是为了发送交易\n1 2  \u0026gt; personal.unlockAccount(account1, \u0026#39;pw1234\u0026#39;) true   13. 初始化智能合约 1 2 3  \u0026gt; bytecode = code[\u0026#34;\u0026lt;stdin\u0026gt;:hello\u0026#34;].code \u0026#34;0x60606040523415600e57600080fd5b5b60978061001d6000396000f300606060405263ffffffff7c0100000000000000000000000000000000000000000000000000000000600035041663e847973c8114603c575b600080fd5b3415604657600080fd5b604f6004356061565b60405190815260200160405180910390f35b600a81025b9190505600a165627a7a72305820395c2030cb020d0b4f79ac0803f1aa28b97082d962a13f37a914f7950e1de5ec0029\u0026#34; \u0026gt;   获取部署合约的gas费用开销\n1 2 3  \u0026gt; web3.eth.estimateGas({data: bytecode}) 30886 \u0026gt;   14. 部署智能合约 1 2 3 4 5 6 7 8 9 10 11 12 13 14  contractInstance = MyContract.new({data: bytecode gas: 1000000, from: account1}, function(e, contract){if(!e){if(!contract.address){console.log(\u0026#34;Contract transaction send: Transaction Hash: \u0026#34;+contract.transactionHash+\u0026#34; waiting to be mined...\u0026#34;);}else{console.log(\u0026#34;Contract mined! Address: \u0026#34;+contract.address);console.log(contract);}}else{console.log(e)}}) Contract transaction send: Transaction Hash: 0xeeac0f028e559d469b94805b986b1d9a0bd0d30289e3285487310ca426dae034 waiting to be mined... { abi: [{ constant: false, inputs: [{...}], name: \u0026#34;multen\u0026#34;, outputs: [{...}], payable: false, type: \u0026#34;function\u0026#34; }], address: undefined, transactionHash: \u0026#34;0xeeac0f028e559d469b94805b986b1d9a0bd0d30289e3285487310ca426dae034\u0026#34; }   如果出现以下错误：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026gt; contractInstance = MyContract.new({data: bytecode gas: 1000000, from: account1}, function(e, contract){if(!e){if(!contract.address){console.log(\u0026#34;Contract transaction send: Transaction Hash: \u0026#34;+contract.transactionHash+\u0026#34; waiting to be mined...\u0026#34;);}else{console.log(\u0026#34;Contract mined! Address: \u0026#34;+contract.address);console.log(contract);}}else{console.log(e)}}) Error: authentication needed: password or unlock { abi: [{ constant: false, inputs: [{...}], name: \u0026#34;multen\u0026#34;, outputs: [{...}], payable: false, type: \u0026#34;function\u0026#34; }], address: undefined, transactionHash: null }   重新解锁用户即可\n14. 重新挖矿 1 2 3 4  \u0026gt; miner.start() true \u0026gt; Contract mined! Address: 0x58dba5bddccde639cef014c1766561abbc46c13f [object Object]   15. 切换 console 1 2 3 4  \u0026gt; Contract mined! Address: 0x58dba5bddccde639cef014c1766561abbc46c13f [object Object] ^C \u0026gt;   16. 检查合约安装是否成功 1 2 3  \u0026gt; eth.getCode(contractInstance.address) \u0026#34;0x606060405263ffffffff7c0100000000000000000000000000000000000000000000000000000000600035041663e847973c8114603c575b600080fd5b3415604657600080fd5b604f6004356061565b60405190815260200160405180910390f35b600a81025b9190505600a165627a7a72305820395c2030cb020d0b4f79ac0803f1aa28b97082d962a13f37a914f7950e1de5ec0029\u0026#34; \u0026gt;   17. 调用合约函数 1 2  \u0026gt; contractInstance.multen.call(9) 90   (end)\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-08-24-ethereum-start\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/dsa\/dfs-vs-bfs\/": {
        
        "title": "DFS与BFS适用场景",
        "tags": ["algorithm","graph",],
        "content": "背景 Depth-First-Search(DFS)深度优先搜索与Breadth-First Search(BFS)广度优先搜索是树与图中最常用的算法。\nDFS 适用于DFS场景：\n 在图中找到两个节点之间中最长路径 检测图中是否存在环 当一个树分支很多，使用BFS会导致内存不足或者占用太多，可以考虑使用DFS 需要在先访问子节点，再访问兄弟节点 通过DFS可以访问更多可能路径，可以用于解决迷宫与拼图问题  BFS 适用于BFS场景：\n 在图中找到两个节点之间的最短路径时 在断定目标节点在根节点或者起始节点附近（不需要深度搜索） 优先搜索靠近起始节点的节点 需要在先访问兄弟节点，再访问子节点  ", 
        "url": "http:\/\/myself659.github.io\/post\/dsa\/dfs-vs-bfs\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-08-22-ethereum-cannot-getsolidity\/": {
        
        "title": "以太坊开发环境问题记录",
        "tags": ["blockchain",],
        "content": "说明 主要记录以太坊开发环境过程出现的问题\ngetCompilers返回失败 问题描述 在搭建以太坊开发环境过程中，出现下面的错误信息：\n1 2 3 4 5 6 7 8 9 10 11  Welcome to the Geth JavaScript console! instance: Geth/v1.6.7-stable-ab5646c5/darwin-amd64/go1.8.3 modules: admin:1.0 debug:1.0 eth:1.0 miner:1.0 net:1.0 personal:1.0 rpc:1.0 shh:1.0 txpool:1.0 web3:1.0 \u0026gt; web3.eth.getCompilers() Error: The method eth_getCompilers does not exist/is not available at web3.js:3104:20 at web3.js:6191:15 at web3.js:5004:36 at \u0026lt;anonymous\u0026gt;:1:1   问题原因 geth版本编译不在gopath目录下编译\n解决方法 在gopath目录重新编译即可\n1 2 3 4 5 6 7 8 9  Michaels-iMac:wallet eric$ geth attach ipc://Users/eric/wallet/privchain/geth.ipc Welcome to the Geth JavaScript console! instance: Geth/v1.5.9-stable-a07539fb/darwin/go1.8.3 modules: admin:1.0 debug:1.0 eth:1.0 miner:1.0 net:1.0 personal:1.0 rpc:1.0 shh:1.0 txpool:1.0 web3:1.0 \u0026gt; web3.eth.getCompilers() [\u0026#34;Solidity\u0026#34;] \u0026gt;   parity启动失败 问题描述 搭建测试环境中出现以下问题：\n1 2 3 4  root@ia:~#parity --chain=kovan --jsonrpc-hosts=all parity: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `CXXABI_1.3.8\u0026#39; not found (required by parity) parity: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.20\u0026#39; not found (required by parity) parity: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21\u0026#39; not found (required by parity)   问题原因 gcc/g++版本是4.8版本\n解决方案 升级gcc/g++\n1 2 3 4  sudo add-apt-repository ppa:ubuntu-toolchain-r/test sudo apt-get update sudo apt-get install gcc-4.9 g++-4.9 sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.9 60 --slave /usr/bin/g++ g++ /usr/bin/g++-4.9   parity访问出现bad gateway问题 问题描述 1  curl -X POST http://localhost:8545 -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;eth_getBlockByNumber\u0026#34;,\u0026#34;params\u0026#34;:[\u0026#34;0x1b4\u0026#34;, true],\u0026#34;id\u0026#34;:1}\u0026#39;   本地访问ok\n1  curl -X POST http://47.96.45.67:8545 -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;eth_getBlockByNumber\u0026#34;,\u0026#34;params\u0026#34;:[\u0026#34;0x1b4\u0026#34;, true],\u0026#34;id\u0026#34;:1}\u0026#39;   远程访问返回失败\n问题原因 1  parity --chain=kovan --jsonrpc-hosts=all   上面命令限定侦听端口为本机接口\n解决方案 1  parity --chain=kovan --jsonrpc-interface=0.0.0.0 --jsonrpc-hosts=all   以上述命令启动parity打开侦听限制\n没有eth无法在kovan上部署智能合约 问题描述 没有eth无法部署成功部署智能合约\n问题原因 天下没有免费的午餐\n解决方法 参考Kovan Faucet,四种方式选择其中一个即可，Github Gist Faucet方式参考这里\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-08-22-ethereum-cannot-getsolidity\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-07-28-slice-trap\/": {
        
        "title": "slice复用的陷阱",
        "tags": ["golang",],
        "content": "前言 先下结论：slice复用得当心，引用不当深埋雷。如若复用请分叉，分叉之后再使用。\n问题 先看一下代码吧\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package main import ( \u0026#34;fmt\u0026#34; ) func a() { x := []int{} x = append(x, 0) x = append(x, 1) // commonTags := labelsToTags(app.Labels) \ty := append(x, 2) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tz := append(x, 3) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tfmt.Println(y, z) } func b() { x := []int{} x = append(x, 0) x = append(x, 1) x = append(x, 2) // commonTags := labelsToTags(app.Labels) \ty := append(x, 3) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tz := append(x, 4) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tfmt.Println(y, z) } func main() { a() b() }   上面的如此简单的代码，分析代码希望得到预期结果如下：\n1 2  [0 1 2] [0 1 3] [0 1 2 3] [0 1 2 4]   但是执行后，得到结果如下：\n1 2 3  Michaels-iMac:golab eric$ go run slice.go [0 1 2] [0 1 3] [0 1 2 4] [0 1 2 4]   原因分析 我们先不急着分析具体原因，我们对比一下下面这段代码，看看执行结果是怎么样\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  package main import ( \u0026#34;fmt\u0026#34; ) func a() { x := []int{} x = append(x, 0) x = append(x, 1) // commonTags := labelsToTags(app.Labels) \ty := append(x, 2) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tz := append(x, 3) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tfmt.Println(y, z) } func deepcopy(src []int) []int { dst := make([]int, len(src)) copy(dst, src) return dst } func b() { x := []int{} x = append(x, 0) x = append(x, 1) x = append(x, 2) // commonTags := labelsToTags(app.Labels) \ty := deepcopy(x) y = append(y, 3) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tz := append(x, 4) // Tags: append(commonTags, labelsToTags(d.Labels)...) \tfmt.Println(y, z) } func main() { a() b() }   具体执行结果如下：\n1 2 3  Michaels-iMac:golab eric$ go run slice-2.go [0 1 2] [0 1 3] [0 1 2 3] [0 1 2 4]   对比错误的代码，会发现问题原因出现下面的代码：\n1 2  y := append(x, 3) // Tags: append(commonTags, labelsToTags(d.Labels)...) z := append(x, 4) // Tags: append(commonTags, labelsToTags(d.Labels)...)   从内存角度来思考，y与z对应是同一段内存，z的操作override的y的操作。（备注：y与z为什么会更对应同一段内存，请了解一下slice的实现及slice的巧妙的使用，也请阅读下面参考文章Golang slices gotcha）\n解决方法就是如果slice要进行复用的时候，进行深度copy再进行使用。\n总结 slice在golang编程属于超高频使用，如果出现上面的错误，前期没有发现，如果上线，并且系统复杂，出现了问题，定位成本是很大。\n虽然上面没有slice的内存分析，但是对于程序员来说学习一些内存知识还很帮助，理解上面的问题就是小case了。\n参考  Golang slices gotcha  ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-07-28-slice-trap\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/%E9%AB%98%E8%B4%A8%E9%87%8F%E6%80%9D%E8%80%83-thinking\/": {
        
        "title": "什么是高质量的思考",
        "tags": ["学习","thinking",],
        "content": "思考的质量 人一思考,上帝就开始发笑。所以人要学会思考，提高思考的质量。\n下面从四个角度来看看有哪些因素决定思考的质量？\n原则  怀疑一切，大胆假设，小心验证 实事求是 注重方法与策略  Input  好问题 问题描述 能量 专注  Process  广度 深度 清晰 适度 创造  Output  清晰 准确 全面 深度 逻辑 创造 可操作性 持续性  总结 高质量思考= 高质量的原则+高质量的Input+高质量的Process+高质量的Output。\n", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/%E9%AB%98%E8%B4%A8%E9%87%8F%E6%80%9D%E8%80%83-thinking\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/principle-to-set-goal-%E7%9B%AE%E6%A0%87\/": {
        
        "title": "设定目标的原则",
        "tags": ["life",],
        "content": "目标的意义  目标是指导前进的方向 目标帮助思考：我们真正想要的是什么？ 目标是动力的来源之一 目标有利于抗干扰，提高专注力  SMART原则 谈及目标原则，必会谈到SMART原则。\n关于SMART原则，可以根据五个字母拆解如下：\n　1. 目标必须是具体的（Specific） 2. 目标必须是可以衡量的（Measurable） 3. 目标必须是可以达到的（Attainable） 4. 目标必须和其他目标具有相关性（Relevant） 5. 目标必须具有明确的截止期限（Time-based）\nSMART原则存在以下问题：\n SMART原则是针对具体目标设置的原则 虽然SMART原则对于目标的完成作了具体的要求，但是缺少对于目标的标准没有明确的说明  针对这些问题，个人补充6个原则：\n 目标要少 目标要准 目标标准要高 目标要有阶段性 目标基于过程而是基于结果 目标与最强的动机结合  目标要少 在生活与工作我们在设定目标的时候最容易出现这种情况： 设定目标如山倒，完成目标如抽丝。出现这种情况的原因之一就是目标太多，导致缺少专注，同时要完成目标多，导致精力有限，目标之间切换成本增高。\n目标少的话，可以提高专注，进一步提高效率，在实际工作中就是遵守one-task的原则。\n目标要准 目标少可以有效提高目标的完成率，目标完成并不一定会有好的产出。这里举一个例子，有一些公司用代码行数来作为员工的考核指标，这种情况下往往只会导致公司的代码库越来越大，代码质量越来越差，整个系统的问题越来越多。这是一个典型目标设定不准确的体现，准确目标应该是提高公司产品稳定性，增加合理的功能，满足市场需求，提高公司的营收与市场竞争力。\n目标标准要高 目标要完成同时也要兼顾高标准，不能为了完成降低标准。特别是个人成长方面，只有高标准才能进一步激发自己的潜能，不断进步。\n典型例子：团队招聘的时候要求新加入的成员的水平要在团队平均水平之上，这样才能不断提高这个团队的水平。\n目标要有阶段性 最常见就是一个年度目标要有对应的季度目标，月度目标，星期目标，这样才能不断推进自己完成目标，而不是光有一个宏伟的目标。\n目标基于过程而是基于结果 基于结果的目标只关注你想要的结果，而不关注实现它所需的行动。如果你过于关注结果，而对实现结果所需的行动不够关注，你就不会取得任何进展。相反基于过程的目标可帮助您专注于实现特定结果所需采取的行动。例如如果要减肥，目标定为一周去四次健身房相比较于一个月减10斤更好。\n目标与最强的动机结合 制定目标要与最强的动机结合起来，动机越强，完成目标的可能性更高。\n怎么加强动机呢？目标要与自己最在意的人和事结合在一起。\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/life\/principle-to-set-goal-%E7%9B%AE%E6%A0%87\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-05-10-linux-process-diagnose\/": {
        
        "title": "Linux进程诊断小结",
        "tags": ["Linux",],
        "content": "日常工作中最常见问题是如何诊断一个进程运行过程中出现的问题，下面的总结从进程诊断的角度来展示，而是不从工具与命令角度来展示，进程诊断是工作的主体，工具与命令只是工具。\n进程信息 获得进程PID 方式一：\n1 2  root@iZ2ze9qnmldt4l3l82gtviZ:~# pidof tmsf-zc 2064   方式2：\n1 2 3 4  root@iZ2ze9qnmldt4l3l82gtviZ:~# ps -ef | grep tmsf-zc root 2064 1 0 Mar17 ? 02:24:25 ./tmsf-zc root 7596 7288 0 15:07 pts/4 00:00:00 grep --color=auto tmsf-zc root@iZ2ze9qnmldt4l3l82gtviZ:~#   查看进程线程个数 及对应PID 1 2 3 4 5 6 7 8  root@iZ2ze9qnmldt4l3l82gtviZ:~# ps -efL | grep tmsf-zc root 2064 1 2064 0 5 Mar17 ? 00:00:00 ./tmsf-zc root 2064 1 2066 0 5 Mar17 ? 01:04:46 ./tmsf-zc root 2064 1 2067 0 5 Mar17 ? 00:44:53 ./tmsf-zc root 2064 1 2068 0 5 Mar17 ? 00:34:39 ./tmsf-zc root 2064 1 2069 0 5 Mar17 ? 00:00:04 ./tmsf-zc root 7604 7288 7604 0 1 15:08 pts/4 00:00:00 grep --color=auto tmsf-zc root@iZ2ze9qnmldt4l3l82gtviZ:~#   查看进程CPU与内存使用情况 1 2 3 4 5 6 7 8 9 10 11 12 13 14  root@iZ2ze9qnmldt4l3l82gtviZ:~# top -H -p 2064 top - 15:10:57 up 14 days, 5:43, 3 users, load average: 0.00, 0.03, 0.05 Threads: 5 total, 0 running, 5 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.0 us, 0.0 sy, 0.0 ni, 99.7 id, 0.3 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem: 2049904 total, 1961580 used, 88324 free, 204396 buffers KiB Swap: 0 total, 0 used, 0 free. 1334832 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2064 root 20 0 55752 7180 2756 S 0.0 0.4 0:00.00 tmsf-zc 2066 root 20 0 55752 7180 2756 S 0.0 0.4 64:46.35 tmsf-zc 2067 root 20 0 55752 7180 2756 S 0.0 0.4 44:53.83 tmsf-zc 2068 root 20 0 55752 7180 2756 S 0.0 0.4 34:39.08 tmsf-zc 2069 root 20 0 55752 7180 2756 S 0.0 0.4 0:04.49 tmsf-zc   1 2 3 4 5 6 7 8 9 10  root@iZ2ze9qnmldt4l3l82gtviZ:~# top -p 2064 top - 15:11:05 up 14 days, 5:43, 3 users, load average: 0.00, 0.03, 0.05 Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.8 us, 1.2 sy, 0.0 ni, 98.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem: 2049904 total, 1961448 used, 88456 free, 204396 buffers KiB Swap: 0 total, 0 used, 0 free. 1334836 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2064 root 20 0 55752 7180 2756 S 0.0 0.4 144:25.09 tmsf-zc   查看进程对应的可执行文件 1 2 3  root@iZ2ze9qnmldt4l3l82gtviZ:~# ls -l /proc/2064/exe lrwxrwxrwx 1 root root 0 Mar 17 10:12 /proc/2064/exe -\u0026gt; /test/tmsf-zc root@iZ2ze9qnmldt4l3l82gtviZ:~#   查看进程占用fd个数 1 2  root@iZ2ze9qnmldt4l3l82gtviZ:~# ls -l /proc/2064/fdinfo | wc -l 18   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  root@iZ2ze9qnmldt4l3l82gtviZ:~# lsof -p 2064 | grep tmsf-zc tmsf-zc 2064 root cwd DIR 253,1 4096 1967431 /test tmsf-zc 2064 root rtd DIR 253,1 4096 2 /test tmsf-zc 2064 root txt REG 253,1 8660422 1049012 test/tmsf-zc tmsf-zc 2064 root mem REG 253,1 1840928 796801 /lib/x86_64-linux-gnu/libc-2.19.so tmsf-zc 2064 root mem REG 253,1 141574 796793 /lib/x86_64-linux-gnu/libpthread-2.19.so tmsf-zc 2064 root mem REG 253,1 149120 796794 /lib/x86_64-linux-gnu/ld-2.19.so tmsf-zc 2064 root 0r CHR 1,3 0t0 5304 /dev/null tmsf-zc 2064 root 1w REG 253,1 306118 1971776 test/nohup.out tmsf-zc 2064 root 2w REG 253,1 306118 1971776 test/nohup.out tmsf-zc 2064 root 3u sock 0,7 0t0 974790 can\u0026#39;t identify protocol tmsf-zc 2064 root 4u 0000 0,9 0 5259 anon_inode tmsf-zc 2064 root 5u IPv4 192212 0t0 TCP 172.17.11.187:47222-\u0026gt;60.191.13.153:http (ESTABLISHED) tmsf-zc 2064 root 6u IPv4 216011 0t0 TCP 172.17.11.187:47275-\u0026gt;60.191.13.153:http (ESTABLISHED) tmsf-zc 2064 root 7u IPv4 270741 0t0 TCP 172.17.11.187:40874-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 8u IPv4 357728 0t0 TCP 172.17.11.187:40966-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 9u IPv4 417481 0t0 TCP 172.17.11.187:47589-\u0026gt;60.191.13.153:http (ESTABLISHED) tmsf-zc 2064 root 10u IPv4 504612 0t0 TCP 172.17.11.187:41185-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 11u IPv4 555010 0t0 TCP 172.17.11.187:47795-\u0026gt;60.191.13.153:http (ESTABLISHED) tmsf-zc 2064 root 12u IPv4 665995 0t0 TCP 172.17.11.187:41409-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 13u IPv4 717507 0t0 TCP 172.17.11.187:42001-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 14u IPv4 755724 0t0 TCP 172.17.11.187:42108-\u0026gt;60.191.13.122:http (ESTABLISHED) tmsf-zc 2064 root 15u IPv4 846915 0t0 TCP 172.17.11.187:48714-\u0026gt;60.191.13.153:http (ESTABLISHED) tmsf-zc 2064 root 16u IPv4 974784 0t0 TCP 172.17.11.187:49598-\u0026gt;60.191.13.153:http (ESTABLISHED)   从proc/pid/stat获取更多进程信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  root@iZ2ze9qnmldt4l3l82gtviZ:~# procstat 2064 pid: 2064 tcomm: (tmsf-zc) state: S ppid: 1 pgid: 2058 sid: 1911 tty_nr: 0 tty_pgrp: -1 flags: 1077960960 min_flt: 7652 cmin_flt: 0 maj_flt: 10 cmaj_flt: 0 utime: 2558.590000 stime: 6106.500000 cutime: 0.000000 cstime: 0.000000 priority: 20 nice: 0 num_threads: 5 it_real_value: 0.000000 start_time: 03.17 10:12 (971043.78s) vsize: 57090048 rss: 1795 rsslim: 9223372036854775807 start_code: 4194304 end_code: 7446752 start_stack: 140735025190528 esp: 140735025189968 eip: 4549907 pending: 0000000000000000 blocked: 0000000000000000 sigign: 0000000000000003 sigcatch: 000000007fc1fefc wchan: 0 zero1: 0 zero2: 0 exit_signal: 0000000000000011 cpu: 0 rt_priority: 0 policy: 0 root@iZ2ze9qnmldt4l3l82gtviZ:~#   查看进程父子关系 1 2 3 4 5 6  root@iZ2ze9qnmldt4l3l82gtviZ:~# pstree -g -p -s 2064 init(1,1)───tmsf-zc(2064,2058)─┬─{tmsf-zc}(2066,2058) ├─{tmsf-zc}(2067,2058) ├─{tmsf-zc}(2068,2058) └─{tmsf-zc}(2069,2058) root@iZ2ze9qnmldt4l3l82gtviZ:~#   查看进程内存map信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  root@iZ2ze9qnmldt4l3l82gtviZ:~# pmap -x -p 2064 2064: ./tmsf-zc Address Kbytes RSS Dirty Mode Mapping 0000000000400000 3180 1472 0 r-x-- /test/tmsf-zc 000000000071b000 2336 948 0 r---- /test/tmsf-zc 0000000000963000 204 104 72 rw--- /test/tmsf-zc 0000000000996000 140 60 60 rw--- [ anon ] 0000000000c6a000 132 4 4 rw--- [ anon ] 000000c000000000 8 8 8 rw--- [ anon ] 000000c41ffc0000 256 256 256 rw--- [ anon ] 000000c420000000 2048 1364 1364 rw--- [ anon ] 000000c420200000 2048 2048 2048 rw--- [ anon ] 000000c420400000 4096 672 672 rw--- [ anon ] 00007f27075d8000 1408 112 112 rw--- [ anon ] 00007f2707738000 4 0 0 ----- [ anon ] 00007f2707739000 8192 8 8 rw--- [ anon ] 00007f2707f39000 4 0 0 ----- [ anon ] 00007f2707f3a000 8192 8 8 rw--- [ anon ] 00007f270873a000 4 0 0 ----- [ anon ] 00007f270873b000 8192 8 8 rw--- [ anon ] 00007f2708f3b000 4 0 0 ----- [ anon ] 00007f2708f3c000 8192 8 8 rw--- [ anon ] 00007f270973c000 1768 232 0 r-x-- /lib/x86_64-linux-gnu/libc-2.19.so 00007f27098f6000 2048 0 0 ----- /lib/x86_64-linux-gnu/libc-2.19.so 00007f2709af6000 16 16 16 r---- /lib/x86_64-linux-gnu/libc-2.19.so 00007f2709afa000 8 8 8 rw--- /lib/x86_64-linux-gnu/libc-2.19.so 00007f2709afc000 20 16 16 rw--- [ anon ] 00007f2709b01000 100 68 0 r-x-- /lib/x86_64-linux-gnu/libpthread-2.19.so 00007f2709b1a000 2044 0 0 ----- /lib/x86_64-linux-gnu/libpthread-2.19.so 00007f2709d19000 4 4 4 r---- /lib/x86_64-linux-gnu/libpthread-2.19.so 00007f2709d1a000 4 4 4 rw--- /lib/x86_64-linux-gnu/libpthread-2.19.so 00007f2709d1b000 16 4 4 rw--- [ anon ] 00007f2709d1f000 140 116 0 r-x-- /lib/x86_64-linux-gnu/ld-2.19.so 00007f2709e6f000 780 376 376 rw--- [ anon ] 00007f2709f3f000 8 8 8 rw--- [ anon ] 00007f2709f41000 4 4 4 r---- /lib/x86_64-linux-gnu/ld-2.19.so 00007f2709f42000 4 4 4 rw--- /lib/x86_64-linux-gnu/ld-2.19.so 00007f2709f43000 4 4 4 rw--- [ anon ] 00007fff6d2d2000 132 16 16 rw--- [ stack ] 00007fff6d3e9000 8 4 0 r-x-- [ anon ] ffffffffff600000 4 0 0 r-x-- [ anon ] ---------------- ------- ------- ------- total kB 55752 7964 5092   从上面可以获取以下信息：\n 进程使用哪些共享库及其版本信息，以及这些共享库在内存中的起始位置 指令起始位置 0000000000400000 初始化全部 RSS  查看进程当前的调用栈 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153  [root@localhost db_proxy_server]# pstack 31002 Thread 22 (Thread 0x7f62dafae700 (LWP 31003)): #0 0x00000038332e1523 in select () from /lib64/libc.so.6 #1 0x00007f62db1e9125 in apr_sleep () from /usr/lib64/libapr-1.so.0 #2 0x00007f62db716096 in log4cxx::helpers::FileWatchdog::run (data=0x2497a70) at filewatchdog.cpp:76 #3 0x00007f62db7778ce in log4cxx::helpers::Thread::launcher (thread=0x2499c00, data=0x2499be8) at threadcxx.cpp:100 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 21 (Thread 0x7f62da5ad700 (LWP 31008)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c3f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c3e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c3e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 20 (Thread 0x7f62d9bac700 (LWP 31009)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c478) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c468) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c468) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 19 (Thread 0x7f62d91ab700 (LWP 31010)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c4f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c4e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c4e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 18 (Thread 0x7f62d87aa700 (LWP 31011)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c578) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c568) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c568) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 17 (Thread 0x7f62d7da9700 (LWP 31012)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c5f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c5e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c5e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 16 (Thread 0x7f62d73a8700 (LWP 31013)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c678) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c668) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c668) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 15 (Thread 0x7f62d69a7700 (LWP 31014)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c6f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c6e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c6e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 14 (Thread 0x7f62d5fa6700 (LWP 31015)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c778) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c768) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c768) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 13 (Thread 0x7f62d55a5700 (LWP 31016)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c7f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c7e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c7e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 12 (Thread 0x7f62d4ba4700 (LWP 31017)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c878) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c868) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c868) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 11 (Thread 0x7f62d41a3700 (LWP 31018)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c8f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c8e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c8e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 10 (Thread 0x7f62d37a2700 (LWP 31019)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c978) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c968) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c968) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 9 (Thread 0x7f62d2da1700 (LWP 31020)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251c9f8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251c9e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251c9e8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 8 (Thread 0x7f62d23a0700 (LWP 31021)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251ca78) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251ca68) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251ca68) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 7 (Thread 0x7f62d199f700 (LWP 31022)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251caf8) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251cae8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251cae8) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 6 (Thread 0x7f62d0f9e700 (LWP 31023)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251cb78) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251cb68) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251cb68) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 5 (Thread 0x7f62d059d700 (LWP 31024)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251f518) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251f508) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251f508) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 4 (Thread 0x7f62cfb9c700 (LWP 31025)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251f598) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251f588) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251f588) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 3 (Thread 0x7f62cf19b700 (LWP 31026)): #0 0x0000003833a0b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x00000000005dd0c7 in CThreadNotify::Wait (this=0x251f618) at /home/wubo/LeTalk/server/src/db_proxy_server/../base/Thread.h:62 #2 0x000000000063f7b6 in CWorkerThread::Execute (this=0x251f608) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:44 #3 0x000000000063f754 in CWorkerThread::StartRoutine (arg=0x251f608) at /home/wubo/LeTalk/server/src/base/ThreadPool.cpp:27 #4 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #5 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 2 (Thread 0x7f62ce79a700 (LWP 31027)): #0 0x0000003833a0ba5e in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0 #1 0x000000000063f12c in CCondition::waitTime (this=0x251fec0, nWaitTime=5000) at /home/wubo/LeTalk/server/src/base/Condition.cpp:43 #2 0x00000000005d8fbb in CSyncCenter::doSyncGroupChat (arg=0x0) at /home/wubo/LeTalk/server/src/db_proxy_server/SyncCenter.cpp:299 #3 0x0000003833a07aa1 in start_thread () from /lib64/libpthread.so.0 #4 0x00000038332e8aad in clone () from /lib64/libc.so.6 Thread 1 (Thread 0x7f62db1be820 (LWP 31002)): #0 0x00000038332e90a3 in epoll_wait () from /lib64/libc.so.6 #1 0x0000000000642f5d in CEventDispatch::StartDispatch (this=0x251f3f0, wait_timeout=10) at /home/wubo/LeTalk/server/src/base/EventDispatch.cpp:365 #2 0x000000000063f5fd in netlib_eventloop (wait_timeout=10) at /home/wubo/LeTalk/server/src/base/netlib.cpp:160 #3 0x00000000005e21ad in main (argc=1, argv=0x7ffd32681a78) at /home/wubo/LeTalk/server/src/db_proxy_server/db_proxy_server.cpp:216 [root@localhost db_proxy_server]#   进程故障信息 dmesg查找 1 2 3 4  [root@sqwx1 demo_server]# dmesg | grep demo_server demo_server[8425]: segfault at 22 ip 0000000000548b4c sp 00007ffff50281b0 error 4 in demo_server[400000+5c4000] demo_server[22891]: segfault at 50a09b ip 0000000000562723 sp 00007ffdde9276d0 error 7 in demo_server[400000+647000] demo_server[26185]: segfault at 52ecdb ip 0000000000562723 sp 00007fff09ca4120 error 7 in demo_server[400000+647000]   查看进程被谁杀死 1 2  root@iZ2ze9qnmldt4l3l82gtviZ:~# cat /var/log/audit/audit.log | grep 16135 type=OBJ_PID msg=audit(1491364584.465:11575): opid=16135 oauid=0 ouid=0 oses=35 ocomm=\u0026#34;tmsf-zc\u0026#34;   进程性能分析 主要有下面两种方式：\n perf工具 google perf  进程调试 主要针对linux上gdb调试，可以参考文章，这里不作描述\n未完，待续 ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-05-10-linux-process-diagnose\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-05-10-golang-present\/": {
        
        "title": "使用golang present工具制作presentation",
        "tags": ["golang",],
        "content": "依赖  依赖golang的开发环境  安装 present工具在golang.org/x/tools中，依赖golang.org/x/net包,安装过程如下：\n1 2 3  root@ia-VirtualBox:~# go get golang.org/x/net root@ia-VirtualBox:~# go get golang.org/x/tools root@ia-VirtualBox:~# go install golang.org/x/tools/cmd/present   安装结束后查看present位置\n1 2  root@ia-VirtualBox:~# which present /usr/local/go/bin/present   slide文件语法 具体参考准官方文档\n更新：Package present\n生成slide 1 2 3  root@ia-VirtualBox:/share/gocode/src/github.com/pcrawfor# present golanguk/talk.slide 2017/05/09 23:53:15 Open your web browser and visit http://127.0.0.1:3999 2017/05/09 23:57:19 accepting connection from: 127.0.0.1:50852   共享slide 通过http选项指定外部访问地址\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  root@ia-VirtualBox:/share/gocode/src/github.com/pcrawfor# present -http=\u0026#34;192.168.56.5:3999\u0026#34; golanguk/talk.slide 2017/05/10 00:02:47 WARNING! WARNING! WARNING! The present server appears to be listening on an address that is not localhost. Anyone with access to this address and port will have access to this machine as the user running present. To avoid this message, listen on localhost or run with -play=false. If you don\u0026#39;t understand this message, hit Control-C to terminate this process. WARNING! WARNING! WARNING! 2017/05/10 00:02:47 Open your web browser and visit http://192.168.56.5:3999   生成PDF 以chrome为例，步骤如下：\n  按ctrl + p进入打印界面   选择打印方式为adode pdf，点击打印，即可保存为pdf\n  (end)\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-05-10-golang-present\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/what-is-matter\/": {
        
        "title": "什么才是重要的",
        "tags": ["life",],
        "content": "什么才是重要的 什么才是重要的？对于这个问题有很多答案，每个人都有自己的回答。\n这里说一下我对这个问题的思考，从哪些角度来判断与评价重要性？\n 基础 稀缺 频率 紧急 第一性原理 与自己的相关性  ", 
        "url": "http:\/\/myself659.github.io\/post\/life\/what-is-matter\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-04-29-about-system-design\/": {
        
        "title": "对于系统设计的一些想法",
        "tags": ["Arch",],
        "content": "前言 学习了google，facebook等国际一流大厂的开源方案，也研究了国内BAT的一些设计案例，在平时工作自然也少不了一些系统设计的工作，想写一些自己的想法，同时也帮助自己梳理一下思路，实现自己的系统设计的套路。\n其实就是这一句话：立足需求与业务，利用工程与技术，得到最合适的tradeofff，追求更简单的设计与方案，以此不断推进系统的演化。\n下面对这句话展开说明（当然，下面是一堆费话，只是为了解决自己的不吐不快而已罢了）。\n立足需求与业务 套用一句话：一切脱离需求的设计都是耍流氓。这里不进行具体案例分析，主要从以下角度来细化需求，提供思考的方向。\n用户角度  performance（性能） availability（可用性） usability（易用性） security（安全性）  研发角度  maintainablity （可维护性性） protability（可移植性） reusability（可重用性） scalable(可扩展性) testability（可测试性）  商业与市场角度  time to market（及时发布推向市场） cost and benifits（成本和收益） projected life time （产品生命周期） targeted market（目标市场） integration with legacy system (系统集成) roll back schedule （回退时间表）  KISS(Keep It Simple, Stupid) 有太多的例子，说明追求简单与遵循简单的设计原则的重要性，最典型就是unix的设计哲学成就伟大的linux的操作系统。\n什么是简单的系统设计呢？ 这是需要不断思考的问题，举个例子说明吧；在GFS实现中，针对client向chunk server写文件失败的问题，GFS的作法是直接返回失败，由client决定是否重写，这种作法就是聪明的简单之举。\n简单并不是随手可得的。关于这个可以参考rob pike，golang发明人之一的这篇演进： Simplicity is Complicated\n下面借此说明以下几个问题？\n 什么是简单？  简单很难定义，还是举例说明吧 追求简单并不是单纯追求技术实现上的简单。简单追求是使用的简单，因为使用是高频，实现可能只有几次，例如上面演进谈到的GC,实现并不简单，想出这个GC算法就相当困难，实现那就更难了，但是有了GC，我们用golang编程的时候就不需要像C/C++那样关心内存的申请释放，再也不用担心踩内存的问题了，专心于设计与业务，给程序员带来了简单。（以我自己为例，学会了golang，我写代码都写得多，之前只会C/C++时候，业余时间主要是阅读代码，写代码都是工作驱动）\n另外还有一点，简单是先实现，再改进，例如golang的GC算法一开始并不好，GC导致应用 延迟大，到了1.5才有改进\n如何实现简单？  演进中const同c语言定义一个常量不一样，不需要关心类型，在生活中一般人说数字2017除了程序员谁关心它是整型数还是浮点数啊\n如何判断设计是否简单呢？  让普通人也能容易理解与使用。\n在生活中能够找到对应参考。\n能够简单描述问题。\n给人一种刚刚好感觉，不多不少。\n还有更多。。。\nEverything is tradeoff  理想很丰满，但是现实很骨感\n  硬币总是两面的\n 在系统设计过程中我们总会遇到下面的问题：\n 分布式场景下CAP只能三选二 Push vs Pull Latency vs Throughput 速度 vs 成本 vs 质量 SSD vs Disk SQL vs NoSQL Sharding vs Partitioning Scale Up vs Scale Out Performance vs Scalability 集中式 vs 分布式 同步 vs 异步 \u0026hellip;  如果系统设计过程不知道系统优缺点，那表示你无法掌握这个系统设计；相反如果深入理解每一个具体方案的优缺点，就可以SWOT原则作出判断与选择，而不是面对选择总是有那么多犹豫不决，而是一种感觉：在这种需求和条件，这样的选择是最合适的。\n工程与技术能力是基础 需要掌握技术，立足需求，协调不断变化需求与技术实现的矛盾。 技术方案实现的实现需要软件工程的指导，保证整个这个方案落地过程中保持顺畅与有序进行。\n对于一个工作多年的程序员来说，从技术上就是要构建自己的知识体系，这里引用一张图如下： 这张图从网络请求处理时序的角度概括系统设计过程中可能涉及的技术点。\n关于软件工程能力，在这里不多讲了，更多请参考微软邹欣老师的大作《构建之法》。\n后记 人生贵在行动，迟疑不决时，不妨先迈出小小一步，若是美好，叫做精彩；若是糟糕，叫做经历！\n写了一篇水货文章，方向大了，内容空洞，只能待以后将其拧干了。\n（to be continued）\n参考  Simplicity is Complicated system design primer 系统设计的典型分层和涉及的知识点  ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-04-29-about-system-design\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-04-08-ecs-basic-sec-check\/": {
        
        "title": "阿里云ECS基本安全检查小结",
        "tags": ["Secure",],
        "content": "背景 查看阿里云ECS服务器日志发现如下：\n1 2 3 4 5 6 7  type=USER_AUTH msg=audit(1491669519.156:15631): pid=22938 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=PAM:authentication acct=\u0026#34;deploy\u0026#34; exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=123.57.245.163 addr=123.57.245.163 terminal=ssh res=failed\u0026#39; type=USER_LOGIN msg=audit(1491669519.156:15632): pid=22938 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=login acct=28696E76616C6964207573657229 exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=? addr=123.57.245.163 terminal=sshd res=failed\u0026#39; type=USER_LOGIN msg=audit(1491669587.368:15634): pid=22940 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=login acct=28756E6B6E6F776E207573657229 exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=? addr=123.57.245.163 terminal=sshd res=failed\u0026#39; type=USER_LOGIN msg=audit(1491669587.368:15635): pid=22940 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=login acct=28696E76616C6964207573657229 exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=? addr=123.57.245.163 terminal=sshd res=failed\u0026#39; type=USER_AUTH msg=audit(1491669589.420:15636): pid=22940 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=PAM:authentication acct=\u0026#34;deploy\u0026#34; exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=123.57.245.163 addr=123.57.245.163 terminal=ssh res=failed\u0026#39; type=USER_LOGIN msg=audit(1491669589.420:15637): pid=22940 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=login acct=28696E76616C6964207573657229 exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=? addr=123.57.245.163 terminal=sshd res=failed\u0026#39; type=USER_LOGIN msg=audit(1491669658.624:15639): pid=22948 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;op=login acct=28756E6B6E6F776E207573657229 exe=\u0026#34;/usr/sbin/sshd\u0026#34; hostname=? addr=123.57.245.163 terminal=sshd res=failed\u0026#39;   百度一下这个ip地址，如下图所示： ![记下这个IP,留下证据](/images/attck ip.png)\n这是有人在阿里云ECS写脚本要暴力破解云主机的密码。这个引起我的注意，赶紧检查一下自己的ECS是否被破解。\n说点题外话：记得去年帮人弄一个网站的时候，后面的她的云主机密码泄漏了，人家第一反应过来就是怀疑我，还得花心思给她解释有多种情况会导致密码泄漏与破解，伤不起啊。\n整个检查大体如下，分为以下几个部分：\n 检查有哪些用户？ 用户会干什么？ 用户干过什么？ 处于什么样的环境？  检查用户 查看当前在线用户 1  root@ecs-1:~# who   为了确定是否当前就有不明用户登录，如果有不明用户登录，那么得赶紧修改密码。\n查看当前ssh连接情况 1  root@ecs-1:~# ss -t sport = :22   查看用户的ssh连接情况，进行对比确认\n查看新增用户 1  root@ecs-1:~# awk -F\u0026#39;:\u0026#39; \u0026#39;{ print $1}\u0026#39; /etc/passwd   查看当前用户 1  root@ecs-1:~# awk -F\u0026#39;:\u0026#39; \u0026#39;{ print $1}\u0026#39; /etc/passwd   主要是确定是否存在可疑用户，是否有可疑用户加入\n检查是否存在特权用户 1 2  root@ecs-1:~# awk -F: \u0026#39;$3==0 {print $1}\u0026#39; /etc/passwd root   检查用户口令是否为空 1  root@ecs-1:~# awk -F: \u0026#39;length($2)==0 {print $1}\u0026#39; /etc/shadow   检查用户会干什么 top查看内存与内存使用情况 1  root@ecs-1:~# top   关注高cpu使用率与高内存占用程序，例如比特币的矿机一般会占用大量的cpu资源\n查看任务计划 1  root@ecs-1:~# crontab -l   查看网络连接情况 1  root@ecs-1:~# netstat -natp   检查隐藏进程 检查隐藏进程，三步走：\n第一步：\n1  root@ecs-1:~# ps -ef | awk \u0026#39;{print $2}\u0026#39; | sort -n | uniq \u0026gt; pid1   第二步：\n1  root@ecs-1:~# ls /proc | grep -E \u0026#39;[0-9]{1,}\u0026#39; | sort -n | uniq \u0026gt; pid2   第三步：\n1 2 3 4 5 6 7 8 9 10 11 12  root@ecs-1:~# diff pid1 pid2 1d0 \u0026lt; PID \u0026lt; 29592 \u0026lt; 29593 \u0026lt; 29594 \u0026lt; 29595 --- \u0026gt; 29588 \u0026gt; 29589 \u0026gt; 29590 \u0026gt; 29591   结果说明： 第一步有4个不同的进程表示这条命令对应的进程，第二步同样的，所以这里没有发现隐藏的进程\n检查rcx.d 1  root@ecs-1:~# ls /etc/rc3.d   检查用户干过什么 重点检查以下情况：\n 用户登录 机器重启情况 安全日志 历史操作 安全文件检查  用last -d 查看登录情况 1  root@ecs-1:~# last -d   用last -x 查看机器重启情况 1  root@ecs-1:~# last -x reboot   查看audit的log信息 1  root@ecs-1:~# cat /var/log/audit/audit.log   查看历史命令 1 2 3  root@ecs-1:~# history 271 iptables -L 272 package main   安全文件检查  检查授权的ssh key，查看是否有未知的ssh key添加  1  root@ecs-1:~# cat ~/.ssh/authorized_keys   检查bashrc  1  root@ecs-1:~# cat ~/.bashrc   检查密码最后修改时间  1  root@ecs-1:~# ls -l /etc/passwd   环境 网络隔离性 网络采用了VPC网络模式，检测结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  root@ecs-1# nmap -v -sT 172.17.11.0/28 --open Starting Nmap 6.40 ( http://nmap.org ) at 2017-03-14 10:23 CST Initiating ARP Ping Scan at 10:23 Scanning 16 hosts [1 port/host] Completed ARP Ping Scan at 10:23, 0.41s elapsed (16 total hosts) Initiating Parallel DNS resolution of 16 hosts. at 10:23 Completed Parallel DNS resolution of 16 hosts. at 10:24, 13.00s elapsed Initiating Connect Scan at 10:24 Scanning 16 hosts [1000 ports/host] Connect Scan Timing: About 2.42% done; ETC: 10:45 (0:20:49 remaining) Connect Scan Timing: About 11.94% done; ETC: 10:46 (0:19:40 remaining) Connect Scan Timing: About 16.72% done; ETC: 10:46 (0:18:31 remaining) Connect Scan Timing: About 21.57% done; ETC: 10:46 (0:17:20 remaining) Connect Scan Timing: About 26.57% done; ETC: 10:46 (0:16:13 remaining) Connect Scan Timing: About 31.72% done; ETC: 10:46 (0:15:06 remaining) Connect Scan Timing: About 37.01% done; ETC: 10:46 (0:13:59 remaining) Connect Scan Timing: About 41.86% done; ETC: 10:46 (0:12:52 remaining) Connect Scan Timing: About 47.34% done; ETC: 10:46 (0:11:45 remaining) Connect Scan Timing: About 52.56% done; ETC: 10:46 (0:10:37 remaining) Connect Scan Timing: About 57.65% done; ETC: 10:46 (0:09:27 remaining) Connect Scan Timing: About 62.67% done; ETC: 10:46 (0:08:19 remaining) Connect Scan Timing: About 67.69% done; ETC: 10:46 (0:07:11 remaining) Connect Scan Timing: About 72.92% done; ETC: 10:46 (0:06:01 remaining) Connect Scan Timing: About 78.18% done; ETC: 10:46 (0:04:51 remaining) Connect Scan Timing: About 83.26% done; ETC: 10:46 (0:03:43 remaining) Connect Scan Timing: About 88.35% done; ETC: 10:46 (0:02:35 remaining) Connect Scan Timing: About 93.58% done; ETC: 10:46 (0:01:25 remaining) Completed Connect Scan against 172.17.11.14 in 1276.55s (15 hosts left) Completed Connect Scan against 172.17.11.7 in 1279.69s (14 hosts left) Completed Connect Scan against 172.17.11.1 in 1280.09s (13 hosts left) Completed Connect Scan against 172.17.11.10 in 1291.35s (12 hosts left) Completed Connect Scan against 172.17.11.12 in 1291.68s (11 hosts left) Completed Connect Scan against 172.17.11.5 in 1322.08s (10 hosts left) Completed Connect Scan against 172.17.11.4 in 1322.13s (9 hosts left) Completed Connect Scan against 172.17.11.15 in 1325.48s (8 hosts left) Completed Connect Scan against 172.17.11.3 in 1328.10s (7 hosts left) Completed Connect Scan against 172.17.11.9 in 1329.43s (6 hosts left) Completed Connect Scan against 172.17.11.11 in 1331.76s (5 hosts left) Completed Connect Scan against 172.17.11.2 in 1335.78s (4 hosts left)) Completed Connect Scan against 172.17.11.0 in 1336.84s (3 hosts leftCompleted Connect Scan against 172.17.11.6 in 1337.46s (2 hosts left) Completed Connect Scan against 172.17.11.8 in 1338.91s (1 host left) Completed Connect Scan at 10:46, 1342.34s elapsed (16000 total ports) Read data files from: /usr/bin/../share/nmap Nmap done: 16 IP addresses (16 hosts up) scanned in 1355.80 seconds Raw packets sent: 16 (448B) | Rcvd: 16 (448B)   如果网络没有隔离，各个VM同一个局域网内，会发现同一个网段的开放的端口，检查结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  root@centos# nmap -v -sT 192.168.20.0/24 --open Discovered open port 80/tcp on 192.168.20.10 Discovered open port 3389/tcp on 192.168.20.63 Discovered open port 80/tcp on 192.168.20.38 Discovered open port 135/tcp on 192.168.20.49 Discovered open port 3389/tcp on 192.168.20.52 Discovered open port 80/tcp on 192.168.20.49 Discovered open port 80/tcp on 192.168.20.34 Discovered open port 445/tcp on 192.168.20.37 Discovered open port 445/tcp on 192.168.20.36 Discovered open port 135/tcp on 192.168.20.14 Discovered open port 3389/tcp on 192.168.20.38 Discovered open port 135/tcp on 192.168.20.50   通过对比可知，采用VPC隔离的ECS不能发现同一个网段开放的网络端口，这样安全性也大大增加，好在阿里云ECS已经支持上VPC,这样就不担心来自同一个网段的攻击了（堡垒更容易从内部攻破）\n总结  安全首先是一个意识问题，需要保证足够的敏锐 阿里云的ip基本是一个大段范围，这么多IP对应的ECS肯定有些用户是安全小白用户，这样攻击者的成本也不会很高，写一个脚本遍历这个大的ip池，就可以获取一些小白用户的ECS 密码一定不要用12345678之类或者那些常用的密码，另外注意定时更换密码 对阿里云一个建议：对于暴力破解ssh密码，增加功能实现同一个ip地址多次尝试ssh的限制 这篇主要写一些基本检查操作，有空的时候再写一篇加强基础安全防护的文章  不足与建议，欢迎指正与交流。\n（end）\n参考  Understanding Audit Log Files linux man Hiding Linux Processes For Fun And Profit Linux: Hide Processes From Other Users Understanding Red Hat Run Levels    ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-04-08-ecs-basic-sec-check\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-03-27-help-internet-available-more-people\/": {
        
        "title": "不要忘记那些正在追赶互联网潮流的用户",
        "tags": ["闲谈乱扯",],
        "content": "引子 在一家推拿店里，排队等叫号，遇到一个五十多数大叔，下面是我们之间的对话：\n大叔： 小伙子，帮我看一下怎么连接wifi？\n我： 好的。\n（他把手机给我，我弄好，把手机给他）\n我： 大叔，你连接wifi要看视频吗？\n大叔：不是的，我看直播\n我：（有点吃惊，直播一般不是年轻人看的吗？）那你用什么软件看直播？\n大叔将手机拿过来，对我说：我秀\n我：这是哪家直播？\n大叔：人人网旗下的，我还有来疯直播，youku下面的，还有快手\n我：想不到连你们都喜欢看直播，我一直以为只有年经人才爱看直播\n大叔： 下班后时间比较多，电视剧不好看，就看直播了\n想到前几天快手E轮融资3.5亿美元，就有下面的感想。\n互联网还有哪些没有覆盖到人群？ 上面引子的大叔虽然算是互联网用户，也只能是入门了，对于使用过程中一些wifi设置，app设置还是没有掌握。\n中国有14亿人口，网民有7亿，还有7亿不是网民，在这7亿中除了一些小孩子（高中生现在有相当一部分都有手机了）有相当一部分人，还是希望赶上互联网这躺车，他们不希望成为那些被抛弃的少数人，例如家里的一个伯母会主动让妈妈教她如何使用微信聊天。\n这里主要是想得出一个这样的人群：\n 50岁以上使用手机，却没有使用智能手机的人群，帮他们跨过手机进入智能手机应该不是很难的事情,毕竟会使用手机升级到使用智能手机也不是件很难的事情。（Ps：当这些用户转化互联网用户，视频是他们第一消费内容， 这个用户群体有多大呢？ 快手主动满足三四线城市的“低俗”用户，到现在收割大量用户，E轮3.5亿融资）  互联网产品如果要覆盖更多的人群要做些什么？ 简单表达如下：\n 追求产品更简单，打开app各个功能入口一目了然 生活化的内容，例如快手定位为生活分享平台 智能的推荐算法，例如今日头条在三四线及以下城市得到大量的使用，占据大量的用户时间 针对性优化，手机有老人机，app也可以针对性优化，视频只会wifi下载和播放，字体变大 剩下的，相信各位产品经理会有更深入的思考。  不要忘记那些正在追赶互联网潮流的用户，用技术与产品帮助他们上车吧！\n希望未来让更多人享受到互联网技术和产品带来的便利。\n参考  2017各省网民人数公布，总数7亿，看你们省多少人  （end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-03-27-help-internet-available-more-people\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/leetcode\/": {
        
        "title": "LeetCode",
        "tags": [],
        "content": "数据结构与算法实践\n", 
        "url": "http:\/\/myself659.github.io\/post\/leetcode\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-02-20-go-case-1-my-shadeofgo\/": {
        
        "title": "Go的50度灰补充--http response只能读一次",
        "tags": ["golang",],
        "content": "问题 还是从代码开始吧\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  func fetch(url string) { tlsConfig := \u0026amp;tls.Config{ InsecureSkipVerify: true, } transport := \u0026amp;http.Transport{ TLSClientConfig: tlsConfig, } client := http.Client{Transport: transport} resp, err := client.Get(url) if err != nil { fmt.Println(err) \u0026lt;-time.After(300 * time.Second) go fetch(url) return } buf, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(\u0026#34;fetchyh:\u0026#34;, err) return } save(buf) //保存html到文件 defer resp.Body.Close() // http to doc doc, err := goquery.NewDocumentFromResponse(resp) if err != nil { fmt.Println(err, \u0026#34;http resp to doc failed\u0026#34;) return } /* \u0026lt;div class=\u0026#34;datanowin\u0026#34; id=\u0026#34;myCont2\u0026#34;\u0026gt; */ datanowin := doc.Find(\u0026#34;div.datanowin\u0026#34;) fmt.Println(\u0026#34;datanowin:\u0026#34;, datanowin.Length()) tables := datanowin.Find(\u0026#34;table\u0026#34;) tablelen := tables.Length() fmt.Println(\u0026#34;tablelen:\u0026#34;, tablelen) for i := 0; i \u0026lt; tablelen; i++ { item := tables.Eq(i) tableDo(item) } fmt.Println(doc.Find(\u0026#34;.table\u0026#34;).Length()) }   调用上面的代码后，html网页上没有找到自己所需要的内容，上面的代码问题在哪里？ 假想一下，一般有以下原因选项：\n http请求失败 html网页没有对应内容 goquery使用错误导致未找到对应内容  自己排查一下，发现原因不是上面三个选项上，那又是什么原因呢？ 原因是对于http response实例只能读一次，只有第一次才是从0开始读，下一次是上一次读到位置开始的\n代码分析 层层调用与跳转就此略过，只看读取buf内容最终实现代码：\n1 2 3 4 5 6 7 8 9 10  // A Reader implements the io.Reader, io.ReaderAt, io.WriterTo, io.Seeker, // io.ByteScanner, and io.RuneScanner interfaces by reading from // a byte slice. // Unlike a Buffer, a Reader is read-only and supports seeking. type Reader struct { s []byte i int64 // current reading index prevRune int // index of previous rune; or \u0026lt; 0 }   1 2 3 4 5 6 7 8 9  func (r *Reader) Read(b []byte) (n int, err error) { if r.i \u0026gt;= int64(len(r.s)) { return 0, io.EOF } r.prevRune = -1 n = copy(b, r.s[r.i:]) r.i += int64(n) // 读index向后移动 return }   看到这些代码问题就很清楚了，第一次读取resp.Body时ioutil.ReadAll将所有内容都完了，第二次读调用goquery.NewDocumentFromResponse没有读到任何内容。\n其实问题不止上面这个：看了ioutil.ReadAll的流程后，又看了goquery.NewDocumentFromResponse的实现，发现还有一个问题:代码还存在一个问题，代码存在两次调用defer resp.Body.Close()，这是goquery.NewDocumentFromResponse接管了resp.Body,代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  func NewDocumentFromResponse(res *http.Response) (*Document, error) { if res == nil { return nil, errors.New(\u0026#34;Response is nil\u0026#34;) } defer res.Body.Close() // 接管了resp.Body if res.Request == nil { return nil, errors.New(\u0026#34;Response.Request is nil\u0026#34;) } // Parse the HTML into nodes root, e := html.Parse(res.Body) if e != nil { return nil, e } // Create and fill the document return newDocument(root, res.Request.URL), nil }   一种简单解决上述问题代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  func fetch(url string) { tlsConfig := \u0026amp;tls.Config{ InsecureSkipVerify: true, } transport := \u0026amp;http.Transport{ TLSClientConfig: tlsConfig, } client := http.Client{Transport: transport} resp, err := client.Get(url) if err != nil { fmt.Println(err) \u0026lt;-time.After(300 * time.Second) go fetch(url) return } /* buf, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(\u0026#34;fetchyh:\u0026#34;, err) return } save(buf) //保存html到文件 */ // defer resp.Body.Close() // http to doc doc, err := goquery.NewDocumentFromResponse(resp) if err != nil { fmt.Println(err, \u0026#34;http resp to doc failed\u0026#34;) return } /* \u0026lt;div class=\u0026#34;datanowin\u0026#34; id=\u0026#34;myCont2\u0026#34;\u0026gt; */ datanowin := doc.Find(\u0026#34;div.datanowin\u0026#34;) fmt.Println(\u0026#34;datanowin:\u0026#34;, datanowin.Length()) tables := datanowin.Find(\u0026#34;table\u0026#34;) tablelen := tables.Length() fmt.Println(\u0026#34;tablelen:\u0026#34;, tablelen) for i := 0; i \u0026lt; tablelen; i++ { item := tables.Eq(i) tableDo(item) } fmt.Println(doc.Find(\u0026#34;.table\u0026#34;).Length()) }   总结 第一次遇到这个问题，我就想到是先调用ioutil.ReadAll读取resp.Body的内容，后面调用goquery.NewDocumentFromResponse就没有读到东西。于是我把ioutil.ReadAll相关代码去掉，问题解决了。后面我就没有深入追究原因(还是给自己找个理由：忙)。\n本来我是抗拒写这篇文章的，想想自己在这个问题老是不长记性，还是读一下相关源码，简单记录下来，加深印象。\n读源码是最有收益的解决问题方式。\n最后推荐一下这篇文章：50 Shades of Go: Traps, Gotchas, and Common Mistakes for New Golang Devs\n(end)\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-02-20-go-case-1-my-shadeofgo\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-02-16-tcp-slow-down\/": {
        
        "title": "TCP连接下载文件失败，也许该看看这篇文章",
        "tags": ["Network",],
        "content": "体验一下标题党，现在自媒体横行，容我也放肆一回（多了我也不行，替自己码字能力捉急）！\n另起一行，到此为止，进入正题\n缘起 最近通过uc浏览器下载apk的时候，偶尔出现下载apk，下载了60%左右卡住，想到以前看到这篇文章：The curious case of slow downloads（PS：毕竟这个问题不是常出现，就算一次下载失败，反正可以重新下载，总能下载成功的）\n说明 由于本人英文水平有限，翻译水平更是不足，就不具体翻译上面的文章，仅作简单说明，更深的理解请阅读The curious case of slow downloads\n问题描述 Cloudflare是美国一家CDN厂商，他们的工程师发现下面的问题：\n 一些下载速度很慢的连接被突然关闭，导致用户下载失败\n  这些连接不是客户端主动关闭，而是服务端主动关闭的\n 问题原因 原文有具体解决这个问题详细过程，还是值得一看，这里不作描述。\n在满足如下条件情况下会出现下载失败：\n socket发送缓冲区可用空间低于缓冲区总大小的三分之一 用户下载速度不能达到在60秒内使该socket发送缓冲区可用空间超过缓冲区总大小的三分之一 nginx配置项send_timeout对应值为60秒  当满足上述条件，当60秒超时后，nginx会关闭该连接\n这里大家可能有一个问题，网速慢也会不断发送，怎么会超时出现关闭连接？\n这里有一个普遍的误解：认为send像recv那样，每发送成功一个都上报epoll事件（以linux为例）,而实际send上报epoll事件条件如下：\n send buffer有可用发送空间 进入发送队列的数据一定要低于LOWAT的设置值（注意：linux 内核2.6版本没有这个限制，linux 内核4.5版本以上有此条件，其他版本情况未知） 发送缓存区的可用空间一定要超过大于发送空间的已使用的空间的二分之一  其中第三个条件对应内核代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102  unsigned int tcp_poll(struct file *file, struct socket *sock, poll_table *wait) { unsigned int mask; struct sock *sk = sock-\u0026gt;sk; struct tcp_sock *tp = tcp_sk(sk); sock_poll_wait(file, sk-\u0026gt;sk_sleep, wait); if (sk-\u0026gt;sk_state == TCP_LISTEN) // 侦听状态，进入listen poll，即检查侦听socket的accpet队列是否为空 return inet_csk_listen_poll(sk); /* Socket is not locked. We are protected from async events * by poll logic and correct handling of state changes * made by other threads is impossible in any case. */ mask = 0; /* * POLLHUP is certainly not done right. But poll() doesn\u0026#39;t * have a notion of HUP in just one direction, and for a * socket the read side is more interesting. * * Some poll() documentation says that POLLHUP is incompatible * with the POLLOUT/POLLWR flags, so somebody should check this * all. But careful, it tends to be safer to return too many * bits than too few, and you can easily break real applications * if you don\u0026#39;t tell them that something has hung up! * * Check-me. * * Check number 1. POLLHUP is _UNMASKABLE_ event (see UNIX98 and * our fs/select.c). It means that after we received EOF, * poll always returns immediately, making impossible poll() on write() * in state CLOSE_WAIT. One solution is evident --- to set POLLHUP * if and only if shutdown has been made in both directions. * Actually, it is interesting to look how Solaris and DUX * solve this dilemma. I would prefer, if POLLHUP were maskable, * then we could set it on SND_SHUTDOWN. BTW examples given * in Stevens\u0026#39; books assume exactly this behaviour, it explains * why POLLHUP is incompatible with POLLOUT. --ANK * * NOTE. Check for TCP_CLOSE is added. The goal is to prevent * blocking on fresh not-connected or disconnected socket. --ANK */ /* socket 与tcp 状态转化 poll事件 */ if (sk-\u0026gt;sk_shutdown == SHUTDOWN_MASK || sk-\u0026gt;sk_state == TCP_CLOSE) mask |= POLLHUP; if (sk-\u0026gt;sk_shutdown \u0026amp; RCV_SHUTDOWN) mask |= POLLIN | POLLRDNORM | POLLRDHUP; /* Connected? */ if ((1 \u0026lt;\u0026lt; sk-\u0026gt;sk_state) \u0026amp; ~(TCPF_SYN_SENT | TCPF_SYN_RECV)) { int target = sock_rcvlowat(sk, 0, INT_MAX); if (tp-\u0026gt;urg_seq == tp-\u0026gt;copied_seq \u0026amp;\u0026amp; !sock_flag(sk, SOCK_URGINLINE) \u0026amp;\u0026amp; tp-\u0026gt;urg_data) target--; /* Potential race condition. If read of tp below will * escape above sk-\u0026gt;sk_state, we can be illegally awaken * in SYN_* states. */ /* 未处理接收报文字节数超过了最小阈值，满足可读条件 */ if (tp-\u0026gt;rcv_nxt - tp-\u0026gt;copied_seq \u0026gt;= target) mask |= POLLIN | POLLRDNORM; if (!(sk-\u0026gt;sk_shutdown \u0026amp; SEND_SHUTDOWN)) { /* sk-\u0026gt;sk_sndbuf - sk-\u0026gt;sk_wmem_queued \u0026gt;= sk-\u0026gt;sk_wmem_queued\u0026gt;\u0026gt;1 (简单理解为最大值 0.5* sk-\u0026gt;sk_wmem_queued) 如果未发送报文超过了66%，那么不会继续上报POLLOUT事件 */ if (sk_stream_wspace(sk) \u0026gt;= sk_stream_min_wspace(sk)) { mask |= POLLOUT | POLLWRNORM; } else { /* send SIGIO later */ /* 发送SIGIO */ set_bit(SOCK_ASYNC_NOSPACE, \u0026amp;sk-\u0026gt;sk_socket-\u0026gt;flags); set_bit(SOCK_NOSPACE, \u0026amp;sk-\u0026gt;sk_socket-\u0026gt;flags); /* Race breaker. If space is freed after * wspace test but before the flags are set, * IO signal will be lost. */ if (sk_stream_wspace(sk) \u0026gt;= sk_stream_min_wspace(sk)) mask |= POLLOUT | POLLWRNORM; } } else mask |= POLLOUT | POLLWRNORM; if (tp-\u0026gt;urg_data \u0026amp; TCP_URG_VALID) mask |= POLLPRI; } /* This barrier is coupled with smp_wmb() in tcp_reset() */ smp_rmb(); if (sk-\u0026gt;sk_err) mask |= POLLERR; return mask; }   解决方案 知道上面的原因对应可以选择方案如下：\n方案一：增加send_timeout时间，例如将时间调整为280秒，可以保证在5M发送缓冲区条件下，用户下载速度超过50Kbps不会出现超时导致连接被关闭\n方案二：通过设置/proc/sys/net/ipv4/tcp_wmem值减小socket发送缓冲区大小，发送缓冲区减小，那么在一定下载速率下在指定的时间需要完成下载的大小变小，就可以避免上述的问题出现的条件\n显而易见，这种两种方案都不能从根本上解决问题，只是降低问题出现的概率（这也是进步）\n方案三：改变超时处理，而不是直接关闭，可利用ioctl(TIOCOUTQ)来获取有多少数据仍停留在发送缓冲区，调整超时时间，具体实现可以参考The curious case of slow downloads中提到的方案：a Linux specific patch to NGINX\n相比较于方案一和方案二，方案三对网络速率变化与波动适应性强\n总结  The curious case of slow downloads值得一看（感谢cloudflare工程师没有放弃一些偶现的问题） nginx现有实现单一固化的处理导致不适应tcp传输的多变性 在复杂多变的网络环境下，保证传输高可靠性里面需要很多技术细节需要挖掘 网络是复杂的，主要由于以下原因：   网络协议复杂，例如tcp 网络本身不可靠 网络连接多样性 网络要求高：低延迟，少丢包，抖动小，高速率，自适应  参考  The curious case of slow downloads linux-2.26.32  ", 
        "url": "http:\/\/myself659.github.io\/post\/2017-02-16-tcp-slow-down\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/internet\/2017-02-03-country-internet-user\/": {
        
        "title": "互联网在农村-用户",
        "tags": ["闲谈乱扯",],
        "content": "上一篇从电和物理网络两个方面说明自己所看到的农村互联网基础设施情况。这一篇就看看在农村的互联网用户的一些情况。 根据对app使用情况分为以下几种情况：\n 基本不使用智能手机 需要引导使用智能手机 自主使用智能手机一些应用 自主使用智能手机大多数应用  基本不使用智能手机 代表人物：大伯父，大伯母\n出生年代：50年代\n教育背景：小学未毕业\n相关经历：基本上很少去城市，只去县城\n需要引导使用智能手机 代表人物：爸爸，妈妈\n出生年代：60年代\n教育背景：爸爸初中未毕业，妈妈小学未毕业\n相关经历：爸爸曾经外出在浙江，江苏打工；妈妈由于晕车基本一直在老家，只有去年去一趟南京\n引导环境：三个孩子都上过大学，使用智能手机是妹妹教他们使用\n使用情况：爸爸把手机当成他的电视，使用手机大部分时间就用爱奇艺看电视剧（他看什么电视剧呢？这个等以后多了解其他用户再写），妈妈主要用微信聊天，聊天主要语音，不会打字聊天，反正我她用的很溜，经常用\n自主使用智能手机一些应用 代表人物：堂叔\n出生年代：1974年\n教育背景：初中未毕业\n相关经历：有一段时间浙江打工经历，近三年没有外出打工\n引导环境：无\n使用情况：自主使用微信，酷我音乐等app，但是还不会下载音乐MV,由于信息的原因未使用网易云音乐\n自主使用智能手机大多数应用 代表人物：堂兄\n出生年代：1979年\n教育背景：初中毕业\n相关经历：长年在苏州打工\n引导环境：无\n使用情况：主流app都有使用（微信，qq， 淘宝， 百度搜索，腾讯新闻，腾讯视频等等），但是有一点就是互联网金融应用不怎么使用，原因主要都是对钱不放心，一直都是把存到银行，对于把钱存在余额宝和微信从心理对安全有一些疑惑\n总结 这样用户基本有以下特征：\n 教育程度低（时代与历史的原因），其实他们都很勤劳善良，互联网产品的使用门槛确实对于他们来说有些高 互联网潮流的落后者或者抛弃者（望见谅：想不出更好的表达） 对互联网依赖性远低于年轻人（35岁以下），所以对于第二点反过来也可以说是他们抛弃了互联网 对于互联网应用以满足生活需求为主，只会使用少量的app，例如微信等聊天工具，爱奇艺等视频应用。。。 App推广成本高，但是这些用户一旦学会用使用则粘性大，不会轻易选用其他可以替换的app  （End）\n", 
        "url": "http:\/\/myself659.github.io\/post\/internet\/2017-02-03-country-internet-user\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/internet\/2017-02-02-country-internet-infra\/": {
        
        "title": "互联网在农村-基础设施",
        "tags": ["闲谈乱扯",],
        "content": "说明 老家在安徽省安庆市的一个小山村里，作为一名互联网从业人员，这次回家特地花了一点心思来观察家乡的互联网应用情况。\n这是第一篇，先看农村互联网基础设施情况，上网要有电，要有接入网络，所以下面内容分为两个方面：\n 电 物理网络  电 电这一部分是我要大力吐槽的，拿除夕晚上来说，来电，断电，来电，断电。。。这样的循环至少五次，原因大概有下面这些：\n 功率不足，除夕晚上电视，家家晚上都把自己家的灯点亮（家乡的风俗习惯） 电工技能水平有限 农村电力基础本身就差 农村有一些人家的线程本身就有问题，例如老化，漏电，甚至还有偷电的行为  除此之外，发现大多数人对于服务质量也没有意识，对于突然的停电也习以为常，毕竟大部分一直在生活在这里，不知道外面的供电服务是什么情况。\n物理网络 物理网络分为两个方面来写吧：\n 固定宽带 移动网络  固定宽带 固定宽带基本在10年到17年这七年的时间实现从无到有，从ADSL到光纤接入的发展。了解情况如下：\n 接入方式：光纤接入与ADSL并存，新接入方式以光纤为准 网络速度：光纤接入可以达到50M，个人在家使用与在杭州感觉不到什么差异，相反网络还更好一些，这主要可能是开通网络人数不多吧 接入高可用性：在家这十天左右的时间内基本没有出现连接不上的情况 接入费用： 我家的套餐是1500包两年电信套餐，与城市相差无异 网络开通率：了解到一个40户左右的村民小组只有4户开通宽带，开通率才10%左右  移动网络 07年放假回家，当时号称移动信号最好的移动手机回家基本上没有信号，要选好位置，作好姿势才能蹭到黄冈的移动网络，发短信，收短信变成一个十分美好的事情，现在回想起来还能感觉到那一刻自己的心情的美好：有信号真好。慢慢地几年内（具体时间已经记不清楚了）移动基站来了，电信基站来了，联通基站也来了\n15-16两年4G商用，想想也知道，这里还是3G，移动网络的速度正如段子所说：\n 2G看苍井空.txt，3G看苍井空.jpg，4G看苍井空.avi\n 这里速度当然不利于农村互联网喜欢的视频应用的使用。\n总结 虽然农村基础设施大大落后城市，但是进步迅速，想想在2010年村里才刚开始有ADSL接入，到现在支持50M光纤接入，在网速方面与城市基本上没有区别。希望今后能够网络连接可靠性方面有较大的进步，这样一年当中有一段时间在老家工作也是不错的，空气好，安静适合思考，而且还能吃到妈妈做的美食。\n最后再说明，这是自己的片面之词，写出来仅是记录一下自己见到的一些真实情况，为以后观察提供一个参考。\n（end）\n", 
        "url": "http:\/\/myself659.github.io\/post\/internet\/2017-02-02-country-internet-infra\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E4%B8%8D%E8%BF%BD%E6%B1%82%E5%AE%8C%E7%BE%8E\/": {
        
        "title": "不追求完美，追求进步",
        "tags": ["life",],
        "content": "完美 完美是一个理想的状态,但在现实生活中很难达成。不同的人对完美有不同的理解:\n  无错误。从客观角度,完美代表一种没有错误、瑕疵和Bug的状态。所有要素都处于最佳状况,没有任何改进的空间。但在复杂系统中要达成这种完美几乎是不可能的。\n  最优解。从目标角度,完美代表一种能达成目标或任务的最佳结果或最优解。所有资源和条件都被最理想地运用和调配。但现实生活中有太多变数,很难作出最优的选择。\n  主观满意。从个人角度,完美更多代表一种主观上的满足或达成感。当个人的愿望、期待和需求被满足时,会感到很完美。但不同人的需求不同,完美标准也随之不同。\n  最高境界。从哲学角度,完美代表一种最高的境界或理想状态。诸如“真、善、美”都可被视为完美,但这些理想很难在现实生活中充分实现。人类只能不断追求,但很难达到。\n  整体优化。从系统角度,完美代表一种全局最优的状态。各个系统要素高度协调,相互配合,整体效能最大化。但任何系统都有其复杂性,要优化到完美程度也属于理想。\n  综上,完美是一个人类永恒追求但很难达成的理想状态。从不同视角,完美可以理解为没有错误、最优解、主观满意、最高境界或整体优化等,但现实生活中的种种复杂性都使得完美变得遥不可及。人类只能不断逼近完美,但永远无法达到完全完美,这也给生活带来动力。完美永远是一种距离感和追求的过程。\n不追求完美   完美是很难具体清晰的定义。完美是一个主观概念,每个人对完美的理解都不同,很难给出一个客观清晰且被广泛接受的定义,这使得追求完美变得无序和模糊。\n  完美往往性价比差。追求完美需要投入大量资源,但收益并不成正比。根据帕累托法则,追求绝对完美的收益是递减的,而成本是递增的,这导致性价比下降。\n  完美是不必要的。大多数情况下,不完美也能满足需求。追求完美带来的边际效用并不高,所以从实用角度完美是不必要的。这符合功利主义观点。\n  完美导致拖延,影响行动。追求完美会不断改进与修正,难以达成结束点,这会产生拖延现象,延缓行动与实现。现实生活需要及时行动。\n  完成与拥有胜过完美。一个不完美的产品或结果,只要可以完成任务并带来实际效用,就已经胜过一件永远无法实现的完美设想。这符合实用主义思想。\n  完美可能是不存在的。就连宇宙这种高度复杂的系统,也难以达到绝对完美的状态。真实世界中,各种不确定因素的存在决定了完美可能永远也不可达成,它只存在于思维的理想境界中。完美就像数学里面无穷大与无穷小一样，你永远不知道它的值到底是多少？\n  追求进步   进步可以实现,完美不可及。进步是一个相对概念,可以通过持续努力逐步实现,而完美是一个绝对概念,现实生活中很难达成。所以进步是一个现实的目标,完美更像一种理想。\n  进步可以持续提高,完美无法衡量。进步度可以通过各种标准进行衡量和评价,并不断提高,而完美作为一种理想状态,很难给出客观衡量标准,无法判断是否真的达到完美。\n  进步可以满足需求,完美不实用。适度的进步可以满足大多数实际需求,实现比较理想的结果,而追求完美带来的收益是递减的,实用性较差。\n  进步促进行动,完美拖延行动。进步是一个渐进的过程,可以边行动边进步,而追求完美需要不断推翻重来,易产生拖延和行动滞后。\n  进步可以带来满足,完美只有距离感。实现一定进步可以带来成就感和满足,而完美作为一种永远无法达到的理想,只会带来无止境的距离感和不满足。\n  进步更科学合理。科学追求渐进改善,讲求实证与效果,而完美属于非理性和极端的思维方式。所以从科学角度来说,追求进步更加合理与适当。\n  综上,作为实用主义者,追求进步而非完美是更科学合理的选择。进步具有较强的实现性、可衡量性、实用性和结果导向性,能满足现实需求,不易拖延行动,更能带来成就感。而完美只是一个理想,科学和现实的思维方式不应追求不可达成的极端状态。所以,Done is better than perfect,但要不断进步,这才是积极实用的态度.\n", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E4%B8%8D%E8%BF%BD%E6%B1%82%E5%AE%8C%E7%BE%8E\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E4%BA%BA%E7%94%9F%E6%9C%89%E5%93%AA%E4%BA%9B%E5%A4%A7%E5%9D%91\/": {
        
        "title": "人生有哪些大坑",
        "tags": ["life",],
        "content": "背景 人生不如意十有八九。生活处处有坑，避免不踩坑不可能，但是还是要努力防止踩大坑。\n认知与心理  偏见、妄想等因素导致不能发现与尊重事实和规则 思维定势，错误地执念，拒绝改变，视野与格局打不开 盲目，盲从，懒惰，不能独立思考与验证 不知道什么是最重要的，没有明确的目标 不知道自己不知道，缺少敬畏 缺少长期心态与长远眼光，没有耐心，不能延迟满足  选择与环境  选择牺牲身体来赚钱 选错专业与行业 关键事件方面选错人来合作如结婚，创业等等 处于烂人的环境当中（如爱抱怨的工作同事，暗规则横行的工作氛围） 缺少对危险因素的洞察与风险控制(君子不立危墙之下)  行为与习惯  不思考，不学习，无进步 恶性循环（如赌博，混自己不喜欢的工作） 不自律，放纵自己 爱与别人比较 跟风与凑热闹 嫉妒 拖延并缺少执行力 只想不做，浅尝辄止，做事不到位 情绪不稳定，波动大，情绪冲动 重复犯相同的错误 拖延症  ", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E4%BA%BA%E7%94%9F%E6%9C%89%E5%93%AA%E4%BA%9B%E5%A4%A7%E5%9D%91\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/life\/%E4%BA%94%E4%B8%AA%E9%97%AE%E9%A2%98%E6%89%BE%E5%88%B0%E7%9C%9F%E6%AD%A3%E8%A6%81%E6%83%B3%E7%9A%84\/": {
        
        "title": "五个问题帮你找到你真正的想要的",
        "tags": ["life",],
        "content": "问题 1. 你想要什么？ 2. 你有多想要它？ 3. 现在的你离你想要的有多远？ 4. 你能做什么来实现你想要的？ 5. 你开始行动吗？ ", 
        "url": "http:\/\/myself659.github.io\/post\/life\/%E4%BA%94%E4%B8%AA%E9%97%AE%E9%A2%98%E6%89%BE%E5%88%B0%E7%9C%9F%E6%AD%A3%E8%A6%81%E6%83%B3%E7%9A%84\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-09-10-from-cepoll-to-go-net\/": {
        
        "title": "从C语言epoll编程到go net实现分析",
        "tags": ["golang",],
        "content": "说明  go源码版本：1.7 go源码运行环境：Linux  epoll在c语言编程示例 先看一下大家比较熟悉的epoll在c语言中应用，代码取自rtmpserver_demo中的文件rtmpepollsrv.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179  int RtmpSessionHandle(int iFd, int iEvent, void *pContext) { int iRet; RTMP_SESSION *pSession = (RTMP_SESSION *)pContext; if(iEvent\u0026amp;EPOLLIN ) { if(0 == pSession-\u0026gt;handshake) { iRet = RtmpSessionHandshake(pSession); if(0 != iRet) { RtmpSessionHandleFin(pSession); } } else { iRet = RtmpPktHandle(pSession); } } if(iEvent \u0026amp; (EPOLLERR |EPOLLHUP) ) { RtmpSessionHandleFin(pSession); } return iRet; } int ListenHandle(int iFd, int iEvent, void *pContext) { int iNewFd; int iRet = 0; struct sockaddr tmpAddr; memset(\u0026amp;tmpAddr, 0, sizeof(tmpAddr)); int iSocketSize = sizeof(tmpAddr); EPOLL_CTX *pCtx; RTMP_SESSION *pServer; if(iEvent|EPOLLIN) { iNewFd = accept(iFd, \u0026amp;tmpAddr, (socklen_t *)\u0026amp;iSocketSize); if(RTMP_EPOLLSRV_INVALIDFD \u0026lt; iNewFd) { pServer = (RTMP_SESSION *)malloc(sizeof(RTMP_SESSION)); if(NULL == pServer) { return -1; } pServer-\u0026gt;handshake = 0; pCtx = (EPOLL_CTX *)malloc(sizeof(EPOLL_CTX)); if(NULL == pCtx) { free(pServer); return -1; } pServer-\u0026gt;socket = iNewFd; pCtx-\u0026gt;iFd = iNewFd; pCtx-\u0026gt;pContext = pServer; pCtx-\u0026gt;pfHandle = RtmpSessionHandle; /* 加入epoll */ iRet = epoll_op(g_iEpollFd, EPOLL_CTL_ADD, iNewFd, EPOLLIN|EPOLLERR|EPOLLHUP, pCtx); } else { printf(\u0026#34;accept errno:%s\u0026#34;,strerror(errno)); } } return iRet; } int epoll_op(int iEpollFd, int iOp, int iFd, int iEvent, EPOLL_CTX *pCtx) { int iRet; struct epoll_event ev; ev.events = iEvent; ev.data.ptr = pCtx; iRet = epoll_ctl(iEpollFd, iOp, iFd, \u0026amp;ev); return iRet; } int epoll_loop(int iEpollFd) { int iNum; struct epoll_event astEpEvent[RTMP_EPOLLSRV_MAXEPOLL]; int i; EpollCallBack_PF pfHandle; EPOLL_CTX *pCtx; for( ; ;) { iNum= epoll_wait(iEpollFd, \u0026amp;astEpEvent[0], RTMP_EPOLLSRV_MAXEPOLL, -1); if( 0 \u0026lt; iNum) { for(i = 0; i \u0026lt; iNum; i++) { pCtx = (EPOLL_CTX *)astEpEvent[i].data.ptr; pfHandle = pCtx-\u0026gt;pfHandle; (void)pfHandle(pCtx-\u0026gt;iFd, astEpEvent[i].events, pCtx-\u0026gt;pContext); } } else { printf(\u0026#34;epoll_wait failed\\r\\n\u0026#34;); } } return 0; } int main(void) { int iFd; struct sockaddr_in addr; printf(\u0026#34;in the main\\r\\n\u0026#34;); /* 初始化epoll */ g_iEpollFd = epoll_create(200); if(RTMP_EPOLLSRV_INVALIDFD \u0026gt;= g_iEpollFd) { printf(\u0026#34;create epoll failed\\r\\n\u0026#34;); return -1; } /* 创建侦听端口 */ iFd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); if(RTMP_EPOLLSRV_INVALIDFD \u0026gt;= iFd) { printf(\u0026#34;create listen socket failed\\r\\n\u0026#34;); return -1; } addr.sin_family = AF_INET; addr.sin_addr.s_addr = inet_addr(g_cRtmpSrvAddr); addr.sin_port = htons(g_usRtmpSrvPort); if( 0 != bind(iFd, (struct sockaddr *) \u0026amp;addr, sizeof(struct sockaddr_in))) { return -1; } if( 0 != listen(iFd, 200)) { return -1; } EPOLL_CTX *pEpollCtx = (EPOLL_CTX *)malloc(sizeof(EPOLL_CTX)); if(NULL == pEpollCtx) { return -1; } pEpollCtx-\u0026gt;iFd = iFd; pEpollCtx-\u0026gt;pfHandle = ListenHandle; pEpollCtx-\u0026gt;pContext = NULL; /* 加入epoll */ if(0 != epoll_op(g_iEpollFd, EPOLL_CTL_ADD, iFd, EPOLLIN|EPOLLERR|EPOLLHUP, pEpollCtx)) { return -1; } g_iListenFd = iFd; epoll_loop(g_iEpollFd); return 0; }   功能 上述代码代码主要通过epoll实现一个最基本的网络服务器（侦听一个端口，处理这个端口上连接）\n几个重要数据结构\n实现分析 简单说明如下：\n用下面的结构体EPOLL_CTX保存epoll的回调及异步处理的上下文\n1 2 3 4 5 6  typedef struct { int iFd; EpollCallBack_PF pfHandle; void *pContext; }EPOLL_CTX;   从面向过程编程角度简单梳理一下epoll相关的代码\n 创建epoll 加入epoll 进入epoll_loop,处理epoll事件  go 编程示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; ) const ( CONN_HOST = \u0026#34;localhost\u0026#34; CONN_PORT = \u0026#34;3333\u0026#34; CONN_TYPE = \u0026#34;tcp\u0026#34; ) func main() { // Listen for incoming connections.  l, err := net.Listen(CONN_TYPE, CONN_HOST+\u0026#34;:\u0026#34;+CONN_PORT) if err != nil { fmt.Println(\u0026#34;Error listening:\u0026#34;, err.Error()) os.Exit(1) } // Close the listener when the application closes.  defer l.Close() fmt.Println(\u0026#34;Listening on \u0026#34; + CONN_HOST + \u0026#34;:\u0026#34; + CONN_PORT) for { // Listen for an incoming connection.  conn, err := l.Accept() if err != nil { fmt.Println(\u0026#34;Error accepting: \u0026#34;, err.Error()) os.Exit(1) } // Handle connections in a new goroutine.  go handleRequest(conn) } } // Handles incoming requests. func handleRequest(conn net.Conn) { // Make a buffer to hold incoming data.  buf := make([]byte, 1024) // Read the incoming connection into the buffer.  reqLen, err := conn.Read(buf) if err != nil { fmt.Println(\u0026#34;Error reading:\u0026#34;, err.Error()) conn.Close() return } fmt.Printf(\u0026#34;recv:%s, len=%d\\n\u0026#34;, string(buf), reqLen) // Send a response back to person contacting us.  conn.Write([]byte(\u0026#34;Message received.\u0026#34;)) // Close the connection when you\u0026#39;re done with it.  conn.Close() }   对比  handleRequest代码对应c语言版本epoll回调，但是这个代码与业务逻辑很搭，读取报文，进行处理，返回结果这些操作可以同一个函数内（也就是同一个逻辑上面）实现，没有异步回调就是爽啊 go语言上编程上不需要看到epoll，也就没添加/删除epoll的操作 编程模型方面无论是原生的回调还是reactor模型，go语言更符合业务的逻辑，而不需要考虑epoll相关处理 够简洁明了，有着与c语言相当的性能，程序员们让我们一起go吧！  Go Net实现分析 通过以上对比，显而易见，go语言保证效率的情况，在易用性大大超过了c，那golang是如何实现的？下面具体分析golang的net库实现\ngoroutine调度时机 一般在以下四种情况下进行goroutine调度：\n channel收发 显示调用go函数 阻塞的系统调用，如read,write GC  epoll使用 先简单看一下各个epoll操作代码实现，先找到他们，再分析如何利用这些操作来完成简洁的网络编程\nepoll初始化 对应c语言版本的epoll_create，go语言版本在初始化在下面的代码中完成:\n1 2 3 4 5 6 7 8 9 10 11 12 13  func netpollinit() { epfd = epollcreate1(_EPOLL_CLOEXEC) if epfd \u0026gt;= 0 { return } epfd = epollcreate(1024) if epfd \u0026gt;= 0 { closeonexec(epfd) return } println(\u0026#34;netpollinit: failed to create epoll descriptor\u0026#34;, -epfd) throw(\u0026#34;netpollinit: failed to create descriptor\u0026#34;) }   将fd加入epoll 对应c语言版本的epoll_op，go语言版本在初始化在下面的代码中完成:\n1 2 3 4 5 6  func netpollopen(fd uintptr, pd *pollDesc) int32 { var ev epollevent ev.events = _EPOLLIN | _EPOLLOUT | _EPOLLRDHUP | _EPOLLET *(**pollDesc)(unsafe.Pointer(\u0026amp;ev.data)) = pd return -epollctl(epfd, _EPOLL_CTL_ADD, int32(fd), \u0026amp;ev) }   注意这里采用的边沿触发\n从epoll摘除fd 对应c语言版本的epoll_op，go语言版本在初始化在下面的代码中完成:\n1 2 3 4  func netpollclose(fd uintptr) int32 { var ev epollevent return -epollctl(epfd, _EPOLL_CTL_DEL, int32(fd), \u0026amp;ev) }   数据结构 pollDesc 结构体pollDesc用于关联fd与epoll，具体结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  // Network poller descriptor. // 每个添加到epoll中的fd都对应了一个PollDesc结构实例 type pollDesc struct { // 指向下一个pollDesc link *pollDesc // in pollcache, protected by pollcache.lock // The lock protects pollOpen, pollSetDeadline, pollUnblock and deadlineimpl operations. // This fully covers seq, rt and wt variables. fd is constant throughout the PollDesc lifetime. // pollReset, pollWait, pollWaitCanceled and runtime·netpollready (IO readiness notification) // proceed w/o taking the lock. So closing, rg, rd, wg and wd are manipulated // in a lock-free way by all operations. // NOTE(dvyukov): the following code uses uintptr to store *g (rg/wg), // that will blow up when GC starts moving objects. lock mutex // protects the following fields // 系统为socket分配的fd fd uintptr closing bool // 是否关闭 // 用于保护旧定时器和就绪的通知 seq uintptr // protects from stale timers and ready notifications // 网络io读状态，分为三种: 网络io就绪， 进入等待状态， 等待状态，此时rg保存等待goroutine实例的指针 rg uintptr // pdReady, pdWait, G waiting for read or nil rt timer // read deadline timer (set if rt.f != nil) // 读超时时间，单位为ns rd int64 // read deadline // 网络io写状态，分为三种: 网络io就绪， 进入等待状态， 等待状态，此时rg保存等待goroutine实例的指针 wg uintptr // pdReady, pdWait, G waiting for write or nil // 写超时时间，单位为ns wt timer // write deadline timer wd int64 // write deadline user uint32 // user settable cookie }   epoll操作封装 以初始化epoll及加入epoll为例，在下面的函数中完成的\n1 2 3 4 5 6 7 8 9 10 11 12  var serverInit sync.Once func (pd *pollDesc) init(fd *netFD) error { serverInit.Do(runtime_pollServerInit) ctx, errno := runtime_pollOpen(uintptr(fd.sysfd)) if errno != 0 { return syscall.Errno(errno) } pd.runtimeCtx = ctx return nil }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  func (fd *netFD) accept() (netfd *netFD, err error) { if err := fd.readLock(); err != nil { return nil, err } defer fd.readUnlock() var s int var rsa syscall.Sockaddr if err = fd.pd.prepareRead(); err != nil { return nil, err } for { s, rsa, err = accept(fd.sysfd) if err != nil { nerr, ok := err.(*os.SyscallError) if !ok { return nil, err } switch nerr.Err { case syscall.EAGAIN: if err = fd.pd.waitRead(); err == nil { continue } case syscall.ECONNABORTED: // This means that a socket on the // listen queue was closed before we // Accept()ed it; it\u0026#39;s a silly error, // so try again. continue } return nil, err } break } if netfd, err = newFD(s, fd.family, fd.sotype, fd.net); err != nil { closeFunc(s) return nil, err } // 调用上面函数加入epoll if err = netfd.init(); err != nil { fd.Close() return nil, err } lsa, _ := syscall.Getsockname(netfd.sysfd) netfd.setAddr(netfd.addrFunc()(lsa), netfd.addrFunc()(rsa)) return netfd, nil }   读处理 先从为Read代码开始\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  func (fd *netFD) Read(p []byte) (n int, err error) { if err := fd.readLock(); err != nil { return 0, err } defer fd.readUnlock() if len(p) == 0 { // If the caller wanted a zero byte read, return immediately // without trying. (But after acquiring the readLock.) Otherwise // syscall.Read returns 0, nil and eofError turns that into // io.EOF. // TODO(bradfitz): make it wait for readability? (Issue 15735) return 0, nil } if err := fd.pd.prepareRead(); err != nil { return 0, err } for { n, err = syscall.Read(fd.sysfd, p) if err != nil { n = 0 if err == syscall.EAGAIN { // 没有可读数据，进行读等待处理 if err = fd.pd.waitRead(); err == nil { continue } } } err = fd.eofError(n, err) break } if _, ok := err.(syscall.Errno); ok { err = os.NewSyscallError(\u0026#34;read\u0026#34;, err) } return }   具体分析读等待处理,跳过封装，直接分析处理代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  //go:linkname net_runtime_pollWait net.runtime_pollWait // 进入pollwait状态进行goroutine调度 func net_runtime_pollWait(pd *pollDesc, mode int) int { err := netpollcheckerr(pd, int32(mode)) if err != 0 { return err } // As for now only Solaris uses level-triggered IO. if GOOS == \u0026#34;solaris\u0026#34; { netpollarm(pd, mode) } // for !netpollblock(pd, int32(mode), false) { err = netpollcheckerr(pd, int32(mode)) if err != 0 { return err } // Can happen if timeout has fired and unblocked us, // but before we had a chance to run, timeout has been reset. // Pretend it has not happened and retry. } return 0 }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  // returns true if IO is ready, or false if timedout or closed // waitio - wait only for completed IO, ignore errors // 返回true表示IO就绪，返回false表示超时或者关闭 // waitio 表示是否等待IO,超时时该参数为false func netpollblock(pd *pollDesc, mode int32, waitio bool) bool { // 从pd.rg取指针 gpp := \u0026amp;pd.rg if mode == \u0026#39;w\u0026#39; { gpp = \u0026amp;pd.wg } // set the gpp semaphore to WAIT for { old := *gpp if old == pdReady { *gpp = 0 return true } if old != 0 { throw(\u0026#34;netpollblock: double wait\u0026#34;) } // cas 设置读状态为pdWait状态 if atomic.Casuintptr(gpp, 0, pdWait) { break } } // need to recheck error states after setting gpp to WAIT // this is necessary because runtime_pollUnblock/runtime_pollSetDeadline/deadlineimpl // do the opposite: store to closing/rd/wd, membarrier, load of rg/wg // 因为runtime_pollUnblock runtime_pollSetDeadline/deadlineimpl 将rg/wg状态修改为closing if waitio || netpollcheckerr(pd, mode) == 0 { gopark(netpollblockcommit, unsafe.Pointer(gpp), \u0026#34;IO wait\u0026#34;, traceEvGoBlockNet, 5) } // be careful to not lose concurrent READY notification old := atomic.Xchguintptr(gpp, 0) if old \u0026gt; pdWait { throw(\u0026#34;netpollblock: corrupted state\u0026#34;) } return old == pdReady }   总结  net网络库的设计的精华,良好的封装与接口,提高简单可靠的接口 充分利用goroutine机制 同步编程，异步执行，这一点其实在内核也能找到，只是调度机制不一样 多学习源码，这里面有精妙的设计，科学的框架 很多问题深入一下就到底层了 异步编程能够带来高性能，但是也是高要求，如果系统复杂，出现问题不好定位，同时代码的可读性也差 代码在满足正确性的基础上，应先追求可读性，规范性，高性能往后排  参考  How Goroutines Work  ", 
        "url": "http:\/\/myself659.github.io\/post\/2016-09-10-from-cepoll-to-go-net\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-08-20-go-channel-program-demo\/": {
        
        "title": "Go channel 编程篇",
        "tags": ["golang",],
        "content": "本篇以ChanBroker版本迭代过程，总结常见Channel编程问题\n简介 ChanBroker设计主要参考Kafka模型，主要提供进程内goroutine之间通信，实现以下功能：\n 支持多个Publisher发布内容 支持Subscriber注册与去注册订阅 发布内容可以是任何形式 ChanBroker根据订阅情况完成内容推送  版本1 具体代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68  package ChanBroker type Content interface{} type Subscriber chan Content type ChanBroker struct { RegSub chan Subscriber UnRegSub chan Subscriber Contents chan Content Stop chan bool Subscribers map[Subscriber]bool } func NewChanBroker() *ChanBroker { ChanBroker := new(ChanBroker) ChanBroker.RegSub = make(chan Subscriber) ChanBroker.UnRegSub = make(chan Subscriber) ChanBroker.Contents = make(chan Content) ChanBroker.Stop = make(chan bool) ChanBroker.Subscribers = make(map[Subscriber]bool) ChanBroker.run() return ChanBroker } func (self *ChanBroker) run() { go func() { // Broker goroutine  for { select { case content := \u0026lt;-self.Contents: for sub := range self.Subscribers { sub \u0026lt;- content } case sub := \u0026lt;-self.RegSub: self.Subscribers[sub] = true case sub := \u0026lt;-self.UnRegSub: delete(self.Subscribers, sub) close(sub) case \u0026lt;-self.Stop: for sub := range self.Subscribers { delete(self.Subscribers, sub) close(sub) } return } } }() } func (self *ChanBroker) RegSubscriber() Subscriber { sub := make(Subscriber) self.RegSub \u0026lt;- sub return sub } func (self *ChanBroker) UnRegSubscriber(sub Subscriber) { self.UnRegSub \u0026lt;- sub } func (self *ChanBroker) StopPublish() { self.Stop \u0026lt;- true } func (self *ChanBroker) PubContent(c Content) { self.Contents \u0026lt;- c }   存在以下问题，具体如下：\n问题1：不支持扩展 问题描述：\n在一个Broker goroutine内完成注册与去注册以及内容发布推送给Subscriber，无法控制Subscriber数量，且不支持扩展\n解决思路：\n主要修改如下：\n 增加Pusher goroutine，Pusher goroutine支持动态创建，由Pusher goroutine完成具体内容的推送  问题2： 推送内容到Subscriber存在Deadlock风险 问题描述：\n例如一个Subscriber不能正确从通道接收订阅内容，那么Broker会阻塞在上述代码的34行，与此同时其他Subscriber都会阻塞，极有可能引起级联阻塞，影响恶劣\n解决思路：\n主要修改如下：\n 支持Subscriber可以定制订阅通道的大小，利用队列缓存内容 增加Pusher goroutine，避免由于某个内容的推送导致整个内容推送的阻塞 增加超时机制，避免在具体内容推送过程由于某一个Subscriber不正常工作影响其他的Subscriber  问题3： Broker goroutine退出后调用RegSubscriber，UnRegSubscriber，StopPublish，PubContent函数存在Deadlock风险 问题描述：\n如题\n解决思路：\n主要修改如下：\n ChanBroker增加退出状态描述，避免Broker goroutine退出之后上述函数向Broker goroutine 的channel发送信息  版本2 具体代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109  package ChanBroker import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) type Content interface{} type Subscriber chan Content type ChanBroker struct { RegSub chan Subscriber UnRegSub chan Subscriber Contents chan Content Stop chan bool exit bool Subscribers map[Subscriber]bool lock sync.RWMutex timeout time.Duration } func NewChanBroker(timeout time.Duration) *ChanBroker { ChanBroker := new(ChanBroker) ChanBroker.RegSub = make(chan Subscriber) ChanBroker.UnRegSub = make(chan Subscriber) ChanBroker.Contents = make(chan Content) ChanBroker.Stop = make(chan bool) ChanBroker.exit = false ChanBroker.Subscribers = make(map[Subscriber]bool) ChanBroker.timeout = timeout ChanBroker.run() return ChanBroker } func (self *ChanBroker) run() { go func() { // Broker goroutine  for { select { case content := \u0026lt;-self.Contents: go func() { // Pusher goroutine  self.lock.RLock() for sub := range self.Subscribers { select { case sub \u0026lt;- content: case \u0026lt;-time.After(self.timeout): fmt.Println(sub, \u0026#34;time out \u0026#34;) } } self.lock.RUnlock() }() case sub := \u0026lt;-self.RegSub: self.lock.Lock() self.Subscribers[sub] = true self.lock.Unlock() case sub := \u0026lt;-self.UnRegSub: self.lock.Lock() delete(self.Subscribers, sub) self.lock.Unlock() close(sub) // may be close of closed channel  case \u0026lt;-self.Stop: if self.exit == false { self.exit = true close(self.Stop) self.lock.Lock() for sub := range self.Subscribers { delete(self.Subscribers, sub) // 必须先删除再close  close(sub) } self.lock.Unlock() return // exit goroutine  } } } }() } func (self *ChanBroker) RegSubscriber(size uint) Subscriber { if self.exit == true { return nil } sub := make(Subscriber, size) self.RegSub \u0026lt;- sub // maybe block  return sub } func (self *ChanBroker) UnRegSubscriber(sub Subscriber) { if self.exit == true { return } self.UnRegSub \u0026lt;- sub // maybe block } func (self *ChanBroker) StopPublish() { if self.exit == true { return } self.Stop \u0026lt;- true // maybe panic } func (self *ChanBroker) PubContent(c Content) { self.Contents \u0026lt;- c // maybe block }   存在以下问题，具体如下：\n问题1：存在 panic:close of closed channel的风险 问题描述：\n如果Subscriber goroutine两次调用UnRegSubscriber，就会发生close of closed channel，导致panic\n相应代码如下：\n1 2 3 4 5  case sub := \u0026lt;-self.UnRegSub: self.lock.Lock() delete(self.Subscribers, sub) self.lock.Unlock() close(sub) // may be close of closed channel   解决思路：\n很简单，关闭前检查Subscriber对应channel是否订阅map当中，代码如下：\n1 2 3 4 5 6 7 8  case sub := \u0026lt;-self.UnRegSub: self.lock.Lock() _, ok := self.Subscribers[sub] if ok { delete(self.Subscribers, sub) close(sub) } self.lock.Unlock()   问题2：不靠谱的exit标记 问题描述：\nexit标记不能同步goroutines对Stop通道的写操作与关闭操作，具体分析如下：\n写操作代码如下：\n1 2 3 4 5 6 7 8  func (self *ChanBroker) RegSubscriber(size uint) Subscriber { if self.exit == true { return nil } sub := make(Subscriber, size) self.RegSub \u0026lt;- sub // maybe block return sub }   关闭操作代码段如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  case \u0026lt;-self.Stop: if self.exit == false { self.exit = true close(self.Stop) self.lock.Lock() for sub := range self.Subscribers { delete(self.Subscribers, sub) // 必须先删除再close close(sub) } self.lock.Unlock() return // exit goroutine }   在多核多个goroutine并发情况，极小概率会发生如下情况：\n 某同一个时刻，CPU0 运行RegSubscriber goroutine检查exit标记为false，CPU0继续运行，CPU1运行到关闭操作代码段第1行，继续运行 CPU0 继续运行RegSubscriber goroutine，直到阻塞在第6行, 切换运行其他goroutine，CPU 1 关闭Stop Channel,并退出broken goroutine CPU0 继续运行其他goroutine，RegSubscriber goroutine一直阻塞在第6行,等待 broken goroutine 读Stop channel CPU0 继续执行其他goroutine，RegSubscriber goroutine一直阻塞在第6行，,等待 broken goroutine 读Stop channel CPU0 继续执行其他goroutine，RegSubscriber goroutine一直阻塞在第6行，,等待 broken goroutine 读Stop channel \u0026hellip;  解决思路：\n不用exit标记了，将状态关联到Stop Channel状态上（这又掉到另一个坑里）\n问题3：不能保证Subscribers有序的接收消息 问题描述：\n版本2中每接收一个Content都会启动一个Push goroutine,这些Push goroutine执行是无序执行的，有序的内容推送需求遇上了无序的goroutine，自然有问题了\n解决思路：\n方案1：无序推送，由Content自身加上序号，同时由各个Subscriber处理逻辑根据序号保证有序处理Content\n方案2：每一个Subcriber有一个Content队列，保证有序推送，简化各个Subscriber处理逻辑，具体实现见版本5\n版本3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159  package ChanBroker import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) type Content interface{} type Subscriber chan Content type ChanBroker struct { RegSub chan Subscriber UnRegSub chan Subscriber Contents chan Content Stop chan bool exit bool Subscribers map[Subscriber]bool lock sync.RWMutex timeout time.Duration } var errBrokerExit error = errors.New(\u0026#34;Broker exit\u0026#34;) var errTimeOut error = errors.New(\u0026#34;Time out\u0026#34;) func NewChanBroker(timeout time.Duration) *ChanBroker { ChanBroker := new(ChanBroker) ChanBroker.RegSub = make(chan Subscriber) ChanBroker.UnRegSub = make(chan Subscriber) ChanBroker.Contents = make(chan Content) ChanBroker.Stop = make(chan bool) ChanBroker.exit = false ChanBroker.Subscribers = make(map[Subscriber]bool) ChanBroker.timeout = timeout ChanBroker.run() return ChanBroker } func (self *ChanBroker) run() { go func() { for { select { case content := \u0026lt;-self.Contents: go func() { self.lock.RLock() for sub := range self.Subscribers { select { case sub \u0026lt;- content: case \u0026lt;-time.After(self.timeout): fmt.Println(sub, \u0026#34;time out \u0026#34;) } } self.lock.RUnlock() }() case sub := \u0026lt;-self.RegSub: self.lock.Lock() self.Subscribers[sub] = true self.lock.Unlock() case sub := \u0026lt;-self.UnRegSub: self.lock.Lock() _, ok := self.Subscribers[sub] if ok { delete(self.Subscribers, sub) close(sub) } self.lock.Unlock() case \u0026lt;-self.Stop: close(self.Stop) self.lock.Lock() for sub := range self.Subscribers { delete(self.Subscribers, sub) close(sub) } self.lock.Unlock() return // exit goroutine  } } }() } func (self *ChanBroker) RegSubscriber(size uint) (Subscriber, error) { select { case _, ok := \u0026lt;-self.Stop: if ok == false { return nil, errBrokerExit } else { sub := make(Subscriber, size) self.RegSub \u0026lt;- sub return sub, nil } case \u0026lt;-time.After(self.timeout): return nil, errTimeOut default: sub := make(Subscriber, size) self.RegSub \u0026lt;- sub return sub, nil } } func (self *ChanBroker) UnRegSubscriber(sub Subscriber) { select { case _, ok := \u0026lt;-self.Stop: if ok == false { return } else { self.UnRegSub \u0026lt;- sub return } case \u0026lt;-time.After(self.timeout): return default: self.UnRegSub \u0026lt;- sub return } } func (self *ChanBroker) StopPublish() { select { case _, ok := \u0026lt;-self.Stop: if ok == false { return } else { self.Stop \u0026lt;- true return } default: self.Stop \u0026lt;- true return } } func (self *ChanBroker) PubContent(c Content) error { select { case _, ok := \u0026lt;-self.Stop: if ok == false { return errBrokerExit } else { self.Contents \u0026lt;- c return nil } case \u0026lt;-time.After(self.timeout): return errTimeOut default: self.Contents \u0026lt;- c return nil } }   存在以下问题，具体如下：\n问题1： 读channel出现错误的竞争 问题描述：\n版本3的一个错误的方案选择，导致Stop Channel出现读竞争，导致不能停止发布，出现goroutine leak，分析如下：\n Stop Channel 只会写一次 Stop Channel 却有多个读goroutine 基于上面有情况，并不能保证Broker goroutine 能收到停止发布的信息，如果被其他goroutine收到，导致Broker goroutine收不到结束消息，进而不能关闭所有Subscriber，导致所有Subscriber goroutine泄露  解决思路：\n版本3引入关闭状态是一个错误的设计，引入状态，也就引入对依赖状态的对象，增加了代码的复杂性，状态的维护容易导致bug，在设计与代码应当追求无状态设计（好处多多）, 这里采用超时来解决，如果超时用由调用者确定处理策略\n版本4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128  package ChanBroker import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) type Content interface{} type Subscriber chan Content type ChanBroker struct { RegSub chan Subscriber UnRegSub chan Subscriber Contents chan Content Stop chan bool exit bool Subscribers map[Subscriber]bool lock sync.RWMutex timeout time.Duration } var errBrokerExit error = errors.New(\u0026#34;ChanBroker exit\u0026#34;) var errTimeOut error = errors.New(\u0026#34;ChanBroker Time out\u0026#34;) func NewChanBroker(timeout time.Duration) *ChanBroker { ChanBroker := new(ChanBroker) ChanBroker.RegSub = make(chan Subscriber) ChanBroker.UnRegSub = make(chan Subscriber) ChanBroker.Contents = make(chan Content) ChanBroker.Stop = make(chan bool) ChanBroker.exit = false ChanBroker.Subscribers = make(map[Subscriber]bool) ChanBroker.timeout = timeout ChanBroker.run() return ChanBroker } func (self *ChanBroker) run() { go func() { for { select { case content := \u0026lt;-self.Contents: go func() { self.lock.RLock() for sub := range self.Subscribers { select { case sub \u0026lt;- content: case \u0026lt;-time.After(self.timeout): fmt.Println(sub, \u0026#34;time out \u0026#34;) } } self.lock.RUnlock() }() case sub := \u0026lt;-self.RegSub: self.lock.Lock() self.Subscribers[sub] = true self.lock.Unlock() case sub := \u0026lt;-self.UnRegSub: self.lock.Lock() _, ok := self.Subscribers[sub] if ok { delete(self.Subscribers, sub) close(sub) } self.lock.Unlock() case \u0026lt;-self.Stop: // close(self.Stop)  self.lock.Lock() for sub := range self.Subscribers { delete(self.Subscribers, sub) close(sub) } self.lock.Unlock() return // exit goroutine  } } }() } func (self *ChanBroker) RegSubscriber(size uint) (Subscriber, error) { sub := make(Subscriber, size) select { case \u0026lt;-time.After(self.timeout): return nil, errTimeOut case self.RegSub \u0026lt;- sub: return sub, nil } } func (self *ChanBroker) UnRegSubscriber(sub Subscriber) { select { case \u0026lt;-time.After(self.timeout): return case self.UnRegSub \u0026lt;- sub: return } } func (self *ChanBroker) StopPublish() error { select { case self.Stop \u0026lt;- true: return nil case \u0026lt;-time.After(self.timeout): return errTimeOut } } func (self *ChanBroker) PubContent(c Content) error { select { case \u0026lt;-time.After(self.timeout): return errTimeOut case self.Contents \u0026lt;- c: return nil } }   存在以下问题，具体如下：\n问题1：timeout问题 问题描述：\n timeout 导致长时间持有读锁 timeout 导致消息丢失，并没有推送成功 上一个Subscriber超时影响后面Subscriber内容的实时性  解决方案：\n 采用select实现channel非阻塞写 对于非阻塞写失败，加入Subscriber对应的链表 非阻塞写保证避免Subscribers之间相互影响  问题2：锁问题 问题描述：\n 每个Pusher goroutine持有读锁，一定情况下会成为性能的瓶颈  解决方案：\n 在上面避免阻塞的基础上，只有一个goroutine来推送内容  版本5 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194  package ChanBroker import ( \u0026#34;container/list\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;time\u0026#34; ) type Content interface{} type Subscriber chan Content type ChanBroker struct { regSub chan Subscriber unRegSub chan Subscriber contents chan Content stop chan bool subscribers map[Subscriber]*list.List timeout time.Duration cachenum uint timerChan \u0026lt;-chan time.Time } var ErrBrokerExit error = errors.New(\u0026#34;ChanBroker exit\u0026#34;) var ErrPublishTimeOut error = errors.New(\u0026#34;ChanBroker Pulish Time out\u0026#34;) var ErrRegTimeOut error = errors.New(\u0026#34;ChanBroker Reg Time out\u0026#34;) var ErrStopPublishTimeOut error = errors.New(\u0026#34;ChanBroker Stop Publish Time out\u0026#34;) func NewChanBroker(timeout time.Duration) *ChanBroker { Broker := new(ChanBroker) Broker.regSub = make(chan Subscriber) Broker.unRegSub = make(chan Subscriber) Broker.contents = make(chan Content) Broker.stop = make(chan bool, 1) Broker.subscribers = make(map[Subscriber]*list.List) Broker.timeout = timeout Broker.cachenum = 0 Broker.timerChan = nil Broker.run() return Broker } func (self *ChanBroker) onContentPush(content Content) { for sub, clist := range self.subscribers { loop := true for next := clist.Front(); next != nil \u0026amp;\u0026amp; loop == true; { cur := next next = cur.Next() select { case sub \u0026lt;- cur.Value: if self.cachenum \u0026gt; 0 { self.cachenum-- } clist.Remove(cur) default: loop = false } } len := clist.Len() if len == 0 { select { case sub \u0026lt;- content: default: clist.PushBack(content) self.cachenum++ } } else { clist.PushBack(content) self.cachenum++ } } if self.cachenum \u0026gt; 0 \u0026amp;\u0026amp; self.timerChan == nil { timer := time.NewTimer(self.timeout) self.timerChan = timer.C } } func (self *ChanBroker) onTimerPush() { for sub, clist := range self.subscribers { loop := true for next := clist.Front(); next != nil \u0026amp;\u0026amp; loop == true; { cur := next next = cur.Next() select { case sub \u0026lt;- cur.Value: if self.cachenum \u0026gt; 0 { self.cachenum-- } clist.Remove(cur) default: loop = false } } } if self.cachenum \u0026gt; 0 { timer := time.NewTimer(self.timeout) self.timerChan = timer.C } else { self.timerChan = nil } } func (self *ChanBroker) run() { go func() { // Broker Goroutine  for { select { case content := \u0026lt;-self.contents: self.onContentPush(content) case \u0026lt;-self.timerChan: self.onTimerPush() case sub := \u0026lt;-self.regSub: clist := list.New() self.subscribers[sub] = clist case sub := \u0026lt;-self.unRegSub: _, ok := self.subscribers[sub] if ok { delete(self.subscribers, sub) close(sub) } case _, ok := \u0026lt;-self.stop: if ok == true { close(self.stop) } else { if self.cachenum == 0 { return } } self.onTimerPush() for sub, clist := range self.subscribers { if clist.Len() == 0 { delete(self.subscribers, sub) close(sub) } } } } }() } func (self *ChanBroker) RegSubscriber(size uint) (Subscriber, error) { sub := make(Subscriber, size) select { case \u0026lt;-time.After(self.timeout): return nil, ErrRegTimeOut case self.regSub \u0026lt;- sub: return sub, nil } } func (self *ChanBroker) UnRegSubscriber(sub Subscriber) { select { case \u0026lt;-time.After(self.timeout): return case self.unRegSub \u0026lt;- sub: return } } func (self *ChanBroker) StopPublish() error { select { case self.stop \u0026lt;- true: return nil case \u0026lt;-time.After(self.timeout): return ErrStopPublishTimeOut } } func (self *ChanBroker) PubContent(c Content) error { select { case \u0026lt;-time.After(self.timeout): return ErrPublishTimeOut case self.contents \u0026lt;- c: return nil } }   存在以下问题，具体如下：\n问题1：不支持扩展 问题描述：\n在一个Broker goroutine内完成注册与去注册以及内容发布推送给Subscriber，无法控制Subscriber数量，且不支持扩展\n解决思路：\n 业务场景：chanbroker是进程内goroutines之间pub-sub通信方式一种实现方案，一个goroutine占用一个核来处理能满足绝太多数需求 即使不能满足极个别需求，也可以选择创建多个ChanBroker来实现扩展  channel编程总结  避免Panic，参考Go channel 特点篇 最大程度保证非阻塞 若非业务需要，避免channel之间读写竞争 channel使用很灵活，也容易出错，建议多在设计上下功夫，分解问题采用简单的模型来解决问题 避免多余的channel状态引入,例如关闭channel 要有并发意识，由代码想到goroutine的运行 禁止通道复用，避免复用带来的复杂性 初期测试很重要，而且应作到充分测试 Don\u0026rsquo;t communicate by sharing memory, share memory by communicating  由于个人水平有限，有什么不足与错误，敬请指正！\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-08-20-go-channel-program-demo\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-08-05-im-user-state\/": {
        
        "title": "IM后端系统设计总结(2)",
        "tags": ["Arch",],
        "content": "这篇具体写一下用户在线状态系统的具体设计。\n后端架构 这个后端系统设计如下图：\n很大众，国内基本都这么干，不多说\n用户状态系统设计 初期设计 单IDC部署，设计如下:\n相关说明  AG：接入网关，负责用户的连接 ConnRouter：连接路由服务器，主要提供以下功能：   所有用户状态的维护 用户状态查询 用户状态推送 用户状态同步 异步消息路由与转发  状态通知流: 用户登录成功或者下线状态通知 状态同步流：ConnRouter服务器之间用户状态的同步，不需要推送给订阅者 用户消息流: 异步发送给用户的消息在服务器内部的传输  设计要点  参考Kafka的模型，将用户状态改变作为事件，将事件描述为消息，将消息队列化成消息队列 AG对应Kafka中的Producer角色，主要原因是用户状态是用户连接的影子，AG能真实快速感知用户状态 ConnRouter对应Kafka中的Broker UserStat（用户统计与分析）与StateNotify（用户状态通知）对应Kafka中的Consumer 减少耦合，以异步发送消息到用户为例，整个流程三步走：   第一步：生成发送消息，发送到ConnRouter 第二步：根据目的用户ID，查找到出口AG，将消息转发到出口AG 第三步：出口AG查找用户连接，通过连接发送到目的用户  ConnRouter设计 用户状态数据存储设计 用户状态数据存储设计，如下图所示：\n 内存消耗 主要内存消耗来自用户状态数组（与ConnRouter连接都是长连接，可以忽略不计） 每种客户端类型下每个用户占用一个1Byte，那么1G内存可以存1073741824个用户的状态，超过了10亿，支持亿级用户内存不是瓶颈 查找用户所在AG与状态O(1)  高可用性  服务器级Master-Master模式 根据用户ID选择ConnRouter Master实现用户级Master-Standby模式  高性能  epoll事件驱动 无锁数据访问 流程无阻塞 O(1)查找 多核并发 支持批量处理  支持Failover，方便升级  当ConnRouter宕机或者主动升级重启时，各AG重新建立连接时，将自身的用户状态同步到ConnRouter，完成用户状态数据恢复  无状态与单点自治  ConnRouter用户状态数据是各个AG的同步，真正用户状态保存在AG网关 单点可以独立工作  数据冲突处理 主要是一个数据优先级的原则（根据数据源，从高到低）：\n 状态数据来自AG 状态数据来自ConnRouter-Master 状态数据来自ConnRouter-Standby 状态数据来自RouterProxy  支持多IDC 保证更高可用性，需要支持多机房部署，实现两城三中心甚至更多节点异地多活，具体设计如下图：\n这里主要是引入了RouterProxy，将跨IDC ConnRouter连接起来，其中RouterProxy主要功能如下：\n 作为Producer同步状态通知到其他IDC RouterProxy 作为Comsumer接收同步状态发布到本IDC的ConnRouter 作为IDC间消息转发的网关  ConnRouter扩展 随着用户量增长，ConnRouter转发消息量，状态通知量，消息转发量都会不断增长，当然可以简单采用更好机器来scale up;下面是考虑进行业务拆分方式进行scale out，具体设计如下图： 从上图可知主要方案：\n 将异步消息转发业务拆分出来由Forward服务器来完成 将RouterProxy跨IDC消息转发业务拆分出来，由ForwardProxy服务器来完成  不足与应对  需要优化跨IDC间消息同步与转发流量 在大量用户且系统中存在多个状态维护服务器，这样会有大量的状态同步通信，服务器的网络与CPU易成为瓶颈 这时候就考虑将用户状态进行拆分，不将用户状态放到同一个服务器上维护，采用以下方式进行用户状态数据划分：   哈希方式 用户ID范围 按用户量划分 一致性hash  后记 方案可以有很多种，觉得引入直接引入Kafka是一个很好的选择，以后再研究。\n由于个人水平有限，有什么不足与错误，敬请指正！\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-08-05-im-user-state\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-07-29-im-message\/": {
        
        "title": "IM后端系统设计总结(1)",
        "tags": ["Arch",],
        "content": "定义IM 为用户提供即时消息服务，这里面有三个关键词：用户，消息，服务；下面根据三个关键词来展开总结，先从消息开始。\n消息 消息分类 对消息分类，很简单但是重要，方便后面业务的拆分。\n 注册 登录 用户信息 聊天消息 群组 好友 文件 版本 内部服务器之间消息 客户端诊断 其他业务消息  信息语义描述 在互联网和移动互联网时代常见有以下几种方式：\n XML 文本 MQTT 自定义二进制（这里一般默认为google protobuf）  这四种类型比较如下表所示：\n   比较项 XML 文本 MQTT 自定义二进制     可读性 好 好 差 差   通用性 标准协议，易通用 支持通用http协议，也可自定义 通用标准协议 私有协议，无法通用   扩展性 易扩展，支持第三方 易扩展 可扩展 仅协议可扩展，不支持第三方   流量消耗 极大 大 小 小   处理效率 低 一般 高 高   网络适应性 差 一般 较好 较好   业内应用 新浪微博/GTalk MSN facebook messenger QQ/weixin    再补充说一点，采用二进制协议，在网络带宽及消息存储方面可以节约成本，特别用户量达到千万级以上\n参考业内应用和移动互联网需求，二进制协议应该是不二选择。这里强烈推荐google protobuf，理由如下：\n 亲爹是google 支持多种编程语言(C++, JAVA, PYTHON, GO，PHP,C#)，支持多种平台 自定义且灵活 支持数据压缩 完整的技术生态，以及多年的应用实践  消息可扩展性 自定义二进制消息（google protobuf）可扩展性方面的一些经验：\n 采用T(ype)L(ength)V(alue) 数据结构中的成员不要使用变长数据类型，例如long，在32位系统中占4Bytes，在64位系统占用8Bytes 不删除消息体的数据成员 消息类型递增，不删除消息类型，即使不再使用也保留 消息头带上版本号，客户端无需要关心版本变化，由服务器完成不同版本的兼容适配处理 消息头与消息体的设计统一管理，不允许任何人私自修改 除非确定，protobuf消息字段尽量使用optional，由代码逻辑确定是否需要相应字段 考虑业务需求与变化，为未来留有应对变化的空间，同时保证消息的简洁  消息存储  初期简单点，采用mysql，同时利用mysql主备部署解决单点故障问题，分布式存储后面再说了，针对大量的消息存储后面考虑 对用户之间的聊天消息分表 对群信息等利用redis缓存 对于热点数据可以直接加载到内存  消息转发  消息从用户到用户（单播） 消息从用户到服务器 （单播） 消息从用户到群组 （组播） 消息从服务器到用户（单播） 消息从服务器到群组（组播）  消息传输 相对于PC互联网情况下，移动互联网情况下，丢包概率高，传输延迟大，问题自然就比较多，这方面优化请参考手机QQ的移动网络实践之路\n消息安全  防修改 消息检查或校验 防窃听 消息加密 防泄漏 系统防入侵，系统加固 防丢失 消息请求与回应机制，消息重传与幂等性 防损坏 多副本，分布式存储 防伪装 身份验证，签名  消息描述 消息由消息头和消息体组成，消息头参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12  #pragma pack(1) typedef struct { uint16_t type; // msg type uint16_t length; // the whole pdu length uint32_t version; // pdu version number uint32_t magic; // magic number uint32_t reserve; //后面为消息体 } UserPduHeader_t; #pragma pack()   后记 由于个人水平有限，有什么不足与错误，敬请指正！\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-07-29-im-message\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-07-26-go-channel-feature\/": {
        
        "title": "Go channel 特点篇",
        "tags": ["golang",],
        "content": "channel模式 根据同步方式不同，channel有两种模式：\n1、同步模式,形式如下：\n1  ch := make(chan int)   2、队列模式，形式如下：\n1  ch := make(chan int, 10)   根据数据方向流不同，channel类型可以有以下三种模式：\n 写操作模式（只发送） 读操作模式（只接收） 读写操作模式（不限发送与接收）  channel操作 channel有以下操作：\n 创建 关闭 写(发送)操作 读(接收)操作  这些操作都是原子操作\nchannel状态 根据模式与操作，channel有以下状态：\n 同步写阻塞 同步读阻塞 关闭状态 队列写阻塞 队列读阻塞 队列可读写 nil状态  channel状态与操作之间关系    状态/操作 写操作 读操作 关闭 创建     nil状态 写阻塞 写阻塞 产生panic(close of nil channel) -   同步写阻塞 写阻塞 成功读取数据 进入关闭状态，产生panic -   同步读阻塞 成功写入数据 读阻塞 进入关闭状态 -   关闭状态 产生panic 立即返回(nil，false) 产生panic -   队列写阻塞 写阻塞 成功读取队列中数据 进入关闭状态，成功写入队列的数据可读 -   队列读阻塞 成功写入数据 读阻塞 进入关闭状态 -   队列可读写 成功写入数据 成功读取数据 进入关闭状态，成功写入队列的数据可读 -    由于个人水平有限，有什么不足与错误，敬请指正！\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-07-26-go-channel-feature\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/learn\/how-to-start-%E5%BC%80%E5%A7%8B\/": {
        
        "title": "如何开始行动",
        "tags": ["学习","成长",],
        "content": "背景 人们常说：\n  万事开头难。\n  好的开始是成功的一半。\n   “The secret of getting ahead is getting started. The secret of getting started is breaking your complex overwhelming tasks into small manageable tasks, and starting on the first one.” — Mark Twain\n 从上可知开始很难，但是开始却很重要。\n为什么是开始行动 行动是实践。\n行动是执行力的体现。\n行动是真正的学习（纸上得来终觉浅，绝知此事要躬行）。\n行动是知行合一的关键（我们懂了很多道理，却依然过不好这一生）。\n所以开始行动是启动实践第一步。\n所以开始行动是打造执行力。\n所以开始行动是开始学习。\n所以开始行动是追求知行合一。\n如何开始行动 思考先行 行动之前先思考：\n what 做什么行动？ why 为什么要行动？ who 与谁一起行动？ when 什么时候行动？ where 在哪行动？ how 怎么行动？  准备 不打没有准备的仗，行动之前一定要做好准备，但是也不存在100%准备好。如果做什么事情都需要100%准备好，那么你将不会开始做任何事情，因为你会一直在准备。\n准备是不可少，但不过度准备。\n开始Tips   尽量早开始\n  从容易的开始，从小的开始，从最基础的开始，从能完成的开始\n  为开始建立触发器Trigger\n  降低开始的难度\n  为开始建立shortcut\n  利用习惯开始\n  为开始建立势头Momentum，利用势头开始\n  自动化开始\n  为开始设置deadline\n  有意识地主动开始\n  挑战5分钟的不舒服\n  开始行动吧 凡事只有开始行动,才有可能。\n凡事只有开始行动,才有收获。\n凡事只有开始行动,才有进步。\n开始行动吧,让过去不再成为遗憾,让将来不再成为憧憬，让现在不再迷茫，让自己享受当下。\n", 
        "url": "http:\/\/myself659.github.io\/post\/learn\/how-to-start-%E5%BC%80%E5%A7%8B\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/arch\/2016-06-02-10-lessons-from-10-years-of-amazon-web-services\/": {
        
        "title": "10 Lessons from 10 Years of Amazon Web Services（译文）",
        "tags": ["Arch",],
        "content": "前言  亚马逊在2006年3月14日发布AWS，到现在差不多10年了。回首过去的10年里，我们在构建 安全，高可用性，可扩展性，低成本的服务方面积累了几百条经验与教训。 由于AWS是建设并在全球运营这些服务的先驱，这些教训对我们的业务至关重要。正如我们以前多次说，“没有压缩经验的算法”，每月有超过百万的活跃客户，这些客户服务几个亿的用户，在这个过程我们不乏机会积累经验并持续优化从而为客户提供更好的服务。\n  我选择了下面这些经验教训，与大家分享，希望它们对你们有用。\n 1. 构建不断进化的系统  几乎从第一天开始,我们知道自己开发的软件在一年后将不会继续运行。我们需要重新审视和改进架构，以确保我们可以解决订单规模增长一到二个数量级所带来的问题。但是我们不能采取停电检修这种旧方法升级系统，这是因为遍布世界各地的海量业务需要我们的平台提供7*24小时高可用性服务。我们需要建立这样架构：能够在不停止服务的情况下引入新的组件。Marvin Theimer,亚马逊杰出工程师，曾开玩笑地说，亚马逊S3的演变可以被描述为从当初的单引擎飞机，随着时间的推移飞机不断升级，先是升级到737，然后是一组747，现在成了3805的空中舰队。在此期间，我们在飞行过程中完成加油，而客户甚至没有觉察到这一点。\n 感悟： 唯有变化才是确定，系统应该保证灵活性与扩展性。云计算系统是需要不断进化，开发人员也需要不断进化\n2. 总有想不到的  异常总是会发生的，随着时间的推移，一切都会出现异常：从路由器到硬盘，从操作系统到内存单元，从瞬态错误到永久性故障。无论你使用的是最高品质的硬件或最低成本的硬件，这些总是会发生的。在大规模系统中更是如此，例如，在S3中处理和存储的万亿交易，任何异常，即使是最小的可能性也将成为现实。部分这样的异常可以事先预见的，但更多的异常却在设计和开发过程中未能被发现。\n  我们需要开发一个视异常为常态的系统，即使我们不知道会有什么样的异常。即使“房子着火了”，系统也需要保持运行。重要的是在整个系统在不宕机的情况下能够处理这些异常。我们掌握隔离异常与控制异常的影响范围的方法从而使整个系统能够正常运行。\n 感悟：异常是常态，如何处理异常是系统设计阶段必须考虑到的问题。\n3. 提供基元而不是框架  我们很快意识到，客户的需求是不断变化的。当客户摆脱传统的IT硬件和数据中心的限制，他们开始使用感兴趣却没有应用过的模式搭建系统。因此，我们努力做到超级敏捷以确保满足客户的需求。\n  其中一个最重要的策略是向客户提供的基元和工具，让客户从中选择最合适他们的集合，而不是只提供一个框架中，迫使他们不得不使用。这种做法使我们的客户取得了成功，其后的AWS服务也同样利用这些客户已经熟悉的基础服务。\n  同样重要的是我们不知道客户下一个关心问题是什么，直到他们开始使用我们的服务。这就是为什么我们经常用最少的功能集提供新的服务，让我们的客户能够帮助推动产品路线图规划与新功能的开发。\n 感悟： 客户的需求是下一个产品。立足基础，理解客户的需求，才能满足客户。\n4. 自动化是关键  提供云计算服务不同于开发并交付软件，管理大规模系统需要不同的思维方式，以确保满足用户的高可用性，高性能和可扩展性的需求。\n  这其中关键的一点是尽可能地实现自动化管理以避免容易出错的手动操作。要做到这一点，我们需要实现管理API从而管理我们的业务的关键功能。AWS可以帮助客户做到这一点。通过为应用程序的每一个分解组件提供管理API，从而应用自动化的规则来保证可靠性和预期的性能。\n  如果你需要SSH到一个服务器或一个实例，那么你仍然需要更多的自动化，这是一个衡量自动化水平的好方法。\n 感悟： 用人管理代码，用代码管理机器\n5. APIs are forever（API是不会变的）  这是我们从亚马逊零售业务经验中吸取的教训，它的重要性甚至超过了AWS中那些以API为中心的业务。\n  一旦客户开始使用我们的API构建他们的应用程序和系统，改变这些API变得不可能，因我们修改这些API,会影响客户的业务运营。我们只有一次机会定义API,所以设计API是一个非常重要的工作。\n 感悟： 接口优先，实现其次，实现可以调整，而接口一旦上线就没有什么回旋的余地。\n6. 监控资源应用  当构建一个服务，一定要有服务及其运营成本的数据以确定相应的计费方式，尤其是对于运行高营业额-低利润率的业务。AWS理所应当关注服务的成本，这样我们在为客户的提供服务的同时能够明确在哪些地方可以提高运营效率，以进一步削减成本，以更低的价格回馈客户。\n  在创业初期，我们不知道S3服务应该采用哪种计费方式：我们曾认为应该对存储和带宽资源计费;经过一段时间，我们认识到请求的数量也应当计费。如果客户有许多微小的文件，即使他们上百万次数请求服务，消耗的存储和带宽都不会很高。我们不得不针对资源使用各个维度调整计费方式使AWS成为是一个可持续发展的业务。\n 感悟： 无监控不系统，无度量不优化。 作任何商业服务不仅要有成本意识，而且应该作到度量成本。\n7. 从一开始集成安全  保护你的客户应该永远是你的首选，对于AWS来说亦是如此。不管运营的角度，还是策略方面，这将永远是我们的头号投资领域。\n  我们很快地发现只有在一开始就把安全考虑进去才能提供安全的服务。安全团队的工作不是服务开发完成之后进行验证，他们必须在服务设计的第一天确认安全已经落实，且稳如泰山。总之对于安全，没有任何妥协。\n 感悟： 安全是基本功能。\n8. 加密是一等公民  加密是为确保客户能控制谁有权访问他们的数据一个关键机制。十年前，加密工具和服务很难使用，直到几年前我们学会更好地将加密集成到我们的服务当中。最早的加密是从S3服务端开始的。如果您想检查我们的数据中心的任何磁盘，任何数据都不可访问的。但随着亚马逊推出CloudHSM（硬件安全模块）和Amazon Key Management Service（密钥管理服务），客户可以加密自己的密钥，从而不再需要AWS来管理钥匙。一段时间以来，每个新服务均支持加密。例如，Amazon Redshift的每个数据块默认以随机密钥加密，随后这些随机密钥被私钥再加密。私钥由客户提供，确保他们是唯一可以解密和访问他们的关键业务数据或个人身份信息。\n  加密仍然是我们业务的重点。我们将继续为我们的客户提供更加便捷的加密方式，使他们能够更好地保护自己及其客户的数据。\n 感悟：一定不要让核心数据裸奔。\n9. 网络相当重要的  AWS已经支持许多不同类型业务：大规模的事务处理，大规模网站流量，视频转码，高性能并行计算。其中每个业务具有独特的要求，但都涉及到网络。\n  利用AWS特有的数据中心技术，我们实现了弹性网络以满足客户的各种不同网络负载。随着时间的推移，我们确信自己开发的硬件解决方案能够帮助客户实现他们的目标。这使我们能够满足非常具体的要求，比如实现不同AWS用户在网络方面达到最高级别的安全（也就是实现不同租户之间的网络隔离）。\n  AWS设计的网络硬件和软件是如何进一步提高我们的客户性能的另一个成功的例子是解决虚拟机的虚拟网络访问的问题。由于网络接入是不同客户共享的，导致客户的网络访问时常有明显的抖动。开发一个支持SRIOV网卡让每个虚拟机拥有自身的虚拟网卡，从而使延迟时间降低2倍以上，并在延迟网络环境的改善超过10倍。\n 感悟： 网络是服务的交付与实现的交通运输线，重要性不言而喻。传统网络难以满足云计算的需求，所以以SDN与NFV为基础的新网络技术会得到广泛的应用，但是这些技术很有可能是由云计算厂商自己开发利用，而不是由思科等传统网络设备商决定的，因为云计算厂商更需要这样的技术也更理解云计算对网络的需求。云计算厂商也有决心来作这件事：既然网络需求会不断变化，那应该将变化掌握在自己手中，另一方面，云计算作为未来长期存在的互联网基础设施，从长远来看网络产品的自研也可以节省一大笔成本。\n10. 保持开放  随着时间的推移，AWS团队通过提供多种服务和功能已经为客户创造了非常广泛而深入的平台。AWS上现有服务数量远远超过我们开发的服务数量：通过我们的合作伙伴，该平台不断扩展新的方向，已经成为一个丰富的生态系统。\n  例如，我们合作伙伴Stripe在AWS上为Twilio提供支付服务。还有许多客户基于AWS构建自己的平台服务于特定垂直需求：飞利浦正在建设自己的Healthsuite数字平台来管理医疗数据，Ohpen已经建立了AWS零售银行业务的平台，Eagle Genomics已经建立了一个基因处理平台，还有很多。最重要的是，目前在AWS平台上没有条条框框告诉我们的合作伙伴，他们可以做什么和不能做什么。 没有条条框框的限制解放了创新，并诞生了许多意想不到的发明，这是一定要遵循的。\n 感悟： 云计算提供开放平台，让百花齐放！ 云计算是互联网的基础的设施！\n后记 这是亚马逊CTO Werner Vogels在AWS发布十年之际写的一篇文章，亚马逊是云计算的先驱和全球的领导者，作为亚马逊CTO还常写一些技术性文章，必定是真知灼见，这些经验教训为今后的系统设计提供了很好的参考，有助于权衡决策。\n第一次翻译一篇完整的文章，表达与措词方面有很多不足，把它发出来了，主要想看看以后能取得多大的进步。\n最后，虽然翻译水平一般，但是还是建议：有时间结合工作认真地读一遍原文\n参考  10 Lessons from 10 Years of Amazon Web Services AWS Key Management Service Amazon Redshift AWS CloudHSM  ", 
        "url": "http:\/\/myself659.github.io\/post\/arch\/2016-06-02-10-lessons-from-10-years-of-amazon-web-services\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/arch\/2016-05-27-facebook-live-detail\/": {
        
        "title": "Facebook live一些技术细节",
        "tags": ["Arch",],
        "content": "协议选择 最初选择HLS,后面切换为RTMP，切换为RTMP主要为了降低延迟，提供更好直播用户体验。\n解决并发问题  分发架构\n采用Live stream server， origin server， edge server 三层架构；如下图如示： ![分发架构图](/images/facebook live arch.png)  一句话就是：通过遍布各地的CDN节点（edge server）实现海量用户的播放请求。\n 请求合并应对高并发 采用的CDN方案，应对一般数量级的播放是没有问题，但是facebook上有很多名人与网红，他们每个人都有几百万个粉丝，这就要求facebook live 直播系统能够处理超过一亿人同时播放的能力。假如一个名人的直播有100万粉丝同时观看，edge server缓存命中率为98%，那么未命中用户为2万，这2万用户回源到origin server甚至回源到Live stream server，服务器压力可想而知，这不是2W个连接而已，而是2W个视频播放，带宽，cpu都是一个很大的考验。用数字说话，以带宽为例； 假设一个HLS切片为3S，高清视频码率为1800K bps，那么一秒带宽需求为：  1  20K /3 *1800K b/s * 1s = 20*600 Mb = 12 Gb   每秒的带宽超过10Gb，服务器网卡高配也才10Gb。\n业务驱动方案，其具体解决方案如下： 在edge server 对同一个视频切片的多人cache miss请求进行合并，只发送一个到 origin server，待origin server 返回该视频切片，同时发送给该视频切片的所有请求。这样就可以大量减少回源的请求数量。origin server亦是如此。\n想到下面的问题：\n 最近520，林心如与霍建华在微博宣布恋爱关系，微博是怎么搞定推送信息众粉丝的呢？ 一个直播有100W在线观看，如何实现海量消息的转发？\n 既然想到了，以微博为例写一下自己的方案：\n 微博消息是一种pub-sub模型，简单的在问题的场景下林心如这样明星是pub，粉丝是sub，粉丝数量是7000W 微博发布了，如何发送到7000W粉丝？不可能直接将立即将消息推送到各个粉丝，不可能是一个推模型，瞬间大并发写与大量存储都会有问题，可能是拉模型吗？拉模型好处只写一条微博，新上线的用户会主动拉取订阅（关注）用户的发布的微博；僵尸用户，活不过来用户，睡眠用户是可以忽略的，怎么触发在线用户主动获取关注的人的动态保证消息的实时性呢？ 在用户线用户定时获取更新，例如60秒定时获取订阅用户是否有更新，这是一个很大的开销，假如微博有2000W同时在线，那么一秒有30多W个拉取更新的请求，每个请求都会查询订阅用户的微博，虽然可以承受的，但是代价还是很大的，同时这种定时拉取会消耗用户的流量，长期下来用户是无法忍受的，所以在线用户拉取是不可行的 对于在线用户采用推消息，7000W粉丝假设有5%用户在线，那在线粉丝为350W，如果在60S内完成，那一秒要完成60W个推送（发送60W个包，更新60W个用户订阅微博信息），如果整个系统只处理这一件事，是可以的，但是微博大V多，假如1分钟有10个类似的情况，同时也还有其他在线千万级用户（数据是乱猜的）; 系统容量是有限的，总会出现抗不住的情况的，墨菲定律告诉我们：这种情况总会发生的，只是我们不知道什么时候会发生。 抗住是目的，这时候需要作好监控，限流，扩容，降级服务保证核心功能 针对粉丝数量超过1000W以上的大V进行特殊处理  实现RTMP 选择基于nginx rtmp改造，并开发rtmp proxy，采用nginx rtmp有如下好处：\n nginx拥有一个良好的技术生态 nginx的多进程模型能够充分分挥多核cpu的能力 nginx rtmp已经有大量的应用，基本功能可靠 nginx rtmp是基于c语言实现，有良好的性能，当有大量的节点部署的情况下，可以省一大批服务器，能够节省一大笔成本  个人水平有限，若有不妥与错误，欢迎指正，谢谢！\n参考  Under the hood: Broadcasting live video to millions  ", 
        "url": "http:\/\/myself659.github.io\/post\/arch\/2016-05-27-facebook-live-detail\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-05-21-git-cmd\/": {
        
        "title": "git常用命令总结",
        "tags": ["Linux",],
        "content": "配置  config user  1 2  git config --global user.email \u0026#34;you@example.com\u0026#34; git config --global user.name \u0026#34;Your Name\u0026#34;   Ignore Git permission changes  1  git config core.fileMode false   Fix .gitignore  1  git rm -r --cached .   git仓库  初始化一个版本仓库  1  git init   clone远程版本库  1  git clone git@github.com:myself659/FFmpeg.git   添加远程版本库origin  1  git remote add origin git@github.com:myself659/rtmpserver_demo.git   查看远程仓库信息  1  git remote -v   删除远程仓库  1  git remote rm \u0026lt;repository\u0026gt;   git修改  添加当前修改的文件到暂存区  1  git add .   提交修改到本地  1  git commit -m \u0026#34;fix bug 0001\u0026#34;   提交修改到远程  1  git push -u origin master   查看修改状态  1  git status   重命名文件  1  git mv README readme   从版本库中删除文件  1  git rm readme   取消对文件修改  1  git checkout -- readme   修改最新一次修改注释  1  git commit amend   显示所有提交  1  git show   1  git show \u0026lt;commit\u0026gt; --stat   1  git show \u0026lt;commit\u0026gt; -- \u0026lt;filepath\u0026gt;   恢复最后一次提交的状态  1  git revert HEAD   恢复某次提交的状态  1  git revert \u0026lt;$id\u0026gt;   Remove untracked files \u0026amp; directories  1 2 3 4  # To remove untracked files git clean -f # TO remove untracked directories git clean -fd   git log  查看修改log  1  git log   查看指定文件每次提交记录  1  git log \u0026lt;filename\u0026gt;   查看最近两次详细修改内容的diff  1  git log -p -2   查看提交统计信息  1  git log --stat   Move a commit from one branch to another  1  git cherry-pick COMMIT-HASH   查看项目各个成员提交代码统计  1  git log --format=\u0026#39;%aN\u0026#39; | sort -u | while read name; do echo -en \u0026#34;$name\\t\u0026#34;; git log --author=\u0026#34;$name\u0026#34; --pretty=tformat: --numstat | awk \u0026#39;{ add += $1; subs += $2; loc += $1 - $2 } END { printf \u0026#34;added lines: %s, removed lines: %s, total lines: %s\\n\u0026#34;, add, subs, loc }\u0026#39; -; done   git log graph  1  git log --graph --format=format:\u0026#39;%C(bold blue)%h%C(reset) - %C(bold green)(%ar)%C(reset) %C(white)%an%C(reset)%C(bold yellow)%d%C(reset) %C(dim white)- %s%C(reset)\u0026#39; --all   git分支  查看远程分支  1  git branch -r   创建新分支  1  git branch \u0026lt;new_branch\u0026gt;   1  git checkout -b NEW-BRANCH-NAME   查看各分支创建最后提交信息  1  git branch -v   删除指定分支  1  git branch -d \u0026lt;branch_name\u0026gt;   强制删除指定分支  1  git branch -D \u0026lt;branch_name\u0026gt;   查看已经被合并到当前分支的分支  1  git branch --merged   查看尚未被合并到当前分支的分支  1  git branch --no-merged   合并分支  1  git merge \u0026lt;merge_branch\u0026gt;   切换分支  1  git checkout \u0026lt;branch_name\u0026gt; -f   抓取远程仓库所有分支更新并合并到本地  1  git pull   抓取远程仓库所有分支更新并合并到本地，不要快进合并  1  git pull --no-ff   抓取远程仓库更新  1  git fetch origin   push所有分支  1  git push   将本地主分支推到远程主分支  1  git push origin master   将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库)  1  git push -u origin master   创建远程分支  1  git push origin \u0026lt;local_branch\u0026gt;:\u0026lt;remote_branch\u0026gt;   查看所有分支名称  1  git branch --all   check branch status  1  git status   rename local branch  1  git branch -m OLD-BRANCH-NAME NEW-BRANCH-NAME   rename remote branch  1  git push origin :OLD-BRANCH-NAME NEW-BRANCH-NAME   Delete a branch on a remote repository  1  git push REMOTE-NAME --delete BRANCH-NAME   clean git branches exclude main and master  1  git branch | grep -v \u0026#34;master\u0026#34; | grep -v \u0026#34;main\u0026#34; | grep -v ^\\* | xargs git branch -D;   git diff  比较当前文件和暂存区文件差异  1  git diff \u0026lt;file\u0026gt;   比较两次提交之间的差异  1  git diff \u0026lt;$id1\u0026gt; \u0026lt;$id2\u0026gt;   比较两个分支  1  git diff \u0026lt;branch1\u0026gt; \u0026lt;branch2\u0026gt;   比较统计信息  1  git diff --stat   提交git diff  How to Include Diff into Git Commit Message\n1 2 3 4 5 6 7 8 9 10 11 12 13  #!/bin/bash  COMMIT_MSG_FILE=$1 COMMIT_SOURCE=$2 SHA1=$3 RESULT=\u0026#34;# Differences to be committed:\u0026#34; while IFS= read -r line do RESULT+=\u0026#34;$IFS# $line\u0026#34; done \u0026lt;\u0026lt;\u0026lt; $(git diff --staged) echo \u0026#34;$RESULT\u0026#34; \u0026gt;\u0026gt; $COMMIT_MSG_FILE   misc  提交文件超过100M  1  git filter-branch -f --index-filter \u0026#34;git rm -rf --cached --ignore-unmatch slides/tt.sql\u0026#34; -- --all   提交代码到新分支  创建新分支  1  git checkout -b feature-43   添加修改  1  git add .   提交修改到本地  1  git commit -m \u0026#34;f43\u0026#34;   将本地修改推送到指定分支  1  git push origin feature-43   丢弃本地修改 1  git reset --hard \u0026lt;the sha1 hash\u0026gt;   Reset to the last commit 1  git reset -hard origin/BRANCH-NAME   拉取所有分支 1  git pull --all   1 2 3 4  #!/bin/bash for branch in $(git branch --all | grep \u0026#39;^\\s*remotes\u0026#39; | egrep --invert-match \u0026#39;(:?HEAD|master)$\u0026#39;); do git branch --track \u0026#34;${branch##*/}\u0026#34; \u0026#34;$branch\u0026#34; done   1 2 3 4 5 6 7 8 9  #!/bin/sh # Usage: fetchall.sh branch ... set -x git fetch --all for branch in \u0026#34;$@\u0026#34;; do git checkout \u0026#34;$branch\u0026#34; || exit 1 git rebase \u0026#34;origin/$branch\u0026#34; || exit 1 done   查看远程git地址 1  git config --get remote.origin.url   merge 1 2  git checkout feature git merge master   将当前分支合并到原来master分支。\nrebase 1 2  git checkout feature git rebase master   将master后面的修改合并到当前分支，将当前分支作为个人开发master分支。\n跳转到根目录 1 2 3  gitroot(){ cd $(git rev-parse --show-toplevel 2\u0026gt; /dev/null) }   gitstart 1 2  mkdir your-project gitstart go   ", 
        "url": "http:\/\/myself659.github.io\/post\/2016-05-21-git-cmd\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-04-17-linux-kernel-crashs\/": {
        
        "title": "Linux内核常见crash原因",
        "tags": ["Linux",],
        "content": "前言 与前同事交流，发现以前的技术经历与解决的问题，现在接触不多，但是想想还是很有意思，虽然很多细节现在已经不能表达出来或展示出来，但是还得写出来。下面写的得主要个人经历的linux内核crash原因。\n内存类 这一类同用户态类似，主要有以下几种情况，\n 访问NULL 访问释放后的内存 非法访问内存 内存被踩 内存耗尽 野指针操作  堆栈类  内核调用栈溢出 写坏调用栈  锁  死锁 rcu使用错误 锁内存被写坏 长期获取不到锁，导致看门狗饿死，狗叫重启  调度  线程陷入死循环或者长时间占用cpu，在非抢占模式下其他线程得不到调度  中断上下文  在中断上下文调用错误的函数，例如在中断上下文使用信号量，更多参考那些可进入睡眠状态的Linux内核函数  硬件故障 在系统运行过程出现硬件故障也会导致内核crash。接触较少，不作说明。\n后记 能力有限，条件有限，写的很虚，也不全面，以后有机会再来点实际的，这个目的主要是回忆总结自己的知识体系。\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-04-17-linux-kernel-crashs\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-03-09-x86-64-call-stack\/": {
        
        "title": "Linux x86-64 函数调用栈实例分析",
        "tags": ["Linux",],
        "content": "前言 动手实践并写文章花5倍的时间一次性把事情做到90分，好过读别人文章只能做到60分，后面还需要花时间继续深入学习(做事情一定要做到有效的阈值)。本文目的希望通过分析一个简单的函数调用加深对x86-64寄存器及栈帧的结构的认识，以便在定位问题需要的时候能够熟练运用。\n环境 1.操作系统和内核\n1 2  [root@localhost ~]# cat /proc/version Linux version 3.10.0-229.4.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) ) #1 SMP Wed May 13 10:06:09 UTC 2015   2.GCC版本\n1 2 3 4 5 6 7 8  [root@localhost ~]# gcc -v Using built-in specs. COLLECT_GCC=gcc COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/4.8.3/lto-wrapper Target: x86_64-redhat-linux Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-linker-hash-style=gnu --enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto --enable-plugin --enable-initfini-array --disable-libgcj --with-isl=/builddir/build/BUILD/gcc-4.8.3-20140911/obj-x86_64-redhat-linux/isl-install --with-cloog=/builddir/build/BUILD/gcc-4.8.3-20140911/obj-x86_64-redhat-linux/cloog-install --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux Thread model: posix gcc version 4.8.3 20140911 (Red Hat 4.8.3-9) (GCC)   3.GDB版本\n1 2 3 4 5 6 7 8 9 10  [root@localhost ~]# gdb --version GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-64.el7 Copyright (C) 2013 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \u0026#34;show copying\u0026#34; and \u0026#34;show warranty\u0026#34; for details. This GDB was configured as \u0026#34;x86_64-redhat-linux-gnu\u0026#34;. For bug reporting instructions, please see: \u0026lt;http://www.gnu.org/software/gdb/bugs/\u0026gt;.   GDB 分析调用栈 1. 准备代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  #include \u0026lt;stdio.h\u0026gt; int sum(int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, int a9) { int s = 0xaaaa; s = a1+a2+a3+a4+a5+a6+a7+a8+a9; return s; } void caller(void) { int iRet = 0x0; iRet = sum(0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99); printf(\u0026#34;sum: %x\\r\\n\u0026#34;, iRet); } int main(void) { caller(); return 0; }   2. 生成可执行文件 1 2 3  [root@localhost cpp]# gcc -g stackexample.c -o stackexample [root@localhost cpp]# ./stackexample sum: 2FD   3. 分析调用栈 主要通过gdb分析调用栈变化情况\n3.1 初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  Breakpoint 1, main () at stackexample.c:22 warning: Source file is more recent than executable. 22 caller(); Missing separate debuginfos, use: debuginfo-install glibc-2.17-78.el7.x86_64 (gdb) info registers rax 0x4005e6 4195814 rbx 0x0 0 rcx 0x400600 4195840 rdx 0x7fffffffe518 140737488348440 rsi 0x7fffffffe508 140737488348424 rdi 0x1 1 rbp 0x7fffffffe420 0x7fffffffe420 rsp 0x7fffffffe420 0x7fffffffe420 r8 0x7ffff7dd5e80 140737351868032 r9 0x0 0 r10 0x7fffffffe270 140737488347760 r11 0x7ffff7a3ba00 140737348090368 r12 0x400440 4195392 r13 0x7fffffffe500 140737488348416 r14 0x0 0 r15 0x0 0 rip 0x4005ea 0x4005ea \u0026lt;main+4\u0026gt; eflags 0x246 [ PF ZF IF ] cs 0x33 51 ss 0x2b 43 ds 0x0 0 es 0x0 0 fs 0x0 0 ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- gs 0x0 0 (gdb)   栈内存（堆栈向下生长）:\n1 2 3 4 5 6 7 8 9 10 11 12  rbp 0x7fffffffe420 0x7fffffffe420 rsp 0x7fffffffe420 0x7fffffffe420 0x7fffffffe428 +------------------+ | | rbp-\u0026gt;0x7fffffffe420 +------------------+ \u0026lt;-rsp | | 0x7fffffffe218 +------------------+ | | 0x7fffffffe210 +------------------+ | | 0x7fffffffe208 +------------------+   3.2 调用caller 寄存器信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  (gdb) s caller () at stackexample.c:14 14 int iRet = 0x0; (gdb) info registers rax 0x4005e6 4195814 rbx 0x0 0 rcx 0x400600 4195840 rdx 0x7fffffffe518 140737488348440 rsi 0x7fffffffe508 140737488348424 rdi 0x1 1 rbp 0x7fffffffe410 0x7fffffffe410 rsp 0x7fffffffe3e0 0x7fffffffe3e0 r8 0x7ffff7dd5e80 140737351868032 r9 0x0 0 r10 0x7fffffffe270 140737488347760 r11 0x7ffff7a3ba00 140737348090368 r12 0x400440 4195392 r13 0x7fffffffe500 140737488348416 r14 0x0 0 r15 0x0 0 rip 0x40058a 0x40058a \u0026lt;caller+8\u0026gt; eflags 0x202 [ IF ] cs 0x33 51 ss 0x2b 43 ds 0x0 0 es 0x0 0 fs 0x0 0 ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- gs 0x0 0 (gdb) x /6gx 0x7fffffffe3e0 0x7fffffffe3e0: 0x0000000000000001 0x000000000040064d 0x7fffffffe3f0: 0x0000000000000000 0x0000000000000000 0x7fffffffe400: 0x0000000000400600 0x0000000000400440 (gdb) (gdb) x /12gx 0x7fffffffe3e0 0x7fffffffe3e0: 0x0000000000000001 0x000000000040064d 0x7fffffffe3f0: 0x0000000000000000 0x0000000000000000 0x7fffffffe400: 0x0000000000400600 0x0000000000400440 #小端系统，前8位存储iRet的值 0x7fffffffe410: 0x00007fffffffe420 0x00000000004005ef 0x7fffffffe420: 0x0000000000000000 0x00007ffff7a3baf5 0x7fffffffe430: 0x0000002000000000 0x00007fffffffe508 (gdb) (gdb) p iRet $3 = 0 (gdb) p \u0026amp;iRet $4 = (int *) 0x7fffffffe40c #局部变量在堆栈的位置   栈内存（堆栈向下生长）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  rbp 0x7fffffffe410 0x7fffffffe410 rsp 0x7fffffffe3e0 0x7fffffffe3e0 0x7fffffffe428 +------------------+ | | 0x7fffffffe420 +------------------+ |0x00000000004005ef| #保存返回main的指令地址,参考汇编代码 0x7fffffffe418 +------------------+ |0x00007fffffffe420| #保存main函数对应rbp rbp --\u0026gt;0x7fffffffe410 +------------------+ | | 0x7fffffffe408 +------------------+ | | 0x7fffffffe400 +------------------+ | | 0x7fffffffe3f8 +------------------+ | | 0x7fffffffe3f0 +------------------+ | | 0x7fffffffe3e8 +------------------+ | | rsp --\u0026gt;0x7fffffffe3e0 +------------------+   main函数的汇编代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  (gdb) disassemble /m main Dump of assembler code for function main: 21 { 0x00000000004005e6 \u0026lt;+0\u0026gt;: push %rbp 0x00000000004005e7 \u0026lt;+1\u0026gt;: mov %rsp,%rbp 22 caller(); 0x00000000004005ea \u0026lt;+4\u0026gt;: callq 0x400582 \u0026lt;caller\u0026gt; 23 24 return 0; 0x00000000004005ef \u0026lt;+9\u0026gt;: mov $0x0,%eax #调用caller返回后执行的指令地址 25 } 0x00000000004005f4 \u0026lt;+14\u0026gt;: pop %rbp 0x00000000004005f5 \u0026lt;+15\u0026gt;: retq End of assembler dump. (gdb)   3.3调用sum 寄存器信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  Breakpoint 2, sum (a1=17, a2=34, a3=51, a4=68, a5=85, a6=102, a7=119, a8=136, a9=153) at stackexample.c:6 6 int s = 0x0; (gdb) info registers rax 0x4005e6 4195814 rbx 0x0 0 rcx 0x44 68 #第四个参数 rdx 0x33 51 #第三个参数 rsi 0x22 34 #第二个参数 rdi 0x11 17 #第一个参数 rbp 0x7fffffffe3d0 0x7fffffffe3d0 rsp 0x7fffffffe3d0 0x7fffffffe3d0 r8 0x55 85 #第五个参数 r9 0x66 102 #第六个参数 r10 0x7fffffffe270 140737488347760 r11 0x7ffff7a3ba00 140737348090368 r12 0x400440 4195392 r13 0x7fffffffe500 140737488348416 r14 0x0 0 r15 0x0 0 rip 0x400548 0x400548 \u0026lt;sum+24\u0026gt; eflags 0x202 [ IF ] cs 0x33 51 ss 0x2b 43 ds 0x0 0 es 0x0 0 fs 0x0 0 ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- gs 0x0 0 (gdb)   caller对应汇编代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  (gdb) disassemble /m caller Dump of assembler code for function caller: 13 { 0x0000000000400582 \u0026lt;+0\u0026gt;: push %rbp #保存调用函数main的rbp 0x0000000000400583 \u0026lt;+1\u0026gt;: mov %rsp,%rbp #将上一个栈顶指针作为本函数的栈底（设置当前函数的栈基址） 0x0000000000400586 \u0026lt;+4\u0026gt;: sub $0x30,%rsp #分配栈空间 14 int iRet = 0x0; 0x000000000040058a \u0026lt;+8\u0026gt;: movl $0x0,-0x4(%rbp) 15 16 iRet = sum(0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99); 0x0000000000400591 \u0026lt;+15\u0026gt;: movl $0x99,0x10(%rsp) #第9个参数 0x0000000000400599 \u0026lt;+23\u0026gt;: movl $0x88,0x8(%rsp) #第8个参考 0x00000000004005a1 \u0026lt;+31\u0026gt;: movl $0x77,(%rsp) #第7个参数 0x00000000004005a8 \u0026lt;+38\u0026gt;: mov $0x66,%r9d #第6个参数 0x00000000004005ae \u0026lt;+44\u0026gt;: mov $0x55,%r8d #第5个参数 0x00000000004005b4 \u0026lt;+50\u0026gt;: mov $0x44,%ecx #第4个参数 0x00000000004005b9 \u0026lt;+55\u0026gt;: mov $0x33,%edx #第3个参数 0x00000000004005be \u0026lt;+60\u0026gt;: mov $0x22,%esi #第2个参数 0x00000000004005c3 \u0026lt;+65\u0026gt;: mov $0x11,%edi #第1个参数 0x00000000004005c8 \u0026lt;+70\u0026gt;: callq 0x400530 \u0026lt;sum\u0026gt; #调用函数sum 0x00000000004005cd \u0026lt;+75\u0026gt;: mov %eax,-0x4(%rbp) #取返回值 ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- 17 printf(\u0026#34;sum: %X\\r\\n\u0026#34;, iRet); 0x00000000004005d0 \u0026lt;+78\u0026gt;: mov -0x4(%rbp),%eax 0x00000000004005d3 \u0026lt;+81\u0026gt;: mov %eax,%esi 0x00000000004005d5 \u0026lt;+83\u0026gt;: mov $0x400690,%edi 0x00000000004005da \u0026lt;+88\u0026gt;: mov $0x0,%eax 0x00000000004005df \u0026lt;+93\u0026gt;: callq 0x400410 \u0026lt;printf@plt\u0026gt; 18 } 0x00000000004005e4 \u0026lt;+98\u0026gt;: leaveq #出栈处理 0x00000000004005e5 \u0026lt;+99\u0026gt;: retq End of assembler dump. (gdb)   通过上面汇编与寄存器信息，可以了解到函数调用的参数一般先通过寄存器传递。但是可用于传递函数的参数有限，超出的参数怎么传递呢？入调用函数的栈空间，具体如下：\n1 2 3 4 5 6 7 8 9  (gdb) x /12gx $rsp 0x7fffffffe3d0: 0x00007fffffffe410 0x00000000004005cd #main函数栈底，返回指令 0x7fffffffe3e0: 0x0000000000000077 0x0000000000000088 #第七个参数 第八个参数 0x7fffffffe3f0: 0x0000000000000099 0x0000000000000000 #第九个参数 0x7fffffffe400: 0x0000000000400600 0x0000000000400440 #这两个内容是什么 0x7fffffffe410: 0x00007fffffffe420 0x00000000004005ef 0x7fffffffe420: 0x0000000000000000 0x00007ffff7a3baf5 (gdb)   栈内存（栈向下生长）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  rbp 0x7fffffffe3d0 0x7fffffffe3d0 rsp 0x7fffffffe3d0 0x7fffffffe3d0 0x7fffffffe428 +------------------+ | | 0x7fffffffe420 +------------------+ |0x00000000004005ef| #保存返回main的地址 0x7fffffffe418 +------------------+ |0x00007fffffffe420| #保存main函数对应rbp 0x7fffffffe410 +------------------+ | | 0x7fffffffe408 +------------------+ | | 0x7fffffffe400 +------------------+ | | 0x7fffffffe3f8 +------------------+ | 0x99 | 0x7fffffffe3f0 +------------------+ | 0x88 | 0x7fffffffe3e8 +------------------+ | 0x77 | 0x7fffffffe3e0 +------------------+ |0x00000000004005cd| #保存调用caller返回的指令地址 0x7fffffffe3e0 +------------------+ |0x00007fffffffe410| #保存caller函数对应的rbp rsp --\u0026gt;0x7fffffffe3e0 +------------------+   3.4 sum获取参数 1 2 3 4 5 6 7 8 9  (gdb) x /16gx $rsp-0x28 0x7fffffffe3a8: 0x0000005500000066 0x0000003300000044 0x7fffffffe3b8: 0x0000001100000022 0x0000000000000006 0x7fffffffe3c8: 0x00000000f7ab9646 0x00007fffffffe410 0x7fffffffe3d8: 0x00000000004005cd 0x0000000000000077 0x7fffffffe3e8: 0x0000000000000088 0x0000000000000099 0x7fffffffe3f8: 0x0000000000000000 0x0000000000400600 0x7fffffffe408: 0x0000000000400440 0x00007fffffffe420 0x7fffffffe418: 0x00000000004005ef 0x0000000000000000   栈内存（栈向下生长）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  rbp 0x7fffffffe3e0 0x7fffffffe3e0 rsp 0x7fffffffe3e0 0x7fffffffe3e0 0x7fffffffe428 +------------------+ | | 0x7fffffffe420 +------------------+ |0x00000000004005ef| #保存返回main的地址 0x7fffffffe418 +------------------+ |0x00007fffffffe420| #保存main函数对应rbp 0x7fffffffe410 +------------------+ | | 0x7fffffffe408 +------------------+ | | 0x7fffffffe400 +------------------+ | | 0x7fffffffe3f8 +------------------+ | 0x99 | 0x7fffffffe3f0 +------------------+ | 0x88 | 0x7fffffffe3e8 +------------------+ | 0x77 | 0x7fffffffe3e0 +------------------+ |0x00000000004005cd| #保存返回caller的指令地址 0x7fffffffe3e0 +------------------+ |0x00007fffffffe410| #保存caller函数对应的rbp rsp --\u0026gt;0x7fffffffe3e0 +------------------+ | | 0x7fffffffe3d8 +------------------+ | | 0x7fffffffe3d0 +------------------+ | | 0x7fffffffe3e8 +------------------+ | | 0x7fffffffe3e0 +------------------+ | | 0x7fffffffe3c8 +------------------+ | | 0x7fffffffe3c0 +------------------+ |0x0000001100000022| 0x7fffffffe3b8 +------------------+ |0x0000005500000066| 0x7fffffffe3b0 +------------------+ |0x0000003300000044| 0x7fffffffe3a8 +------------------+ | | 0x7fffffffe3a0 +------------------+   sum函数对应汇编如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  (gdb) disassemble /m sum Dump of assembler code for function sum: 5 { 0x0000000000400530 \u0026lt;+0\u0026gt;: push %rbp 0x0000000000400531 \u0026lt;+1\u0026gt;: mov %rsp,%rbp 0x0000000000400534 \u0026lt;+4\u0026gt;: mov %edi,-0x14(%rbp) #获取函数参数，顺序为从左到右 0x0000000000400537 \u0026lt;+7\u0026gt;: mov %esi,-0x18(%rbp) 0x000000000040053a \u0026lt;+10\u0026gt;: mov %edx,-0x1c(%rbp) 0x000000000040053d \u0026lt;+13\u0026gt;: mov %ecx,-0x20(%rbp) 0x0000000000400540 \u0026lt;+16\u0026gt;: mov %r8d,-0x24(%rbp) 0x0000000000400544 \u0026lt;+20\u0026gt;: mov %r9d,-0x28(%rbp) 6 int s = 0x0; 0x0000000000400548 \u0026lt;+24\u0026gt;: movl $0x0,-0x4(%rbp) 7 s = a1+a2+a3+a4+a5+a6+a7+a8+a9; =\u0026gt; 0x000000000040054f \u0026lt;+31\u0026gt;: mov -0x18(%rbp),%eax 0x0000000000400552 \u0026lt;+34\u0026gt;: mov -0x14(%rbp),%edx 0x0000000000400555 \u0026lt;+37\u0026gt;: add %eax,%edx 0x0000000000400557 \u0026lt;+39\u0026gt;: mov -0x1c(%rbp),%eax 0x000000000040055a \u0026lt;+42\u0026gt;: add %eax,%edx 0x000000000040055c \u0026lt;+44\u0026gt;: mov -0x20(%rbp),%eax 0x000000000040055f \u0026lt;+47\u0026gt;: add %eax,%edx 0x0000000000400561 \u0026lt;+49\u0026gt;: mov -0x24(%rbp),%eax ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- 0x0000000000400564 \u0026lt;+52\u0026gt;: add %eax,%edx 0x0000000000400566 \u0026lt;+54\u0026gt;: mov -0x28(%rbp),%eax 0x0000000000400569 \u0026lt;+57\u0026gt;: add %eax,%edx 0x000000000040056b \u0026lt;+59\u0026gt;: mov 0x10(%rbp),%eax #取参数a7 = 0x77 0x000000000040056e \u0026lt;+62\u0026gt;: add %eax,%edx 0x0000000000400570 \u0026lt;+64\u0026gt;: mov 0x18(%rbp),%eax #取参数a8 = 0x88 0x0000000000400573 \u0026lt;+67\u0026gt;: add %eax,%edx 0x0000000000400575 \u0026lt;+69\u0026gt;: mov 0x20(%rbp),%eax #取参数a9 = 0x99 0x0000000000400578 \u0026lt;+72\u0026gt;: add %edx,%eax 0x000000000040057a \u0026lt;+74\u0026gt;: mov %eax,-0x4(%rbp) 8 9 return s; 0x000000000040057d \u0026lt;+77\u0026gt;: mov -0x4(%rbp),%eax #计算结果通过eax寄存器返回 10 } 0x0000000000400580 \u0026lt;+80\u0026gt;: pop %rbp 0x0000000000400581 \u0026lt;+81\u0026gt;: retq End of assembler dump. (gdb)   注意的是调用sum的时候并没有分配栈空间？主要原因是sum函数内没有调用其他函数，sum就只能被别的函数调用，sum的局部变量直接由rsp向下生长，调用结束后，直接恢复调用者的栈，这样的好处有两个：\n 少一个指令，提高执行效率 编译的时候并不需要计算需要开辟多少栈空间  为什么需要将值从寄存器取出？直接利用寄存器取值不可以吗？ 传递参数的寄存器在函数执行指令的时候有其他用处，调用函数需要将参数从寄存器取出到栈内存中（在一定的情况下即调用函数的指令不需要占用传递参数的寄存器，如果加大编译的优化级别，是否不会从参数寄存器取出参数到函数的栈内存中而是直接使用寄存器？）另外可以从这里看出，从代码层面优化性能可以考虑减少函数调用以及优化一些不必要的参数传递，尽管只能尽一丝绵薄之力。\n3.5 sum返回值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  (gdb) n caller () at stackexample.c:17 17 printf(\u0026#34;sum: %X\\r\\n\u0026#34;, iRet); (gdb) info registers rax 0x2fd 765 #返回值 rbx 0x0 0 rcx 0x44 68 rdx 0x264 612 rsi 0x22 34 rdi 0x11 17 rbp 0x7fffffffe410 0x7fffffffe410 rsp 0x7fffffffe3e0 0x7fffffffe3e0 r8 0x55 85 r9 0x66 102 r10 0x7fffffffe270 140737488347760 r11 0x7ffff7a3ba00 140737348090368 r12 0x400440 4195392 r13 0x7fffffffe500 140737488348416 r14 0x0 0 r15 0x0 0 rip 0x4005d0 0x4005d0 \u0026lt;caller+78\u0026gt; eflags 0x202 [ IF ] cs 0x33 51 ss 0x2b 43 ds 0x0 0 es 0x0 0 fs 0x0 0 ---Type \u0026lt;return\u0026gt; to continue, or q \u0026lt;return\u0026gt; to quit--- gs 0x0 0 (gdb) (gdb) x /16gx 0x7fffffffe3c0 0x7fffffffe3c0: 0x0000000000000006 0x000002fdf7ab9646 #返回值0x2fd 0x7fffffffe3d0: 0x00007fffffffe410 0x00000000004005cd 0x7fffffffe3e0: 0x0000000000000077 0x0000000000000088 0x7fffffffe3f0: 0x0000000000000099 0x0000000000000000 0x7fffffffe400: 0x0000000000400600 0x000002fd00400440 0x7fffffffe410: 0x00007fffffffe420 0x00000000004005ef 0x7fffffffe420: 0x0000000000000000 0x00007ffff7a3baf5 0x7fffffffe430: 0x0000002000000000 0x00007fffffffe508 (gdb)   x86-64寄存器说明  rsp：对应32位esp寄存器，保存当前堆栈栈顶指针的寄存器 rbp：对应32位ebp寄存器，保存了当前堆栈基地址指针的寄存器 rax: 临时寄存器，当我们调用系统调用的时候，rax保外系统调用号 rdx：传递第3个参数到函数 rdi：传递第1个参数到函数 rsi：传递第2个参数到函数 rip: 下一个执行指令地址  参考  Calling_convention GDB and Reverse Debugging Assembly x86_64 programming for Linux  ", 
        "url": "http:\/\/myself659.github.io\/post\/2016-03-09-x86-64-call-stack\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2016-03-05-do-more-than-coding\/": {
        
        "title": "代码是核心，但不仅仅是代码",
        "tags": ["闲谈乱扯",],
        "content": "其实以前也有类似的想法，但是决定写这篇文章是由下面一件事情引起的。\n引子 同事自已造轮子要实现一个rtmp协议，在调试过程由于有一个问题有没有解决，影响团队的联调，对于他造主动造轮子，我是不支持的。重复实现一个完整的rtmp协议，会走很多坑的，需要花费较多的时间，而开源的librtmp已经实现完整的rtmp协议功能，我决定将librtmp协议移植到现在系统。\n接着就自己开始干，了解librtmp实现，动手写一个利用librtmp支持epoll的rtmpserver。 在调试过程出现rtmp握手失败的问题，初看定位无果的情况下，我修改了makefile，生成调试的符号表，同时打开调试开关。这些弄好之后，试了一下，没有我期待的符号表与调试信息。\n于是我怀疑自己对makefile是否正确。重新学习makefile与编译的一些知识还是无果，觉得makefile修改是正确的。这时候灵光一现，看看进程加载的是哪些lib\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  (gdb) info sharedlibrary From To Syms Read Shared Object Library 0x0000003a74600b00 0x0000003a746198db Yes (*) /lib64/ld-linux-x86-64.so.2 0x00007ffff7dd57e0 0x00007ffff7de4358 Yes (*) /usr/local/lib/librtmp.so.1 #加载的librtmp库 0x0000003c39a18340 0x0000003c39a53558 Yes (*) /usr/lib64/libssl.so.10 0x0000003c39669cc0 0x0000003c3975dbe8 Yes (*) /usr/lib64/libcrypto.so.10 0x0000003a76602120 0x0000003a7660d3a8 Yes (*) /lib64/libz.so.1 0x0000003a74a1ea20 0x0000003a74b3f76c Yes (*) /lib64/libc.so.6 0x0000003a8260ac30 0x0000003a82638728 Yes (*) /lib64/libgssapi_krb5.so.2 0x0000003a8161b430 0x0000003a81694a78 Yes (*) /lib64/libkrb5.so.3 0x0000003a806013f0 0x0000003a80601fc8 Yes (*) /lib64/libcom_err.so.2 0x0000003a812043d0 0x0000003a8121d5a8 Yes (*) /lib64/libk5crypto.so.3 0x0000003a74e00de0 0x0000003a74e01998 Yes (*) /lib64/libdl.so.2 0x0000003a80a02a40 0x0000003a80a080c8 Yes (*) /lib64/libkrb5support.so.0 0x0000003a80e00bf0 0x0000003a80e011d8 Yes (*) /lib64/libkeyutils.so.1 0x0000003a76a03930 0x0000003a76a12938 Yes (*) /lib64/libresolv.so.2 0x0000003a75205660 0x0000003a75210eb8 Yes (*) /lib64/libpthread.so.0 0x0000003a76205850 0x0000003a76215cc8 Yes (*) /lib64/libselinux.so.1 (*): Shared library is missing debugging information. (gdb)   看到上面的一幕，犯了这样的错误：改对了代码，却没有更新lib\n反思 在现实的开发过程中常常碰到下面的情行：\n场景1： “我修改了代码，代码也改好，怎么还是这样的？”\n场景2： “在我的环境下，测试ok，怎么在你的环境就不行了呢？”\n场景3： “前几天运行都ok的，怎么现在不对了？”\n场景4： “以前上线都没事，这次同样的操作却没有成功”\n场景5： \u0026ldquo;原来从业务角度出发，可以设计，确实不要那么麻烦\u0026rdquo;\n以上这些问题，很大一部分因素我们只考虑到代码本身而已，还没有考虑代码的深层次问题，也没有考虑代码与业务的关联，在实际系统中很多问题一部分原因也是因为深层上没有了解代码的本质或者没有吃透业务对代码的要求。\n代码是核心，但不仅仅是代码，还有下面几个方面需要考虑：\n 代码的本质 测试验证 系统设计 业务需求 部署需求 监控需求 升级问题 团队合作 安全问题  对此，个人大胆划分四个层次：\n  码农，以码为主，停留在代码上，关注代码与算法（如果有足够的天赋研究像人工智能这样的顶级算法，请继续深入研究）\n  工程师，以解决具体业务为主，代码作为业务的实现，关注的业务与需求，能够实现技术持续性满足小范围内的业务需求\n  架构师，考虑上述各个方面，从需求，设计，实现，部署，演进等各个阶段满足具体一个产品的技术需求，除此之外，主动思考技术对业务的发展的支撑\n  技术总监，CXO，创始人，这一层次就不YY了\n  后记 需要强调的一点：作为程序员写好代码是第一要务，本文强调写好代码的基础上，要从深度与广度角度思考代码与审视代码，这样让自己不停留在代码层面，让自己不仅能技术上取得进步，更能让技术上的进步转化为业务上的价值\n自己接下来的重点，除了继续提高自已技术能力，另一个重点加强对业务的学习与研究，用技术更快，更好地满足业务需求\n(PS：起了标题，希望后面能够有更深的感悟，写得更具体一些)\n", 
        "url": "http:\/\/myself659.github.io\/post\/2016-03-05-do-more-than-coding\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s\/2016-01-28-docker-cmd-pratice\/": {
        
        "title": "docker image命令实践",
        "tags": ["Linux",],
        "content": "搭建了docker环境，就来体验一下Docker，常用docker image命令如下：\n1. 搜索docker image 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  root@localhost ~]# docker search ubuntu NAME DESCRIPTION STARS OFFICIAL AUTOMATED ubuntu Ubuntu is a Debian-based Linux operating s... 2954 [OK] ubuntu-upstart Upstart is an event-based replacement for ... 58 [OK] dorowu/ubuntu-desktop-lxde-vnc Ubuntu with openssh-server and NoVNC on po... 32 [OK] torusware/speedus-ubuntu Always updated official Ubuntu docker imag... 25 [OK] ubuntu-debootstrap debootstrap --variant=minbase --components... 22 [OK] tleyden5iwx/ubuntu-cuda Ubuntu 14.04 with CUDA drivers pre-installed 18 [OK] rastasheep/ubuntu-sshd Dockerized SSH service, built on top of of... 16 [OK] consol/ubuntu-xfce-vnc Ubuntu container with \u0026#34;headless\u0026#34; VNC sessi... 8 [OK] ioft/armhf-ubuntu [ABR] Ubuntu Docker images for the ARMv7(a... 7 [OK] n3ziniuka5/ubuntu-oracle-jdk Ubuntu with Oracle JDK. Check tags for ver... 7 [OK] nuagebec/ubuntu Simple always updated Ubuntu docker images... 4 [OK] nickistre/ubuntu-lamp-wordpress LAMP on Ubuntu with wp-cli installed 3 [OK] nimmis/ubuntu This is a docker images different LTS vers... 3 [OK] maxexcloo/ubuntu Docker base image built on Ubuntu with Sup... 2 [OK] sylvainlasnier/ubuntu Ubuntu 15.10 root docker images with commo... 1 [OK] isuper/base-ubuntu This is just a small and clean base Ubuntu... 1 [OK] densuke/ubuntu-jp-remix Ubuntu Linuxの日本語remix風味です 1 [OK] seetheprogress/ubuntu Ubuntu image provided by seetheprogress us... 1 [OK] nickistre/ubuntu-lamp LAMP server on Ubuntu 1 [OK] teamrock/ubuntu TeamRock\u0026#39;s Ubuntu image configured with AW... 0 [OK] konstruktoid/ubuntu Ubuntu base image 0 [OK] birkof/ubuntu Ubuntu 14.04 LTS (Trusty Tahr) 0 [OK] zoni/ubuntu 0 [OK] esycat/ubuntu Ubuntu LTS 0 [OK] rallias/ubuntu Ubuntu with the needful 0   2. 下载image 1  docker pull   3. 查看image 1 2 3 4 5 6  [root@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu latest d55e68e6cc9c 4 weeks ago 187.9 MB ubuntu 14.04 d55e68e6cc9c 4 weeks ago 187.9 MB training/sinatra latest f0f4ab557f95 19 months ago 447 MB   4. 删除image 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  [root@localhost ~]# docker rm training/sinatra Error response from daemon: no such id: training/sinatra Error: failed to remove containers: [training/sinatra] [root@localhost ~]# docker rm f0f4ab557f95 Error response from daemon: no such id: f0f4ab557f95 Error: failed to remove containers: [f0f4ab557f95] [root@localhost ~]# docker rmi f0f4ab557f95 Untagged: training/sinatra:latest Deleted: f0f4ab557f954f3e04177663a3af90e88641bcdcce1f02ac900dbd9768ef4945 Deleted: 79e6bf39f99322cc062a79bec4a09de0dd19cb7f5f735b4b6b7832c04b13bb45 Deleted: ce80548340bb03726d391bb8fa4d134f8418c2fff90be9a7323560debdea9bd2 Deleted: e809f156dc985e07105fdc86ec05eb03eb7aac8636dc210e8595d31b55787f4a Deleted: bfab314f3b766eddf9778f8dce089f44e84ea028f4a44ce68740dce81a844ec8 Deleted: be88c4c27e80023b6aea82f0f2e15fb21c6f4193fe814e5b58010d356dd7846b Deleted: 3e76c0a80540a0d36493ae7110796fc92f559a191454e3ac19c1d4c650bdd9e0 Deleted: 511136ea3c5a64f264b78b5433614aec563103b4d4702f3ba7d4d2698e22c158 You have new mail in /var/spool/mail/root [root@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu latest af88597ec24b 6 days ago 187.9 MB ubuntu 14.04 d55e68e6cc9c 4 weeks ago 187.9 MB   5. 运行image 1  [root@localhost ~]# docker run -i -t apache2   6. kill运行的docker image 1 2 3 4 5 6 7 8 9 10  [root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 68333b272b52 ubuntu \u0026#34;/bin/bash\u0026#34; 18 minutes ago Up 18 minutes clever_babbage 0ca2aff5b94b ubuntu \u0026#34;bash\u0026#34; 48 minutes ago Up 48 minutes focused_hypatia You have new mail in /var/spool/mail/root [root@localhost ~]# docker kill 68333b272b52 68333b272b52 [root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0ca2aff5b94b ubuntu \u0026#34;bash\u0026#34; 54 minutes ago Up 54 minutes focused_hypatia   7. 制作image 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  [root@localhost tmp]# more Dockerfile FROM apache2 RUN apt-get install -y wget [root@localhost tmp]# docker build -t wget . Sending build context to Docker daemon 2.609 MB Sending build context to Docker daemon Step 0 : FROM apache2 ---\u0026gt; f5cf247f22af Step 1 : RUN apt-get install -y wget ---\u0026gt; Running in ab3cd326c53c [root@localhost tmp]# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE wget latest be8bf51f39d5 29 seconds ago 229.1 MB apache2 latest f5cf247f22af 5 hours ago 223.8 MB ubuntu latest af88597ec24b 6 days ago 187.9 MB ubuntu 14.04 d55e68e6cc9c 4 weeks ago 187.9 MB   8. docker volume clean 1  docker system prune --all --volumes --force   ", 
        "url": "http:\/\/myself659.github.io\/post\/k8s\/2016-01-28-docker-cmd-pratice\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s\/2015-12-13-docker-way-1-build-docker-env\/": {
        
        "title": "升级Linux内核，搭建docker环境",
        "tags": ["Linux",],
        "content": "docker可以说是去年最热的技术，也是业界大谈特谈的技术，到了今年有很多公司已经将docker应用于自己的生产环境。Docker已经从一个工具转化成平台，小生态圈。作为一名程序员应该与时俱进，学习新技术，不断地提高自己。\n升级内核 docker要求linux内核版本3.12以上，作为常用linux2.26.32版本，虽然也可以安装docker，但是有一些特性不支持，所以第一步就是升级内核。个人选择最新的长期维护版本升级linux4.13,内核升级最关键的一件事情就是配置内核，关于内核支持docker的内核配置文件，如果不想自己动手配置内核，可以参考Linux-4.13-configfordocker;\n在未正确配置linux内核会出现以下一些错误：\n docker启动过程中iptables命令执行失败，原因是 iptables模块没有配置  1 2 3 4 5 6 7 8  [root@localhost ~]# docker -d INFO[0000] Listening for HTTP on unix (/var/run/docker.sock) INFO[0000] [graphdriver] using prior storage driver \u0026#34;devicemapper\u0026#34; FATA[0000] Error starting daemon: Error initializing network controller: Error creating default \u0026#34;bridge\u0026#34; network: Failed to Setup IP tables: Unable to enable NAT rule: iptables failed: iptables -t nat -I POSTROUTING -s 172.17.42.1/16 ! -o docker0 -j MASQUERADE: iptables v1.4.7: can\u0026#39;t initialize iptables table `nat\u0026#39;: Table does not exist (do you need to insmod?) Perhaps iptables or your kernel needs to be upgraded. (exit status 3) You have new mail in /var/spool/mail/root [root@localhost ~]#   cgroup创建失败，具体参考stackoverflow  1 2 3 4  [root@localhost ~]# service docker start Starting cgconfig service: Error: cannot mount memory to /cgroup/memory: No such file or directory /sbin/cgconfigparser; error loading /etc/cgconfig.conf: Cgroup mounting failed Failed to parse /etc/cgconfig.conf or /etc/cgconfig.d[FAILED]   具体内核升级过程参考如下：\n1 2 3 4 5 6 7  [root@localhost linux-4.1.13]# cp /share/github/docker-way/env/linux-4.1.3-configfordocker .config [root@localhost linux-4.1.13]# sh -c \u0026#39;yes \u0026#34;\u0026#34; | make oldconfig\u0026#39; [root@localhost linux-4.1.13]# make -j2 bzImage [root@localhost linux-4.1.13]# make -j2 modules [root@localhost linux-4.1.13]# make -j2 modules_install [root@localhost linux-4.1.13]# make install   检查grub配置，修改并将linux-4.13作为默认启动项，重启系统，系统启动成功后，查看内核版本：\n1 2  [root@localhost ~]# uname -a Linux localhost.localdomain 4.1.13 #1 SMP Sat Dec 5 11:17:50 CST 2015 x86_64 x86_64 x86_64 GNU/Linux   安装device-mapper 1 2  [root@localhost ~]#yum install -y device-mapper   安装docker 1  [root@localhost ~]# yum -y install docker-io   安装完成后，检查docker是否能够正确启动\n1 2 3 4 5 6 7 8 9  [root@localhost ~]# docker -d INFO[0000] [graphdriver] using prior storage driver \u0026#34;devicemapper\u0026#34; INFO[0000] Listening for HTTP on unix (/var/run/docker.sock) WARN[0000] Your kernel does not support swap memory limit. INFO[0000] Loading containers: start. INFO[0000] Loading containers: done. INFO[0000] Daemon has completed initialization INFO[0000] Docker daemon commit=786b29d execdriver=native-0.2 graphdriver=devicemapper version=1.7.1   没有错误，接下来可以开启一段docker学习之旅了!\n(更新)\nUninstall old versions 1  sudo apt-get remove docker docker-engine docker.io containerd runc   install How To Install and Use Docker on Ubuntu 18.04\n", 
        "url": "http:\/\/myself659.github.io\/post\/k8s\/2015-12-13-docker-way-1-build-docker-env\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2015-08-28-gdb-command-example\/": {
        
        "title": "gdb自定义断点操作",
        "tags": ["Linux",],
        "content": "gdb是c/c++上调试利器，有很多技巧能让调试程序与解决问题更加方便与高效，下面关于command 命令的使用一个实例，具体如下：\n1. 设置断点 1 2 3  (gdb) b GenVedioSeekPoint Breakpoint 1 at 0x402e58: file GenIndex.cpp, line 140. (gdb)   2. 利用commad自定义断点操作 1 2 3 4 5 6 7  (gdb) command 1 Type commands for breakpoint(s) 1, one per line. End with a line saying just \u0026#34;end\u0026#34;. \u0026gt;p *pstPktHead \u0026gt;continue \u0026gt;end (gdb)   3. 设置gdb log信息输出到指定文件 1 2 3 4 5  (gdb) set logging file genindex.txt (gdb) set logging on Copying output to genindex.txt. (gdb) set pagination off (gdb)   4. 开始或继续执行程序 1  (gdb) run   有输出信息如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  ... Breakpoint 1, GenVedioSeekPoint (pstPktHead=0x7fffffdfdcff, offset=71678) at GenIndex.cpp:140 140 uiTimeStamp = pstPktHead-\u0026gt;stBlockHead.iTimeStamp; $253 = {cFlag = 170 \u0026#39;\\252\u0026#39;, uiPktLen = 236, uiPktSeq = 3418810467, sCheckNum = 1, cBlockCount = 27 \u0026#39;\\033\u0026#39;, stBlockHead = {cBlogTag = 90 \u0026#39;Z\u0026#39;, iTimeStamp = 14811476, iDatalen = 0}} Breakpoint 1, GenVedioSeekPoint (pstPktHead=0x7fffffdfddeb, offset=71914) at GenIndex.cpp:140 140 uiTimeStamp = pstPktHead-\u0026gt;stBlockHead.iTimeStamp; $254 = {cFlag = 170 \u0026#39;\\252\u0026#39;, uiPktLen = 155, uiPktSeq = 3962300516, sCheckNum = 1, cBlockCount = 59 \u0026#39;;\u0026#39;, stBlockHead = {cBlogTag = 90 \u0026#39;Z\u0026#39;, iTimeStamp = 9503060, iDatalen = 0}} Breakpoint 1, GenVedioSeekPoint (pstPktHead=0x7fffffdfde86, offset=72069) at GenIndex.cpp:140 140 uiTimeStamp = pstPktHead-\u0026gt;stBlockHead.iTimeStamp; $255 = {cFlag = 170 \u0026#39;\\252\u0026#39;, uiPktLen = 1959, uiPktSeq = 3774212197, sCheckNum = 257, cBlockCount = 125 \u0026#39;}\u0026#39;, stBlockHead = {cBlogTag = 90 \u0026#39;Z\u0026#39;, iTimeStamp = 127730004, iDatalen = 0}} ...   同时在gdb的运行程序的目录下生成genindex.txt文件，这样可以通过分析genindex.txt找问题的原因；同时整个执行的过程中不需要个人操作，在断点不断命中的情况下极大提高效率，如果是生产的环境，避免长时间占用进程，进而影响业务，\n5. 分析log文件 这一步你可以用shell，awk， sed，python等来分析genindex.txt文件内容\n", 
        "url": "http:\/\/myself659.github.io\/post\/2015-08-28-gdb-command-example\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2015-08-08-nginx-pratice-1-add-hello-module\/": {
        
        "title": "nginx实践-添加自定义模块hello",
        "tags": ["nginx",],
        "content": "nginx是一个值得学习与研究的开源代码，写这篇文章主要目的是让自己能够能够从最简单的任务开始，通过写作促进自己一步一步地深入学习与分析nginx。本文是这个系列的第一篇，主要是记录自己实现一个自定义的模块hello的过程。\n1. 下载源码 下载nginx 1.8.0 源代码\n1 2  root@localhost github]# wget http://nginx.org/download/nginx-1.8.0.tar.gz root@localhost github]# tar zxf   2. 准备文件与代码 在nginx解压目录下，添加如下文件：\n1 2 3 4 5 6 7 8 9 10  [root@localhost nginx-1.8.0]# tree | more . |-- **addon** | `-- **hello** | |-- **config** | `-- **ngx_http_hello_module.c** |-- auto | |-- cc | | |-- acc | | |-- bcc   新增文件分析参考nginx-hello\n1 2 3 4 5 6 7 8  [root@localhost nginx-1.8.0]# grep -r ngx_addon_name /share/github/nginx-1.8.0 /share/github/nginx-1.8.0/auto/modules: echo \u0026#34; + $ngx_addon_name was configured\u0026#34; /share/github/nginx-1.8.0/addon/hello/config:ngx_addon_name=ngx_http_hello_module [root@localhost nginx-1.8.0]# [root@localhost nginx-1.8.0]# grep -r add-module /share/github/nginx-1.8.0 /share/github/nginx-1.8.0/auto/options: --add-module=*) NGX_ADDONS=\u0026#34;$NGX_ADDONS $value\u0026#34; ;; /share/github/nginx-1.8.0/auto/options: --add-module=PATH enable an external module   3. 编译与安装 编译三步走\n1 2 3 4 5  1. ./configure --add-module=/share/github/nginx-1.8.0/addon/hello 2. make 3. make install   4.测试 在/usr/local/nginx/conf/nginx.conf文件的http配置项下，添加如下内容：\n1 2 3  location =/hello{ hello; }   过程如下：\n1 2 3 4 5 6 7  [root@localhost ~]# nginx -t nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful [root@localhost ~]# service nginx restart Restarting nginx (via systemctl): [ OK ] [root@localhost nginx-1.8.0]# curl http://localhost/hello/ hello nginx!   另外也可以通过浏览器访问：http://serverip/hello\n如果出现不能打开，检查一下iptable 设置，在/etc/sysconfig/iptables增加下面一条配置，允许80端口通过：\n1  -A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT   然后输入命令service iptables restart重启iptables服务，使新增配置生效\n5. 实例代码 本文代码请参考：nginx-hello\n本人水平有限，若有疏漏与错误，欢迎交流与指正。\n", 
        "url": "http:\/\/myself659.github.io\/post\/2015-08-08-nginx-pratice-1-add-hello-module\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2015-07-28-linux-netstat\/": {
        
        "title": "Linux netstat 应用示例",
        "tags": ["Linux",],
        "content": "关于netstat netstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态 (Interface Statistics)，masquerade 连接，多播成员 (Multicast Memberships) 等等。\n常用参数 -a (all)显示所有选项，默认不显示LISTEN相关\n-t (tcp)仅显示tcp相关选项\n-u (udp)仅显示udp相关选项\n-n 拒绝显示别名，能显示数字的全部转化成数字\n-l 仅列出有在 Listen (监听) 的服務状态\n-p 显示建立相关链接的程序名\n-r 显示路由信息，路由表\n-e 显示扩展信息，例如uid等\n-s 按各个协议进行统计\n-c 每隔一个固定时间，执行该netstat命令\n注意：LISTEN和LISTENING的状态只有用-a或者-l才能看到\n应用实例 1. 选项组合应用 命令：\n1  netstat -tlnp   说明：显示处于listen状态的tcp连接，并显示对应进程pid\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  [root@localhost default]# netstat -tlnp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:21 0.0.0.0:* LISTEN 1284/pure-ftpd tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1022/sshd tcp 0 0 0.0.0.0:445 0.0.0.0:* LISTEN 1309/smbd tcp 0 0 0.0.0.0:139 0.0.0.0:* LISTEN 1309/smbd tcp 0 0 0.0.0.0:6379 0.0.0.0:* LISTEN 1298/redis-server tcp 0 0 0.0.0.0:11211 0.0.0.0:* LISTEN 1002/memcached tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 31604/nginx tcp 0 0 :::21 :::* LISTEN 1284/pure-ftpd tcp 0 0 :::22 :::* LISTEN 1022/sshd   2. 显示网关地址 命令：\n1  netstat -rn | grep UG | tr -s \u0026#34; \u0026#34; | cut -d \u0026#34; \u0026#34; -f2   说明：先显示路由信息，找出网关所对应表项，删除多余的空格并显示第二个表项field\n示例：\n1 2 3  [root@localhost default]# netstat -rn | grep UG | tr -s \u0026#34; \u0026#34; | cut -d \u0026#34; \u0026#34; -f2 192.168.20.1   3.统计tcp各种连接状态的个数 命令：\n1  netstat -n | awk \u0026#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}   说明：显示连接信息，通过awk统计各tcp状态连接个数\n示例：\n1 2 3 4  [root@localhost default]#netstat -n | awk \u0026#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]} ESTABLISHED 516 TIME_WAIT 14   4.显示所有tcp监听端口 命令：\n1  netstat -lnt | awk \u0026#39;{print $4}\u0026#39; | cut -f2 -d: | grep -o \u0026#39;[0-9]*\u0026#39;   说明：\n示例：显示处于listen状态的tcp连接，打印每行第4个域元素，并以:作为该域的内部分隔符，同时显示其中第二个域元素，对结果进行过滤，只显示数字部分\n1 2 3 4 5 6 7 8 9  [root@localhost default]# netstat -lnt | awk \u0026#39;{print $4}\u0026#39; | cut -f2 -d: | grep -o \u0026#39;[0-9]*\u0026#39; 21 22 445 139 6379 11211 80   5.统计每个IP连接数 命令：\n1  netstat -anp |grep \u0026#39;tcp\\|udp\u0026#39; | awk \u0026#39;{print $5}\u0026#39; | sed s/::ffff:// | cut -d: -f1 | sort | uniq -c | sort -n   说明：显示所有网络连接并从中过滤出tcp与udp连接，打印这些连接表项的第5个域元素，删除包含/::ffff:的表项，以：为分隔符显示剩下的内容的第一个域元素，再进行排序并统计个数，最后以数值排列显示结果\n示例：\n1 2 3 4 5  [root@localhost default]# netstat -anp |grep \u0026#39;tcp\\|udp\u0026#39; | awk \u0026#39;{print $5}\u0026#39; | sed s/::ffff:// | cut -d: -f1 | sort | uniq -c | sort -n 3 192.168.70.36 8 0.0.0.0   6.查看80端口的连接，并排序 命令：\n1  netstat -ant | grep “:80″ | grep ESTABLISHED | awk ‘{printf “%s %s\\n”,$5,$6}’ | sort   说明： 不解释了，你懂的\n示例：\n未完，待续\n", 
        "url": "http:\/\/myself659.github.io\/post\/2015-07-28-linux-netstat\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2015-07-03-thought-about-zero-to-one\/": {
        
        "title": "读书笔记：《从0到1---开启商业与未来的秘密》",
        "tags": ["闲谈乱扯",],
        "content": "启发思考  在什么重要问题上你与其他有不同的看法？   除了书中讲到参考模式:太多数人相信X，但是事实却是X的对立面；世界是多样的，我们应当追求正确的差异化\n  企业失败的共同的原因   企业失败的原因却是相同：它们都无法逃脱竞争\n  应对趋势潮流   最反主流的行动不是抵制潮流，而是在潮流中不丢弃自己的独立思考\n 从0到1vs从1到N   从0到1是创新，创造；从1到N是创新成果应用及商业化\n ###关于团队\n 现金奖励不是王道，股票报酬才能让员工全力以赴 那些决定命运的基础元素：合伙人，早期团队成员 所有权，经营权，控制权 招聘要求：有才华+真正喜欢与团队合作及一起成长的意愿 特立独行的创始人  ###关于销售 这一部分内容作者回答一系列问题：\n 销售是什么？   产品离不开销售，销售是产品设计的一部分；销售是隐形的，销售人员第一要务是说服而不是真诚\n 谁是销售对象？   品牌无界限，销售对象除了产品与服务的潜在用户，还要社会，媒体销售公司，建立品牌\n 谁是销售员？   不论是员工，创始人，还是投资者，都应该是销售，无人不销售，无时不销售\n 怎么进行销售？   常用销售方法：复杂销售，人员销售，市场营销和广告，病毒式营销，粉丝营销；\n  销售的法则？   选择一个最有效的销售方法或者销售渠道\n 绿色能源与特斯拉 绿色能源与特斯拉是《从0到1》这本书倒数是第二章，这一章是对前面章节讲到竞争，团队，未来，销售等观点在具体行业与具体公司的具体应用的一个展示，有意创业，投资或者像我有时仅好分析一个企业的人，可以细细口味。\n这一章节提到的七个必须回答的问题，可以作为分析一家企业的checklist问题，具体如下：\n 工程问题：   你的技术具有突破性，而不是仅仅是稍有改进吗？\n 时机问题：   现在开创事业，时机合适吗？\n 垄断问题：   开创之初，是在一个小市场抢占大份额吗？\n 人员问题：   你有合适的团队吗？\n 销售问题：   除了创造产品，你有没有办法销售产品？\n 持久问题:   未来10年或者20年，你能保住自己的市场地位吗？\n 秘密问题：   你有没有找到一个其他人没有发现的独特机会？\n 总之，Peter_Thiel作为一个成功的创业家和投资家，《从0到1 开启商业与未来的秘密》为我们讲了很多干货，作者分享了很多真知灼见，值得阅读与学习。\n相关参考  Peter_Thiel palantir  ", 
        "url": "http:\/\/myself659.github.io\/post\/2015-07-03-thought-about-zero-to-one\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2015-06-14-number-divide\/": {
        
        "title": "实现无符号整型数的分解",
        "tags": ["编程",],
        "content": "题目 将一个无符号数N拆分为不多于M个数，使拆分的数之和等于N,条件：\n N \u0026gt;= M； N与M都是无符号整型数  求：一共有多少中拆分方法？\n分析 参考代码\n代码 代码实现计算拆分方法及打印拆分组合信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149  #include \u0026lt;iostream\u0026gt; #include \u0026lt;stdint.h\u0026gt; using namespace std; class CSolution { private: uint32_t uiM; uint32_t uiN; uint32_t uiCount; uint32_t *puiRecord; public: CSolution(); CSolution(uint32_t uiM, uint32_t uiN); ~CSolution(); uint32_t GetCount() {return uiCount;} void PrintCombinations(); uint32_t CountNum(uint32_t uiM, uint32_t uiN);\tvoid GetCombination(uint32_t uiMin, uint32_t uiLeft, uint32_t uiGetNum, uint32_t uiTargetNum, uint32_t *puiRecord); }; CSolution::CSolution(uint32_t uiM,uint32_t uiN){ this-\u0026gt;uiM = uiM; this-\u0026gt;uiN = uiN; this-\u0026gt;puiRecord = new unsigned int [uiM]; this-\u0026gt;uiCount = CountNum(uiM, uiN); return ; } CSolution::CSolution() { uiM = 1; uiN = 1; puiRecord = new unsigned int [uiM]; uiCount = CountNum(uiM, uiN); return ; } CSolution::~CSolution() { delete [] puiRecord; return ; } uint32_t CSolution::CountNum(uint32_t uiM, uint32_t uiN) { if((0 == uiM) || (0 == uiN) || ( 1 == uiM) || ( 1 == uiN)) { return 1; } if(uiN \u0026lt; uiM) { return CountNum(uiN,uiN); } return CountNum(uiM - 1, uiN) + CountNum(uiM, uiN - uiM); }\t/* UINT uiMin 最小值 UINT uiLeft 剩下值 UINT uiGetNum 已拆分元素个数 UINT uiTargetNum\t需要拆分的个数 UINT *puiCombination 拆分组合首地址 */ void CSolution::GetCombination(uint32_t uiMin, uint32_t uiLeft, uint32_t uiGetNum, uint32_t uiTargetNum, uint32_t *puiRecord) { uint32_t i; uint32_t j; /*递归结束条件 */ if(1 == uiTargetNum) { cout \u0026lt;\u0026lt; uiLeft\u0026lt;\u0026lt;endl; return ; } /* 将剩下值拆分为多个数,除了最后一个拆分值，其他的拆分数都应小于等于uiLeft/2 */ for(i = uiMin; i \u0026lt;= uiLeft / 2; i++) { puiRecord[uiGetNum] = i; uiGetNum++; if(uiGetNum + 1 == uiTargetNum) { puiRecord[uiGetNum] = uiLeft - i; for(j = 0; j \u0026lt; uiTargetNum; j++) { cout \u0026lt;\u0026lt;puiRecord[j]\u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } else { GetCombination(i, uiLeft - i, uiGetNum, uiTargetNum, puiRecord); } uiGetNum--; } return ;\t} void CSolution::PrintCombinations() { uint32_t i; cout\u0026lt;\u0026lt;\u0026#34;print combinations as follow:\u0026#34;\u0026lt;\u0026lt;endl; for(i = 1; i \u0026lt;= uiM; i++) { GetCombination(1, uiN, 0, i, puiRecord);\t} cout\u0026lt;\u0026lt;\u0026#34;The Total num is \u0026#34;\u0026lt;\u0026lt; GetCount()\u0026lt;\u0026lt;endl; return ; } int main(void) { CSolution test(7, 11); test.PrintCombinations(); return 0; }   运行结果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  [root@localhost cpp]# ./numdecom print combinations as follow: 11 1 10 2 9 3 8 4 7 5 6 1 1 9 1 2 8 1 3 7 1 4 6 1 5 5 2 2 7 2 3 6 2 4 5 3 3 5 3 4 4 1 1 1 8 1 1 2 7 1 1 3 6 1 1 4 5 1 2 2 6 1 2 3 5 1 2 4 4 1 3 3 4 2 2 2 5 2 2 3 4 2 3 3 3 1 1 1 1 7 1 1 1 2 6 1 1 1 3 5 1 1 1 4 4 1 1 2 2 5 1 1 2 3 4 1 1 3 3 3 1 2 2 2 4 1 2 2 3 3 2 2 2 2 3 1 1 1 1 1 6 1 1 1 1 2 5 1 1 1 1 3 4 1 1 1 2 2 4 1 1 1 2 3 3 1 1 2 2 2 3 1 2 2 2 2 2 1 1 1 1 1 1 5 1 1 1 1 1 2 4 1 1 1 1 1 3 3 1 1 1 1 2 2 3 1 1 1 2 2 2 2 The Total num is 49   ", 
        "url": "http:\/\/myself659.github.io\/post\/2015-06-14-number-divide\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/2015-05-27-ping-error\/": {
        
        "title": "ping不通常见原因总结",
        "tags": ["Network",],
        "content": "ping不通从ping的流程分为两大类：\n 请求报文没有到达对端 应答报文未收到  请求报文没有到达对端的可能原因：\n 发送端发送流程出错 源端,转发设备没有目的地址的路由 ttl 小于转发跳数 分片丢包 MTU限制 转发丢包 报文错误 防火墙规则不允许该类型报文通过 中间进行nat转换等处理出错 目的地址不存在 接收端收包流程出错  应答报文未收到的可能原因：\n 发送端发送流程出错 MTU限制 目的端禁止应答 接收报文错误 防火墙规则不允许该类型报文通过 接收到了报文，但是超出等待时间 接收报文错误，ping 应答检查失败 转发丢包  ", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/2015-05-27-ping-error\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/2015-06-01-linux-may-sleep-function\/": {
        
        "title": "那些可进入睡眠状态的Linux内核函数",
        "tags": ["Linux",],
        "content": "在linux内核开发中断处理函数不能调用可能导致睡眠的函数，下面总结linux内核可能引起睡眠的函数如下：\nschedule函数    schedule_timeout schedule_timeout_uninterruptible schedule_timeout_interruptible cond_resched might_resched    sleep函数    msleep msleep_interruputible ssleep osal_usleep might_sleep    取信号量函数    down down_timeout down_read down_write down_interruptible wait_for_completion wait_for_completion_interruptible wait_for_completion_timeout wait_for_completion_interruptible_timeout    kmalloc相关函数含有标志GFP_KERNEL    kmalloc kzalloc krealloc kmem_cache_create kmem_cache_alloc kmem_cache_zalloc    取睡眠锁函数    mutex_lock mutex_lock_timeout mutex_lock_nested mutex_lock_interruptible mutex_lock_interruptible_nested    在中断处理函数不能使用睡眠函数原因 主要原因如下：\n 中断是一种紧急事务，中断处理函数要求快 linux是以进程为调度单位的，调度器只看到进程内核栈，而看不到中断栈，在独立中断栈的模式下，如果linux内核在中断处理函数内发生了调度或者睡眠，导致无法找到回家的路，未执行的中断处理代码再也无法获得执行机会（贪睡开小差是有代价哦）  ", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/2015-06-01-linux-may-sleep-function\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/c-codereivew\/": {
        
        "title": "C语言代码 review的总结",
        "tags": ["编程",],
        "content": "代码review是保证代码质量在项目开发及代码修改中一项重要的环节，下面就代码reiew的一些总结，总结一些代码的review的关注点，提高代码review的效率与效果，提前发现问题，降低后期的测试成本，以及避免软件上线或交付出问题导致的经济损失和恶劣影响（ps:对每一行代码保持敬畏之心）。\n代码中的资源  以内存为例，C语言内存操作都是由程序员来定义与控制，内存的一些错误总是不断地出现，例如内存泄漏，踩内存，写越界等，如果这种问题在线上系统中出现，定位与修复的成本都是很高的。\n    动态内存 信号量 文件描述符 锁 句柄 中断 资源的引用 资源的引用计数  代码的错误高发特征    冗余实现 异常处理 结构复杂 层次嵌套多 不合理实现 字符串处理 代码临界区 移植代码  代码的追求    正确性 可靠性 可读性 可维护性 可测试性 可扩展性 可移植性 可伸缩性 易用性 可用性 可重用性 互操作性 可管理性 一致性 安全性 性能 稳定性 精确性 可差异化性 魯棒性  ", 
        "url": "http:\/\/myself659.github.io\/post\/c-codereivew\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-thought\/": {
        
        "title": "Linux性能优化杂谈",
        "tags": ["Linux",],
        "content": "性能不仅仅是一串串数字，性能体现更大的吞吐量及更低的延迟；如果网络延迟增加0.1秒，google每秒损失100W,不是人民币是美元；网页响应慢0.1秒，运营成本每天增加100万美金。亚马逊的数据也显示，网页延迟1秒可能导致全年损失16亿美金；移动页面加载时间时长超过5秒，74%的用户会选择离开，高性能主要体现下面三个方面：\n 少资源 高吞吐 低延迟  在具体网络转发性能优化过程中对性能优化有以下几点体会与总结：\n软硬结合 软件灵活，硬件高效，软硬结合就像双剑合壁，威力巨大；具体在网络设备中交换机就是一个很好的例子：通常由CPU完成协议的处理，下发转发表项到芯片，由芯片完成报文的转发，在这种思路下才会cisco，H3C，Huawei的大容量的交换机；如果完全交给CPU来处理成本很高，而且在现有技术下很难完成那么大的交换容量（1T以上）。在这种情况对于软件上来说基本不需要优化，本文后面的优化是针对软转的优化；\n分离与分解 控制与转发分离 由控制平面维护转发表项，转发平面根据表项完成转发\n针对性优化 性能优化一定要指定优化场景，例如对于收包优化针对不同的接入方式，不同报文类型；\n快慢结合，先慢后快 对于交换机与路由机这种网络转发设备，通过首包建流，后续报文匹配流实现快慢结合提高报文转发效率；\n缓存 缓存大法好，在现在各种系统与应用中缓存无处不在，硬件上看，有硬盘缓存，RAID卡缓存，存储缓存，主存，NUMA特性，CPU cache；软件架构上看，有全局数据缓存，私有数据缓存，连接池，应用服务器缓存，WEB服务器缓存，CDN缓存，客户端文件缓存，客户端内存缓存等等。\ndo more with less 性能优化大体就是开源与节流，do more with less需要考虑如何提高cpu，存储，网络的利用效率\n预处理 兵马未动粮草先行 例如在报文发送针对不同流准备相应的链路层头，避免发送报文再逐字段填充，作到一次性完成报文贴头处理；其实很多应用系统的线程池，内存池，连接池等也是类似思想\n二八原则 主要体现如下:\n 对于优化的代码，集中精力优化是关键20%的代码 在具体的系统性能优化过程刚开始投入20%可以使取得整个优化成果的80%，而最后的20%需要花费80%的时间来完成，而且涉及的挑战会更多，更有难度，所以优化过程越到后面越难，需要良好的心态与意志  无profile，不优化 If you can\u0026rsquo;t measure it, you can\u0026rsquo;t improve it。若无度量，则无提高。优化一定要有一套profile方法，profile以下几个方面的作用：\n profile建立一个性能基线，有利于优化过程中比较与参考 profile查找系统的瓶颈，在一个大型的系统查找到性能瓶颈是一件很有挑战的事情,通过profile有利于快速定位瓶颈 profile评估优化结果，对每一个优化点有一个数字化清晰的记录 profile指导优化的方向  避免过度优化 在性能优化过程中切忌一味追求性能，忽略了业务，没有关注优化对系统带来的哪些不好影响，例如：\n 优化使系统变得更复杂，不利于维护 优化影响了其他业务 优化忽略了业务功能（功能正确性，功能可扩展性等等） 优化只是特定环境下数据提升并不适用具体应用  减少状态的改变 在报文处理与协议处理过程中设计更精简的状态机，避免过多的状态变化处理的开销。\n避免代码的黑盒 避免代码的黑盒，主要有下面几点：\n1.优化过程忽略部分代码，导致这一部分代码未能出现优化对象中\n2.虽然考虑了所有该关注的代码，但是没有理解代码，特别这一部分代码涉及跨团队，个人经验：这一部分代码需要重点关注，往往有意想不到的收获\n总之，性能优化需要充分理解业务，根据数据，实现硬件，系统，业务三者最佳协同。\n", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-thought\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-droppacket\/": {
        
        "title": "一个linux网络丢包问题分析",
        "tags": ["编程",],
        "content": "丢包问题是十分常见一类问题，下面总结的一个网络丢包问题的分析过程。\n问题描述 组网：\nTC-PORT1\u0026mdash;\u0026mdash;-VSR-eth1\nTC-PORT2\u0026mdash;\u0026mdash;-VSR-eth2\n打流：\n报文从TC-Port1打入VSR-eth1，再从VSR-eth2出，到TC-Port2，打流的时候变换了源ip与源端口\n问题：\n测试同学在根据RFC2544打流测试转发性能中，发现报文有效转发性能总是小于40W pps，总是会出现丢包，而实际cpu利用率才20%左右\n问题分析 丢包的原因很多，需要根据现场进行具体问题分析，下面就一个一个排查怀疑点，没有怀疑点再分析的过程：\n 昨天测试都ok的，检查一下测试打流报文，报文正确 查看报文处理过程中丢包计数，以确认丢包阶段，不幸地发现处理过程中无丢包统计 与打多条流有关？实测打一流问题同样存在，与多条流无关 再次回头检查报文是否有多种code path，导致第2步遗漏检查到丢包点，确认报文走一条code path 上面又被否认，继续分析怀疑点，没有分析出怀疑点，自已动手打流，观察TC收发包统计发现丢包有周斯性，大概周期是30s，这是一个重要信息 又回过头去确认一下丢包统计是否有漏统计，很欣慰又很失望的结果：丢包，错包统计没有遗漏统计 这时候收包处理过程丢包可能性已经排除 从上到下的报文流排查，报文丢在网卡上送cpu过程中？ 内核采用epoll收包存在问题？ 进程如果得到调度就没有问题 top 查看进程调度，这时候有重大发现了： 看tc丢包统计与top的里面的进程natlog运行就同步了，但是看到natlog的线程状态为D状态，同时检查配置，开启nat log功能   natlog进程设置为D状态，导致不响应异步信号，在natlog释放cpu前，在转发线程与natlog运行在同一个cpu的情况下，转发线程得不到调度，导致报文接收缓冲区溢出，导致部分报文丢弃；\n  与natlog线程开发同学交流，natlog早期是基于多核开发，natlog根据运营商需求，每30s定时运行，natlog线程运行在控制核，转发线程运行在数据核，导致问题没有暴露出来\n 问题总结  定位问题，特别是未知的问题是一步步有依据推断与确认的过程 获取现场的全方位消息，同时要对信息进行去噪，避免关键信息遗漏与无关干扰  ", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-droppacket\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-tips-nobranchmiss\/": {
        
        "title": "在没有分支miss条件下，实现取最小值",
        "tags": ["Linux",],
        "content": "在实际性能优化过程，加了一个if判断整个系统转发性能就有大约5%的下降，下面简单分享一种在没有分支miss条件下，实现取最小值的方法。\n一般实现 取两个数最小值，一般代码常见两种写法如下：\n 写法一：  1  if(a \u0026lt; b ) { min = a } else { min = b}   写法二：  1  min = a \u0026lt; b ? a:b;   这两种写法只是代码写法不一致，实际都是通过一个if的语句的比较，存在if语句就代码运行过程就存在分支miss，而一个分支的miss的开销范围40到60 cycles；在追求高性能代码，且没有太多的优化点的过程中这是极其宝贵，且这两个分支出现概率都相当，也就不能简单通过likely与unlikely来实现分支预测\n无分支miss实现 无分支实现代码如下：\n1  min = b ^ ((a ^ b) \u0026amp;-(a\u0026lt;b));   分两种情况分析如下：\n当a\u0026lt;b时,-(a\u0026lt;b)为True，表达式等价于min= b ^(a ^ b) = a;\n当a\u0026gt;=b时，-（a \u0026lt; b）为False，表达式等价于min= b ^ 0 = b\n故可以宏定义如下：\n1  #define min(a,b) = (b) ^ ( ((a) ^ (b)) \u0026amp; (-((a)\u0026lt;(b))) )   ", 
        "url": "http:\/\/myself659.github.io\/post\/linux\/2015-05-24-linux-perf-tips-nobranchmiss\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/2017-05-09-web-server-perf-and-design\/": {
        
        "title": "",
        "tags": [],
        "content": "+++ banner = \u0026quot;\u0026quot; categories = [\u0026ldquo;Arch\u0026rdquo;] date = \u0026ldquo;2017-05-09T11:58:06+02:00\u0026rdquo; description = \u0026quot;\u0026quot; images = [] menu = \u0026quot;\u0026quot; tags = [\u0026ldquo;Arch\u0026rdquo;] title = \u0026ldquo;高性能服务器设计与优化\u0026rdquo; draft = false +++\n为了构建自己的知识体系，对高性能服务器设计与优化一点想法，其中不足与错误，欢迎指正。\n高性能服务器设计与优化\n", 
        "url": "http:\/\/myself659.github.io\/post\/2017-05-09-web-server-perf-and-design\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/ai\/gpt-code-errors\/": {
        
        "title": "",
        "tags": [],
        "content": "", 
        "url": "http:\/\/myself659.github.io\/post\/ai\/gpt-code-errors\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/internet\/2017-02-04-country-internet-music\/": {
        
        "title": "",
        "tags": [],
        "content": "+++ banner = \u0026quot;\u0026quot; categories = [\u0026ldquo;闲谈乱扯\u0026rdquo;] date = \u0026ldquo;2017-02-04T11:58:06+02:00\u0026rdquo; description = \u0026quot;\u0026quot; images = [] menu = \u0026quot;\u0026quot; tags = [\u0026ldquo;闲谈乱扯\u0026rdquo;] title = \u0026ldquo;互联网在农村-音乐\u0026rdquo; draft = false +++\n手机上网就是通过app获取服务，在农村里人们上网喜欢干些什么呢？先从喜欢听什么歌开始？ 在家里时间有限，这次就写这么多，待以后回家再观察其他方面。这里仅仅是开一个小引子：农村互联网用户喜欢什么样内容？\n通过小样本获取不负责农村流行歌单如下：\n 小苹果 青藏高原 送情郎 江南 十三不亲 辣妹子 刘三姐 路边的野花不要采 美酒加咖啡 南泥湾 伤不起 妈妈的吻 茉莉花 火苗 月亮之上  再次申明，样本数量有限，不要太当真，随手记记而已\n从上面的歌单可以看出神曲，流行歌曲在哪里都流行，另外就是90年代左右的经典歌曲。\n（End）\n", 
        "url": "http:\/\/myself659.github.io\/post\/internet\/2017-02-04-country-internet-music\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/invest\/invest-l0\/": {
        
        "title": "",
        "tags": [],
        "content": "banner = \u0026quot;\u0026quot; categories = [\u0026ldquo;Invest\u0026rdquo;] date = \u0026ldquo;2021-01-08T11:58:06+02:00\u0026rdquo; description = \u0026quot;\u0026quot; images = [] menu = \u0026quot;\u0026quot; tags = [\u0026ldquo;Invest\u0026rdquo;] title = \u0026quot;\u0026quot; draft = true +++\n交易 https://bridge.harmony.one/erc20/operations/06cb73c6-cb6a3860-78e416ed-b41f39e2\nhttps://explorer.harmony.one/tx/0x23d7957bbb268c3e92a0711fe0ec8959cdac5b9b515ee779ecd1b06ea21f673c\nhttps://layerzeroscan.com/116/address/0xf4d83e35874bee7cb363d37d45ca2adf8c6c26d7/message/102/address/0x1edb8bded80e1b87ed19ee7d97ee80b4fdb615c1/nonce/6\n使用layerzero获利空投。\n两次使用。\n桥是连接的机会。\n跨链6000个one到bsc上面，将来可以当作bsc链上的手续费\nhttps://bridge.harmony.one/one/operations/3733aa6d-5e7d808e-e26819bf-fd25952b\nhttps://explorer.harmony.one/tx/0xc76821b7c62a36568a4d784b62414e201c6a2586400faac8a4575e76ad15cbb9\nhttps://bscscan.com/tx/0xae2deccb48e438125c7bccf434d2f2a96d47bd33c6bee47889182f96a230a332\n希望有空投的机会的。\n原理 Circumventing Layer Zero: Why Isolated Security is No Security\n", 
        "url": "http:\/\/myself659.github.io\/post\/invest\/invest-l0\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/k8s-githubaction\/": {
        
        "title": "",
        "tags": [],
        "content": "banner = \u0026quot;\u0026quot; categories = [\u0026ldquo;Kubernetes\u0026rdquo;] date = \u0026ldquo;2020-10-17T11:58:06+02:00\u0026rdquo; description = \u0026quot;\u0026quot; images = [] menu = \u0026quot;\u0026quot; tags = [\u0026ldquo;Docker\u0026rdquo;, \u0026ldquo;Kubernetes\u0026rdquo;] title = \u0026ldquo;利用github action部署到k8s集群\u0026rdquo; draft = true +++\n目标 个人开发项目软件工程实践。\n概念 先从静态开始\n列表  Cluster pods labels Replication Controllers services Nodes  vs gitlab https://docs.github.com/en/enterprise-server@2.22/actions/learn-github-actions/migrating-from-gitlab-cicd-to-github-actions\n参考  file:///E:/Docker/Using%20GitHub%20Actions%20to%20deploy%20to%20Kubernetes%20-%20Project%20A%20Insights.mht Using GitHub Actions to deploy to Kubernetes https://dotblogs.com.tw/explooosion/2020/10/09/143330 https://gianarb.it/blog/kubernetes-github-action  ", 
        "url": "http:\/\/myself659.github.io\/post\/k8s-githubaction\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/substrate-runtime\/": {
        
        "title": "",
        "tags": [],
        "content": "banner = \u0026quot;\u0026quot; categories = [\u0026ldquo;Substrate\u0026rdquo;] date = \u0026ldquo;2019-09-19T11:58:06+02:00\u0026rdquo; description = \u0026quot;\u0026quot; images = [] menu = \u0026quot;\u0026quot; tags = [\u0026ldquo;Substrate\u0026rdquo;, \u0026ldquo;BlockChain\u0026rdquo;] title = \u0026ldquo;Substrate Runtime实践\u0026rdquo; draft = true +++\ninstall substrate 安装substrate有以下两种方式：\n 快速安装 完全安装  快速安装 1  curl https://getsubstrate.io -sSf | bash -s -- --fast   完全安装 1  curl https://getsubstrate.io -sSf | bash   更新环境变量 1  source ~/.cargo/env   检查版本 1 2 3 4  root@IA:~/rust/install-substrate# substrate --version substrate 2.0.0-37bc8c545-x86_64-linux-gnu root@IA:~/rust/install-substrate# subkey --version subkey 2.0.0   同时安装的还有以下文件：\n substrate-module-new substrate-node-new substrate-ui-new  更新substrate 1 2 3 4  f=`mktemp -d` git clone https://github.com/paritytech/substrate-up $f cp -a $f/substrate-* ~/.cargo/bin cp -a $f/polkadot-* ~/.cargo/bin   substrate \u0026ndash;help 这一步虽然简单，但是很有必要，了解常用的substrate命令。方便以后出现问题快速解决或者找到线索。\n这相当于官方文档。必须要做的一步。短时间的投入，有益的作用。\nRuntime SRML SRML全称Substrate Runtime Module Library。\n实践 准备作一个基于substrate的hello world的实例。\n创建节点 1  root@IA:~/rust/runtime-demo# substrate-node-new hello-node chenfeng   这个过程可以持续10分钟左右。\n启动节点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  root@IA:~/rust/runtime-demo/hello-node# ./target/release/hello-node --dev 2019-09-20 16:04:28 Substrate Node 2019-09-20 16:04:28 version 1.0.0-7f6843a-x86_64-linux-gnu 2019-09-20 16:04:28 by chenfeng, 2017, 2018 2019-09-20 16:04:28 Chain specification: Development 2019-09-20 16:04:28 Node name: exotic-drain-0405 2019-09-20 16:04:28 Roles: AUTHORITY 2019-09-20 16:04:28 Initializing Genesis block/state (state: 0xc727…2701, header-hash: 0x4e61…bccd) 2019-09-20 16:04:28 Loaded block-time = 10 seconds from genesis on first-launch 2019-09-20 16:04:28 Best block: #0 2019-09-20 16:04:28 Using default protocol ID \u0026#34;sup\u0026#34; because none is configured in the chain specs 2019-09-20 16:04:28 Local node identity is: QmXzUZcAxzmAWL8htpX6upw1W9tvecUXLx5h8dP18j3ouL 2019-09-20 16:04:28 Libp2p =\u0026gt; Random Kademlia query has yielded empty results 2019-09-20 16:04:28 Listening for new connections on 127.0.0.1:9944. 2019-09-20 16:04:28 Using authority key 5FA9nQDVg267DEd8m1ZypXLBnvN7SFxYwV7ndqSYGiN9TTpu 2019-09-20 16:04:30 Starting consensus session on top of parent 0x4e61ac8af8f7b3e822d04c678e85c954eb1ec09256253a61c59a3e38d719bccd 2019-09-20 16:04:30 Prepared block for proposing at 1 [hash: 0x0004fc217c56f2970fd3e9d4b80b8263d258424edd13454d34cabda98ff8c110; parent_hash: 0x4e61…bccd; extrinsics: [0x44d0…6310]] 2019-09-20 16:04:30 Pre-sealed block for proposal at 1. Hash now 0x17574e947b8024789cc1af6048fdc69e00ec92fbec46a57c8844989e909fb058, previously 0x0004fc217c56f2970fd3e9d4b80b8263d258424edd13454d34cabda98ff8c110. 2019-09-20 16:04:30 Imported #1 (0x1757…b058) 2019-09-20 16:04:30 Accepted a new tcp connection from 127.0.0.1:20003. 2019-09-20 16:04:31 Libp2p =\u0026gt; Random Kademlia query has yielded empty results 2019-09-20 16:04:33 Idle (0 peers), best: #1 (0x1757…b058), finalized #0 (0x4e61…bccd), ⬇ 0 ⬆ 0 2019-09-20 16:04:35 Libp2p =\u0026gt; Random Kademlia query has yielded empty results 2019-09-20 16:04:38 Idle (0 peers), best: #1 (0x1757…b058), finalized #0 (0x4e61…bccd), ⬇ 0 ⬆ 0 2019-09-20 16:04:40 Starting consensus session on top of parent 0x17574e947b8024789cc1af6048fdc69e00ec92fbec46a57c8844989e909fb058 2019-09-20 16:04:40 Prepared block for proposing at 2 [hash: 0x773e99df58009dd0331262b6468131c3d4ce9de609db8a79ef0e5e1f673de5ae; parent_hash: 0x1757…b058; extrinsics: [0x0bf0…c888]] 2019-09-20 16:04:40 Pre-sealed block for proposal at 2. Hash now 0x6e5b0fb72f9476d03b7b510f21935a8238eaa3f85d8ff7355a66a466b8637204, previously 0x773e99df58009dd0331262b6468131c3d4ce9de609db8a79ef0e5e1f673de5ae. 2019-09-20 16:04:40 Imported #2 (0x6e5b…7204)   连接远端节点 前面的文章提到，在中国现在的网络环境下，选择远端节点开发是一个十分明智的选择。 根据前面的文章，连接远端节点即可以。\n这个我们省得自己搭节点，直接用官方的UI: polkadot.js.org/apps。\n具体步骤如下：\n 进入 https://polkadot.js.org/apps/#/setting 页面 打开custom endpoint选项，设置对应wss网址即可  添加模块 进入runtime目录 1  root@IA:~/rust/runtime-demo/hello-node/runtime/src#   新建mod 1 2 3 4 5 6 7 8 9  root@IA:~/rust/runtime-demo/hello-node/runtime/src# substrate-module-new hello Substrate Module Setup Creating module in .... Customising module... SRML module created as ./hello.rs and added to git. Ensure that you include in your ./lib.rs the line: mod hello;   修改lib.rs 引入hello mod 1  mod hello;   为hello实现Runtime trait 1 2 3  impl hello::Trait for Runtime { type Event = Event; }   添加mod到construct_runtime!宏 1 2 3 4 5 6 7 8 9 10 11 12  construct_runtime!( pub enum Runtime with Log(InternalLog: DigestItem\u0026lt;Hash, AuthorityId, AuthoritySignature\u0026gt;) where Block = Block, NodeBlock = opaque::Block, UncheckedExtrinsic = UncheckedExtrinsic { // add hello mod //Hello: hello::{Module, Call, Storage}, Hello: hello::{Module, Call, Storage, Event\u0026lt;T\u0026gt;}, } );   重新编译与启动 1 2 3 4 5 6 7 8 9 10 11 12  # 编译runtime的wasm版本 ./scripts/build.sh # 编译runtime的本地二进制版本，并构建可执行的客户端 cargo build --release # 删除链上的历史数据 ./target/release/hello-node purge-chain --dev # 启动本地测试网络 ./target/release/hello-node --dev   自定义业务 自动生成mod代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128  ///Aruntimemoduletemplatewithnecessaryimports///Feelfreetoremoveoreditthisfileasneeded.///Ifyouchangethenameofthisfile,makesuretoupdateitsreferencesinruntime/src/lib.rs///Ifyouremovethisfile,youcanremovethosereferences///FormoreguidanceonSubstratemodules,seetheexamplemodule///https://github.com/paritytech/substrate/blob/master/srml/example/src/lib.rsusesupport::{decl_event,decl_module,decl_storage,dispatch::Result,StorageValue};usesystem::ensure_signed;///Themodule\u0026#39;s configuration trait. pub trait Trait: system::Trait { // TODO: Add other types and constants required configure this module. /// The overarching event type. type Event: From\u0026lt;Event\u0026lt;Self\u0026gt;\u0026gt; + Into\u0026lt;\u0026lt;Self as system::Trait\u0026gt;::Event\u0026gt;; } /// This module\u0026#39;sstorageitems.decl_storage!{traitStoreforModule\u0026lt;T:Trait\u0026gt;ashello{//Justadummystorageitem.//HerewearedeclaringaStorageValue,`Something`asaOption\u0026lt;u32\u0026gt;//`get(something)`isthedefaultgetterwhichreturnseitherthestored`u32`or`None`ifnothingstoredSomethingget(something):Option\u0026lt;u32\u0026gt;;}}decl_module!{///Themoduledeclaration.pubstructModule\u0026lt;T:Trait\u0026gt;forenumCallwhereorigin:T::Origin{//Initializingevents//thisisneededonlyifyouareusingeventsinyourmodulefndeposit_event\u0026lt;T\u0026gt;()=default;//Justadummyentrypoint.//functionthatcanbecalledbytheexternalworldasanextrinsicscall//takesaparameterofthetype`AccountId`,storesitandemitsaneventpubfndo_something(origin,something:u32)-\u0026gt;Result{//TODO:Youonlyneedthisifyouwanttocheckitwassigned.letwho=ensure_signed(origin)?;//TODO:Codetoexecutewhensomethingcallsthis.//Forexample:thefollowinglinestoresthepassedinu32inthestorage\u0026lt;Something\u0026lt;T\u0026gt;\u0026gt;::put(something);//hereweareraisingtheSomethingeventSelf::deposit_event(RawEvent::SomethingStored(something,who));Ok(())}}}decl_event!(pubenumEvent\u0026lt;T\u0026gt;whereAccountId=\u0026lt;Tassystem::Trait\u0026gt;::AccountId,{//Justadummyevent.//Event`Something`isdeclaredwithaparameterofthetype`u32`and`AccountId`//Toemitthisevent,wecallthedepositfuntion,fromourruntimefuntionsSomethingStored(u32,AccountId),});///testsforthismodule#[cfg(test)] modtests{usesuper::*;useprimitives::{Blake2Hasher,H256};useruntime_io::with_externalities;useruntime_primitives::{testing::{Digest,DigestItem,Header},traits::{BlakeTwo256,IdentityLookup},BuildStorage,};usesupport::{assert_ok,impl_outer_origin};impl_outer_origin!{pubenumOriginforTest{}}//Fortestingthemodule,weconstructmostofamockruntime.Thismeans//firstconstructingaconfigurationtype(`Test`)which`impl`seachofthe//configurationtraitsofmoduleswewanttouse.#[derive(Clone, Eq, PartialEq)] pubstructTest;implsystem::TraitforTest{typeOrigin=Origin;typeIndex=u64;typeBlockNumber=u64;typeHash=H256;typeHashing=BlakeTwo256;typeDigest=Digest;typeAccountId=u64;typeLookup=IdentityLookup\u0026lt;Self::AccountId\u0026gt;;typeHeader=Header;typeEvent=();typeLog=DigestItem;}implTraitforTest{typeEvent=();}typehello=Module\u0026lt;Test\u0026gt;;//Thisfunctionbasicallyjustbuildsagenesisstoragekey/valuestoreaccordingto//ourdesiredmockup.fnnew_test_ext()-\u0026gt;runtime_io::TestExternalities\u0026lt;Blake2Hasher\u0026gt;{system::GenesisConfig::\u0026lt;Test\u0026gt;::default().build_storage().unwrap().0.into()}#[test] fnit_works_for_default_value(){with_externalities(\u0026amp;mutnew_test_ext(),||{//Justadummytestforthedummyfuntion`do_something`//callingthe`do_something`functionwithavalue42assert_ok!(hello::do_something(Origin::signed(1),42));//assertingthatthestoredvalueisequaltowhatwestoredassert_eq!(hello::something(),Some(42));});}}  修改代码如下 1    参考  Getting Started on Substrate Substrate Collectables Using the Substrate Scripts Codec types  欢迎关注 欢迎关注微信公众帐号：沉风网事(savewind)\n", 
        "url": "http:\/\/myself659.github.io\/post\/substrate-runtime\/"
    },
    
    
    
    "http:\/\/myself659.github.io\/post\/rt\/stupid-foolish-is-enemy\/": {
        
        "title": "愚蠢：危险的敌人",
        "tags": ["Thinking",],
        "content": "背景 今天是愚人节。愚人是今天大部分人的例行活动。这里不列举各种愚人的活动，只谈一下这些愚人活动的意义。 在我看来，这些愚人活动有以下作用：\n 大部分愚人活动提供了一些幽默 提供教育价值，让大部分了解一些骗人的方法与形式 测试一下哪些人容易被骗  愚蠢的人与社会 愚蠢的人 对于愚蠢的人caoz总结下面的六大定律：\n第一定律，从来没觉得自己傻逼过的，往往是不可救药的大傻逼\n第二定律，觉得别人都是傻逼的，往往自己才是最傻逼的一个\n第三定律，收割傻逼的会被傻逼们封神，试图唤醒傻逼的是傻逼眼中的傻逼\n第四定律，热衷于证明傻逼是傻逼的，自己也是傻逼\n第五定律，永远不要认为事实会教育傻逼，因为他们对事实的解读方式和你不一样\n第六定律，过度强调团体荣誉的往往也是极度自卑的体现，要用团体的强大幻象掩盖自己的虚弱本质\n愚蠢的社会  低估社会上愚蠢的数量 每个人都会愚蠢的时候 损人不利已是愚蠢的共性 重复别人的愚蠢 大部分会低估愚蠢的破坏力 蠢货，是最危险的一类人  愚蠢来源  自己 他人 环境与系统  应对愚蠢 自己  保持敬畏之心 保持怀疑，大胆猜想，小心求证 不断学习，不断反思 提高自己的圈子水平或者加入高一档水平的圈子 敢于接受错误与事实  他人  不要试图改变他人 远离这些愚蠢的人 对这些愚蠢的人的行为建立防火墙 发现自己与愚蠢的人有一些合作，要学会主动止损  环境与系统  危邦不入,乱邦不居,天下有道则入,无道则隐 如果一个系统出了问题，不要心存侥幸，逃离系统是最好的选择 如果制度出了问题，不要对未来抱有侥幸，时间会给出最坏的结果  ", 
        "url": "http:\/\/myself659.github.io\/post\/rt\/stupid-foolish-is-enemy\/"
    },
    
}
</script>

<script src="/js/lunr.min.js"></script>
<script src="/js/search.js"></script> 
  
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.2517c0eb67172a0bae917de4af59b10ca2531411a009d4c0b82f5685259e5771.js"></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-144475213-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>







</body>
</html>
