---
layout: post
title: 爬虫Tip系列：利用PPPoE突破单个IP的限制 
categories: Python
tags: Python  Scrapy
---

最近从一个网站上爬取大量数据，调试好基本代码准备大干一场，爬虫运行一个小时左右就失败: 被网站检查出来单个IP访问此数过多，被限制访问。 

为了继续进行爬取数据，那就找代理IP，这样就能解决单个IP限制问题，就写一个通过scary从西刺网站获取免费代理的代码，具体代码参考[spider_xici](https://github.com/myself659/X-Scrapy/tree/master/spider_xici) 

通过上面获取到代理ip，就可以在代码中应用了，应用了代理IP是解决只有单个IP的问题，但是也带来问题，爬取数据从原来10K每小时下降到了1K左右。问题又来了：如何提高速度呢？

方案一： 花钱买优质代理IP（用钱能解决的问题都不是问题）,但是我不想花钱啊，还得在网上找卖代理IP的

方案二： 研究用户登录，实现用户登录再爬取数据，这个需要花时间，虽然登录可以参考知乎与新浪微博的实现，而且还存在这个问题：不能确定登录再爬取数据是否还有单个IP次数限制  

上面这个两个方案都是不是很如意，那怎么办呢？代理IP不是就换IP吗？那能不能定时换公网IP吗？

这个时候，灵光一现：自己不是研发PPPoE Server吗？通过定时下线再上线就可以重新获取新的IP地址

那如何实现定时下线再上线呢？浏览器自动化啊，有两个方案了：

方案一： splinter
方案二： selenium 

最终采用selenium来完成这个浏览器自动化操作(selenium完胜splinter)，主要就是登录路由器，点击重启路由器就可以，重启过程中路由器通过PPPoE重新申请IP 

这时候很多人肯定有下面这个疑问：再次申请ip会不会申请到原来的ip地址？
作为一个曾经开发过pppoe server通信民工，这个基本不会的；原因如下：
1. pppoe重启，原来client（就是重启的路由器）申请到IP如果没有发送下线请求，那么PPPoE Server认为IP认为还在使用 
2. 原来client（就是重启的路由器）发送到下线请求，那PPPoE Server一般将这个IP放到空闲地址池队列的尾部，也不会被立即申请到(运营商的IP地址池数量还是很大的)

最终采用方案三如下：
方案三：定时（例如1个小时）或者访问受限时通过selenium实现路由器重启达到更换IP继续爬取数据（类似于GOLANG中GC功能） 

优点：
1. 不花钱，省成本  
2. 不用担心IP质量，爬取速度快  

这个方案不足：
1. 路由器重启可能会一段时间影响上网，差不多就1到2分钟
2. 场景限制：只适用于通过pppoe拨号上网的环境


### 后记

想不到从11年开始弄的pppoe到现在还有派上用场了

（end）




















